<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In a broad range of natural language processing tasks, large-scale knowledge-base of paraphrases is anticipated to improve their performance.</S>
		<S sid ="2" ssid = "2">The key issue in creating such a resource is to establish a practical method of computing semantic equivalence and syntactic substitutability, i.e., paraphrasability, between given pair of expressions.</S>
		<S sid ="3" ssid = "3">This paper addresses the issues of computing paraphrasability, focusing on syntactic variants of predicate phrases.</S>
		<S sid ="4" ssid = "4">Our model estimates paraphrasability based on traditional distributional similarity measures, where the Web snippets are used to overcome the data sparseness problem in handling predicate phrases.</S>
		<S sid ="5" ssid = "5">Several feature sets are evaluated through empirical experiments.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">One of the common characteristics of human languages is that the same concept can be expressed by various linguistic expressions.</S>
			<S sid ="7" ssid = "7">Such linguistic variations are called paraphrases.</S>
			<S sid ="8" ssid = "8">Handling paraphrases is one of the key issues in a broad range of natural language processing (NLP) tasks.</S>
			<S sid ="9" ssid = "9">In information retrieval, information extraction, and question answering, technology of recognizing if or not the given pair of expressions are paraphrases is desired to gain a higher coverage.</S>
			<S sid ="10" ssid = "10">On the other hand, a system which generates paraphrases for given expressions is useful for text-transcoding tasks, such as machine translation and summarization, as well as beneficial to human, for instance, in text-to-speech, text simplification, and writing assistance.</S>
			<S sid ="11" ssid = "11">Paraphrase phenomena can roughly be divided into two groups according to their compositionality.</S>
			<S sid ="12" ssid = "12">Examples in (1) exhibit a degree of compositionality, while each example in (2) is composed of totally different lexical items.</S>
			<S sid ="13" ssid = "13">(1) a. be in our favor ⇔ be favorable for us b. show a sharp decrease ⇔ decrease sharply (Fujita et al., 2007) (2) a. burst into tears ⇔ cried b. comfort ⇔ console (Barzilay and McKeown, 2001) A number of studies have been carried out on both compositional (morpho-syntactic) and non compositional (lexical and idiomatic) paraphrases (see Section 2).</S>
			<S sid ="14" ssid = "14">In most research, paraphrases have been represented with the similar templates, such as shown in (3) and (4).</S>
			<S sid ="15" ssid = "15">(3) a. N1 V N2 ⇔ N1 ’s V -ing of N2 b. N1 V N2 ⇔ N2 be V -en by N1 (Harris, 1957) (4) a. X wrote Y ⇔ X is the author of Y b. X solves Y ⇔ X deals with Y (Lin and Pantel, 2001) The weakness of these templates is that they should be applied only in some contexts.</S>
			<S sid ="16" ssid = "16">In other words, the lack of applicability conditions for slot fillers may lead incorrect paraphrases.</S>
			<S sid ="17" ssid = "17">One way to specify the applicability condition is to enumerate correct slot fillers.</S>
			<S sid ="18" ssid = "18">For example, Pantel et al.</S>
			<S sid ="19" ssid = "19">(2007) have harvested instances for the given paraphrase templates based on the co-occurrence statistics of slot fillers and lexicalized part of templates (e.g. “deal with” in (4b)).</S>
			<S sid ="20" ssid = "20">Yet, there is no method which assesses semantic equivalence and syntactic substitutability of resultant pairs of expressions.</S>
			<S sid ="21" ssid = "21">In this paper, we propose a method of directly computing semantic equivalence and syntactic sub- stitutability, i.e., paraphrasability, particularly focusing on automatically generated compositional paraphrases (henceforth, syntactic variants) of predicate phrases.</S>
			<S sid ="22" ssid = "22">While previous studies have mainly targeted at words or canned phrases, we treat predicate phrases having a bit more complex structures.</S>
			<S sid ="23" ssid = "23">This paper addresses two issues in handling phrases.</S>
			<S sid ="24" ssid = "24">The first is feature engineering.</S>
			<S sid ="25" ssid = "25">Generally speaking, phrases appear less frequently than single words.</S>
			<S sid ="26" ssid = "26">This implies that we can obtain only a small amount of information about phrases.</S>
			<S sid ="27" ssid = "27">To overcome the data sparseness problem, we investigate if the Web snippet can be used as a dense corpus for given phrases.</S>
			<S sid ="28" ssid = "28">The second is the measurement of paraphrasability.</S>
			<S sid ="29" ssid = "29">We assess how well the traditional distributional similarity measures approximate the paraphrasability of predicate phrases.</S>
	</SECTION>
	<SECTION title="Related work. " number = "2">
			<S sid ="30" ssid = "1">2.1 Representation of paraphrases.</S>
			<S sid ="31" ssid = "2">Several types of compositional paraphrases, such as passivization and nominalization, have been represented with some grammar formalisms, such as transformational generative grammar (Harris, 1957) and synchronous tree adjoining grammar (Dras, 1999).</S>
			<S sid ="32" ssid = "3">These grammars, however, lack the information of applicability conditions.</S>
			<S sid ="33" ssid = "4">Word association within phrases has been an attractive topic.</S>
			<S sid ="34" ssid = "5">Meaning-Text Theory (MTT) is a framework which takes into account several types of lexical dependencies in handling paraphrases (Mel’cˇuk and Polgue`re, 1987).</S>
			<S sid ="35" ssid = "6">A bottleneck of MTT is that a huge amount of lexical knowledge is required to represent various relationships between lexical items.</S>
			<S sid ="36" ssid = "7">Jacquemin (1999) has represented the syntagmatic and paradigmatic correspondences between paraphrases with context-free transformation rules and morphological and/or semantic relations between lexical items, targeting at syntactic variants of technical terms that are typically noun phrases consisting of more than one word.</S>
			<S sid ="37" ssid = "8">We have proposed a framework of generating syntactic variants of predicate phrases (Fujita et al., 2007).</S>
			<S sid ="38" ssid = "9">Following the previous work, we have been developing three sorts of resources for Japanese.</S>
			<S sid ="39" ssid = "10">2.2 Acquiring paraphrase rules.</S>
			<S sid ="40" ssid = "11">Since the late 1990’s, the task of automatic acquisition of paraphrase rules has drawn the attention of an increasing number of researchers.</S>
			<S sid ="41" ssid = "12">Although most of the proposed methods do not explicitly eliminate compositional paraphrases, their output tends to be non-compositional paraphrase.</S>
			<S sid ="42" ssid = "13">Previous approaches to this task are twofold.</S>
			<S sid ="43" ssid = "14">The first group espouses the distributional hypothesis (Harris, 1968).</S>
			<S sid ="44" ssid = "15">Among a number of models based on this hypothesis, two algorithms are referred to as the state-of-the-art.</S>
			<S sid ="45" ssid = "16">DIRT (Lin and Pantel, 2001) collects paraphrase rules consisting of a pair of paths between two nominal slots based on point-wise mutual information.</S>
			<S sid ="46" ssid = "17">TEASE (Szpektor et al., 2004) discovers binary relation templates from the Web based on sets of representative entities for given binary relation templates.</S>
			<S sid ="47" ssid = "18">These systems often output directional rules such as exemplified in (5).</S>
			<S sid ="48" ssid = "19">(5) a. X is charged by Y ⇒ Y announced the arrest of X b. X prevent Y ⇒ X lower the risk of Y They are actually called inference/entailment rules, and paraphrase is defined as bidirectional inference/entailment relation1 . While the similarity score in DIRT is symmetric for given pair of paths, the algorithm of TEASE considers the direction.</S>
			<S sid ="49" ssid = "20">The other utilizes a sort of parallel texts, such as multiple translation of the same text (Barzilay and McKeown, 2001; Pang et al., 2003), corresponding articles from multiple news sources (Barzilay and Lee, 2003; Dolan et al., 2004), and bilingual corpus (Wu and Zhou, 2003; Bannard and CallisonBurch,2005).</S>
			<S sid ="50" ssid = "21">This approach is, however, limited by the dif ficulty of obtaining parallel/comparable corpora.</S>
			<S sid ="51" ssid = "22">2.3 Acquiring paraphrase instances.</S>
			<S sid ="52" ssid = "23">As reviewed in Section 1, paraphrase rules generate incorrect paraphrases, because their applicability conditions are not specified.</S>
			<S sid ="53" ssid = "24">To avoid the drawback, several linguistic clues, such as fine-grained classification of named entities and coordinated sentences, have been utilized (Sekine, 2005; Torisawa, 2006).</S>
			<S sid ="54" ssid = "25">Although these clues restrict phenomena to those appearing in particular domain or those describing coordinated events, they have enabled us to collect 1 See http://nlp.cs.nyu.edu/WTEP/.</S>
			<S sid ="55" ssid = "26">paraphrases accurately.</S>
			<S sid ="56" ssid = "27">The notion of Inferential Selectional Preference (ISP) has been introduced by Pantel et al.</S>
			<S sid ="57" ssid = "28">(2007).</S>
			<S sid ="58" ssid = "29">ISP can capture more general phenomena than above two; however, it lacks abilities to distinguish antonym relations.</S>
			<S sid ="59" ssid = "30">2.4 Computing semantic equivalence.</S>
			<S sid ="60" ssid = "31">Semantic equivalence between given pair of expressions has so far been estimated under the distributional hypothesis (Harris, 1968).</S>
			<S sid ="61" ssid = "32">Geffet and Dagan (2005) have extended it to the distributional inclusion hypothesis for recognizing the direction of lexical entailment.</S>
			<S sid ="62" ssid = "33">Weeds et al.</S>
			<S sid ="63" ssid = "34">(2005), on the other hand, have pointed out the limitations of lexical similarity and syntactic transformation, and have proposed to directly compute the distributional similarity of pair of sub-parses based on the distributions of their modifiers and parents.</S>
			<S sid ="64" ssid = "35">We think it is worth examining if the Web can be used as the source for extracting features of phrases.</S>
	</SECTION>
	<SECTION title="Computing  paraphrasability between. " number = "3">
			<S sid ="65" ssid = "1">predicate phrases using Web snippets We define the concept of paraphrasability as follows: A grammatical phrase s is paraphrasablewith another phrase t, iff t satisfies the fol lowing three: • t is grammatical • t holds if s holds • t is substitutable for s in some context Most previous studies on acquiring paraphrase rules have evaluated resultant pairs from only the second viewpoint, i.e., semantic equivalence.</S>
			<S sid ="66" ssid = "2">Additionally, we assume that one of a pair (t) of syntactic variants is automatically generated from the other (s).</S>
			<S sid ="67" ssid = "3">Thus, grammaticality of t should also be assessed.</S>
			<S sid ="68" ssid = "4">We also take into account the syntactic substitutability, because headwords of syntactic variants sometimes have different syntactic categories.</S>
			<S sid ="69" ssid = "5">Given a pair of predicate phrases, we compute their paraphrasability in the following procedure: Step 1.</S>
			<S sid ="70" ssid = "6">Retrieve Web snippets for each phrase.</S>
			<S sid ="71" ssid = "7">Step 2.</S>
			<S sid ="72" ssid = "8">Extract features for each phrase.</S>
			<S sid ="73" ssid = "9">Step 3.</S>
			<S sid ="74" ssid = "10">Compute their paraphrasability as distributional similarity between their features.</S>
			<S sid ="75" ssid = "11">The rest of this section elaborates on each step in turn, taking Japanese as the target language.</S>
			<S sid ="76" ssid = "12">3.1 Retrieving Web snippets.</S>
			<S sid ="77" ssid = "13">In general, phrases appear less frequently than single words.</S>
			<S sid ="78" ssid = "14">This raises a crucial problem in computing paraphrasability of phrases, i.e., the sparseness of features for given phrases.</S>
			<S sid ="79" ssid = "15">One possible way to overcome the problem is to take back-off statistics assuming the independence between constituent words (Torisawa, 2006; Pantel et al., 2007).</S>
			<S sid ="80" ssid = "16">This approach, however, has a risk of involving noises due to ambiguity of words.</S>
			<S sid ="81" ssid = "17">We take another approach, which utilizes the Web as a source of examples instead of a limited size of corpus.</S>
			<S sid ="82" ssid = "18">For each of the source and target phrases, we retrieve snippets via the Yahoo API2.</S>
			<S sid ="83" ssid = "19">The number of snippets is set to 500.</S>
			<S sid ="84" ssid = "20">3.2 Extracting features.</S>
			<S sid ="85" ssid = "21">The second step extracts the features for each phrase from Web snippets.</S>
			<S sid ="86" ssid = "22">We have some options for feature set, feature weighting, and snippet collection.</S>
			<S sid ="87" ssid = "23">Feature sets To assess a given pair of phrases against the definition of paraphrasability, the following three sets of features are examined.</S>
			<S sid ="88" ssid = "24">HITS: A phrase must appear in the Web if it is grammatical.</S>
			<S sid ="89" ssid = "25">The more frequently a phrase appears, the more likely it is grammatical.</S>
			<S sid ="90" ssid = "26">BOW: A pair of phrases are likely to be semantically similar, if the distributions of words surrounding the phrases are similar.</S>
			<S sid ="91" ssid = "27">MOD: A pair of phrases are likely to be substitutable with each other, if they share a number of instances of modifiers and modifiees.</S>
			<S sid ="92" ssid = "28">To extract BOW features from sentences including the given phrase within Web snippets, a morphological analyzer MeCab3 was firstly used; however, it resulted wrong POS tags for unknown words, and hurt statistics.</S>
			<S sid ="93" ssid = "29">Thus, finally ChaSen4 is used.</S>
			<S sid ="94" ssid = "30">To collect MOD features, a dependency parser CaboCha5 is used.</S>
			<S sid ="95" ssid = "31">Figure 1 depicts an example of extracting MOD features from a sentence within Web snippet.</S>
			<S sid ="96" ssid = "32">A feature is generated from a bun- setsu, the Japanese base-chunk, which is either mod 2 http://developer.yahoo.co.jp/search/ 3 http://mecab.sourceforge.net/ 4 http://chasen.naist.jp/hiki/ChaSen/ 5 http://chasen.org/˜taku/software/cabocha/ Sentence within snippet (dependency tree) yoteeiida Features Modifiee/D: yotei the source phrase.</S>
			<S sid ="97" ssid = "33">The “anchored version” of Web snippets is retrieved in the following steps: kenshhoouu--ssuurruu (plan) Step 21.</S>
			<S sid ="98" ssid = "34">Determine the anchor using Web snip pets for the given source phrase.</S>
			<S sid ="99" ssid = "35">We regarded saaiiggeenn--sseeii-o kuwasshhiikkuu Modifier/D: kuwashii a noun which most frequently modifies the jjiikkkkeenn--kkeekkkkaa--nnoo kkaarree--nnoo Given phrase (in detail) Modifier/D: kare_no (his) source phrase as its anchor.</S>
			<S sid ="100" ssid = "36">Example s of source phrases and their anchors are shown in (6).</S>
			<S sid ="101" ssid = "37">Step 22.</S>
			<S sid ="102" ssid = "38">Retrieve Web snippets by querying the (I am) planning to verify the reproducibility of his experimental result in detail.</S>
			<S sid ="103" ssid = "39">Figure 1: An example of MOD feature extraction.</S>
			<S sid ="104" ssid = "40">An oval in the dependency tree denotes a bunsetsu.</S>
			<S sid ="105" ssid = "41">ifier or modifiee of the given phrase.</S>
			<S sid ="106" ssid = "42">Each feature is composed of three or more elements: (i) modifier or modifiee, (ii) dependency relation types (direct dependency, appositive, or parallel, c.f., RASP and MINIPAR), (iii) base form of the headword, and (iv) case marker following noun, auxiliary verb and verbal suffixes if they appear.</S>
			<S sid ="107" ssid = "43">The last feature is employed to distinguish the subtle difference of meaning of predicate phrases, such as voice, tense, aspect, and modality.</S>
			<S sid ="108" ssid = "44">While Lin and Pantel (2001) have calculated similarities of paths based on slot fillers of subject and object slots, MOD targets at sub-trees and utilizes any modifiers and modifiees.</S>
			<S sid ="109" ssid = "45">anchor for the source phrase AND each of source and target phrases, respectively.</S>
			<S sid ="110" ssid = "46">Step 23.</S>
			<S sid ="111" ssid = "47">Extract features for HITS, BOW, MOD.</S>
			<S sid ="112" ssid = "48">Those sets are referred to as Anc.∗, while the normal versions are referred to as Nor.∗.</S>
			<S sid ="113" ssid = "49">(6) a. “emi:o:ukaberu” ··· “manmen” (be smiling ··· from ear to ear) b. “doriburu:de:kake:agaru” ··· “saido” (overlap by dribbling ··· side) c. “yoi:sutaato:o:kiru” ··· “saisaki” (make a good start ··· good sign) 3.3 Computing paraphrasability.</S>
			<S sid ="114" ssid = "50">Paraphrasability is finally computed by two conventional distributional similarity measures.</S>
			<S sid ="115" ssid = "51">The first is the measure proposed in (Lin and Pantel, 2001): Lf ∈Fs ∩Ft (w(s, f )+ w(t, f )) Feature weighting ParLin (s⇒t)= L f ∈Fs w(s, f )+ L f ∈Ft w(t, f ) , Geffet and Dagan (2004) have reported on that the better quality of feature vector (weighting function) leads better results.</S>
			<S sid ="116" ssid = "52">So far, several weighting functions have been proposed, such as point-wise mutual information (Lin and Pantel, 2001) and Relative Feature Focus (Geffet and Dagan, 2004).</S>
			<S sid ="117" ssid = "53">While these functions compute weights using a small corpus for merely re-ranking samples, we are developing a measure that assesses the paraphrasability of arbitrary pair of phrases, where a more robust weighting function is necessary.</S>
			<S sid ="118" ssid = "54">Therefore we directly use frequencies of features within Web snip where Fs and Ft denote feature sets for s and t, respectively.</S>
			<S sid ="119" ssid = "55">w(x, f ) stands for the weight (frequency in our experiment) of f in Fx.</S>
			<S sid ="120" ssid = "56">While ParLin is symmetric, it has been arguedthat it is important to determine the direction of para phrase.</S>
			<S sid ="121" ssid = "57">As an asymmetric measure, we examine α- skew divergence defined by the following equation (Lee, 1999): dskew (t, s) = D (Ps αPt + (1 − α)Ps ) ,where Px denotes a probability distribution esti 6 pets as weight.</S>
			<S sid ="122" ssid = "58">Normalization will be done when the matedfrom a feature set Fx . How well Pt approx paraphrasability is computed (Section 3.3).</S>
			<S sid ="123" ssid = "59">Source-focused feature extraction Independent collection of Web snippets for each phrase of a given pair might yield no intersection of feature sets even if they have the same meaning.</S>
			<S sid ="124" ssid = "60">To obtain more reliable feature sets, we retrieve Web imates Ps is calculated based on the KL divergence, D. The parameter α is set to 0.99, following tradition, because the optimization of α is difficult.</S>
			<S sid ="125" ssid = "61">To take consistent measurements, we define the paraphrasability score Parskew as follows: Parskew (s⇒t) = exp (−dskew (t, s)) . 6 We estimate them simply using maximum likelihood esti-.</S>
			<S sid ="126" ssid = "62">snippets by querying the phrase AND the anchor of mation, i.e., Px (f ) = w(x, f )/ P ∈ x w(x, f ∗ ).</S>
			<S sid ="127" ssid = "63">Table 1: # of sampled source phrases and automatically generated syntactic variants.</S>
			<S sid ="128" ssid = "64">Phras e type # of token s # of types th ty pe s C ov .( % ) Out put Ave. N : C : V N1 : N2 : C : V N : C : V1 : V2 N : C : Adv : V Adj : N : C : V N : C : Adj 20,20 0,041 4,323, 756 3,79 6,35 1 2,01 3,68 2 32 5,9 64 21 3,9 23 1,20 9,26 5 923, 475 37 8,6 17 23 3,9 52 78 8,0 38 20 3,8 45 1,000 1,014 10.7 107 1,00 5 6.3 15 1,0 22 12.9 21 1,0 97 3.9 20 1,0 49 14.1 86 1,0 03 31.4 1,5 36 (48 9) 3.1 88,0 40 (966 ) 91.1 75,3 44 (982 ) 76.7 8,2 81 (52 3) 15.</S>
			<S sid ="129" ssid = "65">7 1 2 8 (50) 2.6 3,2 12 (99 2) 3.2 Total 26,69 8,276 7,912 ,633 6 , 1 9 0 176,5 41 (4,00 2) 44.1 Table 2: # of syntactic variants whose paraphrasability scores are computed.</S>
			<S sid ="130" ssid = "66">Nor.HITS ⊃ Nor.BOW.∗⊃ Nor.MOD.∗.</S>
			<S sid ="131" ssid = "67">Anc.HITS ⊃ Anc.BOW.∗⊃ Anc.MOD.∗.</S>
			<S sid ="132" ssid = "68">Nor.HITS ⊃ Anc.HITS.</S>
			<S sid ="133" ssid = "69">Nor.BOW.∗⊃ Anc.BOW.∗.</S>
			<S sid ="134" ssid = "70">Nor.MOD.∗⊃ Anc.MOD.∗.</S>
			<S sid ="135" ssid = "71">X denotes the set of syntactic variants whose scores are computed based on X. Phras e type N o r . H I T S Outpu t Ave. N o r . B O W . ∗ Outpu t Ave. N o r . M O D . ∗ Outpu t Ave. A n c . H I T S Outpu t Ave. A n c . B O W . ∗ Outpu t Ave. A n c . M O D . ∗ Outpu t Ave. M a i n i c h i Outpu t Ave. N : C : V N1 : N2 : C : V N : C : V1 : V2 N : C : Adv : V Adj : N : C : V N : C : Adj 1,40 5 (489 ) 2.9 9,54 4 (964 ) 9.9 3,76 9 (876 ) 4.3 69 0 (35 9) 1.9 4 5 (20) 2.3 1,45 9 (885 ) 1.6 1,40 2 (488 ) 2.9 9,24 9 (922) 10.0 3,40 6 (774 ) 4.4 50 6 (24 7) 2.0 4 5 (20) 2.3 1,45 9 (885 ) 1.6 1,39 6 (488 ) 2.9 8,65 2 (921 ) 9.4 3,10 9 (762 ) 4.1 47 5 (23 3) 2.0 4 2 (17) 2.5 1,39 9 (864 ) 1.6 1,36 8 (488 ) 2.8 7,43 7 (897 ) 8.3 2,51 7 (697 ) 3.6 34 2 (17 4) 2.0 4 1 (18) 2.3 1,23 5 (809 ) 1.5 1,36 6 (487 ) 2.8 7,42 4 (894 ) 8.3 2,49 7 (690 ) 3.6 33 9 (17 3) 2.0 4 1 (18) 2.3 1,23 5 (809 ) 1.5 1,36 0 (487 ) 2.8 6,79 5 (891 ) 7.6 2,25 8 (679 ) 3.3 32 2 (16 8) 1.9 3 9 (16) 2.4 1,16 1 (779 ) 1.5 1,10 3 (457 ) 2.4 3,04 1 (948 ) 3.2 1,15 6 (548 ) 2.1 21 5 (16 7) 1.3 1 4 (7) 2.0 55 9 (45 9) 1.2 Total 16,91 2 (3,59 3) 4.7 16,06 7 (3,33 6) 4.8 15,07 3 (3,28 5) 4.6 12,94 0 (3,08 3) 4.2 12,90 2 (3,07 1) 4.2 11,93 5 (3,02 0) 4.0 6,08 8 (2,5 86) 2.4 Now Parx falls within [0, 1], and a larger Parx indicates a more paraphrasable pair of phrases.</S>
	</SECTION>
	<SECTION title="Experimental setting. " number = "4">
			<S sid ="136" ssid = "1">We conduct empirical experiments to evaluate the proposed methods.</S>
			<S sid ="137" ssid = "2">Settings are described below.</S>
			<S sid ="138" ssid = "3">4.1 Test collection.</S>
			<S sid ="139" ssid = "4">First, source phrases were sampled from a 15 years of newspaper articles (Mainichi 19912005, approximately 1.5GB).</S>
			<S sid ="140" ssid = "5">Referring to the dependency structure given by CaboCha, we extracted most frequent 1,000+ phrases for each of 6 phrase types.</S>
			<S sid ="141" ssid = "6">These phrases were then fed to a system proposed in (Fujita et al., 2007) to generate syntactic variants.</S>
			<S sid ="142" ssid = "7">The numbers of the source phrases and their syntactic variants are summarized in Table 1, where the numbers in the parentheses indicate that of source phrases paraphrased.</S>
			<S sid ="143" ssid = "8">At least one candidate was generated for 4,002 (64.7%) phrases.</S>
			<S sid ="144" ssid = "9">Although the system generates numerous syntactic variants from a given phrase, most of them are erroneous.</S>
			<S sid ="145" ssid = "10">For example, among 159 syntactic variants that are automatically generated for the phrase “songai:baishou:o:motomeru” (demand compensation for damages), only 8 phrases are grammatical, and only 5 out of 8 are correct paraphrases.</S>
			<S sid ="146" ssid = "11">Paraphrasability of each pair of source phrase and candidate is then computed by the methods proposed in Section 3.</S>
			<S sid ="147" ssid = "12">Table 2 summarizes the numbers of pairs whose features can be extracted from the Web snippets.</S>
			<S sid ="148" ssid = "13">While more than 90% of candidates were discarded due to ’No hits’ in the Web, at least one candidate survived for 3,020 (48.8%) phrases.</S>
			<S sid ="149" ssid = "14">Mainichi is a baseline which counts HITS in the corpus used for sampling source phrases.</S>
			<S sid ="150" ssid = "15">4.2 Samples for evaluation.</S>
			<S sid ="151" ssid = "16">We sampled three sets of pairs for evaluation, where Mainichi, ∗.HITS, ∗.BOW, ∗.MOD, the harmonic mean of the scores derived from ∗.BOW and ∗.MOD (referred to as ∗.HAR), and two distributional similarity measures for ∗.BOW, ∗.MOD, and ∗.HAR, in total 15 models, are compared.</S>
			<S sid ="152" ssid = "17">Ev.Gen: This investigates how well a correct candidate is ranked first among candidates for a given phrase using the top-ranked pairs for randomly sampled 200 source phrases for each of 15 models.</S>
			<S sid ="153" ssid = "18">Ev.Rec: This assesses how well a method gives higher scores to correct candidates using the 200-best pairs for each of 15 models.</S>
			<S sid ="154" ssid = "19">Ev.Ling: This compares paraphrasability of each phrase type using the 20-best pairs for each of 6 phrase type and 14 Web-based models.</S>
			<S sid ="155" ssid = "20">4.3 Criteria of paraphrasability.</S>
			<S sid ="156" ssid = "21">To assess by human the paraphrasability discussed in Section 3, we designed the following four questions based on (Szpektor et al., 2007): Qsc: Is s a correct phrase in Japanese?</S>
			<S sid ="157" ssid = "22">Qtc: Is t a correct phrase in Japanese?</S>
			<S sid ="158" ssid = "23">Qs2t: Does t hold if s holds and can t substituted for s in some context?</S>
			<S sid ="159" ssid = "24">Qt2s: Does s hold if t holds and can s substituted for t in some context?</S>
	</SECTION>
	<SECTION title="Experimental results. " number = "5">
			<S sid ="160" ssid = "1">5.1 Agreement of human judge.</S>
			<S sid ="161" ssid = "2">Two human assessors separately judged all of the 1,152 syntactic variant pairs (for 962 source phrases) within the union of the three sample sets.</S>
			<S sid ="162" ssid = "3">They agreed on all four questions for 795 (68.4%) pairs.</S>
			<S sid ="163" ssid = "4">For the 963 (83.6%) pairs that passed Qsc and Qtc in both two judges, we obtained reasonable agreement ratios 86.9% and 85.0% and substantial Kappa values 0.697 and 0.655 for assessing Qs2t and Qt2s.</S>
			<S sid ="164" ssid = "5">5.2 Ev.Gen. Table 3 shows the results for Ev.Gen, where the strict precision is calculated based on the number of two positive judges for Qs2t , while the lenient precision is for at least one positive judge for the same question.</S>
			<S sid ="165" ssid = "6">∗.MOD and ∗.HAR outperformed the other models, although there was no statistically significant difference7 . Significant differences between Mainichi and the other models in lenient precisions indicate that the Web enables us to compute paraphrasability more accurately than a limited size of corpus.</S>
			<S sid ="166" ssid = "7">From a closer look at the distributions of paraphrasability scores of ∗.BOW and ∗.MOD shown in Table 4, we find that if a top-ranked candidate for a given phrase is assigned enough high score, it is very likely to be correct.</S>
			<S sid ="167" ssid = "8">The scores of Anc.∗ aredistributed in a wider range than those of Nor.∗, pre serving precision.</S>
			<S sid ="168" ssid = "9">This allows us to easily skim the most reliable portion by setting a threshold.</S>
			<S sid ="169" ssid = "10">5.3 Ev.Rec.</S>
			<S sid ="170" ssid = "11">The results for Ev.Rec, as summarized in Table 5, show the significant differences of performances be tween Mainichi or ∗.HITS and the other models.</S>
			<S sid ="171" ssid = "12">The results of ∗.HITS supported the importance of comparing features of phrases.</S>
			<S sid ="172" ssid = "13">On the other hand, ∗.BOW performed as well as ∗.MOD and ∗.HAR.This sounds nice because BOW features can be ex tracted extremely quickly and accurately.</S>
			<S sid ="173" ssid = "14">Unfortunately, Anc.∗ led only a small impact on strict precisions.</S>
			<S sid ="174" ssid = "15">We speculate that the selection of the anchor is inadequate.</S>
			<S sid ="175" ssid = "16">Another possible interpretation is that source phrases are rarely ambiguous, because they contain at least two content words.</S>
			<S sid ="176" ssid = "17">In 7 p &lt; 0.05 in 2-sample test for equality of proportions.</S>
			<S sid ="177" ssid = "18">Table 3: Precision for 200 candidates (Ev.Gen).</S>
			<S sid ="178" ssid = "19">Mode l S t r i c t Leni ent Nor .∗ Anc .∗ No r.∗ An c.∗ Maini chi HITS BOW .Lin BOW .skew MOD .Lin MOD .skew HAR.</S>
			<S sid ="179" ssid = "20">Lin HAR.</S>
			<S sid ="180" ssid = "21">skew 77 (39% ) 84 (42% ) 82 (41% ) 86 (43% ) 91 (46% ) 92 (46% ) 90 (45% ) 93 (47% )- 83 (42% ) 85 (43% ) 87 (44% ) 91 (46% ) 90 (45% ) 90 (45% ) 90 (45% ) 101 (51% ) 120 (60% ) 123 (62% ) 125 (63% ) 130 (65% ) 132 (66% ) 129 (65% ) 134 (67% )- 119 (60%) 124 (62%) 124 (62%) 131 (66%) 130 (65%) 130 (65%) 131 (66%) Table 4: Distribution of paraphrasability scores and lenient precision (Ev.Gen).</S>
			<S sid ="181" ssid = "22">Par (s⇒ t) N o r . B O W A n c . B O W L i n s k e w L i n s k e w0.9 1.00.8 1.00.7 1.00.6 1.00.5 1.00.4 1.00.3 1.00.2 1.00.1 1.00.0 1.0 11/ 12 (92 %) 45/ 49 (92 %) 72/ 88 (82 %) 94/1 27 (74 %) 102/1 45 (70% ) 107/1 58 (68% ) 113/1 73 (65% ) 119/1 84 (65% ) 123/1 98 (62% ) 123/2 00 (62% ) 0/ 0 1/ 1 (10 0% ) 7/ 7 (10 0% ) 11/ 11 (100 %) 13/ 13 (100 %) 13/ 14 (93 %) 25/ 26 (96 %) 40/ 41 (98 %) 74/ 86 (86 %) 125/2 00 (63%) 17/ 18 (94 %) 45/ 50 (90 %) 73/ 92 (79 %) 83/1 13 (74 %) 96/1 28 (75 %) 103/1 45 (71% ) 114/1 66 (69% ) 121/1 86 (65% ) 124/2 00 (62% ) 124/2 00 (62% ) 2/ 2 (10 0% ) 6/ 6 (10 0% ) 10/ 11 (91 %) 12/ 13 (92 %) 14/ 15 (93 %) 21/ 22 (96 %) 31/ 32 (97 %) 49/ 50 (98 %) 82/ 99 (83 %) 124/2 00 (62%) Varia nce 0 . 0 5 2 0 . 0 3 1 0 . 0 6 1 0 . 0 4 4 Par (s⇒ t) N o r . M O D A n c . M O D L i n s k e w L i n s k e w0.9 1.00.8 1.00.7 1.00.6 1.00.5 1.00.4 1.00.3 1.00.2 1.00.1 1.00.0 1.0 2/ 2 (10 0% ) 10/ 10 (100 %) 13/ 14 (93 %) 20/ 21 (95 %) 31/ 32 (97 %) 42/ 44 (96 %) 61/ 68 (90 %) 81/ 92 (88 %) 105/1 33 (79%) 130/2 00 (65%) 0/ 0 0/ 0 0/ 0 1/ 1 (10 0% ) 6/ 6 (10 0% ) 11/ 11 (100 %) 12/ 12 (100 %) 13/ 13 (100 %) 17/ 18 (94 %) 132/2 00 (66%) 7/ 7 (10 0% ) 12/ 13 (92 %) 17/ 18 (94 %) 27/ 28 (96 %) 36/ 37 (97 %) 51/ 53 (96 %) 61/ 68 (90 %) 82/ 94 (87 %) 104/1 26 (83%) 131/2 00 (66%) 1/ 1 (10 0% ) 2/ 2 (10 0% ) 6/ 6 (10 0% ) 9/ 9 (10 0% ) 10/ 10 (100 %) 12/ 12 (100 %) 13/ 14 (93 %) 18/ 19 (95 %) 24/ 25 (96 %) 130/2 00 (65%) Varia nce 0 . 0 5 7 0 . 0 1 4 0 . 0 7 2 0 . 0 3 0 paraphrase generation, capturing the correct boundary of phrases is rather vital, because the source phrase is usually assumed to be grammatical.</S>
			<S sid ="182" ssid = "23">Qsc for 55 syntactic variants (for 44 source phrases) were actually judged incorrect.</S>
			<S sid ="183" ssid = "24">The lenient precisions, which were reaching a ceiling, implied the limitation of the proposed methods.</S>
			<S sid ="184" ssid = "25">Most common errors among the proposed methods were generated by a transformation pattern N1 : N2 : C : V ⇒ N2 : C : V . Typically, dropping a nominal element N1 of the given nominal compound N1 : N2 generalizes the meaning that the compound conveys, and thus results correct paraphrases.</S>
			<S sid ="185" ssid = "26">However, it caused errors in some cases; for example, since N1 was the semantic head in (7), dropping it was incorrect.(7) s. “shukketsu:taryou:de:shibou suru” (die due to heavy blood loss) t.∗“taryou:de:shibousuru” (die due to plenty) Table 5: Precision for 200 candidates (Ev.Rec).</S>
			<S sid ="186" ssid = "27">Table 6: Precision for each phrase type (Ev.Ling).</S>
			<S sid ="187" ssid = "28">Phras e type S t r i c t L e ni e nt N : C : V N1 : N2 : C : V N : C : V1 : V2 N : C : Adv : V Adj : N : C : V N : C : Adj 52/ 98 (53 %) 51/ 72 (71 %) 42/ 86 (49 %) 33/ 61 (54 %) 0/ 25 (0 %) 18/ 73 (25 %) 69/ 98 (70 %) 64/ 72 (89 %) 60/ 86 (70 %) 44/ 61 (72 %) 4/ 25 (16 %) 38/ 73 (52 %) Total 196/4 15 (47% ) 279/4 15 (67% ) 5.4 Ev.Ling.</S>
			<S sid ="188" ssid = "29">Finally the results for Ev.Ling is shown in Table 6.</S>
			<S sid ="189" ssid = "30">Paraphrasability of syntactic variants for phrases containing an adjective was poorly computed.</S>
			<S sid ="190" ssid = "31">The primal source of errors for Adj : N : C : V type phrases was the subtle change of nuance by switching syntactic heads as illustrated in (8), where underlines indicate heads.</S>
			<S sid ="191" ssid = "32">(8) s. “yoi:shigoto:o:suru” (do a good job) t1./=“yoku:shigotosuru” (work hard) t2./=“shigoto:o:yoku:suru” (improve the work) Most errors in paraphrasing N : C : Adj type phrases, on the other hand, were caused due to the difference of aspectual property and agentivity between adjectives and verbs.</S>
			<S sid ="192" ssid = "33">For example, (9s) can describe not only things those qualities have been improved as inferred by (9t), but also those originally having a high quality.</S>
			<S sid ="193" ssid = "34">Qs2t for (9) was thus judged incorrect.</S>
			<S sid ="194" ssid = "35">(9) s. “shitsu:ga:takai” (having high quality) t./=“shitsu:ga:takamaru” (quality rises) Precisions of syntactic variants for the other types of phrases were higher, but they tended to include trivial paraphrases such as shown in (10) and (11).</S>
			<S sid ="195" ssid = "36">Yet, collecting paraphrase instances statically will contribute to paraphrase recognition tasks.</S>
			<S sid ="196" ssid = "37">(10) s. “shounin:o:eru” (clear) t. “shouninsa-re-ru” (be approved) (11) s. “eiga:o:mi:owaru” (finish seeing the movie) t. “eiga:ga:owaru” (the movie ends)</S>
	</SECTION>
	<SECTION title="Discussion. " number = "6">
			<S sid ="197" ssid = "1">As described in the previous sections, our quite naive methods have shown fairly good performances in this first trial.</S>
			<S sid ="198" ssid = "2">This section describes some remaining issues to be discussed further.</S>
			<S sid ="199" ssid = "3">Table 7: # of features.</S>
			<S sid ="200" ssid = "4">Nor.BOW Nor.MOD Anc.BOW Anc.MOD # of featur es (type) 73 ,8 48 471, 720 72,1 09 409, 379 avera ge featur es (type) 1 , 3 2 2 2 1 1 1,2 77 2 0 2 avera ge featur es (toke n) 4 , 8 8 3 3 9 1 4,7 28 3 8 3 are semantically equivalent and syntactically substitutable, following the spirit described in (Fujita et al., 2007).</S>
			<S sid ="201" ssid = "5">Through the comparisons of Nor.∗ andAnc.∗, we have shown a little evidence that the am biguity of phrases was not problematic at least for handling syntactic variants, arguing the necessity of detecting the appropriate phrase boundaries.</S>
			<S sid ="202" ssid = "6">To overcome the data sparseness problem, Web snippets are harnessed.</S>
			<S sid ="203" ssid = "7">Features extracted from the snippets outperformed newspaper corpus; however, the small numbers of features for phrases shown in Table 7 and the lack of sophisticated weighting function suggest that the problem might persist.</S>
			<S sid ="204" ssid = "8">To examine the proposed features and measures further, we plan to use TSUBAKI8, an indexed Web corpus developed for NLP research, because it allow us to obtain snippets as much as it archives.</S>
			<S sid ="205" ssid = "9">The use of larger number of snippets increases the computation time for assessing paraphrasability.</S>
			<S sid ="206" ssid = "10">For reducing it as well as gaining a higher coverage, the enhancement of the paraphrase generation system is necessary.</S>
			<S sid ="207" ssid = "11">A look at the syntactic variants automatically generated by a system, which we proposed, showed that the system could generate syntactic variants for only a half portion of the input, producing many erroneous ones (Section 4.1).</S>
			<S sid ="208" ssid = "12">To prune a multitude of incorrect candidates, statistical language models such as proposed in (Habash, 2004) will be incorporated.</S>
			<S sid ="209" ssid = "13">In parallel, we plan to develop a paraphrase generation system which lets us to quit from the labor of maintaining patterns such as shown in (4).</S>
			<S sid ="210" ssid = "14">We think a more unrestricted generation algorithm will gain a higher coverage, preserving the meaning as far as handling syntactic variants of predicate phrases.</S>
			<S sid ="211" ssid = "15">The aim of this study is to create a thesaurus of phrases to recognize and generate phrases that 8 http://tsubaki.ixnlp.nii.ac.jp/se/index.cgi</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "7">
			<S sid ="212" ssid = "1">In this paper, we proposed a method of assessing paraphrasability between automatically generated syntactic variants of predicate phrases.</S>
			<S sid ="213" ssid = "2">Web snippets were utilized to overcome the data sparseness problem, and the conventional distributional similarity measures were employed to quantify the similarity of feature sets for the given pair of phrases.</S>
			<S sid ="214" ssid = "3">Empirical experiments revealed that features extracted from the Web snippets contribute to the task, showing promising results, while no significant difference was observed between two measures.</S>
			<S sid ="215" ssid = "4">In future, we plan to address several issues such as those described in Section 6.</S>
			<S sid ="216" ssid = "5">Particularly, at present, the coverage and portability are of our interests.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="217" ssid = "6">We are deeply grateful to all anonymous reviewers for their valuable comments.</S>
			<S sid ="218" ssid = "7">This work was supported in part by MEXT Grant-in-Aid for Young Scientists (B) 18700143, and for Scientific Research (A) 16200009, Japan.</S>
	</SECTION>
</PAPER>
