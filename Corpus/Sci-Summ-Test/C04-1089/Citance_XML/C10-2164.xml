<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">This paper focuses on the Web-based EnglishChinese OOV term translation pattern, and emphasizes particularly on the translation selection strategy based on the fusion of multiple features and the ranking mechanism based on Ranking Support Vector Machine (Ranking SVM).</S>
		<S sid ="2" ssid = "2">By utilizing the CoNLL2003 corpus for the English Named Entity Recognition (NER) task and selected new terms, the experiments based on different data sources show the consistent results.</S>
		<S sid ="3" ssid = "3">Our OOV term translation model can “filter” the most possible translation candidates with better ability.</S>
		<S sid ="4" ssid = "4">From the experimental results for combining our OOV term translation model with EnglishChinese Cross- Language Information Retrieval (CLIR) on the data sets of Text Retrieval Evaluation Conference (TREC), it can be found that the obvious performance improvement for both query translation and retrieval can also be obtained.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">In Cross-Language Information Retrieval (CLIR), most of users’ queries are generally composed of short terms, in which there are many Out-of-Vocabulary (OOV) terms like Named Entities (NEs), new words, terminologies and so on.</S>
			<S sid ="6" ssid = "6">The translation quality of OOV term directly influences the precision of querying relevant multilingual information.</S>
			<S sid ="7" ssid = "7">Therefore, OOV term translation has become a very important and challenging issue in CLIR.</S>
			<S sid ="8" ssid = "8">With the increasing growth of Web information which includes multilingual hypertext resources with abundant topics, it appears that Web information can mitigate the problem of the restricted OOV term translation accuracy (Lu and Chien, 2002).</S>
			<S sid ="9" ssid = "9">However, how to select the correct translations from Web information and locate the appropriate translation resources rapidly is still the main goal for OOV term translation.</S>
			<S sid ="10" ssid = "10">Hence, finding the effective feature representation and the optimal ranking pattern for translation candidates is the core part for the Web-based OOV term translation.</S>
			<S sid ="11" ssid = "11">This paper focuses on the Web-based English-Chinese OOV term translation pattern, and emphasizes particularly on the translation selection strategy based on the fusion of multiple features and the translation ranking mechanism based on Ranking Support Vector Machine (Ranking SVM).</S>
			<S sid ="12" ssid = "12">By utilizing the CoNLL2003 corpus for the English Named Entity Recognition (NER) task and manually selected new terms in various fields, the established OOV term translation model can “filter” the most possible translation candidates with better ability.</S>
			<S sid ="13" ssid = "13">This paper also attempts to apply the OOV term translation mechanism above in EnglishChinese CLIR.</S>
			<S sid ="14" ssid = "14">It can be observed from the experimental results on the data sets of Text Retrieval Evaluation Conference (TREC) that the obvious performance improvement for query translation can be obtained, which is very beneficial to CLIR and can improve the whole retrieval performance.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "2">
			<S sid ="15" ssid = "1">At present, the methods for OOV term translation have changed from the basic pattern based on bilingual dictionary, transliteration or parallel corpus to the intermediate pattern based on comparable corpus (Lee et al., 2006; Shao and Ng, 2004; Virga and Khudanpur, 2003), and 1435 Coling 2010: Poster Volume, pages 1435–1443, Beijing, August 2010 then become a new pattern based on Web mining (Fang et al., 2006; Sproat et al., 2006).</S>
			<S sid ="16" ssid = "2">In recent years, many researchers have utilized Web to find the translation candidates on webpages (Wu and Chang, 2007).</S>
			<S sid ="17" ssid = "3">AlOnaizan and Knight (2002) used Web statistics information to validate the translation candidates generated by language model, and obtained the accuracy of 72.6% in ArabicEnglish OOV word translation.</S>
			<S sid ="18" ssid = "4">Lu and Chien (2004) utilized the statistics information about the anchor texts in Web search results to recognize the translation candidates, and got the accuracy of 63.6% in EnglishChinese title query term translation.</S>
			<S sid ="19" ssid = "5">Zhang and Vines (2004) extracted the translation candidates for OOV query terms in CLIR from Web, and improved the performance of EnglishChinese/ChineseEnglish CLIR to some extent.</S>
			<S sid ="20" ssid = "6">Zhang et al.</S>
			<S sid ="21" ssid = "7">(2005) searched the translation candidates by using cross-language query expansion and Web, and obtained the Top-1 accuracy of 81.0% in ChineseEnglish OOV word translation.</S>
			<S sid ="22" ssid = "8">Chen and Chen (2006) used the combination of Web statistics and the vocabulary, and acquired the Top-1 accuracy of 87.6% in ChineseEnglish OOV word translation.</S>
			<S sid ="23" ssid = "9">Jiang et al.</S>
			<S sid ="24" ssid = "10">(2007) utilized the combination of Web mining, transliteration and ranking based on Maximum Entropy (ME), only focused on EnglishChinese person name translation and got the Top-1 accuracy of 47.5%.</S>
			<S sid ="25" ssid = "11">Although the methods above can improve the translation performance for OOV term to a certain degree, there are still three common problems in the OOV term translation based on Web mining.</S>
			<S sid ="26" ssid = "12">(1) Chinese key term extraction pattern from Web documents is over complex and the complexity is always higher.</S>
			<S sid ="27" ssid = "13">Because of the inherent property of having no segmentation delimitation in Chinese, it’s very difficult for EnglishChinese OOV term translation to extract Chinese key terms from Web documents.</S>
			<S sid ="28" ssid = "14">The cost for the extraction computation is generally overlarge (Wang et al., 2004; Zhang and Vines, 2004).</S>
			<S sid ="29" ssid = "15">(2) The feature information for the evaluation of translation candidates is not enough and comprehensive.</S>
			<S sid ="30" ssid = "16">Most of OOV term translation methods implement the evaluation for candidates through mining simple local and Boolean features, that is, inherent features in candidates and their surrounding context features.</S>
			<S sid ="31" ssid = "17">However, if only a certain Web document that an OOV term appears is explored, the global information contained in the whole Web document set will be ignored, and the inconsistency and polyse- my of candidates cannot be considered.</S>
			<S sid ="32" ssid = "18">(3) The relevance measurement for translation pairs is very simple, or the computation cost is too high.</S>
			<S sid ="33" ssid = "19">For ranking candidates, most of OOV term translation approaches adopt the simple combination computation of the feature values used, or get assessment based on classification models.</S>
			<S sid ="34" ssid = "20">Hence, the feature weights are determined according to the corresponding induction and suitable for some specific fields, but cannot guarantee the accuracy of the final translation ranking results.</S>
			<S sid ="35" ssid = "21">However, the Ranking SVM model can effectively express multiple ranking constraints, and has better universality and applicability (Cao et al., 2006; Joa- chimes, 2002; Vapnik, 1995).</S>
	</SECTION>
	<SECTION title="Our Solutions. " number = "3">
			<S sid ="36" ssid = "1">To support more precise EnglishChinese OOV term translation, we establish a multiple- feature-based translation pattern based on Web mining and Ranking SVM.</S>
			<S sid ="37" ssid = "2">On the one hand, a Chinese key term extraction strategy is built on the simplified extraction computation for PAT- Tree, in which the optimization processing for the confidence of word building is improved to a certain extent.</S>
			<S sid ="38" ssid = "3">On the other hand, translation candidates are chosen by the fusion of multiple features.</S>
			<S sid ="39" ssid = "4">The representation forms of local, global and Boolean feature are constructed under the consideration of the complex characteristics of English/Chinese OOV term and Web information.</S>
			<S sid ="40" ssid = "5">Moreover, for the relevance measurement between an OOV term to be translated and its translation candidates, the supervised learning based on Ranking SVM is introduced to rank candidates precisely.</S>
			<S sid ="41" ssid = "6">At first, given an OOV term to be translated as a query, it is input into the Google search engine to acquire the returned webpage snippet set.</S>
			<S sid ="42" ssid = "7">Next, Chinese key terms are extracted from the PAT-Tree built on the snippet set to determine the translation candidates.</S>
			<S sid ="43" ssid = "8">Subse quently, local, global and Boolean features are extracted from the candidates based on the fusion of multiple features.</S>
			<S sid ="44" ssid = "9">Finally, the candidates are filtered and ranked through the supervised learning based on Ranking SVM.</S>
	</SECTION>
	<SECTION title="Chinese Key Term Extraction. " number = "4">
			<S sid ="45" ssid = "1">In Web mining of EnglishChinese OOV term translation, an important problem is to extract the target translation candidates from the returned Chinese Web documents, which can be considered as a key term extraction task.</S>
			<S sid ="46" ssid = "2">The PAT-Tree structure is an efficient indexing method in both IR and Information Extraction (IE) domains (Chien, 1997; Gonnet et al., 1992).</S>
			<S sid ="47" ssid = "3">Its superior feature is the Semi Infinite String, which can store all the strings from the whole corpus (i.e., the returned snippet set in this paper) in a binary tree.</S>
			<S sid ="48" ssid = "4">The branch node indicates the search direction and the leaf node stores the index and frequency for a string.</S>
			<S sid ="49" ssid = "5">Generally, a Chinese character corresponds to a binary-coded form with 2 bytes (16 bits).</S>
			<S sid ="50" ssid = "6">Chinese strings can be transformed into binary strings.</S>
			<S sid ="51" ssid = "7">There is an ending tag for each string and its binary form is “00000000”.</S>
			<S sid ="52" ssid = "8">Take “中文 信息抽取” (Chinese IE) and “信息检索” (IR) as an example, the binary strings for them are of both two child nodes are added as the frequency of the common string (i.e., the parent branch node).</S>
			<S sid ="53" ssid = "9">At last, the common strings with the frequency values larger than 2 are extracted as the key terms.</S>
			<S sid ="54" ssid = "10">For the PAT-Tree in Figure 2, there is a branch node with the Comp-bit value of 37, which indicates that at least the prefixes of two strings contain two identical characters.</S>
			<S sid ="55" ssid = "11">It can be known from the leaf nodes that two strings are “信息抽取” (IE) and “信息检索”(IR).</S>
			<S sid ="56" ssid = "12">Hence, the prefix substring “信息” (in formation) with the frequency of 2 is extracted as the common string.</S>
			<S sid ="57" ssid = "13">Thus the key terms with the arbitrary lengths and frequency values can be retrieved from the built PAT-Tree.</S>
			<S sid ="58" ssid = "14">However, with the common strings being extracted, large amounts of noisy terms and fragments are also extracted.</S>
			<S sid ="59" ssid = "15">To filter noisy fragments, Wang et al.</S>
			<S sid ="60" ssid = "16">(2004) used SPDCD and the Local-Maxima algorithm, but the computation cost was too expensive.</S>
			<S sid ="61" ssid = "17">Therefore, the simplified filtering manner is adopted here: described in Figure 1.</S>
			<S sid ="62" ssid = "18">Thus a PAT-Tree can be built based on these strings, as shown in Figure α(ci Lcj ) = f (ci Lcj )− f (c1Lcn) f (ci Lcj ) (1) 2.</S>
			<S sid ="63" ssid = "19">The branch node stands for the comparison.</S>
			<S sid ="64" ssid = "20">bit (Comp-bit), which represents the position of different bit in binary strings.</S>
			<S sid ="65" ssid = "21">Some binary strings have the value of 0 in such a bit and are classified into the left branch, while others have 1 and turn to the right branch.</S>
			<S sid ="66" ssid = "22">Figure 1.</S>
			<S sid ="67" ssid = "23">Binary string representation instantiation.</S>
			<S sid ="68" ssid = "24">Figure 2.</S>
			<S sid ="69" ssid = "25">PAT-Tree Instantiation for Figure 1.</S>
			<S sid ="70" ssid = "26">In the extraction process, the PAT-tree is traversed first, and the branch nodes with the Comp-bit values larger than 32 are selected.</S>
			<S sid ="71" ssid = "27">This is because the minimum length of a Chinese common string is 2 characters and each has 16 binary bits.</S>
			<S sid ="72" ssid = "28">Next, the frequency valueswhere c1…cn is a n-gram that contains the substring ci…cj; ci…cj is the n-1-gram to be esti mated, i.e., ci…cj=c1…cn1 or ci…cj=c2…cn; f( ) denotes the string frequency; α represents the cohesion factor of the n-1-gram string, that is, the ability of independent word building.</S>
			<S sid ="73" ssid = "29">The closer to 1 the value of α is, the more possible meaningful key term ci…cj is.</S>
	</SECTION>
	<SECTION title="Multiple Feature Representation. " number = "5">
			<S sid ="74" ssid = "1">Local Feature (LF) is constructed based on neighboring tokens and the token itself.</S>
			<S sid ="75" ssid = "2">There are two types of contextual information to beconsidered when extracting LFs, namely inter nal lexical and external contextual information.</S>
			<S sid ="76" ssid = "3">(1) Term length (Len) – Aims to consider the length of the translation candidate.</S>
			<S sid ="77" ssid = "4">(2) Phonetic Value (PV) – Aims to investigate the phonetic similarity between an OOV termand its translation candidates.</S>
			<S sid ="78" ssid = "5">Because the as sociated syllabification representations can often be found between Chinese and English syllables with fewer ambiguities, the syllabification has become an effective channel in phonetic feature expression.</S>
			<S sid ="79" ssid = "6">PV means that for measuring the edit distance similarity between the syllabification sequences of an OOV term and its candidates, the processing is executed according to the specific linguistic rules.</S>
			<S sid ="80" ssid = "7">Global Feature (GF) is extracted from other occurrences of the same or similar tokens in PV (S , T ) = 1 − EditDist (S OOV &apos; , TOOV &apos;) (2) the Web docume nt set.</S>
			<S sid ="81" ssid = "8">The commo n case in OOV OOV Len (S OOV &apos;)+ Len (TOOV &apos;)the Web based OOV term translation is that where SOOV and TOOV denote the OOV term in the source language and its translation candidate in the target language respectively, SOOV’ and TOOV’ are the character strings after the syllabification and removing the vowels, EditDist( , ) indicates the edit distance between two strings, and Len( ) is the string length.</S>
			<S sid ="82" ssid = "9">(3) Length Ratio of OOV Term and Its Translation Candidate (LR) – Aims to explore the composition possibility that the extracted key term can be regarded as the translation for an OOV term.</S>
			<S sid ="83" ssid = "10">An OOV term and its translation should have the similar length, so the LR value is close to 1 as possible.</S>
			<S sid ="84" ssid = "11">A Chinese term is segmented into significant pieces first, and the number of pieces is taken as its length.</S>
			<S sid ="85" ssid = "12">For example, “非典型肺炎” (SARS) is segmented into “非” (non), “典型” (typical) and “肺炎” (pneumonia), and its length is 3.</S>
			<S sid ="86" ssid = "13">For an English term, the number of words is counted as the length.</S>
			<S sid ="87" ssid = "14">If there is only one word composed of capital letters, its length is defined as the number of letters, e.g., “SARS” has the length of 4.</S>
			<S sid ="88" ssid = "15">Thus the LR value of “SARS” the translation candidates in the previous parts of Web documents will often occur with the same or similar forms in the latter parts.</S>
			<S sid ="89" ssid = "16">The contextual information from the same and other Web documents may play an important role in determining the final translation.</S>
			<S sid ="90" ssid = "17">To utilize such global information, GFs are constructed based on the characteristics of Web documents.</S>
			<S sid ="91" ssid = "18">(1) Global Term Frequency (G_Freq) – Aims to utilize the frequency information that an OOV term and its translation candidates appear in the Web document set.</S>
			<S sid ="92" ssid = "19">It is always the most important feature and includes four parameters.</S>
			<S sid ="93" ssid = "20">FreqSOOV denotes the frequency of SOOV in all the returned webpage snippets.</S>
			<S sid ="94" ssid = "21">TFTOOV indicates the number of TOOVs in all the snippets.</S>
			<S sid ="95" ssid = "22">DFTOOV represents the number of snippets that contain TOOV.</S>
			<S sid ="96" ssid = "23">CO_Freq means the number of snippets that contain both SOOV and TOOV, i.e, co-occurrence frequency.</S>
			<S sid ="97" ssid = "24">(2) Chi-Square (χ2) Feature Value (CV) – Aims to evaluate the semantic similarity between an OOV term and its translation candidates by their occurrence in Web documents.</S>
			<S sid ="98" ssid = "25">and its candidate “非典型肺炎” is 4/3=1.3.</S>
			<S sid ="99" ssid = "26">CV 2 (SOOV , TOOV ) N × (a × d − b × c )2 = (a + b)× (a + c )× (b + d )× (c + d ) (4)(4) Phonetic and Semantic Integration Fea ture (P&amp;S_IF) – Aims to consider the phonetic information and senses of an OOV term and its candidates synthetically.</S>
			<S sid ="100" ssid = "27">It is set up for mul- ti-word OOV terms, especially for NEs and new terms.</S>
			<S sid ="101" ssid = "28">Each constituent can be translated by the phonetic information or senses.</S>
			<S sid ="102" ssid = "29">P &amp; S _ IF (SOOV , TOOV ) LScore(SOOV , TOOV )+ PV (SOOV &apos; &apos;, TOOV &apos; &apos;) where a is the number of snippets that contain both SOOV and TOOV, b is the number of snippets that contain SOOV but do not contain TOOV, c is the number of snippets that do not contain SOOV but contain TOOV, d is the number of snippets that do not contain neither of SOOV and TOOV, and N=a+b+c+d.</S>
			<S sid ="103" ssid = "30">(3) Co-occurrence Distance (CO_Dist) – = LScore(S OOV , TOOV )+ 1 (3) Aims to investigate the distance between an OOV term and its candidates in Web docu where LScore( , ) is the matching word number of non-transliteration words in SOOV and TOOV, while SOOV’’ and TOOV’’ are the remaining strings of SOOV and TOOV after computing LScore.</S>
			<S sid ="104" ssid = "31">For example, given SOOV “Capitoline Museum” and its TOOV “卡比多里尼博物馆” (Capitoline Museum), the non-transliteration words “Museum” and “博物馆” (museum) are matched, then LScore(SOOV, TOOV)=1; the PV value between the remaining strings “Capitoline” and “卡比多里尼” (Capitoline) is 0.8, so the final P&amp;S_IF value is 1.8/2=0.9.</S>
			<S sid ="105" ssid = "32">ments.</S>
			<S sid ="106" ssid = "33">This distance is often very closer.</S>
			<S sid ="107" ssid = "34">For each snippet that contains both SOOV and TOOV, three positions are considered, that is, the first position that SOOV and TOOV appear (p1), the second position (p2) and the last one (p3).</S>
			<S sid ="108" ssid = "35">In the following snippet, SOOV is “AARP” andTOOV is “美国退休者协会” (America Associa tion of Retired Persons, AARP).</S>
			<S sid ="109" ssid = "36">p1SOOV=6, p2SOOV=62, p3SOOV=97; p1TOOV=54, p2TOOV=-1, p3TOOV=54.</S>
			<S sid ="110" ssid = "37">The position is indexed from 0 and p2TOOV=-1 means only one candidate exists in the snippet.</S>
			<S sid ="111" ssid = "38">Then the nearest position pair p2SOOV and p1TOOV can be found for this example.</S>
			<S sid ="112" ssid = "39">The distance Dist between SOOV and TOOV is computed as: “TOOV (SOOV)” or “SOOV (TOOV)”, then this feature is set as 1.</S>
			<S sid ="113" ssid = "40">(4) Special Mark Word (SMW) – This is an intuitive feature.</S>
			<S sid ="114" ssid = "41">Within a certain co-occurrence distance (usually less than 10 characters) between an OOV term and its can Dist(S T ) = ⎧piSOOV − pjTOOV − Len(TOOV ), pi &gt; pj OOV OOV didate s, if there is such a term like “全称 ” (full OOV , OOV ⎨pj − pi − Len(S ), pi &lt; pj (5) ⎩ TOOV SOOV OOV SOOV TOOV name), “叫” (be named as), “译为” (be trans Given the example above, Dist=p2SOOVp1TOOV-7 =6254-7=1, that is, SOOV and TOOV are a left bracket ‘(’ apart.</S>
			<S sid ="115" ssid = "42">Finally, the average distance CODist in the snippet set can be computed as: CO _ Dist(SOOV , TOOV ) = AVG _ Dist(SOOV , TOOV ) Sum(Dist ) lated as …), “名称” (name), or “(或/又)称为” ((or/also) be called as …), or within 5 characters if there are some punctuations like “( )”, “[ ]” and “（）”, then this feature is set as 1.</S>
	</SECTION>
	<SECTION title="Ranking based on Ranking SVM. " number = "6">
			<S sid ="116" ssid = "1">= CO _ Freq(S OOV , TOOV ) (6) For the OOV term translation based on Web where Sum( ) is the sum of Dist in each snippet.</S>
			<S sid ="117" ssid = "2">(4) Rank Value (RV) – Aims to consider the rank for translation candidates in the Web document set.</S>
			<S sid ="118" ssid = "3">It includes five parameters.</S>
			<S sid ="119" ssid = "4">Top_Rank (T_Rank) is the rank of the snippet that first contains TOOV and given by the search engine.</S>
			<S sid ="120" ssid = "5">Average_Rank (A_Rank) is the average position of TOOV in the returned snippets.</S>
			<S sid ="121" ssid = "6">mining, another difficulty is how to evaluate the relevance between an OOV term and its translation candidates, that is, how to rank the translation candidates from “best” to “worst”.</S>
			<S sid ="122" ssid = "7">The candidate ranking can be regarded as a binary classification problem.</S>
			<S sid ="123" ssid = "8">However, usually only highly related fragments of OOV terms can be found, rather than their correct A _ Rank(T ) = Sum(Rank ) (7) translations.</S>
			<S sid ="124" ssid = "9">Instead of regarding the candidate OOV DF OOV (TOOV ) ranking as binary classification, it is solved as where Sum( ) denotes the rank sum of each snippet.</S>
			<S sid ="125" ssid = "10">Simple_Rank (S_Rank) is computed as S_Rank(TOOV)=TFTOOV(TOOV)*Len(TOOV), which aims at investigating the impact of the frequency and length of TOOV on ranking.</S>
			<S sid ="126" ssid = "11">R_Rank is utilized as a comparison basis.</S>
			<S sid ="127" ssid = "12">an Ordinal Regression problem.</S>
			<S sid ="128" ssid = "13">Ranking SVM maps different objects into a certain kind of order relation.</S>
			<S sid ="129" ssid = "14">The key is modeling the judgements for user’s preferences, and then the constraint relations for ranking can be derived (Herbrich et al., 1999; Xu et al., 2005).</S>
			<S sid ="130" ssid = "15">R _ Rank(T ) = β × TOOV + (1 − β )× TFT (TOOV ) (8) For a given OOV term SOOV, if there are two OOV MAX _WL FreqS OOV (SOOV ) translation candidates T OOVi and T OOVj, the pre where β is set as 0.25 empirically, |TOOV| is the length of TOOV, and MAX_WL denotes the maximum length of candidate terms.</S>
			<S sid ="131" ssid = "16">DF_Rank (D_Rank) is similar to S_Rank and computed as D_Rank(TOOV)=DFTOOV(TOOV)*Len(TOOV).</S>
			<S sid ="132" ssid = "17">ference judgement can be formulated as TOOVi&gt;SOOVTOOVj.</S>
			<S sid ="133" ssid = "18">Thus more training samples are constructed, which contain multiple constraint features.</S>
			<S sid ="134" ssid = "19">The preference judgement can be transformed into the feature function as: Boolean Feature (BF) is a binary feature and f (w, T , S ) &gt; S f (w, T , S ) (9) equivalent to a heuristic rule designed for the particular relationship between an OOV term and its translation candidates.</S>
			<S sid ="135" ssid = "20">BFs are used to where w is a parameter and represented as a n- dimensional vector w={w1, w2, …, wn}.</S>
			<S sid ="136" ssid = "21">This feature function can also be expressed as: explore the different occurrence forms with f (w, T , S p ) = ∑ w LF (T , S )+ higher possibility for the translation candidates OOV q OOV k k k =1 n OOV OOV in Web documents.</S>
			<S sid ="137" ssid = "22">(1) Position Distance with ∑ wl GFl (TOOV , SOOV )+ ∑ wm BFm (TOOV , SOOV ) (10) OOV Term (PD_SOOV) – If TOOV occurs close l = p +1 m =q +1 to SOOV (within 10 characters), then this feature is set as 1, else -1.</S>
			<S sid ="138" ssid = "23">(2) Neighbor Relationship with OOV Term (NR_SOOV) – If TOOV occurs prior or next to SOOV, then this feature is set as 1.</S>
			<S sid ="139" ssid = "24">(3) Bracket Neighbor Relationship with OOV Term (BNR_SOOV) – If TOOV locates where LFk( , ), GFl( , ) and BFm( , ) are the local, global and Boolean feature representa tion respectively.</S>
			<S sid ="140" ssid = "25">These three kinds of feature representation are incorporated as a whole and represented as a feature function family with the multidimensional feature vector in (11).</S>
			<S sid ="141" ssid = "26">prior or next to SOOV and occurs with the form f (w, TOOV , SOOV ) = w ⋅ h(TOOV , SOOV ) (11) That is the ranking results for candidates.</S>
			<S sid ="142" ssid = "27">Thus the relevance for each feature vector x (translation candidate) containing a group of features can be evaluated through Ranking SVM.</S>
	</SECTION>
	<SECTION title="Experiment and Analysis. " number = "7">
			<S sid ="143" ssid = "1">7.1 Data Set and Evaluation Metrics.</S>
			<S sid ="144" ssid = "2">For the performance evaluation, 4,593 English NEs are selected from the English corpus of the NER task in CoNLL2003.</S>
			<S sid ="145" ssid = "3">The test set contains 446 Person Names (PRNs), 329 Location Names (LCNs) and 455 Organization Names (OGNs), and the remaining is taken as the training set (including 1,137 PRNs, 1,152 LCNs and 1,074 OGNs) through manually tagging.</S>
			<S sid ="146" ssid = "4">Additionally, 300 English new terms are chosen randomly from 9 categories, including movie name, book title, brand name, terminology, idiom, rare animal name, rare PRN and OGN.</S>
			<S sid ="147" ssid = "5">Such terms are used to investigate the generalization ability of our model.</S>
			<S sid ="148" ssid = "6">Top-N-Inclusion-Rate is used as a measurement for the translation performance.</S>
			<S sid ="149" ssid = "7">For a set of OOV terms to be translated, its Top-N- Inclusion-Rate is defined as the percentage of the OOV terms whose translations could be found in the first N extracted translations.</S>
			<S sid ="150" ssid = "8">7.2 Experiment on Parameter Setting.</S>
			<S sid ="151" ssid = "9">For Chinese key term extraction, the test on the threshold α is performed.</S>
			<S sid ="152" ssid = "10">As shown in Figure 3, when the lower bound of α is set as 0.4, the best performance can be achieved.</S>
			<S sid ="153" ssid = "11">Figure 3.</S>
			<S sid ="154" ssid = "12">Results for α value setting.To get the most relevant candidates into top 10 before the final ranking, an initial ranking test is performed on S_Rank, R_Rank and D_Rank.</S>
			<S sid ="155" ssid = "13">It can be seen from Figure 4 that D_Rank exhibits the better performance.</S>
			<S sid ="156" ssid = "14">Figure 4.</S>
			<S sid ="157" ssid = "15">Results for initial ranking manner.</S>
			<S sid ="158" ssid = "16">To find how many returned webpage snippets are suitable for the translation acquisition, the test on the snippet number is performed.</S>
			<S sid ="159" ssid = "17">As shown in Figure 5, the best performance can be obtained by using 200 snippets.</S>
			<S sid ="160" ssid = "18">Figure 5.</S>
			<S sid ="161" ssid = "19">Results for webpage snippet number.</S>
			<S sid ="162" ssid = "20">7.3 Experiment on Multiple Feature Fusion.</S>
			<S sid ="163" ssid = "21">To verify the effectiveness for multiple feature fusion, the test on the feature combination for OOV term translation is implemented.</S>
			<S sid ="164" ssid = "22">As shown in Table 1, the highest accuracy (the percentage of the correct translations in all the extracted translations) of 83.1367% can be acquired by using all the features.</S>
			<S sid ="165" ssid = "23">-LR -P IF -CV Table 1.</S>
			<S sid ="166" ssid = "24">Results for feature combination.</S>
			<S sid ="167" ssid = "25">In Table 1, ‘-’ before the specific feature denotes that the OOV term is translated by combining all the other features except this feature; “Reduction” represents the difference value between the translation accuracy obtained by using all the features and that by removing a specific feature.</S>
			<S sid ="168" ssid = "26">The positive “Reduction” indicates that the accuracy is improved after removing a specific feature, while the negative shows the accuracy is decreased.</S>
			<S sid ="169" ssid = "27">It can be seen from Table 1 that for mining the translations for OOV terms, the most important three features are PV, P&amp;S_IF and BNR, then LR, Len and CO_Dist.</S>
			<S sid ="170" ssid = "28">As for the frequency feature, its contribution is limited, because many translation candidates with higher PV or P&amp;S_IF values are the terms with low frequency.</S>
			<S sid ="171" ssid = "29">It shows that PV and P&amp;S_IF play a very crucial role in mining the translation candidates with low frequency.</S>
			<S sid ="172" ssid = "30">In addition, the contribution degree of CV is also positive.</S>
			<S sid ="173" ssid = "31">However, when training based on only the features that are beneficial to the whole translation performance, the best translation accuracy is 83.1243%, which is worse than that by combining all the features.</S>
			<S sid ="174" ssid = "32">From a view of the effect of the single feature on the whole translation performance, some features may have slightly negative impact.</S>
			<S sid ="175" ssid = "33">Nevertheless, through combining all the features, the multiple feature fusion mechanism can indeed efficiently improve the translation accuracy.</S>
			<S sid ="176" ssid = "34">7.4 Experiment on OOV Term Translation.</S>
			<S sid ="177" ssid = "35">Some translation examples based on different ranking patterns are given in Table 2, in which the score represents the correlation degree between the translation pair.</S>
			<S sid ="178" ssid = "36">The closer to -1 the score is, the more irrelevant the translation pair is; while the closer to 3 the score is, the more relevant the translation pair is. conventional ranking strategies, and Ranking SVM is superior to SVM and ME for translation candidate ranking.</S>
			<S sid ="179" ssid = "37">From the contrast between our model and Jiang’s method, it can be found that our approach is superior to Jiang’s and the better performance can be achieved based on the fusion of multiple features proposed in this paper.</S>
			<S sid ="180" ssid = "38">Meanwhile, it can also be observed from Table 3 that the performance for LCN and OGN translation is better, while the best performance is obtained for PRN translation.</S>
			<S sid ="181" ssid = "39">It shows that our translation model is sensitive to the category and the popularity degree of OOV term to some extent.</S>
			<S sid ="182" ssid = "40">In order to test the translation performance for the other kinds of English OOV term, another test is performed based on the OOV new terms selected randomly from 9 categories.</S>
			<S sid ="183" ssid = "41">The experimental results are shown in Table 4.</S>
			<S sid ="184" ssid = "42">Table 4.</S>
			<S sid ="185" ssid = "43">Results for other OOV terms.</S>
			<S sid ="186" ssid = "44">Furthermore, the translations for some OOV terms based on different translation manners are compared, including our proposed model, Google Translate and the Live Trans translation model developed by WKD Lab at National Taiwan University, as shown in Table 5.</S>
			<S sid ="187" ssid = "45">Table 2.</S>
			<S sid ="188" ssid = "46">OOV term translation examples.</S>
			<S sid ="189" ssid = "47">Furthermore, Jiang et al.</S>
			<S sid ="190" ssid = "48">(2007) utilized the combination of Web mining, transliteration and ME-based ranking to implement EnglishChinese PRN translation, which is very similar to our approach.</S>
			<S sid ="191" ssid = "49">To make a contrast with it, we accomplished this method on the same data set.</S>
			<S sid ="192" ssid = "50">The comparison results are shown in Table 3.</S>
			<S sid ="193" ssid = "51">Table 3.</S>
			<S sid ="194" ssid = "52">Performance comparison results.</S>
			<S sid ="195" ssid = "53">From the experimental results above, it can be concluded that the ranking based on the supervised learning significantly outperforms the Red Mansio Table 5.</S>
			<S sid ="196" ssid = "54">Comparison for different translation manners.</S>
			<S sid ="197" ssid = "55">The results above demonstrate that our model can be applicable to all kinds of OOV terms and has better translation performance.</S>
			<S sid ="198" ssid = "56">7.5 Experiment on EnglishChinese CLIR.</S>
			<S sid ="199" ssid = "57">To explore the applicability and usefulness of our OOV term translation model in EnglishChinese CLIR, four CLIR runs based on long query (terms in both title and description fields) and short query (only terms in the title field) are carried out on the English topic set (25 topics) and Chinese corpus (127,938 documents) from TREC9.</S>
			<S sid ="200" ssid = "58">(1) E-C_LongCLIR1 – using long query and the bilingual-dictionary-based query translation; (2) E-C_LongCLIR2 – using long query, the bilingual-dictionary-based query translation and our OOV term translation; (3) E-C_ShortCLIR1 – using short query and the bilingual-dictionary-based query translation; (4) E-C_ShortCLIR2 – using short query, the bilingual-dictionary-based query translation and our OOV term translation.</S>
			<S sid ="201" ssid = "59">The Precision-Recall curves and Median Average Precision (MAP) values are shown in Figure 6.</S>
			<S sid ="202" ssid = "60">Figure 6.</S>
			<S sid ="203" ssid = "61">Results for EnglishChinese CLIR combining our OOV term translation model.</S>
			<S sid ="204" ssid = "62">It can be seen from Figure 6 that the best run is E-C_LongCLIR2, and its results exceed those by another run E-C_LongCLIR1 based on long query.</S>
			<S sid ="205" ssid = "63">By adopting both query translation based on bilingual dictionary and OOV term translation, the EnglishChinese CLIR for long query has gained the significant improvement on the whole retrieval performance.</S>
			<S sid ="206" ssid = "64">Compared with the traditional query translation based on bilingual dictionary, such a combination manner is exactly a better way for query translation from the source language to the target language.</S>
			<S sid ="207" ssid = "65">Additionally, through comparing the results for the other two runs E- C_ShortCLIR1 and E-C_ShortCLIR2 based on short query, it can also be further confirmed that our OOV term translation mechanism can also support CLIR for short query effectively.</S>
			<S sid ="208" ssid = "66">7.6 Analysis and Discussion.</S>
			<S sid ="209" ssid = "67">Through analyzing the results for translation extraction and ranking, it can be found that the translation quality is highly related to the following aspects.</S>
			<S sid ="210" ssid = "68">(1) The translation results are associated with the search engine used, especially for some specific OOV terms.</S>
			<S sid ="211" ssid = "69">For example, given an OOV term “Cross-Strait Three-links”, the mining result based on Google in China is “两岸大三通”, while some meaningless information is mined by Live Trans.</S>
			<S sid ="212" ssid = "70">(2) Some terms are conventional terminologies and cannot be translated literally.</S>
			<S sid ="213" ssid = "71">For example, “Woman PaceSetter”, a proper noun with the Chinese characteristic, should be translated into “三八红旗手”, rather than “女 子的步伐” (women’s pace) or “制定” (estab lishment) given by Google Translate.</S>
			<S sid ="214" ssid = "72">(3) The proposed model is sensitive to the notability degree of OOV term.</S>
			<S sid ="215" ssid = "73">This phenomenon is the main reason why there is obvious difference among the translation performance for PRN, LCN and OGN.</S>
			<S sid ="216" ssid = "74">(4) There is a “fragment effect” in PAT-Tree-based Chinese key term extraction.</S>
			<S sid ="217" ssid = "75">The fragments of Chinese terms have become the main noisy data.</S>
			<S sid ="218" ssid = "76">Such a problem should be solved by setting the specific threshold for additional features like heuristic rules and occurrence distance.</S>
			<S sid ="219" ssid = "77">(5) Word Sense Disambiguation (WSD) should be added to improve the translation performance.</S>
			<S sid ="220" ssid = "78">Although most of OOV terms have a unique semantic definition, there are still a few OOV terms with ambiguity, e.g., “AARP” (American Association of Retired Persons or AppleTalk Address Resolution Protocol).</S>
			<S sid ="221" ssid = "79">(6) The ranking pattern based on the supervised learning is able to synthesize various feature representations for translation candidates.</S>
			<S sid ="222" ssid = "80">Thus the rank for a candidate can be precisely predicted through tagging and training.</S>
	</SECTION>
	<SECTION title="Conclusions. " number = "8">
			<S sid ="223" ssid = "1">In this paper, the proposed model improves the acquirement ability for OOV term translation through Web mining, and solves the translation pair selection and evaluation in a novel way by fusing multiple features and introducing the supervised learning based on Ranking SVM.</S>
			<S sid ="224" ssid = "2">Furthermore, it is significant to apply the key techniques in machine translation into OOV term translation, such as OOV term recognition, statistical machine learning, alignment of sentence and phoneme, and WSD.</S>
			<S sid ="225" ssid = "3">All these aspects will be our research focus in the future.</S>
	</SECTION>
	<SECTION title="Acknowledgements">
			<S sid ="226" ssid = "4">This work is supported by National Natural Science Fund of China (No. 60773124), Shanghai Natural Science Fund (No. 09ZR1403000), National Science and Technology Pillar Program of China (No. 2007BAH09B03), 973 Program of China (No. 2010CB327906), Shanghai Municipal R&amp;D Foundation (No. 08dz1500109) and Shanghai Key Laboratory of Intelligent Information Processing.</S>
			<S sid ="227" ssid = "5">Cheng Jin from Fudan University is the corresponding author.</S>
	</SECTION>
</PAPER>
