Relation Extraction Using Label Propagation Based Semi-supervised
Learning


Jinxiu Chen1	Donghong Ji1	Chew Lim Tan2	Zhengyu Niu1
1Institute for Infocomm Research	2Department of Computer Science
21 Heng Mui Keng Terrace	National University of Singapore
119613 Singapore	117543 Singapore
{jinxiu,dhji,zniu}@i2r.a-star.edu.sg	tancl@comp.nus.edu.sg






Abstract


Shortage of manually labeled data is an 
obstacle to supervised relation extraction 
methods.  In this paper we investigate a 
graph based semi-supervised learning al- 
gorithm, a label propagation (LP) algo- 
rithm, for relation extraction. It represents 
labeled and unlabeled examples and their 
distances as the nodes and the weights of 
edges of a graph, and tries to obtain a la- 
beling function to satisfy two constraints:
1) it should be fixed on the labeled nodes,
2) it should be smooth on the whole graph. 
Experiment results on the ACE corpus 
showed that this LP algorithm achieves 
better performance than SVM when only 
very few labeled examples are available, 
and it also performs better than bootstrap- 
ping for the relation extraction task.


1   Introduction

Relation extraction is the task of detecting and 
classifying relationships between two entities from 
text.  Many machine learning methods have been 
proposed to address this problem, e.g., supervised 
learning algorithms (Miller et al., 2000; Zelenko et 
al., 2002; Culotta and Soresen, 2004; Kambhatla,
2004;  Zhou et al.,  2005), semi-supervised learn- 
ing algorithms (Brin, 1998; Agichtein and Gravano,
2000; Zhang, 2004), and unsupervised learning al- 
gorithms (Hasegawa et al., 2004).
  Supervised methods for relation extraction per- 
form well on the ACE Data, but they require a large


amount of manually labeled relation instances. Un- 
supervised methods do not need the definition of 
relation types and manually labeled data, but they 
cannot detect relations between entity pairs and its 
result cannot be directly used in many NLP tasks 
since  there  is  no  relation type  label  attached to 
each instance in clustering result. Considering both the 
availability of a large amount of untagged cor- pora 
and direct usage of extracted relations, semi- 
supervised learning methods has received great at- 
tention.
  DIPRE (Dual Iterative Pattern Relation Expan- sion)  
(Brin,  1998)  is  a  bootstrapping-based sys- tem that 
used a pattern matching system as clas- sifier to 
exploit the duality between sets of pat- terns and 
relations.  Snowball (Agichtein and Gra- vano, 2000) is 
another system that used bootstrap- ping techniques for 
extracting relations from un- structured text.  Snowball 
shares much in common with DIPRE, including the 
employment of the boot- strapping framework as well 
as the use of pattern matching to extract new 
candidate relations.   The third system approaches 
relation classification prob- lem with bootstrapping on 
top of SVM, proposed by Zhang (2004). This system 
focuses on the ACE sub- problem, RDC, and extracts 
various lexical and syn- tactic features for the 
classification task.  However, Zhang (2004)’s method 
doesn’t actually “detect” re- laitons but only performs 
relation classification be- tween two entities given that 
they are known to be related.
  Bootstrapping works by iteratively classifying un- 
labeled examples and adding confidently classified 
examples into labeled data using a model learned 
from augmented labeled data in previous iteration. It








129

Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 129–136, 
Sydney, July 2006. Qc 2006 Association for Computational Linguistics


can be found that the affinity information among un- 
labeled examples is not fully explored in this boot- 
strapping process.
  Recently a promising family of semi-supervised 
learning algorithm is introduced, which can effec- 
tively combine unlabeled data with labeled data in 
learning process by exploiting manifold structure 
(cluster structure) in data (Belkin and Niyogi, 2002; 
Blum and Chawla, 2001; Blum et al., 2004; Zhu 
and Ghahramani, 2002; Zhu et al., 2003).  These 
graph-based semi-supervised methods usually de- 
fine a graph where the nodes represent labeled and 
unlabeled examples in a dataset, and edges (may be 
weighted) reflect the similarity of examples.  Then 
one wants a labeling function to satisfy two con- 
straints at the same time: 1) it should be close to the 
given labels on the labeled nodes, and 2) it should be 
smooth on the whole graph. This can be expressed 
in a regularization framework where the first term 
is a loss function, and the second term is a regu- 
larizer. These methods differ from traditional semi- 
supervised learning methods in that they use graph 
structure to smooth the labeling function.
  To the best of our knowledge, no work has been 
done on using graph based semi-supervised learning 
algorithms for relation extraction.  Here we inves- 
tigate a label propagation algorithm (LP) (Zhu and 
Ghahramani, 2002) for relation extraction task. This 
algorithm works by representing labeled and unla- 
beled examples as vertices in a connected graph, 
then propagating the label information from any ver- 
tex to nearby vertices through weighted edges itera- 
tively, finally inferring the labels of unlabeled exam- 
ples after the propagation process converges. In this 
paper we focus on the ACE RDC task1.


2   The Proposed Method

2.1   Problem Definition
The problem of relation extraction is to assign an ap- 
propriate relation type to an occurrence of two entity 
pairs in a given context. It can be represented as fol- 
lows:
R → (Cpre, e1, Cmid, e2, Cpost) 	(1)

where e1 and e2 denote the entity mentions, and 
Cpre,Cmid,and Cpost are the contexts before, be- 
tween and after the entity mention pairs. In this pa- 
per, we set the mid-context window as the words be- 
tween the two entity mentions and the pre- and post- 
context as up to two words before and after the cor- 
responding entity mention.
Let X  = {xi}i=1  be a set of contexts of occur-
rences of all the entity mention pairs, where xi  rep-
resents the contexts of the i-th occurrence, and n is 
the total number of occurrences.  The first l exam-
ples (or contexts) are labeled as yg ( yg ∈ {rj }R    ,
rj  denotes relation type and R is the total number of 
relation types). The remaining u(u = n − l) exam-
ples are unlabeled.
  Intuitively, if two occurrences of entity mention 
pairs have the similarity context, they tend to hold 
the same relation type. Based on the assumption, we 
define a graph where the vertices represent the con- 
texts of labeled and unlabeled occurrences of entity 
mention pairs, and the edge between any two ver- 
tices xi and xj  is weighted so that the closer the ver- 
tices in some distance measure, the larger the weight 
associated with this edge. Hence, the weights are de- 
fined as follows:
s2


  The rest of this paper is organized as follows. Sec- 
tion 2 presents related work.  Section 3 formulates


Wij  = exp(−


ij ) 	(2)
α2


relation extraction problem in the context of semi- 
supervised learning and describes our proposed ap- 
proach. Then we provide experimental results of our 
proposed method and compare with a popular su- 
pervised learning algorithm (SVM) and bootstrap- 
ping algorithm in Section 4.  Finally we conclude 
our work in section 5.

  1    http://www.ldc.upenn.edu/Projects/ACE/, Three tasks of 
ACE program:  Entity Detection and Tracking (EDT), Rela- 
tion Detection and Characterization (RDC), and Event Detec- 
tion and Characterization (EDC)


where sij  is the similarity between xi  and xj  calcu-
lated by some similarity measures, e.g., cosine sim- 
ilarity, and α is used to scale the weights.  In this 
paper, we set α as the average similarity between la- 
beled examples from different classes.

2.2   A Label Propagation Algorithm
In the LP algorithm, the label information of any 
vertex in a graph is propagated to nearby vertices 
through weighted edges until a global stable stage is 
achieved. Larger edge weights allow labels to travel


through easier. Thus the closer the examples are, the 
more likely they have similar labels.
  We define soft label as a vector that is a proba- 
bilistic distribution over all the classes.  In the la- 
bel propagation process, the soft label of each initial 
labeled example is clamped in each iteration to re-
plenish label sources from these labeled data. Thus


Step 5 : Assign xh(l + 1 ≤ h ≤ n) with a label:
yh = argmaxj Yhj .

  The above algorithm can ensure that the labeled 
data YL never changes since it is clamped in Step 3. 
Actually we are interested in only YU .  This algo- 
rithm has been shown to converge to a unique solu-



U	t→∞


U  = (I − T¯


)− Tul YL  (Zhu


the labeled data act like sources to push out labels


tion Yˆ


= lim 	Y t


uu 	1 ¯	0


through unlabeled data.   With this push from la-


and Ghahramani, 2002). Here, T¯


and T¯


are ac-


beled examples, the class boundaries will be pushed 
through edges with large weights and settle in gaps 
along edges with small weights. Hopefully, the val-


quired by splitting matrix T¯ after the l-th row and 
the l-th column into 4 sub-matrices. And I is u × u
identity matrix. We can see that the initialization of


0	0


ues of Wij across different classes would be as small
as possible and the values of Wij  within the same 
class would be as large as possible. This will make 
label propagation to stay within the same class. This 
label propagation process will make the labeling 
function smooth on the graph.
Define an n × n probabilistic transition matrix T
wij


YU in this solution is not important, since YU does
not affect the estimation of Yˆ  .

3   Experiments and Results

3.1   Feature Set
Following (Zhang, 2004), we used lexical and syn- 
tactic features in the contexts of entity pairs, which 
are extracted and computed from the parse trees de-


Tij  = P (j → i) = �n
k=1


(3)


rived from Charniak Parser (Charniak, 
1999) and the
Chunklink script 2 written by Sabine 
Buchholz from


where Tij  is the probability to jump from vertex xj
to vertex xi.   We define a n × R label matrix Y ,
where Yij  representing the probabilities of vertex yi
to have the label rj .
  Then the label propagation algorithm consists the 
following main steps:

Step1 : Initialization
• Set the iteration index t = 0;
• Let Y 0 be the initial soft labels attached to
each vertex, where Y 0 = 1 if yi is label rj


Tilburg University.

Words: Surface tokens of the two entities and 
words in the three contexts.

Entity Type: the entity type of both entity men- 
tions, which can be PERSON, ORGANIZA- 
TION, FACILITY, LOCATION and GPE.

POS features: Part-Of-Speech tags corresponding 
to all tokens in the two entities and words in 
the three contexts.


and 0 otherwise.
• Let Y 0 be the top l rows of Y 0 and Y 0



Chunking features: This category of features are


L	U


be the remaining u rows. Y 0 is consistent
with the labeling in labeled data and the 
initialization of Y 0 can be arbitrary.

Step 2 :   Propagate  the  labels  of  any  vertex  to 
nearby  vertices  by  Y t+1   =  T Y t  ,  where 
T  is  the  row-normalized  matrix  of  T ,  i.e.
Tij    = Tij / �k Tik , which can maintain the
class probability interpretation.

Step 3 : Clamp the labeled data, that is, replace the 
top l row of Y t+1 with Y 0.

Step 4 : Repeat from step 2 until Y converges.


extracted from the chunklink representation,
which includes:
• Chunk tag information of the two enti- ties 
and words in the three contexts. The “0” tag 
means that the word is not in any chunk.   
The “I-XP” tag means that this
word is inside an XP chunk. The “B-XP” by 
default means that the word is at the 
beginning of an XP chunk.
• Grammatical function of the two enti-
ties and words in the three contexts. The
2 Software available at http://ilk.uvt.nl/∼sabine/chunklink/


last word in each chunk is its head, and 
the function of the head is the function of 
the whole chunk. “NP-SBJ” means a NP 
chunk as the subject of the sentence. The 
other words in a chunk that are not the 
head have “NOFUNC” as their function.
• IOB-chains of the heads of the two enti-
ties. So-called IOB-chain, noting the syn-
tactic categories of all the constituents on 
the path from the root node to this leaf 
node of tree.



Table 1: Frequency of Relation SubTypes in the ACE training 
and devtest corpus.





  The position information is also specified in the 
description of each feature above.   For example, 
word features with position information include:
1) WE1 (WE2): all words in e1 (e2)
2) WHE1 (WHE2): head word of e1 (e2)
3) WMNULL: no words in Cmid
4) WMFL: the only word in Cmid
5) WMF, WML, WM2, WM3, ...: first word, last
word, second word, third word, ...in Cmid  when at 
least two words in Cmid
  6) WEL1, WEL2, ...: first word, second word, ... 
before e1
7) WER1, WER2, ...: first word, second word, ...

















J S(q, r) = 1 [D
2	KL

















(q p¯) + DKL

















(r p¯)]	(4)


after e2
We combine the above lexical and syntactic features 
with their position information in the contexts to 
form context vectors. Before that, we filter out low 
frequency features which appeared only once in the
dataset.



DKL (q p¯) =     q(y)(log
y

DKL (r p¯) =     r(y)(log
y

where p¯ = 1


q(y)
p¯(y)

r(y)
p¯(y)



) 	(5)



) 	(6)




3.2   Similarity Measures

The similarity sij  between two occurrences of entity 
pairs is important to the performance of the LP al- 
gorithm. In this paper, we investigated two similar- 
ity measures, cosine similarity measure and Jensen- 
Shannon (JS) divergence (Lin, 1991).  Cosine sim- 
ilarity is commonly used semantic distance, which 
measures the angle between two feature vectors. JS 
divergence has ever been used as distance measure 
for document clustering, which outperforms cosine 
similarity based document clustering (Slonim et al.,
2002). JS divergence measures the distance between 
two probability distributions if feature vector is con- 
sidered as probability distribution over features. JS 
divergence is defined as follows:


2 (q + r) and J S(q, r) represents JS
divergence between probability distribution q(y) and
r(y) (y is a random variable), which is defined in 
terms of KL-divergence.

3.3	Experimental Evaluation
3.3.1	Experiment Setup
  We evaluated this label propagation based rela- 
tion extraction method for relation subtype detection 
and characterization task on the official ACE 2003 
corpus. It contains 519 files from sources including 
broadcast, newswire, and newspaper. We dealt with 
only intra-sentence explicit relations and assumed 
that all entities have been detected beforehand in the 
EDT sub-task of ACE. Table 1 lists the types and 
subtypes of relations for the ACE Relation Detection 
and Characterization (RDC) task, along with their


Table 2: The Performance of SVM and LP algorithm with different sizes of labeled data for relation detection on relation subtypes. 
The LP algorithm is run with two similarity measures: cosine similarity and JS divergence.


S
V
M
L
P
C
o
s
i
n
e
L
P
J
 
S
Per
cen
tag
e
P	R	F
P	R	F
P	R	F
1
%
1
0
%
2
5
%
5
0
%
7
5
%
1
0
0
%
35.
9	32.6	34.4
51.
3	41.5	45.9
67.
1	52.9	59.1
74.
0	57.8	64.9
77.
6	59.4	67.2
79.
8	62.9	70.3
58.
3	56.1	57.1
64.
5	57.5	60.7
68.
7	59.0	63.4
69.
9	61.8	65.6
71.
8	63.4	67.3
73.
9	66.9	70.2
58.
5	58.7	58.5
64.
6	62.0	63.2
68.
9	63.7	66.1
70.
1	64.1	66.9
72.
4	64.8	68.3
74.
2	68.2	71.1


Table 3: The performance of SVM and LP algorithm with different sizes of labeled data for relation detection and classification 
on relation subtypes. The LP algorithm is run with two similarity measures: cosine similarity and JS divergence.


S
V
M
L
P
C
o
s
i
n
e
L
P
J
 
S
Per
cen
tag
e
P	R	F
P	R	F
P	R	F
1
%
1
0
%
2
5
%
5
0
%
7
5
%
1
0
0
%
31.
6	26.1	28.6
39.
1	32.7	35.6
49.
8	35.0	41.1
52.
5	41.3	46.2
58.
7	46.7	52.0
60.
8	48.9	54.2
39.
6	37.5	38.5
45.
9	39.6	42.5
51.
0	44.5	47.3
54.
1	48.6	51.2
56.
0	52.0	53.9
56.
2	52.3	54.1
40.
1	38.0	39.0
46.
2	41.6	43.7
52.
3	46.0	48.9
54.
9	50.8	52.7
56.
1	52.6	54.3
56.
3	52.9	54.6




frequency of occurrence in the ACE training set and 
test set.  We constructed labeled data by randomly 
sampling some examples from ACE training data 
and additionally sampling examples with the same 
size from the pool of unrelated entity pairs for the 
“NONE” class. We used the remaining examples in 
the ACE training set and the whole ACE test set as 
unlabeled data.  The testing set was used for final 
evaluation.

3.3.2   LP vs. SVM
  Support Vector Machine (SVM) is a state of the 
art technique for relation extraction task. In this ex- 
periment, we use LIBSVM tool 3 with linear kernel 
function.
  For comparison between SVM and LP, we ran 
SVM and LP with different sizes of labeled data 
and evaluate their performance on unlabeled data 
using precision, recall and F-measure.  Firstly, we 
ran SVM or LP algorithm to detect possible rela- 
tions from unlabeled data. If an entity mention pair 
is classified not to the “NONE” class but to the other
24 subtype classes, then it has a relation. Then con- 
struct labeled datasets with different sampling set
size l, including 1% × Ntrain, 10% × Ntrain, 25% ×
Ntrain, 50% ×Ntrain, 75% ×Ntrain, 100% ×Ntrain
(Ntrain is the number of examples in the ACE train-

    3 LI BSV M : a library for support vector machines.  Soft- 
ware available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.


ing set). If any relation subtype was absent from the 
sampled labeled set, we redid the sampling. For each 
size, we performed 20 trials and calculated average 
scores on test set over these 20 random trials.
  Table 2 reports the performance of SVM and LP 
with different sizes of labled data for relation detec- 
tion task. We used the same sampled labeled data in 
LP as the training data for SVM model.
  From Table 2,  we see that both LPC osine  and 
LPJ S achieve higher Recall than SVM. Specifically, 
with small labeled dataset (percentage of labeled
data ≤ 25%), the performance improvement by LP
is significant. When the percentage of labeled data
increases from 50% to 100%, LPC osine is still com- 
parable to SVM in F-measure while LPJ S achieves 
slightly better F-measure than SVM. On the other 
hand, LPJ S consistently outperforms LPC osine.
  Table 3 reports the performance of relation clas- 
sification by using SVM and LP with different sizes 
of labled data.  And the performance describes the 
average values of Precision, Recall and F-measure 
over major relation subtypes.
  From Table 3, we see that LPC osine and LPJ S out- 
perform SVM by F-measure in almost all settings 
of labeled data, which is due to the increase of Re- 
call. With smaller labeled dataset (percentage of la-
beled data ≤ 50%), the gap between LP and SVM
is larger.  When the percentage of labeled data in-



0.6

0.55


1.5

1

0.5


1.5

1

0.5



0.5

0.45

0.4

0.35

0.3




SVM 
LP_Cosine 
LP_JS



0

-0.5

-1

-1.5

-2
-3 	-2 	-1 	0 	1 	2
(
a
)
 



0

-0.5

-1

-1.5

-2
-3 	-2 	-1 	0 	1 	2
(
b
)
 



0.25




1% 	10% 	25%     50% 	75%     100%
Perc
enta
ge of 
Labe
led 
Exa
mple
s



1.5

1

0.5



1.5

1

0.5



0 	0



Figure 1: Comparison of the performance of SVM
and LP with different sizes of labeled data


creases from 75% to 100%, the performance of LP



-0.5

-1

-1.5

-2
-3 	-2 	-1 	0 	1 	2
(c) 



-0.5

-1

-1.5

-2
-3 	-2 	-1 	0 	1 	2
(d) 


algorithm is still comparable to SVM. On the other 
hand, the LP algorithm based on JS divergence con- 
sistently outperforms the LP algorithm based on Co- 
sine similarity. Figure 1 visualizes the accuracy of 
three algorithms.
  As shown in Figure 1, the gap between SVM 
curve and LPJ S curves is large when the percentage 
of labeled data is relatively low.

3.3.3   An Example
  In Figure 2, we selected 25 instances in train- 
ing set and 15 instances in test set from the ACE 
corpus,which covered five relation types.    Using 
I somap tool 4 , the 40 instances with 229 feature di- 
mensions are visualized in a two-dimensional space 
as the figure.  We randomly sampled only one la- 
beled example for each relation type from the 25 
training examples as labeled data.  Figure 2(a) and
2(b) show the initial state and ground truth result re- 
spectively. Figure 2(c) reports the classification re-


Figure 2: An example: comparison of SVM and 
LP
algorithm on a data set from ACE corpus.  ◦  
and
6 denote the unlabeled examples in training set 
and
test set respectively, and other symbols (o, ×, ✷, 
+
and v) represent the labeled examples with 
respec-
tive relation type sampled from training 
set.


strategy achieves better performance than the 
local consistency based SVM strategy when the 
size of labeled data is quite small.

3.3.4   LP vs. 
Bootstrapping
  In (Zhang, 2004), they perform relation classifi- 
cation on ACE corpus with bootstrapping on top 
of SVM. To compare with their proposed 
Bootstrapped SVM algorithm, we use the same 
feature stream set- ting and randomly selected 100 
instances from the training data as the size of 
initial labeled data.
Table 4 lists the performance of the bootstrapped
SVM method from (Zhang, 2004) and LP 
method


sult on test set by SVM (accuracy =  4


= 26.7%),


with 100 seed labeled examples for 
relation type


and Figure 2(d) gives the classification result on both
training set and test set by LP (accuracy = 11  =
73.3%).

  Comparing Figure 2(b) and Figure 2(c), we find 
that many examples are misclassified from class o
to other class symbols.  This may be caused that 
SVMs method ignores the intrinsic structure in data. 
For Figure 2(d), the labels of unlabeled examples 
are determined not only by nearby labeled examples, 
but also by nearby unlabeled examples, so using LP

4 The tool is available at http://isomap.stanford.edu/.


classification task.  We can see that LP 
algorithm outperforms the bootstrapped SVM 
algorithm on four relation type classification 
tasks, and perform comparably on the relation 
”SOC” classification task.

4   
Discussion

In this paper,we have investigated a graph-based 
semi-supervised learning approach for relation ex- 
traction problem. Experimental results showed 
that the LP algorithm performs better than 
SVM and


Table 4: Comparison of the performance of the bootstrapped SVM method from (Zhang, 2004) and LP method with 100 seed 
labeled examples for relation type classification task.


B
o
o
t
s
t
r
a
p
p
i
n
g
L
P
J
 
S
Rel
ati
on 
typ
e
P	R	F
P	R	F
RO
LE
P
A
R
T
 
A
T
 
S
O
C
 
N
E
A
R
78.
5	69.7	73.8
65.
6	34.1	44.9
61.
0	84.8	70.9
47.
0	57.4	51.7
−	−	−
81.
0	74.7	77.7
70.
1	41.6	52.2
74.
2	79.1	76.6
45.
0	59.1	51.0
13.
7	12.5	13.0


Table 5: Comparison of the performance of previous methods on ACE RDC task.


Rel
ati
on 
De
cte
cti
on
Relation 
Detectio
n and 
Classifi
cation



o
n
 
T
y
p
e
s
o
n
 
S
u
b
t
y
p
e
s

Me
tho
d
P	R	F
P	R	F
P	R	F
C
ul
ot
ta 
an
d 
S
or
es
en 
(2
0
0
4) 
K
a
m
b
ha
tl
a 
(2
0
0
4)

Zh
ou 
et 
al. 
(20
05)
Tr
ee 
ke
rn
el 
ba
se
d 
F
ea
tu
re  
ba
se
d,  
M
ax
i- 
m
u
m 
E
nt
ro
p
y
Fe
atu
re 
bas
ed,
SV
M
81
.2	51.8	63.2
-
	
-
	
-

84
.8	66.7	74.7
67
.1	35.0	45.8
-
	
-
	
-

77
.2	60.7	68.0
-
	
-
	
-
63
.5	45.2	52.8

63
.1	49.5	55.5




bootstrapping.  We have some findings from these 
results:

  The LP based relation extraction method can use 
the graph structure to smooth the labels of unlabeled 
examples. Therefore, the labels of unlabeled exam- 
ples are determined not only by the nearby labeled 
examples, but also by nearby unlabeled examples. 
For supervised methods, e.g., SVM, very few la- 
beled examples are not enough to reveal the struc- 
ture of each class.  Therefore they can not perform 
well, since the classification hyperplane was learned 
only from few labeled data and the coherent struc- 
ture in unlabeled data was not explored when in- 
ferring class boundary. Hence, our LP-based semi- 
supervised method achieves better performance on 
both relation detection and classification when only 
few labeled data is available. Bootstrapping

  Currently most of works on the RDC task of 
ACE focused on supervised learning methods Cu- 
lotta and Soresen (2004; Kambhatla (2004; Zhou 
et al. (2005).  Table 5 lists a comparison on re- 
lation detection and classification of these meth- 
ods.  Zhou et al. (2005) reported the best result as
63.1%/49.5%/55.5% in Precision/Recall/F-measure 
on the relation subtype classification using feature 
based method, which outperforms tree kernel based 
method by Culotta and Soresen (2004). Compared 
with Zhou et al.’s method, the performance of LP al- 
gorithm is slightly lower. It may be due to that we 
used a much simpler feature set.  Our work in this


paper focuses on the investigation of a graph based 
semi-supervised learning algorithm for relation ex- 
traction. In the future, we would like to use more ef- 
fective feature sets Zhou et al. (2005) or kernel based 
similarity measure with LP for relation extraction.



5   Conclusion and Future Work


This paper approaches the problem of semi- 
supervised relation extraction using a label propaga- 
tion algorithm.  It represents labeled and unlabeled 
examples and their distances as the nodes and the 
weights of edges of a graph, and tries to obtain a 
labeling function to satisfy two constraints: 1) it 
should be fixed on the labeled nodes, 2) it should 
be smooth on the whole graph.   In the classifica- 
tion process, the labels of unlabeled examples are 
determined not only by nearby labeled examples, 
but also by nearby unlabeled examples. Our exper- 
imental results demonstrated that this graph based 
algorithm can achieve better performance than SVM 
when only very few labeled examples are available, 
and also outperforms the bootstrapping method for 
relation extraction task.
  In the future, we would like to investigate more 
effective feature set or use feature selection to im- 
prove the performance of this graph-based semi- 
supervised relation extraction method.


References

Agichtein E. and Gravano L..   2000.   Snowball: Ex- 
tracting Relations from large Plain-Text Collections, 
In Proceedings of the 5th  ACM International Confer- 
ence on Digital Libraries (ACMDL’00).

Belkin M. and Niyogi P..  2002.  Using Manifold Struc- 
ture for Partially Labeled Classification. Advances in 
Neural Infomation Processing Systems 15.

Blum A. and Chawla S.  2001.  Learning from Labeled 
and Unlabeled Data Using Graph Mincuts. In Pro- 
ceedings of the 18th International Conference on Ma- 
chine Learning.

Blum A., Lafferty J., Rwebangira R. and Reddy R. 2004.
Semi-Supervised Learning Using Randomized Min- 
cuts. In Proceedings of the 21th International Confer- 
ence on Machine Learning..

Brin Sergey.   1998.   Extracting patterns and relations 
from world wide web. In Proceedings of WebDB Work- 
shop at 6th International Conference on Extending 
Database Technology (WebDB’98). pages 172-183.

Charniak E. 1999. A Maximum-entropy-inspired parser.
Technical Report CS-99-12.   Computer Science De- 
partment, Brown University.

Culotta A. and Soresen J. 2004. Dependency tree kernels 
for relation extraction, In Proceedings of 42th Annual 
Meeting of the Association for Computational Linguis- 
tics. 21-26 July 2004. Barcelona, Spain.

Hasegawa T., Sekine S. and Grishman R.   2004.  Dis- 
covering Relations among Named Entities from Large 
Corpora, In Proceeding of Conference ACL2004. 
Barcelona, Spain.

Kambhatla N.  2004.  Combining lexical, syntactic and 
semantic features with Maximum Entropy Models for 
extracting relations, In Proceedings of 42th Annual 
Meeting of the Association for Computational Linguis- 
tics.. 21-26 July 2004. Barcelona, Spain.

Lin J.  1991.  Divergence Measures Based on the Shan- 
non Entropy. IEEE Transactions on Information The- 
ory. Vol 37, No.1, 145-150.

Miller S.,Fox H.,Ramshaw L. and Weischedel R.  2000.
A novel use of statistical parsing to extract information 
from text. In Proceedings of 6th Applied Natural Lan- 
guage Processing Conference  29 April-4 may 2000, 
Seattle USA.

Slonim, N., Friedman, N., and Tishby, N.   2002.  Un- 
supervised Document Classification Using Sequential 
Information Maximization. In Proceedings of the 25th 
Annual International ACM SIGIR Conference on Re- 
search and Development in Information Retrieval.



Yarowsky D.  1995.  Unsupervised Word Sense Disam- 
biguation Rivaling Supervised Methods. In Proceed- 
ings of the 33rd Annual Meeting of the Association for 
Computational Linguistics. pp.189-196.

Zelenko D., Aone C. and Richardella A.   2002.   Ker- 
nel Methods for Relation Extraction, Proceedings of 
the Conference on Empirical Methods in Natural Lan- 
guage Processing (EMNLP). Philadelphia.

Zhang Zhu.  2004.  Weakly-supervised relation classifi- 
cation for Information Extraction, In Proceedings of 
ACM 13th conference on Information and Knowledge 
Management (CIKM’2004).   8-13 Nov 2004. Wash- 
ington D.C.,USA.

Zhou GuoDong,  Su Jian,  Zhang Jie and Zhang min.
2005.  Exploring Various Knowledge in Relation Ex- 
traction. In Proceedings of 43th Annual Meeting of the 
Association for Computational Linguistics. USA.

Zhu Xiaojin and Ghahramani Zoubin.  2002.  Learning 
from Labeled and Unlabeled Data with Label Propa- 
gation. CMU CALD tech report CMU-CALD-02-107.

Zhu Xiaojin, Ghahramani Zoubin, and Lafferty J. 2003.
Semi-Supervised Learning Using Gaussian Fields and 
Harmonic Functions. In Proceedings of the 20th Inter- 
national Conference on Machine Learning.

