A Cross-lingual Annotation Projection Approach 
for Relation Detection


Seokhwan Kim†, Minwoo Jeong‡, Jonghoon Lee† , Gary Geunbae Lee†
† Department of Computer Science and Engineering, 
Pohang University of Science and Technology
{megaup|jh21983|gblee}@postech.ac.kr
‡ Saarland University
m.jeong@mmci.uni-saarland.de



Abstract

While extensive studies on relation ex- 
traction have been conducted in the last 
decade, statistical systems based on su- 
pervised learning are still limited because 
they require large amounts of training data 
to achieve high performance.  In this pa- 
per, we develop a cross-lingual annota- 
tion projection method that leverages par- 
allel corpora to bootstrap a relation detec- 
tor without significant annotation efforts 
for a resource-poor language. In order to 
make our method more reliable, we intro- 
duce three simple projection noise reduc- 
tion methods. The merit of our method is 
demonstrated through a novel Korean re- 
lation detection task.

1   Introduction

Relation extraction aims to identify semantic re- 
lations of entities in a document.   Many rela- 
tion extraction studies have followed the Rela- 
tion Detection and Characterization (RDC) task 
organized by the Automatic Content Extraction 
project (Doddington et al., 2004) to make multi- 
lingual  corpora  of  English,  Chinese  and  Ara- 
bic.  Although these datasets encourage the de- 
velopment and evaluation of statistical relation 
extractors for such languages, there would be a 
scarcity of labeled training samples when learn- 
ing a new system for another language such as 
Korean.  Since manual annotation of entities and 
their relations for such resource-poor languages 
is very expensive, we would like to consider in- 
stead a weakly-supervised learning technique in


order to learn the relation extractor without sig- 
nificant annotation efforts. To do this, we propose 
to leverage parallel corpora to project the relation 
annotation on the source language (e.g. English) 
to the target (e.g. Korean).

  While many supervised machine learning ap- 
proaches have been successfully applied to the 
RDC task (Kambhatla, 2004; Zhou et al., 2005; 
Zelenko et al., 2003; Culotta and Sorensen, 2004; 
Bunescu and Mooney, 2005; Zhang et al., 2006), 
few have focused on weakly-supervised relation 
extraction. For example, (Zhang, 2004) and (Chen 
et al., 2006) utilized weakly-supervised learning 
techniques for relation extraction,  but they did 
not consider weak supervision in the context of 
cross-lingual relation extraction. Our key hypoth- 
esis on the use of parallel corpora for learning 
the relation extraction system is referred to as 
cross-lingual annotation projection.  Early stud- 
ies of cross-lingual annotation projection were ac- 
complished for lexically-based tasks; for exam- 
ple part-of-speech tagging (Yarowsky and Ngai,
2001),  named-entity  tagging  (Yarowsky et  al.,
2001), and verb classification (Merlo et al., 2002). 
Recently, there has been increasing interest in ap- 
plications of annotation projection such as depen- 
dency parsing (Hwa et al., 2005), mention de- 
tection (Zitouni and Florian, 2008), and semantic 
role labeling (Pado and Lapata, 2009). However, 
to the best of our knowledge, no work has reported 
on the RDC task.

  In this paper, we apply a cross-lingual anno- 
tation projection approach to binary relation de- 
tection, a task of identifying the relation between 
two entities.  A simple projection method propa- 
gates the relations in source language sentences to







564
Proceedings of the 23rd International  Conference on Computational Linguistics (Coling 2010), pages 564–571, 
Beijing,  August 2010


word-aligned target sentences, and a target rela- 
tion detector can bootstrap from projected annota- 
tion. However, this automatic annotation is unre- 
liable because of mis-classification of source text 
and word alignment errors, so it causes a critical 
falling-off in annotation projection quality. To al- 
leviate this problem, we present three noise reduc- 
tion strategies: a heuristic filtering; an alignment 
correction with dictionary; and an instance selec- 
tion based on assessment, and combine these to 
yield a better result.
  We provide a quantitive evaluation of our 
method on a new Korean RDC dataset.   In our 
experiment, we leverage an English-Korean par- 
allel corpus collected from the Web, and demon- 
strate that the annotation projection approach and 
noise reduction method are beneficial to build an 
initial Korean relation detection system.  For ex- 
ample, the combined model of three noise reduc- 
tion methods achieves F1-scores of 36.9% (59.8% 
precision and 26.7% recall), favorably comparing 
with the 30.5% shown by the supervised base- 
line.1
  The remainder of this paper is structured as fol- 
lows. In Section 2, we describe our cross-lingual 
annotation projection approach to relation detec- 
tion task.  Then, we present the noise reduction 
methods in Section 3. Our experiment on the pro- 
posed Korean RDC evaluation set is shown in Sec- 
tion 4 and Section 5, and we conclude this paper 
in Section 6.

2	Cross-lingual Annotation Projection 
for Relation Detection

The annotation projection from a resource-rich 
language L1 to a resource-poor language L2 is 
performed by a series of three subtasks: annota- 
tion, projection and assessment.
  The annotation projection for relation detection 
can be performed as follows:

1) For a given pair of bi-sentences in parallel cor- 
pora between a resource-rich language L1  and 
a target language L2, the relation detection task 
is carried out for the sentence in L1 .

  1 The dataset and the parallel corpus are available on the 
author’s website,
http://isoft.postech.ac.kr/∼megaup/research/resources/.


2) The annotations obtained by analyzing the sen- 
tence in L1  are projected onto the sentence in 
L2 based on the word alignment information.

3) The projected annotations on the sentence in 
L2  are utilized as resources to perform the re- 
lation detection task for the language L2.

2.1   Annotation

The first step to projecting annotations from L1 
onto L2 is obtaining annotations for the sentences 
in L1.  Since each instance for relation detection 
is composed of a pair of entity mentions, the in- 
formation about entity mentions on the given sen- 
tences should be identified first.  We detect the 
entities in the L1 sentences of the parallel cor- 
pora. Entity identification generates a number of 
instances for relation detection by coupling two 
entities within each sentence.  For each instance, 
the existence of semantic relation between entity 
mentions is explored, which is called relation de- 
tection. We assume that there exist available mod- 
els or systems for all annotation processes, includ- 
ing not only an entity tagger and a relation de- 
tector themselves, but also required preprocessors 
such as a part-of-speech tagger, base-phrase chun- 
ker, and syntax parser for analyzing text in L1.
Figure 1 shows an example of annotation pro-
jection for relation detection of a bitext in En- 
glish and Korean. The annotation of the sentence 
in English shows that “Jan Mullins” and “Com- 
puter Recycler Incorporated” are entity mentions 
of a person and an organization, respectively. Fur- 
thermore, the result indicates that the pair of en- 
tities has a semantic relationship categorized as 
“ROLE.Owner” type.

2.2   Projection

In order to project the annotations from the sen- 
tences in L1  onto the sentences in L2 , we utilize 
the information of word alignment which plays 
an important role in statistical machine transla- 
tion techniques.  The word alignment task aims 
to identify translational relationships among the 
words in a bitext and produces a bipartite graph 
with a set of edges between words with transla- 
tional relationships as shown in Figure 1.  In the 
same manner as the annotation in L1, entities are


ROLE.Owner

PER 	ORG



Jan



Mullins,  owner  of



Computer  Recycler  
Incorporated  said  that  ...







컴퓨터리사이클러
(keom-pyu-teo-ri-sa-i-keul-reo)


의
(ui)


잔
(jan)


멀린스
(meol-rin-seu)


사장
(sa-jang)


은
(eun)


… 라고
(ra-go)


말했다
(mal-haet-da)


ORG 	PER

ROLE.Owner

Figure 1: An example of annotation projection for relation detection of a bitext in English and Korean




considered as the first units to be projected. We as- 
sume that the words of the sentences in L2 aligned 
with a given entity mention in L1 inherit the infor- 
mation about the original entity in L1.
  After projecting the annotations of entity men- 
tions, the projections for relational instances fol- 
low. A projection is performed on a projected in- 
stance in L2  which is a pair of projected entities 
by duplicating annotations of the original instance 
in L1 .
  Figure 1 presents an example of projection of a 
positive relational instance between “Jan Mullins” 
and “Computer Recycler Incorporated” in the 
English sentence onto its translational counter- 
part sentence in Korean.  “Jan meol-rin-seu” and 
“keom-pyu-teo-ri-sa-i-keul-reo” are labeled as en- 
tity mentions with types of a person’s name and an 
organization’s name respectively. In addition, the 
instance composed of the two projected entities is 
annotated as a positive instance, because its orig- 
inal instance on the English sentence also has a 
semantic relationship.
  As the description suggests, the annotation pro- 
jection approach is highly dependant on the qual- 
ity of word alignment. However, the results of au- 
tomatic word alignment may include several noisy 
or incomplete alignments because of technical dif- 
ficulties. We present details to tackle the problem 
by relieving the influence of alignment errors in 
Section 3.

2.3   Assessment

The most important challenge for annotation pro- 
jection approaches is how to improve the robust-


ness against the erroneous projections. The noise 
produced by not only word alignment but also 
mono-lingual annotations in L1  accumulates and 
brings about a drastic decline in the quality of pro- 
jected annotations.
  The simplest policy of utilizing the projected 
annotations for relation detection in L2  is to con- 
sider that all projected instances are equivalently 
reliable and to employ entire projections as train- 
ing instances for the task without any filtering. In 
contrast with this policy, which is likely to be sub- 
standard, we propose an alternative policy where 
the projected instances are assessed and only the 
instances judged as reliable by the assessment are 
utilized for the task. Details about the assessment 
are provided in Section 3.

3   Noise Reduction Strategies

The efforts to reduce noisy projections are consid- 
ered indispensable parts of the projection-based 
relation detection method in a resource-poor lan- 
guage. Our noise reduction approach includes the 
following three strategies:  heuristic-based align- 
ment filtering, dictionary-based alignment correc- 
tion, and assessment-based instance selection.

3.1   Heuristic-based Alignment Filtering

In order to improve the performance of annotation 
projection approaches, we should break the bottle- 
neck caused by the low quality of automatic word 
alignment results. As relation detection is carried 
out for each instance consisting of two entity men- 
tions, the annotation projection for relation detec- 
tion concerns projecting only entity mentions and


their relational instances.  Since this is different 
from other shallower tasks such as part-of-speech 
tagging, base phrase chunking, and dependency 
parsing which should consider projections for all 
word units, we define and apply some heuristics 
specialized to projections of entity mentions and 
relation instances to improve robustness of the 
method against erroneous alignments, as follows:
  

In order to solve this problem, a dictionary- 
based alignment correction strategy is incorpo- 
rated in our method. The strategy requires a bilin- 
gual dictionary for entity mentions. Each entry of 
the dictionary is a pair of entity mention in L1 and 
its translation or transliteration in L2.   For each 
entity to be projected from the sentence in L1 , 
its counterpart in L2  is retrieved from the bilin-
gual dictionary. Then, we seek the retrieved entity


• A projection for an entity mention should
be based on alignments between contiguous



mention from the sentence in L2



by finding the


word sequences.  If there are one or more 
gaps in the word sequence in L2 aligned 
with an entity mention in the sentence in 
L1, we assume that the corresponding align- 
ments are likely to be erroneous.  Thus, the 
alignments of non-contiguous words are ex- 
cluded in projection.

• Both an entity mention in L1  and its projec- 
tion in L2  should include at least one base 
noun phrase.   If no base noun phrase oc- 
curs in the original entity mention in L1, it 
may suggest some errors in annotation for 
the sentence in L1.   The same case for the 
projected instance raises doubts about align- 
ment errors.  The alignments between word 
sequences without any base noun phrase are 
filtered out.

• The  projected  instance  in  L2  should  sat- 
isfy the clausal agreement with the original 
instance in L1.   If entities of an instance 
are located in  the same clause (or differ- 
ent clauses), its projected instance should be 
in the same manner.  The instances without 
clausal agreement are ruled out.

3.2   Dictionary-based Alignment Correction
The errors in word alignment are composed of 
not only imprecise alignments but also incomplete 
alignments.  If an alignment of an entity among 
two entities of a relation instance is not provided 
in the result of the word alignment task, the pro- 
jection for the corresponding instance is unavail- 
able.  Unfortunately, the above-stated alignment 
filtering heuristics for improving the quality of 
projections make the annotation loss problems 
worse by filtering out several alignments likely to 
be noisy.


longest common subsequence.  If a subsequence
matched to the retrieved mention is found in the 
sentence in L2, we make a new alignment between 
it and its original entity on the L1 sentence.

3.3   Assessment-based Instance Selection

The reliabilities of instances projected via a series 
of independent modules are different from each 
other.  Thus, we propose an assessment strategy 
for each projected instance.  To evaluate the reli- 
ability of a projected instance in L2, we use the 
confidence score of monolingual relation detec- 
tion for the original counterpart instance in L1 . 
The acceptance of a projected instance is deter- 
mined by whether the score of the instance is 
larger than a given threshold value θ.  Only ac- 
cepted instances are considered as the results of 
annotation projection and applied to solve the re- 
lation detection task in target language L2.

4   Experimental Setup

To demonstrate the effectiveness of our cross- 
lingual annotation projection approach for rela- 
tion detection, we performed an experiment on 
relation detection in Korean text with propagated 
annotations from English resources.

4.1   Annotation

The first step to evaluate our method was annotat- 
ing the English sentences in a given parallel cor- 
pus.  We use an English-Korean parallel corpus 
crawled from an English-Korean dictionary on the 
web. The parallel corpus consists of 454,315 bi- 
sentence pairs in English and Korean 2 . The En- 
glish sentences in the parallel corpus were prepro-

  2 The parallel corpus collected and other resources are all 
available in our website
http://isoft.postech.ac.kr/∼megaup/research/resources/


cessed by the Stanford Parser 3 (Klein and Man- 
ning, 2003) which provides a set of analyzed re- 
sults including part-of-speech tag sequences, a de- 
pendency tree, and a constituent parse tree for a 
sentence.
  The annotation for English sentences is di- 
vided into two subtasks: entity mention recogni- 
tion and relation detection.   We utilized an off- 
the-shelf system, Stanford Named Entity Recog- 
nizer 4 (Finkel et al., 2005) for detecting entity 
mentions on the English sentences.   The total 
number of English entities detected was 285,566. 
Each pair of recognized entities within a sentence 
was considered as an instance for relation detec- 
tion.
  A classification model learned with the train- 
ing  set  of  the  ACE  2003  corpus  which  con- 
sists of 674 documents and 9,683 relation in- 
stances was built for relation detection in English. 
In our implementation, we built a tree kernel- 
based SVM model using SVM-Light 5 (Joachims,
1998) and Tree Kernel Tools 6 (Moschitti, 2006).
The subtree kernel method (Moschitti, 2006) for 
shortest  path  enclosed  subtrees  (Zhang  et  al.,
2006)  was  adopted  in  our  model.    Our  rela- 
tion detection model achieved 81.2/69.8/75.1 in 
Precision/Recall/F-measure on the test set of the 
ACE 2003 corpus, which consists of 97 docu- 
ments and 1,386 relation instances.
  The annotation of relations was performed by 
determining the existence of semantic relations 
for all 115,452 instances with the trained model 
for relation detection.   The annotation detected
22,162 instances as positive which have semantic 
relations.

4.2   Projection

The labels about entities and relations in the En- 
glish sentences of the parallel corpora were propa- 
gated into the corresponding sentences in Korean. 
The Korean sentences were preprocessed by our 
part-of-speech tagger 7 (Lee et al., 2002) and a de- 
pendency parser implemented by MSTParser with

3 http://nlp.stanford.edu/software/lex-parser.shtml
4 http://nlp.stanford.edu/software/CRF-NER.shtml
5 http://svmlight.joachims.org/
6 http://disi.unitn.it/∼moschitt/Tree-Kernel.htm
7 http://isoft.postech.ac.kr/∼megaup/research/postag/


Filter	Without assessing	With 
assessing none		97,239	
	39,203
+ heuristics	31,652
	12,775
+ dictionary	39,891
	17,381

Table 1: Numbers of projected 
instances


a model trained on the Sejong corpus (Kim, 
2006).
  The annotation projections were performed 
on the bi-sentences of the parallel corpus 
followed by descriptions mentioned in 
Section 2.2.   The bi-sentences were processed 
by the GIZA++ soft- ware (Och and Ney, 
2003) in the standard con- figuration in both 
English-Korean and Korean- English 
directions.  The bi-direcional alignments were 
joined by the grow-diag-final algorithm, which 
is widely used in bilingual phrase extrac- tion 
(Koehn et al., 2003) for statistical machine 
translation.  This system achieved 
65.1/41.6/50.8 in Precision/Recall/F-measure 
in our evaluation of 201 randomly sampled 
English-Korean bi- sentences with manually 
annotated alignments.
  The number of projected instances varied 
with the applied strategies for reducing noise as 
shown in Table 1.  Many projected instances 
were fil- tered out by heuristics, and only 
32.6% of the in- stances were left. However, 
several instances were rescued by dictionary-
based alignment correction and the number of 
projected instances increased from 31,652 to 
39,891. For all cases of noise re- duction 
strategies, we performed the assessment- based 
instance selection with a threshold value θ of 
0.7, which was determined empirically through 
the grid search method.  About 40% of the 
pro- jected instances were accepted by instance 
selec- tion.

4.3   
Evaluation

In order to evaluate our proposed method, we 
pre- pared a dataset for the Korean RDC task.  
The dataset was built by annotating the 
information about entities and relations in 100 
news docu- ments in Korean. The annotations 
were performed by two annotators following the 
guidelines for the ACE corpus processed by 
LDC. Our Korean RDC corpus consists of 835 
sentences, 3,331 entity mentions, and 8,354 
relation instances. The sen-


w/o assessing	with assessing








Table 2: Experimental Results




tences of the corpus were preprocessed by equiva- 
lent systems used for analyzing Korean sentences 
for projection.  We randomly divided the dataset 
into two subsets with the same number of in- 
stances for use as a training set to build the base- 
line system and for evaluation.
  For evaluating our approach, training instance 
sets to learn models were prepared for relation 
detection in Korean.  The instances of the train- 
ing set (half of the manually built Korean RDC 
corpufs) were used to train the baseline model. 
All other sets of instances include these baseline 
instances and additional instances propagated by 
the annotation projection approach.   The train- 
ing sets with projected instances are categorized 
into three groups by the level of applied strategies 
for noise reduction.  While the first set included 
all projections without any noise reduction strate- 
gies, the second included only the instances ac- 
cepted by the heuristics. The last set consisted of 
the results of a series of heuristic-based filtering 
and dictionary-based correction. For each training 
set with projected instances, an additional set was 
derived by performing assessment-based instance 
selection.
  We built the relation detection models for all 
seven training sets (a baseline set, three pro- 
jected  sets  without  assessing,  and  three  pro- 
jected sets with assessing). Our implementations 
are based on the SVM-Light and Tree Kernel 
Tools described in the former subsection.  The 
shortest path dependency kernel (Bunescu and 
Mooney, 2005) implemented by the subtree kernel 
method (Moschitti, 2006) was adopted to learn all 
models.
  The performance for each model was evaluated 
with the predictions of the model on the test set, 
which was the other half of Korean RDC corpus.


We measured the performances of the models on 
true entity mentions with true chaining of coref- 
erence.   Precision, Recall and F-measure were 
adopted for our evaluation.

5   Experimental Results

Table 2 compares the performances of the differ- 
ent models which are distinguished by the applied 
strategies for noise reduction. It shows that:

• The  model  with  non-filtered  projections 
achieves extremely poor performance due to 
a large number of erroneous instances. This 
indicates that the efforts for reducing noise 
are urgently needed.

• The heuristic-based alignment filtering helps 
to improve the performance.  However, it is 
much worse than the baseline performance 
because of a falling-off in recall.

• The dictionary-based correction to our pro- 
jections increased both precision and recall 
compared with the former models with pro- 
jected instances. Nevertheless, it still fails to 
achieve performance improvement over the 
baseline model.

• For   all    models    with   projection,    the 
assessment-based instance selection boosts 
the performances significantly.  This means 
that this selection strategy is crucial in 
improving the performance of the models 
by excluding unreliable instances with low 
confidence.

• The model with heuristics and assessments 
finally achieves better performance than the 
baseline model.  This suggests that the pro- 
jected instances have a beneficial influence


on the relation detection task when at least 
these two strategies are adopted for reducing 
noises.

• The final model incorporating all proposed 
noise reduction strategies outperforms the 
baseline model by 6 in F-measure.  This is 
due to largely increased recall by absorbing 
more useful features from the well-refined 
set of projected instances.

  The experimental results show that our pro- 
posed techniques effectively improve the perfor- 
mance of relation detection in the resource-poor 
Korean language with a set of annotations pro- 
jected from the resource-rich English language.

6   Conclusion

This paper presented a novel cross-lingual annota- 
tion projection method for relation extraction in a 
resource-poor language. We proposed methods of 
propagating annotations from a resource-rich lan- 
guage to a target language via parallel corpora. In 
order to relieve the bad influence of noisy projec- 
tions, we focused on the strategies for reducing the 
noise generated during the projection. We applied 
our methods to the relation detection task in Ko- 
rean. Experimental results show that the projected 
instances from an English-Korean parallel corpus 
help to improve the performance of the task when 
our noise reduction strategies are adopted.
  We would like to introduce our method to the 
other subtask of relation extraction, which is re- 
lation categorization.  While relation detection is 
a binary classification problem, relation catego- 
rization can be solved by a classifier for multi- 
ple classes.   Since the fundamental approaches 
of the two tasks are similar, we expect that our 
projection-based relation detection methods can 
be easily adapted to the relation categorization 
task.
  For this further work, we are concerned about 
the problem of low performance for Korean, 
which was below 40 for relation detection. The re- 
lation categorization performance is mostly lower 
than detection because of the larger number of 
classes to be classified, so the performance of 
projection-based approaches has to be improved


in order to apply them.  An experimental result 
of this work shows that the most important factor 
in improving the performance is how to select the 
reliable instances from a large number of projec- 
tions.  We plan to develop more elaborate strate- 
gies for instance selection to improve the projec- 
tion performance for relation extraction.

Acknowledgement

This research was supported by the MKE (The 
Ministry of Knowledge Economy),  Korea,  un- 
der the ITRC (Information Technology Research 
Center) support program supervised by the NIPA 
(National IT Industry Promotion Agency) (NIPA-
2010-C1090-1031-0009).


References

Bunescu, Razvan C. and Raymond J. Mooney. 2005.
A shortest path dependency kernel for relation ex- 
traction.  In Proceedings of the conference on Hu-
man Language Technology and Empirical Methods 
in Natural Language Processing, page 724731.

Chen, Jinxiu, Donghong Ji, Chew Lim Tan, and 
Zhengyu Niu.  2006.  Relation extraction using la- 
bel propagation based semi-supervised learning. In 
Proceedings of the 21st International Conference 
on Computational Linguistics and the 44th annual 
meeting of the Association for Computational Lin- 
guistics, pages 129–136, Sydney, Australia. Associ- 
ation for Computational Linguistics.

Culotta, Aron and Jaffrey Sorensen.   2004.   Depen- 
dency tree kernels for relation extraction.  In Pro- 
ceedings of ACL, volume 4.

Doddington, George, Alexis Mitchell, Mark Przy- 
bocki, Lance Ramshaw, Stephanie Strassel, and 
Ralph Weischedel.  2004.  The automatic content 
extraction (ACE) programtasks, data, and evalua- 
tion.    In Proceedings of LREC, volume 4,  page
837840.

Finkel, Jenny R., Trond Grenager, and Christopher 
Manning.  2005.  Incorporating non-local informa- 
tion into information extraction systems by gibbs 
sampling. In Proceedings of the 43rd Annual Meet- 
ing on Association for Computational Linguistics, 
volume 43, page 363.

Hwa, Rebecca, Philip Resnik, Amy Weinberg, Clara 
Cabezas, and Okan Kolak.   2005.   Bootstrapping 
parsers via syntactic projection across parallel texts. 
Natural Language Engineering, 11(03):311–325.


Joachims, Thorsten.  1998.  Text categorization with 
support vector machines: Learning with many rele- 
vant features. In Proceedings of the European Con- 
ference on Machine Learning, pages 137–142.

Kambhatla, Nanda. 2004. Combining lexical, syntac- 
tic, and semantic features with maximum entropy 
models for extracting relations.  In Proceedings of 
the ACL 2004 on Interactive poster and demonstra- 
tion sessions, page 22, Barcelona, Spain. Associa- 
tion for Computational Linguistics.

Kim, Hansaem.  2006.  Korean national corpus in the
21st century sejong project.  In Proceedings of the
13th NIJL International Symposium, page 4954.

Klein, Dan and Christopher D. Manning.  2003.  Ac- 
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, pages 423–430, Sap- 
poro, Japan. Association for Computational Lin- 
guistics.

Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
2003.  Statistical phrase-based translation.  In Pro- 
ceedings of the 2003 Conference of the North Amer- 
ican Chapter of the Association for Computational
Linguistics on Human Language Technology, vol- 
ume 1, pages 48–54.

Lee, Gary Geunbae, Jeongwon Cha, and Jong-Hyeok 
Lee.  2002.  Syllable pattern-based unknown mor- 
pheme segmentation and estimation for hybrid part- 
of-speech tagging of korean.  Computational Lin- 
guistics, 28(1):53–70.

Merlo, Paola, Suzanne Stevenson, Vivian Tsang, and 
Gianluca Allaria.  2002.  A multilingual paradigm 
for automatic verb classification. In Proceedings of 
the 40th Annual Meeting on Association for Compu- 
tational Linguistics, pages 207–214, Philadelphia, 
Pennsylvania. Association for Computational Lin- 
guistics.

Moschitti, Alessandro.  2006.  Making tree kernels 
practical for natural language learning. In Proceed- 
ings of EACL06.

Och, Franz Josef and Hermann Ney.   2003.  A sys- 
tematic comparison of various statistical alignment 
models.   Computational Linguistics, 29(1):19–51, 
March.

Pado,	Sebastian   and   Mirella   Lapata.	2009.
Cross-lingual  annotation  projection  of  semantic
roles.   Journal of Artificial Intelligence Research,
36(1):307340.

Yarowsky, David and Grace Ngai.   2001.   Inducing 
multilingual POS taggers and NP bracketers via ro- 
bust projection across aligned corpora.  In Second


meeting of the North American Chapter of the Asso- 
ciation for Computational Linguistics on Language 
technologies 2001, pages 1–8, Pittsburgh, Pennsyl- 
vania. Association for Computational Linguistics.

Yarowsky, David, Grace Ngai, and Richard Wicen- 
towski.  2001.  Inducing multilingual text analysis 
tools via robust projection across aligned corpora. 
In Proceedings of the first international conference 
on Human language technology research, pages 1–
8, San Diego. Association for Computational Lin- 
guistics.

Zelenko, Dmitry, Chinatsu Aone, and Anthony 
Richardella. 2003. Kernel methods for relation ex- 
traction. J. Mach. Learn. Res., 3:1083–1106.

Zhang, Min, Jie Zhang, Jian Su, and Guodong Zhou.
2006.  A composite kernel to extract relations be- 
tween entities with both flat and structured features.
In Proceedings of the 21st International Conference 
on Computational Linguistics and the 44th annual 
meeting of the Association for Computational Lin- 
guistics, pages 825–832, Sydney, Australia. Associ-
ation for Computational Linguistics.

Zhang, Zhu.  2004.  Weakly-supervised relation clas- 
sification for information extraction.   In Proceed- 
ings of the thirteenth ACM international conference 
on Information and knowledge management, pages
581–588, Washington, D.C., USA. ACM.

Zhou, Guodong, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex- 
traction. In Proceedings of the 43rd Annual Meeting 
on Association for Computational Linguistics, page
434.

Zitouni, Imed and Radu Florian. 2008. Mention detec- 
tion crossing the language barrier.  In Proceedings 
of the Conference on Empirical Methods in Natural 
Language Processing, pages 600–609, Honolulu, 
Hawaii. Association for Computational Linguistics.

