Unknown Word Extraction for Chinese Documents Keh-Jiann Chen Institute of Information science, Academia Sinica kchen@iis.sinica.edu.tw Wei-Yun Ma Institute of Information science, Academia Sinica ma@iis.sinica.edu.tw Abstract There is no blank to mark word boundaries in Chinese text. As a result, identifying words is difficult, because of segmentation ambiguities and occurrences of unknown words. Conventionally unknown words were extracted by statistical methods because statistical methods are simple and efficient. However the statistical methods without using linguistic knowledge suffer the drawbacks of low precision and low recall, since character strings with statistical significance might be phrases or partial phrases instead of words and low frequency new words are hardly identifiable by statistical methods. In addition to statistical information, we try to use as much information as possible, such as morphology, syntax, semantics, and world knowledge. The identification system fully utilizes the context and content information of unknown words in the steps of detection process, extraction process, and verification process. A practical unknown word extraction system was implemented which online identifies new words, including low frequency new words, with high precision and high recall rates. 1 Introduction One of the most prominent problems in computer processing of Chinese language is identification of the word sequences of input sentences. There is no blank to mark word boundaries in Chinese text. As a result, identifying words is difficult, because of segmentation ambiguities and occurrences of unknown words (i.e. out-of-vocabulary words). Most papers dealing with the problem of word segmentation focus their attention only on the resolution of ambiguous segmentation. The problem of unknown word identification is considered more difficult and needs to be further investigated. According to an inspection on the Sinica corpus (Chen etc., 1996), a 5 million word Chinese corpus with word segmented, it shows that 3.51% of words are not listed in the CKIP lexicon, a Chinese lexicon with more than 80,000 entries. Identifying Chinese unknown words from a document is difficult; since 1. There is no blank to mark word boundaries; 
2. Almost all Chinese characters and words are also 
morphemes; 
3. Morphemes are syntactic ambiguous and semantic 
ambiguous; 
4. Words with same morpho-syntactic structure might 
have different syntactic categories; 
5. No simple rules can enumerate all types of unknown 
words; 
6. Online identification from a short text is even harder, 
since low frequency unknown words are not 
identifiable by naive statistical methods. 
It is difficult to identify unknown words in a text since all Chinese characters can either be a morpheme or a word and there are no blank to mark word boundaries. Therefore without (or even with) syntactic or semantic checking, it is difficult to tell whether a character in a particular context is a part of an unknown word or whether it stands alone as a word. Compound words and proper names are two major types of unknown words. It is not possible to list all of the proper names and compounds neither in a lexicon nor enumeration by morphological rules. Conventionally unknown words were extracted by statistical methods for statistical methods are simple and efficient. However the statistical methods without using linguistic knowledge suffer the drawbacks of low precision and low recall. Because character strings with statistical significance might be phrases or partial phrases instead of words and low frequency new words are hardly identifiable by statistical methods. Common statistical features for unknown word extraction are mutual information (Church 90), entropy (Tung 94), association strength (Smadja 93, Wang 95) and dice coefficients (Smadja 96) etc. Chang etc. (Chang etc. 97) iteratively apply the joint character association metric, which is derived by integrating above statistical features. Their performance is recall rate:81%, precision rate: 72% in disyllabic unknown word, recall rate:88%, precision rate: 39% in trisyllabic unknown word, and recall rate:94%, precision rate: 56% in four-syllabic unknown word. Chang etc. (1994) used statistical methods to identify personal names in Chinese text which achieved a recall rate of 80% and a precision rate of 90%. Chen & Lee (1994) used morphological rules and contextual information to identify the names of organizations. Since organizational names are much more irregular than personal names in Chinese, they achieved a recall rate of 54.50% and a precision rate of 61.79%. Lin etc. (1993) made a preliminary study of the problem of unknown word identification. They used 17 morphological rules to recognize regular compounds and a statistical model to deal with irregular unknown words, such as proper names etc.. With this unknown word resolution procedure, an error reduction rate of 78.34% was obtained for the word segmentation process. Since there is no standard reference data, the claimed accuracy rates of different papers vary due to different segmentation standards. In this paper we use the Sinica corpus as a standard reference data. As mentioned before, the Sinica corpus is a word-segmented corpus based on the Chinese word segmentation standard for information processing proposed by ROCLING (Huang et al 1997). Therefore it contains both known words and unknown words, which are properly segmented. The corpus was utilized for the purposes of training and testing. From the above discussion, it is known that identification of unknown words is difficult and need to adopt different methods in identifying different types of unknown words. The objective of this research is to find methods to extract unknown words from a document and identify their syntactic and semantic categories. Although both processing are interrelated, for limiting scope of this paper, we will focus our discussion on the extraction process only and leave the topics of syntactic and semantic category predictions to other papers. 2 Steps to Identify Unknown Words In addition to statistical information, we try to use as much information as possible, such as morphology, syntax, semantics, and world knowledge, to identify unknown words. The identification system fully utilizes the context and content information of unknown words in each three steps of processes, i.e. detection process, extraction process, and verification process. The detection process detects the occurrences of unknown words for better focusing, so that on the next step extraction process, it needs only focus on the places where unknown were detected. In addition, it also helps in identifying low frequency unknown words, which hardly can be identified by conventional statistical extraction methods. The extraction process extracts unknown words by applying morphological rules and statistical rules to match for different types of unknown words. As usual, tradeoff would occur between recall and precision. Enriching the extraction rules might increase recall rates, but it also increases the ambiguous and false extractions and thus lowers the precision. The final verification process comes to rescue. It resolves ambiguous and false extractions based on the morphological validity, syntactic validity, and statistical validity. 3 Unknown Word Detection Conventionally a word segmentation process identifies the words in input text by matching lexical entries and resolving the ambiguous matching (Chen & Liu, 1992, Sproat et al 1996). Hence after segmentation process the unknown words in the text would be incorrectly segmented into pieces of single character word or shorter words. If all occurrences of monosyllabic words are considered as morphemes of unknown words, the recall rate of the detection will be about 99%, but the precision is as low as 13.4% (Chen & Bai, 1998). Hence the complementary problem of unknown word detection is the problem of monosyllabic known-word detection, i.e. to remove the monosyllabic known-words as the candidates of unknown morphemes. A corpus-based learning method is proposed to derive a set of syntactic discriminators for monosyllabic words and monosyllabic morphemes (Chen & Bai, 1998). The following types of rule patterns were generated from the training corpus. Each rule contains a key token within curly brackets and its contextual tokens without brackets. For some rules there may be no contextual dependencies. The function of each rule means that in a sentence, if a character and its context match the key token and the contextual tokens of the rule respectively, this character is a proper word (i.e. not a morpheme of an unknown word). For instance, the rule ? {Dfa} Vh? says that a character with syntactic category Dfa is a proper word, if it follows a word of syntactic category Vh. Rule type Example ================================= 
char   {?} 
word char  ? {? } 
char word  {? } ? ? 
category {T} 
{category} category {Dfa} Vh 
category {category} Na {Vcl} 
char category  {?} VH 
category char  Na {? } 
category category char Na Dfa {? } 
char category category {?} Vh T 
=================================== 
Table1. Rule types and Examples 
Rules of the 10 different types of patterns 
above were generated automatically by 
extracting each instance of monosyllabic words 
in the training corpus. Every generated rule 
pattern was checked for applicability and 
accuracy. At the initial stage, 1455633 rules 
were found. After eliminating the low 
applicability rules, i.e. frequency less than 3, 
there are 215817 rules remained. At next stage, 
the rules with accuracy greater than 98% are 
selected for better recall rate. However the 
selected rules may subsume each other. Shorter 
rule patterns are usually more general than the 
longer rules. A further screening process is 
applied to remove the redundant rules. The final 
rule sets contain 45839 rules and were used to 
detect unknown words in the experiment. It 
achieves the detection rate of 96% and the 
precision rates of 60%. Where detection rate 
96% means that for 96% of unknown words in 
the testing data, at least one of its morpheme 
was detected as part of unknown word. However 
the boundaries of unknown words are still not 
known. For more detail discussion, see (Chen & 
Bai 1998). For convenience, hereafter we use (?) 
to mark detected morphemes of unknown words 
and () to mark the words which are not detected 
as morphemes of unknown words. 
4 Unknown Word Extraction 
At detection stages, the contextual rules were 
applied to detect fragments of unknown words, 
i.e. monosyllabic morphemes. The extraction rules will be triggered by the detected morphemes only. The extraction rules are context, content, and statistically constrained. Rule-design targets for high recall rate and try to maintain high precision at the mean time. It is hard to derive a set of morphological rules, which exactly cover all types of unknown words. Our approach is that if morphological structures of certain types of unknown words are well established, their fine-grain morphological rules will be designed. Otherwise statistical rules are designed without differentiate their extracted word types. Redundancy is allowed to achieve better coverage. Both morphological rules and statistical rules use context, content and statistical information in their extraction. 4.1 Morphological rules Since there are too many different types of unknown words, we cannot go through the detail extraction processes for each different type. It will be exemplified by the personal name extraction to illustrate the idea of using different clues in the extraction process. First of all the content information is used, each different type of unknown words has its own morphological structure. For instance, a typical Chinese personal name starts with a last name and followed by a given name. The set of last names is about one hundred. Most of them are common characters. Given names are usually one or two characters and seldom with bad meaning. Based on the above structure information of Chinese personal names, the name extraction rules are designed as shown in Table 2. Context information is used for verification and determining the boundary of the extracted word. For instance, in the last rule of Table 2, it uses context information and statistical information to resolve ambiguity of the word boundary. It is illustrated by the following examples. 1) after detection   : ?(? ) ?(? ) ?() ? () ? () ?()?  extractnion : ? ? ? ? ? ? ?             Ming-Zheng Zhang want kill somebody.         or ?? ? ? ? ??              Ming Zhang just want kill somebody. Rule type                Constraints & Procedure ========================================== (? )  (? )  (? ) 21 ++ iii msmsms combine  )2,1,( ++ iii (? )  (? )    () 21 ++ iii msmsms combine       )2,1,( ++ iii (? ) ()  (? ) 21 ++ iii msmsms combine       )2,1,( ++ iii ()   (? ) 1+ii dsms combine           )1,( +ii ()  (? )  (? ) 21 ++ iii psmsms                )1,( +iicombine ()  (? )  (? ) 21 ++ iii msmsms      as follows: ( ) 1|  12 <++ iiidocument msmsmsprobif namedisyllabicaasiicombine         )1,( + ( ) 1,,  32 ?++ iicoupus wordmsNAMEfreqelsif namedisyllabicaasiicombine         )1,( + ( )3,  + ? coupusicoupus freqwordNAMEfreq ( ) yllabic na as a tris,ii,i 21 ++  combine ( 2, +imsNAMEelsif me ) ) ( ) else namedisyllabicaasiicombine         )1,( + Notes: ms denotes monosyllable. ds denotes disyllable. ps denotes polysyllable which consists of more than one syllable. word denotes a word which could consist of any number of syllable. msi must belong to Common Chinese Last Name Set, such as ?, ??etc. =========================================      Table 2. Rule types of Chinese personal name In the examples 1), there are two possible candidates of personal names, ? ? and ? ? ? . By context information, the bi-gram (NAME, ?) is less freguent than (NAME, ?) in the corpus, so without considering statistical constraints, it would suggest that ? ? ? is a correct extraction instead of ? ? . However, the locality of the keywords is very important clue for identification, since the keywords of a text are usually unknown words and they are very frequently reoccurred in the text. The statistical information is used here for verification. For instance, if an another sentence which is like ? (? ) ? (? ) ? () ? () occurs in the same document, it suggests ??  is the correct extraction, since the statistical constraint rejects? ? ? . ( 1| < ? ? ? documentprob 4.2 Statistical Rules It is well known that keywords often reoccur in a document (Church, 2000) and very possible the keywords are also unknown words. Therefore statistical extraction methods utilize the locality of unknown words. The idea is that if two consecutive morphemes are highly associated then combine them to form a new word. Mutual information-like statistics are very often adopted in measuring association strength between two morphemes (Church & Merser, 1993, Sproat et al 1996). However such kind of statistic does not work well when the sample size is very limited. Therefore we propose to use reoccurrence frequency and fan-out numbers to characterize words and their boundaries (Chien, 1999). 12 statistical rules are derived to extract unknown words. Each rule is triggered by detected morphemes and executed in iteration. The boundaries of unknown words might extend during iteration until no rule could be applied. Following are two examples of statistical rules. 
Rule id Pattern          Statistical constraint 
========================================== 
R1         Lm(? ) Rm() S1 
R2         Lm(? ) Rm(? ) S2
 ( ) ( ) 
( ) 2  and
 8.0| and  8.0| : S1 
? 
?? 
LmRmFreq 
LmRmPRmLmP 
( ) ( )( ) 
( ) 
( ) ( )( )8.0| and 8.0|or 
2 8.0|or    8.0| : S2 
?? 
??? 
LmRmPRmLmP 
LmRmFreqandLmRmPRmLmP 
==========================================
     Table 3. Two examples of statistical rules The rule R1 says that Lm and Rm will be combined, if both conditional probability P(Lm|Rm)>=0.8 and P(Rm|Lm)>=0.8 hold and the string LmRm occurred more than once in the processed document. Conditional probabilities constrain the fan-out number on each side of morpheme, i.e. the preceding morpheme of Rm should almost be limited to Lm only and vice versa. The threshold value 0.8 is adjusted according to the experimental results, which means at least four out of five times the preceding morpheme of Rm is Lm and vice versa. However the statistical constraints are much loose when the right morpheme Rm is also a detected morpheme, as exemplified in R2. You may notice that it also accepts the unknown words occurred only once in the document. Conventional statistical extraction methods are simple and efficient. However if without supporting linguistic evidences the precision of extraction is still not satisfactory, since a high frequency character string might be a phrase or a partial phrase instead of a word. In addition to statistical constraint, our proposed statistical method requires that a candidate string must contain detected morphemes. In other words, the statistical rules are triggered by detected morphemes only. Furthermore the morphological structure of extracted unknown word must be valid. A validation process will be carried out at the different stages for all extracted unknown words. 5 Verification To verify a correct extraction depends on the following information. 1. Structure validity: the morphological structure of a word should be valid. 2. Syntactic validity: the syntactic context of an identified new word should be valid. 3. Local consistency: the identified unknown words should satisfy the local statistical constraints, i.e. no inconsistent extension on the morphological structures. For instance, a new word was identified by the pattern rules, but if it violates the statistical constraints, as exemplified in 1), will be rejected. Each extracted candidate will be evaluated according to the validity of above three criteria. For the candidates extracted by the statistical rules, their structure validity and syntactic validity are checked after extraction. On the other hand, for the unknown words extracted according to the morphological rules, their structure validity and syntactic validity are checked at extraction stage and their local statistical consistency is checked after extraction. To verify the structure validity and syntactic validity of the unknown words extracted by statistical methods, their syntactic categories are predicted first, since statistical rules do not classify unknown word types. The prediction method is adopted from (Chen, Bai & Chen, 1997). They use the association strength between morpheme and syntactic category to predict the category of a word. The accuracy rate is about 80%. Once the syntactic category of an unknown word is known its contextual bi-gram will be checked. If the bi-grams of (preceding word/category, unknown word category) and (unknown word category, following word/category) are syntactically valid, i.e. the bi-gram patterns are commonly occurred in the corpus, the extracted word is considered to be a valid word. Otherwise this candidate will be rejected. 5.1 Final Selection It is possible that the extracted candidates conflict each other. For instance, in the following example, both candidates are valid. ????, Bennet? is extracted by name rules and ????, lawyer-class ? is extracted by suffix rules. name  ==> ?? ?? ?? ??? ? ?       An-jan company lawyer Bennett said, suffix  ==> ?? ?? ??? ? ? ? ?  An-jan company lawyer-class is pecial said, The extracted new words will form a word lattice. The selection process finds the most probable word sequence among word lattice as the final result. In the current implementation, we used a very simple heuristics of maximizing the total weights of words to pick the most probable word sequence. The weight of a word w is defined to be freq(w)*length(w), where freq(w) is the occurrence frequency of w in the document and length is the number of characters in w. For the above example, ? ? ? ? , Bennett? occurred 5 times and ? ? ? ? , lawyer-class ? occurred twice only in the document. Therefore the final result is ?? ?? ?? ? ? ? An-jan company lawyer Bennett said , ?Bennett, the lawyer of An-jan company, said? ? 6 Experimental Results In the current implementation, the morphological rules include the rules for Chinese personal names, foreign transliteration names, and compound nouns. In addition to the morphological rules, twelve constrained statistical rules were implemented to patch the under coverage of the morphological rules. Although the current implementation is not complete, morphological rules of many other types of unknown words were not included, such as rules for compound verbs. The experiment results still show that the proposed methods work well and the morphological rules and the statistical rules complement each other in the extraction and verification. The Sinica balanced corpus provides the major training and testing data. The training data contains 8268 documents with 4.6 million words. We use it to train the detection rules and morphological rules. We randomly pick 100 documents from rest of the corpus as the testing data, which contain 17585 words and 1160 unknown word types. A word is considered as an unknown word, if neither it is in the CKIP lexicon nor it is identified as foreign word (for instance English) or a number. The CKIP lexicon contains about 80000 entries. The precision and recall rates are provided. The target of our approach is to extract unknown 
words from a document, so we define ? correct 
extractions? as unknown word types correctly 
identified in the document. The precision and 
recall rate formulas are as follows: 
idocument in sextractioncorrect  ofnumber NCi = 
idocument 
in    typesrdunknown wo extracted ofnumber NEi = 
idocument 
in    typesrdunknown wo reference ofnumber NRi = 
? 
? 
= 
= 
= 
== 100 
1 
i 
100 
1 
i 
NE 
NC 
ratePrecision i 
i 
i 
i 
? 
? 
= 
= 
= 
== 100 
1 
i 
100 
1 
i 
NR 
NC 
rate Recall i 
i 
i 
i
  To observe the frequency impact on our system, the performance evaluation on both high frequency and low frequency unknown word identifications are also provided at Table 5 & 6. A word occurs more than or equal to 3 times in a document is considered a high frequency word. There are only 66 high frequency unknown words in our testing data. It counts less than 6% of the total unknown words. Correct# Extract# Precision Recall Morphological rules 541 590 92% 47% Statistical rules 455 583 78% 39% Total system 791 890 89% 68% Table 4. Experimental result of total unknown word types Correct# Extract# Precision Recall Morphological rules 25 26 96% 38% Statistical rules 50 60 83% 76% Total system 54 64 84% 82% Table 5. The performance on the set of unknown words with frequency >= 3 in a document Correct# Extract# Precision Recall Morphological rules 510 564 90% 47% Statistical rules 400 523 76% 37% Total system 731 826 88% 67% Table 6. The performance on the set of unknown words with frequency <3 in a document Recall rate of total unknown word types is not very high, because not all of the morphological rules were implemented and some of the word tokens in the testing data are arguable. The experiment results in Table 6 show that the proposed methods work well on low frequency unknown word identification. 7 Conclusions and Future Works Unknown word extraction is a very hard task. In addition to statistical information, it requires supporting knowledge of morphological, syntactic, semantic, word type specific and common sense. One important trend is to look harder for sources of knowledge and managing knowledge that can support unknown word identification. A word segmented and tagged corpus is essential for the success of the whole research. The corpus provides the major training and testing data. It also supports plenty of unknown words and their contextual data to derive extraction rules. In this work we are managing to use the structure information, the context environment, and statistical consistency of the unknown words and to increase the recall and precision of the extraction process. The syntactic and semantic classifications for unknown words are executed in parallel with the extraction process. Both classification processes are very hard and need further researches. 8 References Chang J. S.,S.D. Chen, S. J. Ker, Y. Chen, & J. Liu,1994 "A Multiple -Corpus Approach to Recognition of Proper Names in Chinese Texts", Computer Processing of Chinese and Oriental Languages, Vol. 8, No. 1, 75-85. Chang, Jing-Shin and Keh-Yih Su, 1997a. "An Unsupervised Iterative Method for Chinese New Lexicon Extraction", International Journal of Computational Linguistics & Chinese Language Processing, 1997. Chen, H.H., & J.C. Lee, 1994,"The Identification of Organization Names in Chinese Texts", Communication of COLIPS, Vol.4 No. 2, 131-142. Chen, K.J. & S.H. Liu, 1992,"Word Identification for Mandarin Chinese Sentences," Proceedings of 14th Coling, pp. 101-107. Chen, K.J., C.R. Huang, L. P. Chang & H.L. Hsu, 1996,"SINICA CORPUS: Design Methodology for Balanced Corpora," Proceedings of PACLIC 11th Conference, pp.167-176. Chen, C. J., M. H. Bai, K. J. Chen, 1997, ? Category Guessing for Chinese Unknown Words.? Proceedings of the Natural Language Processing Pacific Rim Symposium 1997, pp. 35-40. NLPRS ? 97 Thailand. Chen, K.J. & Ming-Hong Bai, 1998, ?Unknown Word Detection for Chinese by a Corpus-based Learning Method,? international Journal of Computational linguistics and Chinese Language Processing, Vol.3, #1, pp.27-44. Chen, K.J., Chao-Jan Chen. 1998. ?A Corpus Based Study on Computational Morphology for Mandarin Chinese????????????????? ???.? Quantitative and Computational Studies on the Chinese Language. Benjamin K. T? sou, Tom B.Y. Lai, Samuel W. K. Chan, William S-Y. Wang, ed. HK: City Univ. of Hong Kong. pp.283-306. Chiang, T. H., M. Y. Lin, & K. Y. Su, 1992,? Statistical Models for Word Segmentation and Unknown Word Resolution,? Proceedings of ROCLING V, pp. 121-146. Chien, Lee-feng, 1999,? PAT-tree-based Adaptive Keyphrase Extraction for Intelligent Chinese Information Retrieval,? Information Processing and Management, Vol. 35, pp. 501-521. Church, K. W., & R. L. Mercer, 1993, ?Introduction to the Special Issue on Computational Linguistics Using Large Corpora.? Computational Linguistics, Vol. 19, #1, pp. 1-24 Church, Kenneth W., 2000,? Empirical Estimates of Adaptation: The Chance of Two Noriegas is Closer to p/2 than p*p? , Proceedings of Coling 2000, pp.180-186. Huang, C. R. Et al.,1995,"The Introduction of Sinica Corpus," Proceedings of ROCLING VIII, pp. 
81-89. 
Lin, M. Y., T. H. Chiang, &  K. Y. Su, 1993,? A 
Preliminary Study on Unknown Word Problem in 
Chinese Word Segmentation,? Proceedings of 
ROCLING VI, pp. 119-137. 
Smadja, F., 1993,? Retrieving Collocations from 
Text: Xtract,? Computational Linguistics, 
19(1),143-177. 
Smadja, F., K. McKeown, and V. Hatzivassiloglou, 
1996,?Translating Collocations for Bilingual 
Lexicons: A Statistical Approach,? Computational 
Linguistics, 22(1). 
Sproat, R., C. Shih, W. Gale, & N. Chang,1996, "A 
Stochastic Finite-State Word-Segmentation 
Algorithm for Chinese," Computational Linguistics, 
22(3),377-404. 
Sun, M. S., C.N. Huang, H.Y. Gao, & Jie Fang, 1994, 
"Identifying Chinese Names in Unrestricted Texts", 
Communication of COLIPS, Vol.4 No. 2, 113-122. 
