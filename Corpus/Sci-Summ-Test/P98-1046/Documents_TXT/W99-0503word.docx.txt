Supervised Learning of Lexical Setuantic Verb  Classes Using  Frequency Distributions



Suzanne Stevenson 
Rutgers Umversxty 
suzanne cs rutgers edu


Paola  Merlo
Umvers1ty of Geneva
merlo lettres un1ge ch


Natalia 
Kariaeva
Rutgers  
Umvers1ty
kar1aeva rc1 rutgers 
edu



Kamin Whitehouse
Rutgers  Umvers1ty
kam1nw©rc1 rutgers edu




Abstract

We  report  a number  of computational ex­ 
periments  in  supervised    learnig   whose 
goal  IS   to  automatically classify  a  set  of 
verbs  mto  lexrcal  semantic classes,  based 
on  frequency   drstrrbut1on  approx1mat1ons 
of grammatical features  extracted  from  a 
very large  annotated corpus   D1strrbutrons 
of five syntactic features  that  approx1mate 
trans1trv1ty  alternations and  thematic  role 
ass1gnments  are  sufficient  to  reduce  error 
rate   by  56% over  chance      We conclude 
that  corpus  data IS  a  usable  repos1tory  of 
verb  class  mformation, and  that   corpus­ 
drrven  extractiOn  of grammatical features 
IS a promismg  methodology for automatic 
lexical  acquisition


1 	Introduction

Recent  years  have Witnessed a shift  m grammar de­ 
velopment   methodology, from  craftmg large  gram­ 
mars,   to  annotation of corpora 	Correspondmgly, 
there  has  been a change from developmg  rule-based 
parsers  to developmg  stat1st1cal  methods for mduc­ 
mg grammatical knowledge  from  annotated  corpus 
data  The  sh1ft has mostly  occurred  because  bu!ld­ 
mg wrde-coverage grammars 1s  t1me-consummg,  er­ 
ror  prone,  and  difficult    The  same  can  be sa1d for 
craftmg the  nch  lexrcal representatiOns  that   are  a 
central   component of hngu1strc knowledge,  and  re­ 
search   m  automatic le-..1cal  acqu1s1t1on has  sought 
to address th1s ((Dorr  and Jones,  1996, Dorr,  1997), 
among others)  Yet there have been few attempts to 
learn fine-gramed  lexical classificatiOns from the sta­ 
tistical   analysiS  of d1stnbutwnal  data,  analogously 
to the mduct1on of syntactic knowledge (though  see, 
e g,  (Brent, 1993,  Klavans  and  Chodorow,   1992,


Resml.., 1992))   In  th1s paper.  we propose uth an 
approach   for  the  automatic classlficatwn  of  \erb
mto  lex1cal semantic classes 1
  We can express  the  Issues raised by th1s approach 
as follows

Wh1ch   hngu1st1c  d1stmctwns   among   le\.Ical 
classes can  we e\.pect  to find m a corpus>

2   How easily can  we extract  the frequency drstn­ 
butlons  that  approx1mate  the relevant hngutstiC 
properties?

3   Wh1ch frequency  d1stnbut1ons work best to dls­
tmgmsh  the  verb classes?

  In explormg these quest1ons, we focus on verb clas­ 
Sificatwn  for several  reasons   Verbs are very Impor­ 
tant  sources of knowledge m many language eng1- 
neermg  tasks,  and the relat10nsh1ps among verbs ap­ 
pear to play a maJor role m the orgamzatwn and use 
of this knowledge   h.nowledge about verb classe  1s 
cruc1al for lexical acqu1srt10n m support  of language 
generatiOn and machme translatiOn (Dorr, 1997) and 
document clC!bsrficatwn (Klavans  and  Kan,  1998),
:yet manual  class1ficatwn of large numbers of verb'S 1s 
a d1fficult and  resource  mtens1ve task  (Levm,  1993
MJ!ler et  a! , 1990, Dang et al , 1998)
  To  address  these 1ssues, we suggest  that  one can 
tram  an automatic classifier for verbs on the bast'S of 
stattst1cal apprm.. tmatwns to verb dtatheses    We use 
dratheses-alternattOns m the e\.presswn of the ar­ 
guments of the  verb-followmg Levm and  Dorr,  for 
two reasons   Fnst, verb dratheses  are syntacttc 
cue'>

     1 We are aware that a d!stnbuttonal approach  rests on 
one strong  assumptiOn regardmg the nature of the repre­ 
sentatiOns  under  study    semantic  not10ns and syntact1c 
notions are correlated,  at least m part   Tlus assumptton 
IS   under  debate   (Bnscoe  and  Copestake,  1995,   Levm,
1993,  Dorr and  Jones,  1996,  Dorr, 1997),  but  we adopt
1t here w1thout further d1scuss1on








15


to semantic  classes, hence they can  be more eas1ly 
captured  by corpus-based techn ques  Second, usmg 
verb diatheses  reduces no1se There IS a certam con­ 
sensus  (Bnscoe  and Copestake,  1995, Pustejovsky,
1995, Palmer,  1999) that  verb d1atheses are regular 
sense extensions    Hence focussmg on  th1s type of 
classlficatton  allows one to abstract  from the  prob­ 
lem of word sense d1sambiguatton and treat  residual 
differences m word senses as no1se m the classifica­ 
tiOn task
  We present  an  m-depth  case study,  m wh1ch we 
apply machme learmng techn ques to automatically 
class1fy a set of verbs based on d1stnbutwns of gram­ 
matical  md1cators of  diatheses,  extracted   from  a 
very large corpus    We look at  three  very mterest­ 
mg classes of verbs  unergat1ves, unaccusat1ves, and 
object-drop verbs (Levm, 1993)  These are mterest­ 
mg classes because they all participate  m the transi­ 
tiVIty alternatiOn, and they are m1n1mal pa1rs- that
1s, a small number of well-defined d1stmct10ns differ­ 
entiate  then  transltlve/mtransJtlve behaviOr Thus, 
we expect  the d1fferences m the1r d1stnbutwns  to be 
small,  entallmg  a  fine-gramed d1scrlmmatwn  task 
that   prov1des a  challengmg  testbed  for  automat1c 
class1ficat10n
  The spec1fic theoretical questwn we mvest1gate IS 
whether the factors underlymg the verb class d!s­ 
tmcttons  are reflected m the statistical d1stnbut10ns 
of lex1cal features  related to diatheses presented by 
the mdivJdual verbs m the corpus   In domg th1s, we 
address the questwns above by determmmg what are 
the lex1cal features that could d1stmgmsh the behav­ 
Ior of the classes of verbs wtth respect to the relevant 
diatheses,   'Nh1ch  of those features  can  be gleaned 
from the corpus,  and  wh1ch  of those, once the sta­ 
tistical d1stnbut10ns are available, can be used suc­ 
cessfully by an automatic classifier
  In Initial  work (Stevenson and  Merlo, 1999), \\e 
found that  hngmst1cally mot1vated features that d1s­ 
tmgu1sh the  verb classes can be extracted  from an 
annotated, and  m one case parsed, corpus    These 
features   are  sufficient  to  almost  halve  the  error 
rate  compared  to chance (45% reductwn)  m auto­ 
matic verb class1ficat10n, suggestmg that dtstnbu­ 
twnal data  provtdes knowledge useful to the classt­ 
ficatwn  of verbs    The  focus of our ongmal  studj 
was thP demonstration m pnnctple of IPc>•nmg verb 
classes from frequency d1stnbutwns of syntactic fea­ 
tures, and an analysis of the relative contnbutwn of 
the  vanous  features  to learnmg   Th1s paper  turns 
to the Important ne\.t steps of rephcatmg our find­ 
mgs usmg other  trammg methods and learnmg al­ 
gonthms, and analyzmg the performance on each of 
the three classes of verbs  Th1s more detalied anal­ 
ysis of accuracy  w1thm each class 111 turn  leads to


the development of a new dtstnbutwnal  featme  
m­ tended to 1m prove dJscrlmmabthty among t\\O 
of the classes  The addttiOn of the ne\\ feature 
successfully reduces the error rate of ou1 Initial 
results m classi­ ficatiOn by 19%, for a 56% overall 
reductiOn m error rate compared  to chance

2    Determining the  
Features

In th1s sectwn,  we present mottvatwn for the 
llllttal features  that  we mvest1gated m terms of 
thetr  wle m learnmg  the  verb classes    \Ve first 
present  the lmgmst1cally denved features  then 
turn toe\ tdence from e\.penmental  
psychohngutsttcs to e\.tend  the set of potenttally  
relevant features

2.1   Features of  the Vetb  
Classes
The three verb classes under mvesttgatwn - 
unerga­ tJves, unaccusattves,  and object-drop - 
dtffer 111   the properttes  of  the1r 
transtttve/mtranstttve alterna­ tiOns, wh1ch are 
exemphfied below

Unergat1
ve
( 1a) The horse raced past the 
barn
( 1b) The Jockey raced the horse past the 
batn

Unaccusat1
ve
(2a) The butter  melted m the 
pan
(2b) The cook melted the butter  m the 
pan

Object-
drop
(3a) The boy washed the 
hall
(3b) The boy 
washed

The sentences m ( 1) use an unergattve Vl't b. weed 
Unergattves are mt1anstttve actton verbs whose 
tran­ SitiVe  form  ts the  causattve  counterpart  of 
the  m­ transttlve  form   Thus,  the subject  of the 
mttanst­ tne  (1a)  becomes the obJect of the 
transttl\e (lb) (Brousseau and Rttter  1991, Hale 
and h.ejset  1993
Levm and  Rappaport  Hovav, 1995)  The 
sentences m  (2)  use an  unaccusattve  verb,  melt  
:cl 	(_ nac­ cusattves are 
mtranstttve change of statl'  \et bs (2a) hke 
unergattves, the transttl\e countetpart  fot thh<' 
verbs ts also causattve  (2b)	The sentenc<'tn  ( J)
use an obJect-dlOp vet b  u·u hed, thee vet b-; ha1 c 
a non-causatne tran ttl\e/mtranstttve altettM\lon   
tn
11 luch the obJect ts 
stmplopttonal
  Both   unergattves   and   unaccusatn I'S      hm e   
a causative  transtttve  form. but dtffer tn the 
semanttc roles that  they asstgn to the parttctpants 
m thl' e1 ent descnbed   In an mtranstttve  
unetgattve, the ubJect ts an 1\.gent {the doer of the 
event), and Ill an tnttan­ stttve unaccusattve,  the 
subject  ts a Theme  (ome­ thmg affected by the 
event)   The role asstgnments to the correspondmg  
semanttc  arguments of the  t1an­ stttve forms-t e , 
the duect  obJects-;:ue th<>  amc






16


wtth  the  additiOn  of a Causal  Agent  (the  causer  of 
the  event)   as  subject  m  both  cases     Object-drop 
verbs s1mply assign  Agent  to the subject and Theme 
to the optiOnal  object
We expect  the dlffermg semantic role assignments
of  the  verb  classes  to  be  reflected  m  their  syntac­ 
tic  behaviOr, and  consequently m the distributiOnal 
data we collect  from a corpus   The  three classes can 
be characterized by their occurrence  m two alter­ 
natiOns    the  transittve/mtransitive alternatiOn  and 
the causative alternatiOn   Unergatives are dJstm­ 
gUished from the other classes m bemg rare m the 
transitive form (see (Stevenson  and  Merlo, 1997) for 
an e\.planatiOn  of this fact)   Both unergattves and 
unaccusat1ves  are distmgUished  from object-drop m 
bemg  causatiVe  m  the1r  transitive form,  and  sun­ 
tlarly  we expect   th1s to  be  reflected  m amount  of 
detectable causat1ve  use    Furthermore, smce the 
causative IS a transitive use, and the transitive use of 
unergat1ves 1s expected to be rare, causatlvity should 
pnmanly  distmgUish    unaccusatives  from   object­ 
drops    In conclusion, we expect  the definmg features 
of the verb classes-the mtransitive/transitive and 
causatiVe alternatiOns-to lead to distribUtiOnal dif­ 
ferences m the observed  usages of the verbs m these 
alternatiOns

2 2    Psycholingwstlcally Relevant Features
The   verbs   under   study  not   only   differ  m  their 
thematic properties, they also differ m their pro­ 
cessmg  properties    Because  these  verbs can  occur 
both  m a  transitive and  an  mtransittve form,  they 
have been  particularly studied m the conte\.t  of the 
mam  verb/reduced relative  (MV /RR) ambigUity Il­ 
lustrated below (Bever,  1970)

The  horse  raced  past  the  barn  fell

The  verb  weed can  be mterpreted as either  a  past 
tense  mam  verb, or as a past  participle wtthm a re­ 
duced  relat1ve clause  (1 e , the horse (that  was] raced 
past the barn)   Because  fellts the mam verb, the I e­ 
duced  relative  InterpretatiOn of raced  IS reqUired for 
a coherent   analysts  of the  complete  sentence    But 
the  mam  verb  mterpretatton of raced  1s so strongly 
preferred   that   people  expenence great  dtfficulty  at 
the  verb  fell. unable  to  mtegrate It w1th the  Inter­ 
pretatiOn  that  has been developed  to that  pomt
  However, the reduced  relat1ve mterpretatton ts not 
dtfficult  for all verbs,  as m the follO\ mg example

The  boy washed  m the  tub  was angry

The  dtfference   m  ease  of  mterpretmg  the  tesolu­ 
tiOns of thts  ambtgmty has  been  shown  to  be sen­ 
stttve   to  both  frequency   dtfferenttals   (MacDonald
1994, Trueswell,  1996) and  to verb class d1stmct10ns
(Stevenson  and  Merlo, 1997,  F1ltp et  al , 1999)


Constder  the features  that  dtstmgutsh  the t\\O 1 e ­
olutiOns of the  Mv /RR ambtgutty

MV   The  horse  raced  past  the barn quickly

RR  The  horse  raced  past the  barn fell

In  the  maiO  verb  resolutiOn,  the  ambiguous  verb 
raced IS used m Its mtransttlve form, wh1le m the re­ 
duced  relat1ve, It IS  used m 1ts transitive,  causative 
form 	These   features   correspond   directly  to  the 
definmg  alternatiOns of  the  three  verb classes  un­ 
der study (mtransttlve/transittve, causattve)   -\ddt­ 
tlOnally, we see  that  other  related  featureto  t hPse 
usages serve to dtstmgutsh the two resolut10ns of the 
ambiguity  The mam  verb form IS active and a mam 
verb  part-of-speech  (labeled  as VBD  by automatic 
POS taggers),  by contrast, the reduced relatne foun 
IS  passive  and  a  past  participle  (tagged  as  \ B:'-1) 
Smce these features  (acttvefpasstve and VBD/\'BN) 
are related  to the mtranstttve/transttlve alte111at10 n, 
we expect  them  to also exhibit  dtstrtbutlOnal  differ­ 
ences among  the verb classes  Specifically, \\e e\.pect 
the unergattves to yteld a htgher proportiOn of actl\e 
and \tBD  usage, smce, as noted above, the tianstt1 ve 
use of unergattves IS  rare

3 	Frequency Distributions of the
Features

We  assume   that   currently   available  large  co1po1a 
are  a  reasonable   approximatiOn  to  language  (Pul­ 
lum,  1996)    Usmg a combmed  corpus  of 65-mtlhon 
words,  we measured  the relative frequenc} d1stnbu­ 
tiOns of the four hngUisttc features  (VBD/\ B\   ac­ 
tive/passive, mtranstttve/transtttve, causatt\P/non­ 
causattve) over a sample  of verbfrom the thtPe Ie,­ 
tcal semantic classes

3 1   Matenals
\Ve chose a set of 20 verbs from each class based pit­ 
mat tly on the classtficatiOn of verbs m ( Le\ m  191).3) 
(see  AppendiX  A.)    The  unetgattves   ate  marmet  of 
motiOn verbs   The  unaccusatnes ate \erbs of thitnge 
of state  The  object-drop verbs are  un pectfted  ob­ 
ject alternatiOn  verbs   The  vetbs \\ere selected  f10m 
Le\m's classes  based  on  thetr  absolute   ftequPnc 
FUI thermore, they do not generally shO\  m  l\ f' de­ 
pat tures  from the mtended  verb sense Ill the co1 pu., 
(Though note  that  there  are only 19 unaccu  att\ f''> 
because  rzpped. \ luch  \\a-s tnittally  counted   111   thP 
unaccusattves.  was  then  e\cluded  from  the  anal\­ 
SIS  as It occurred   mostly 1n  a dtfferent  usagp 111  tl;e 
corpus,  as a ve1 b plus  pat t1cle )   Most of the  ve 1 b 
can occur  Ill the  transtttve  and  m the  pa  lve   Earh 
verb  presents  the arne f01m m the stmple  pat  and 
m the past  patttctple  In order to Simphf} the count-


mg procedure,  we made  the assumptiOn  that  counts 
on this smgle verb form  would appro\.Imate the dis­ 
tnbutiOn of the features across all forms of the verb
  Most counts  were performed  on the tagged version 
of the  Brown Corpus  and on the  portiOn of the Wall 
Street Journal distributed by the  ACL/DCI (years
1987,  1988,  1989),  a combmed  corpus  m excess of
65  mdhon words,  With  the  exceptiOn  of causativ­ 
Ity which  was counted  only for the 1988 year of the 
WSJ,  a corpus  of 29 million words

3 2     Method

We counted   the  occurrences   of each  verb  token  m 
a  transitive or  mtiansltlve use  (INTR), m an act1ve 
or  passive  use (ACT), m a past  paiticlple or s1mple 
past  use (vao), and  m a causative or non-causat1ve 
use  ( CAUS)      More  prec1sely, features were counted 
as follows
INTR    a verb occurrence was counted  as trans1t1ve
1f  Immediately followed by a nommal  group,  else 1t 
was counted  as mtrans1t1ve
   ACT    mam  verbs  (tagged  VBD)  were counted  as 
active,  partiCiples (tagged vBN)  counted  as actiVe If 
the closest  precedmg  aux1hary  was have,  as passive
1f the  closest  precedmg  aux1liary was be
  VBD    occurrences   tagged  VBD  were s1mple past, 
VBN were past  partiCiple
  (Each  of the  above  three  counts  was normalized 
over all occurrences  of the  verb,  y1eldmg a smgle 
relat1ve frequency measure  for each verb for that fea­ 
ture)
   CAUS   The causative feature  was approximated by 
the  followmg steps     FirSt,  for each  verb,  all cooc­ 
cumng  subjects and  objects   were e\.tracted  from
a  parsed  corpus  (Collms,  1997)   Then  the  propor­



d1menswn,  the set of 59 vectors constitute the data 
for our  machme  learnmg  expenments

Template  (verb,  VBD,  ACT,  INTR,  CAliS,  class) 
Example  (opened,   79,  91,  31,  16, unacc]
Our  goal was to determme whether automatic clas­ 
SificatiOn techmques could determme  the class of a 
verb  from  the  dtstnbutwnal properties  represented 
m this  vector
  In  related  work (Stevenson  and  Merlo, 1999)  11e 
descnbe lllltial unsupervised  and superv1sed lea1 n111o- 
e\.penments on  th1s data, and d1scuss the contllbu- 
tlOn of the four different features  (the frequenL} d1s­ 
tnbutwns) to accuracy  m verb classificatiOn  In th 1s
paper,  we extend  the work m several \\ays   Fu-,t, 11e
report  further analys1s of rephcat10ns of our  uut1al 
supervised  learnmg   results    Next,  we demonstrate 
s1miiar performance usmg different trammg methods 
and  learmng  algonthms, md1catmg that  the perfor­ 
mance  IS  mdependent of the  particular learmng ap­ 
proach    Furthermore, these additiOnal expenments 
allow  us to evaluate the  performance  separately  on 
each of the three  verb classes   Fmally, based on th1s 
evaluatwn, we suggest  a new feature  to better  d1s­ 
tmgUish  the  thematic properties  of the classes, and 
present  experimental results showmg that Its use 1m­ 
proves our origmal accuracy  rate

4.1   lnit1al Experiments
Imt1al experiments were earned  out  usmg a decision 
tree  mductwn algonthm, the C5 0 system  available 
from  http / jwww  rulequest com/   (Qumlan,   1992), 
to automatically create a classificatiOn program ftom a 
trammg set  of verb vecto1s w1th known classlf1ca­
2


tiOn of overlap  bet....,een  the  two mult1sets of nouns


tJOn


In  our  earhe1  e\.pellments  11e  ran  10-fold


was calculated, meant  to capture the causat1ve al­ 
ternatiOn,  \here the  subject  of the  mtrans1t1ve can 
occur   as  the  object   of  the  transitive    \ve  define 
overlap  as  the  largest   mult1set of elements  belong­ 
mg  to  both  the  subjects and  the  object  mult1sets, 
eg    {a,a,a,b}n {a}=  {a,a,a} The  proportiOn 
IS  the  rat1o between  the  0\erlap and  the sum  of the 
subject and  object  mult1sets   (For \.ample, for the 
s1mple sets  above,  the  ratiO would be 3/5 or  60 )
  All ral\  and  normalized  corpus  data  a1e available 
from the authors, and  more deta1l concernmg data 
collectiOn  can  be  found   m  (Stevenson   and  !Vlerlo,
1999)


cross-vahdatwns repeated   10 times   he1e 11e  tepeat
the  CJoss-vahdatwns 50 t1mes. and  the numbe1s 1e­
p01 ted  are averages  over all the  1un'3 3
  Table  1 shows  the  re'3ult'>  of our  e\.penment'> 011 
the  four  features   we counted   m the  co1po1 a  (\so 
ACT,  I'<TR,  CAUS),  as well as all three-featu1e '>ubsets 
of those four   The  basel me (chance)  pe1 fo1 mance 111 
thl'3 task  1s  33 8%, smce  the1e  are  59 lector'> and

     2 The S)stem generates both decision trees and rule 
sets fm use m classification  Smce the d1fferenct 111 per_ 
fonnance between the t\\O IS ne\er sigmficant \le report 
here on!} the results usmg the extracted rules  The rules 
prov1de a confidence level for each classificatiOn 11 hJCh 
IS  unavailable With the decision tree data structure
3



4    Experiments in Verb  Classification

The frequency d1stnbut10ns of the verb alternatiOn 
features y1eld a vector  for each  verb that  reprebents 
the  relat1ve frequency   values  for  the  verb  on each


.\  10-fold cross-vahdat10n means that  the S\ stem
randomly divides the data  mto 10 parts,  and runs 10
times  on  a  different  90%-traimng-data/ 10%-test-data 
spht,  y1eldmg an average accuracy and standard  enor 
Th1s procedure IS  then repeated for 50 different random
diVISions  of the. data   and accurac)  and standard  error 
are agam averaged across the 50 runs


II	Features	Ace%	SE%  II


II 	Classes 	Percent  -\ccuracy   II
II All Classes 	61 o 	11










Table 1  Percentage Accuracy  (Ace%) and Standard
Error  (SE%) of C5 0 (33 8% baseline)


3  poss1ble classes 	(That 1s, ass1gmng one  of  the 
two most common classes-of  20 verbs each-to  all 
cases would yield 20 out  of 59 correct,  or 33 8% )  As 
seen m the table, classificatiOn  based on the four fea­ 
tures  performs  at  63 7%, or 30% over chance    The 
true  mean of the sample cross-vahdatiOnS hes Within 
plus  or  mmus  two standard errors  of the  reported 
mean (df=49, t=2 01, p<  05)   In all cases, the range
1s  plus  or  mmus  1 0  or  1 2,  y1eldmg a  very  nai­
row predicted  accuracy range   Furthermore, we per­ 
formed  t-tests companng the results  of the 50 cross­ 
validatiOns  for each  of the  different  feature  subsets 
All pairs  were s1gmficantly  different  (p<  05) except 
for the results  usmg all four features (first row m the 
table)  and  those excludmg ACT  (second  row m the 
table) 	We conclude   that   all  features except   ACT 
contnbute pOSitively to  classificatiOn  performance, 
and  that ACT  does  not degrade  performance  In our 
rephcat10ns,  then,  we focus on all four features

4 2 	Rephcat10n with Different Trammg and
Learmng Methods
There  are  conceptual and  practical reasons  for  m­ 
vestlgatmg  the  performance of  other   trammg  ap­ 
proaches and learnmg  algonthms apphed  to our verb 
d1stnbut10n  data 	Conceptually. 1t IS  des1rable  to 
know  whether   a  particular  learnmg   algonthm  or 
trammg techmque  affects  the  level of performance 
Practically, different   methods enable   us  to  evalu­ 
ate  more eas1ly the  performance of the classificatiOn 
method w1thm each  verb  class    (When  we run  re­
peated   cross-validatiOns With t {:'5 0. system,   we
don't have access to the accuracy  rate for each class, 
the sy<>tem only outputs an overall mean error  rate  ) 
To preview,  we find that the  different  trammg and 
learnmg   methods we tned   alL gave  similar  perfor­ 
mance  to  our  ongmal results,   and  m  addition   al­ 
lowed us to evaluate the  accuracy  w1thm each verb 
class
  In one set of expenments, we used the same  C5 0 
system, but employed a trammg and testmg  method­ 
ology  that   used  a  smgle   hold-out   case     We  held 
om  a smgle  verb  vector,   tramed  on  the  remammg
.58 cases,  then  tested   the  resultmg  cla<>slfier  on  the


Table  2   Percentage Accuracy  of C5 0 Wtth Smgle
Hold-Out  Trammg


smgle  hold-out  case,  and  recorded  the co!tect  and 
ass1gned classes  for  that   verb 	Th1s was then  1 e­ 
peated  for each of the 59 ve1 bs  Th1s approach }1elds 
both  an overall  accuracy  rate  (when the tesultare 
averaged  across  all  59  tnals), as  well as  p!O\ 1dmg 
the data necessary for determmmg accuracy f01 each 
verb class (because  Y<e have the classificatiOn of each 
verb  when 1t 1s  the  test  case)    The  results a1e pre­ 
sented  m Table 2  The overall accuracy IS a little less 
than  that  ach1eved w1th the 10-fold cross-vdhdatwn 
methodology (61 0%  versus  63 7%)	However.  we 
can  see  clearly  now  that   the  unergat1ve verbare 
classified  w1th much  greater   accuracy  (75%),  wlule 
the unaccusattve and object-drop verbs are class1fied 
w1th much  lower accuracy  (57 9% and  50% respec­ 
tively)   The  d!stnbutiOnal features  we have appear 
to be much better at d1stmgmshmg  unergat1ves than 
una.ccusatJve or object-drop  verbs
  To  test  th1s directly  under  our  ongmal   t1ammg 
assumptiOns,  we ran  two different  expenment-s,  u::.­ 
mg 10-fold cross-validatiOn  repeated  10 tane»   The 
first expeument tested  the ab1lity of the classtfiet to 
d1stmgmsh  between  unergatlves and  the  other  (\\O 
verb  types,  wrthout   havmg  to  dtstmgursh   bet\\een 
the  latter   two    The  data mcluded  the  20 unerga­ 
tive verbs and  a random  sample  of 10 unaccu5attve 
and  10 object-drop verbs,  10 different  random am­ 
pies  were selected   to  form  10 such  data   set	In 
these  data sets,   the  \erbs were labeled  as  unerga­
tt ve or  "other"  The  basel me (chance)  clas tficatton 
accuracy  fot  th1s data ts 50%,  the  mean  acrut ac\ 
ach1eved across all data sets was i8 5% (standard e;­
!Or 0 8%),  a srzable  Improvement  o\er  chance   The 
second  e\.peument  \\as  mtended  to deter mmP ltm\ 
well the classifier  can  d1stmgut»h. unaccu->att'e from 
object-drop  verbs 	The  data consrsted  of one   et 
that  mcluded  all  the  unaccusatrve and  object-drop 
verbs,  w1th no unergat1ves    Because  there  ate  only
19 unaccusat1ve  verbs,  the  basehne  accuracy 1ate  1s
51% (20/39), here the classrfier achreved an dCC'uracy
only slightly  above chance,  at 58 3% (standard er10r
1 8%)  These  results,  summanzed m Table 3  
rlea.rlY confirm the h1gher accuracy  of cla5 tfymg 
unergattv verbs wtth  the  current feature  set
Thts  pattern of results  \\as  tepeated unc!Pt  "\PI)



Classes



Ace%	SE%


II	Classes 	I 
VBD    I ACT    I INTR I 
CAUS II


Unergat1ve vs   Other	78 5 	08


Unerg vs   Unacc 	***	***	* 	***


Unaccusat1ve  vs   ObjectDrop	58 3 	1 8


Table 3  Percentage Accuracy  (Ace%) and Standard
Error  (SE%)  of C5 0 (50-51%  baseline)


Unerg vs   ObjDrop	*** 	***
Unacc vs   ObjDrop	ns 	ns

*** p$ 001
** p< 01
*	p$ 05


***	*
**	*


II	Classes


PCA%


FMP%   II
II


ns   non-s1gmficant


Table  5   S1gmficance 
Levels ofT-Tests 
Comparmg
Feature  Values 
Between  Verb Classes







Table  4  Percentage Accuracy  of PCA  (PCA%)  and
Feature  Map (FMP%) Neural  Networks


different  type of learnmg algorithm as well   We per­ 
formed a set of neural  network expenments,  usmg 
NeuroSolutwns 3 0  (see  http/ jwww  nd com),  and 
report  here on the networks that  achieve the best 
performance on our  data  These  are  prmc1pal com­ 
ponents analysis   and   automatic feature map  net­ 
works,   which  are  essentially  feed-forward   percep­ 
trons  w1th pre-processmg  umts  that  transform the 
ex1stmg features mto  a more  useful format   In our 
tests,   both   methods  performed best  overall  when 
there  were no hidden  layer  umts, and  the  networks 
were tramed  for  1000  epochs     The  mean  accuracy 
rates  of 10-fold cross-vahdatwns With these  param­ 
eter  settmgs are summanzed m Table  4  Agam,  the 
overall percentage accuracy ISm the low sixties,  w1th 
better   performance on  the  unergat1ves  than  on  the 
other   two  verb  classes,   the  difference  was particu­ 
larly  stnkmg w1th the  PCA  networks    Th1s overall 
pattern doesn't change  w1th further  trammg, m fact, 
trammg up to 10,000 epochs  resulted  m very low 
accuracy   (of 45%)  for either   unaccusat1ves,  object­ 
drops,  or both
  To summanze, followmg a different  trammg ap­ 
proach \Hth C5 0 (the smgle hold-out  method), and 
applymg  very  different   learnmg   approaches  (two 
kmds  of neural  networks), resulted  m smula1  O\er­ 
all performance to our  ongmal C5 0 results    Th15 
md1cates that  the  accurac) achieved  IS  at  lea.5t 
somewhat mdependent of specific learnmg  or tram­ 
mg  techmques     Moreover,  these  different  methods, 
along with experiments directly  testmg  unergat1ve 
versus unaccusativefobject-drop classificatwn, allow 
us to examme more closely where the  resultmg  clas­ 
sifiers  have the  most  senous problems    In d.ll cases, 
the  accuracy   IS  best  for  unergat1ves,  and  the  accu­ 
racy  of unaccusat1ves,  object-drops, or  both,  IS  de­ 
graded    If thts  performance IS  mdeed a reliable  mdt-


catwn  of the  mherent  discnnunabiiity of the distn­ 
butwnal data,  then  we must  e\.amme  more closely 
the  properties  of the data Itself to understand   (and 
potentially Improve)  the performance

4 3   DJscr1mmatmg UnaccusatJve and
ObJect-Drop Verbs

To  understand why the  data  d1scnmmates  unerga­ 
tives  reasonably   well,  but   not  unaccusat1ves  and 
object-drops, we need to directly  test the discnm­ 
mabihty of the features  across the classes   We do so 
by usmg t-tests to compare  the  values of the differ­ 
ent features-VBD, ACT, INTR, CAUS-for  unergat1ve 
and unaccusattve verbs, unergatlve and object-drop 
verbs,  and  unaccusat1ve  and  object-drop verbs    In 
each case, the t-test  ts gtvmg the hkehhood  that  the 
two sets  of values-e g , the VBD  feature  values for 
unergattves and  for  unaccusatives-are dra\lrn from 
different  populatiOns   Table 5 shows that  d.ll seto; of 
features  are s1g,mficantly different for unerg,at1ve and 
unaccusattve verbs,  and  for unergat1ve and  object­ 
drop  verbs   Hm\ever,  only  INTR and  CAUS  a1e sig­ 
mficantly different for unaccusat1ve and object-diOp 
verbs,  md1catmg  that   we need  additiOnal  fectlUle5 
that  have different  values across these two clas5es
  In SectiOn 2 1, we noted the d1ffenng semantic role 
assignments for the  verb classes,  and  hypothesized 
that  these differences would affect the expre'5siOn of 
syntactic features   that   a1e countable   m  a  co1 pus 
For e\.ample,  the c -I.LS feature  approximates seman­ 
tic role mfounat1on  bj  encodmg, the 0\erlap bet\\een 
nouns  that  can occu1 111 the -,ubject  and  obJPCt po­ 
SitiOns of a cau-,ative  \el b  He1e \\e '>ug,g,e'>t  anothe1 
featUie, that  of animacy  of subject, that  1s mtended 
to dtstmgUish nouns that  recetve an Agent role f10m 
those  that  receive a Theme  role   Recall that  object­ 
drop  verbs assign Agent to their subject  m both  the 
trans1t1ve aRd mtranstttve alternatwns, wh1le unac­ 
cusatives asstgn Agent to their subject only m the 
transitive, and Theme  m the mtrans1t1ve  \Ve P\.pect 
then  that  object-drop verbs  will occur  more  often 
with  an  ammate subject     '\/ote  ag,am that   \\P are


Features
VBO  ACT  INTR  CAUS
VBO  ACT  INTR  CAUS  PRO


Ace% 	SE%
63 7 	06
70 7 	04


wtthm  the  verb classes of thts 
new set of features   to see 
whether  accuracy  has also 
tmproved for unerg,a­ ttve verbs

5
    
C
o
n
c
l
u
s
i
o
n
s


Table 6   Percentage Accuracy  (Ace%) and Standard
Error  (SE%)  of C5 0, Wtth  and  Wtthout New PRO
Feature, All Verb Classes  (33 8% baselme)


makmg  use of frequency  dtstnbuttons-the clatm  ts 
not that  only Agents can  be ammate, but rather  that 
nouns  that  recetve the  Agent  role wtll more often  be 
ammate than  nouns  that recetve the  Theme  role
  A problem wtth a feature ltke ammacy  ts that  tt 
requtres etther  manual determmat10n of the ammacy 
of extracted subjects, or  reference  to an on-hne re­ 
source  such  as  WordNet   for  determmmg  antmacy 
To approxtmate ammacy wtth a feature that  can  be 
extracted automattcally, and  wtthout reference  to a 
resource external to the corpus,  we mstead  count 
pronouns (other   than   zt) m subject  posttton     The 
assumptton ts that   the  words  I, we 1     you, she  1     he, 
and  they most  often  refer  to ammate enttttes    The
values  for  the  new  feature,  PRO,   were determm.ed · ·
by automatically extractmg all subJect/verb  tuples 
mcludmg our 59 examples verbs (from the WSJ88 
parsed corpus),  and computmg the rat10 of occur­ 
rences of pronouns to all subjects
  We agam  apply  t-tests to our  new data to deter­ 
rome  whether   the  sets  of  PRO   values  dtffer  across 
the  verb classes   Interestmgly, we find that  the  PRO 
values for  unaccusattve verbs  (the  only  class  to  as­ 
stgn Theme role to the subject tn one of tts alterna­ 
tiOns) are stgmficantly dtffetent  from  those for  both 
unergattve and  object-drop  verbs  (p<  05)     More­ 
over, the  PRO  values for unergattve and  object-drop 
verbs  (whose  subjects are  Agents  m  both  alterna­ 
tiOns) are not stgmficantly dtfferent    Thts  pattern 
confirms  the  abtltty   of  the  feature   to  capture  the 
themattc dtstmctton bet.,.,een unaccusattve verbs and 
the other  two classes
  Table 6 shows the result  of applymg C5 0 (10-fold 
cross-vahdatton repeated 50 ttmes)  to the three-\\ay 
classtficatton  task  usmg the  PRO  feature  m conjunc­ 
tiOn wtth  the  four  prevtous  features   -\ccuracy  tm­ 
proves to over 70%, a teductton m the  etrot  rate  of 
almost  20% due  to  thts  smgle  ne\v feature 	:\Iote­ 
over,  classtfymg  the  unaccusattve a.1object-drop 
verbs usmg  the new feature m conJunctiOn wtth  the 
prev10us four  leads  to  accuracy  of over 68% (com­ 
pared  to 58% wtthout PRO)     We conclude  that  thts 
feature  IS  tmportant m dtstmgmshmg unaccusattve 
and object-drop verbs,  and  likely contnbutes to the 
Improvement m the  three-way  classtficatton  because 
of thts    Future  work  will exam me the  pet fot mance



In  thts  paper,   we have  presented  an  m-depth  case 
study, m wh1ch we mvest1gate vanous machme learn­ mg  
techmques  to  automatically class1fy a  set  of verbs,   
based   on  dtstrtbutiOnal  features   e\.tracted from a 
very large corpus    Results show that  a small number  of 
lmgmsttcally mottvated grammatical fea­ tures  are 
suffictent  to reduce the error  rate  bv 11101e than   50%  
ovez  chance,   acluevmg  a  70% a cutacy rate  m  a  
three-way   classtficatton  tash.   Tim  leads us to 
conclude  that  corpus  data  ts a usable repost­ tory of 
verb class mformatton  On one hand   \\e ob­ serve  that  
semantiC  properties  of verb classe( uch
as causattvzty, or  ammacy  of subject)   may  be use­
fully approxtmated through  countable  syntacttc  fea­ 
tures    Even  wtth  some  nOise, lexzcal properttes  are 
reflected  m the corpus  robustly  enough to postttvely 
contnbute m classtficatzon   On the other  hand, how­ 
ever,  we remark  that  deep hngUistzc analysts cannot be 
eltmmated-m our  approach,  1t ts embedded  111 the 
selectton  of the features  to count   We also thmk that   
usmg  lmguzstlcally  motzvated  features  makes the 
approach very effective and eastly scalable   we report  a 
56% reductton m error  rate,  w1th only five features 
that  are relatively stratghtforward to count

Acknowledgements

Thts  research  was partly  sponsored  by the S\HS->  Na­
tiOnal Sctence  Foundatton,  under  fello\ slup  8210-
46569  to  Paola  :Vlerlo, by the  US Nattonal  Sctence
Found at ton,  under  grants  #9702331 and  #918 322 to 
Suzanne  Stevenson, and  by the Infounatton ')c1- ences  
Counctl   of  Rutgers   Umverszty	\'ve  thank 
Martha Palmer  for gettmg  us started on tlus  \\ ork and  
:\hchael Collins for gtvmg us access to the out­ put  of  
hts  parser 	We gratefully   acknowledge  the 
help  of h.tva Dtckmson,  \\ ho calculated   not maltza­ 
ttons  of the corpus  data

Appendix  A

The  une1gatnes  are  manner of  motion \erh	Jtm1 pul 
ruohed, marched, !taped floated, raced, lwrl!cd   uan­ 
dered, vaulted,  paraded, galloped, glzded,  hz!..ed hvpptd 
Jogged, ocooted, ocurned,  ol..zpped, tzptoed, trotted
The   unaccusati\eS   are  verbs  of   change  of  state
opened,  exploded, flooded, dzsoolved, cracked, hmdtned 
bozled,  melted,   fractured,  oolzdzfied, collapoed     cooled 
folded,  wzdened, changed,  cleared, dzvzded, >lllllnered 
stabzlzzed
  The  object-dtop  verbs are  unspecified object  alter­ 
natiOn verbs   played, pmnted, kzc!..ed, carved, reaptd, 
washed, danced, yelled, typed, !..nttted   borrowed    rnh r-






&ted, orgamzed, rented, sketched, cleaned, packed,  stud­
zed, swallowed,  called


References
Thomas G  Bever   1970   The cogrut1ve basis for IIngws­ 
tic structure   In J   R   Hayes, editor,   Cogmt&on and 
the  Development of Language  John  Wiley, New York

Michael Brent    1993   From grammar to le"<lcon Un- 
supervised learrung of leXIcal syntax    Computatzonal 
Lmguast&cs, 19(2)  243-262

Edward  Bnscoe and Ann Copestake    1995   Le"<lcal rules 
m the TDFS  framework    Techrucal report,  Acqmlex-
11 Working·Papers

Anne-Mane Brousseau  and  Elizabeth   R1tter    1991    A 
non-urufied analysis  of agent1ve verbs   In  West  Coast 
Conference on  Formal  Lmguut&cs,  number  20,  pages
53-64

Michael  John   Collins     1997     Three  generative,   leXI- 
calised  models for statistical parsmg    In  Proc   of the
15th  Annual Meetmg of the  ACL,  pages 16-23

Hoa  Trang   Dang,  Kann   Kipper,   Martha   Palmer,  and 
Joseph Rosenzweig  1998  lnvest1gatmg regular sense 
extensiOns  based  on  Interesective  Levm  classes     In 
Proc    of  the  36th   Annual  Meetmg of  the   ACL   and 
the  17th  International Conference on  Computational 
Lmguashcs (COLJNG-ACL '98}, pages 293-299,  Mon­ 
treal,  Canada  Uruvers1te de Montreal

Bonrue Dorr and  Doug Jones   1996   Role of word sense 
disambiguatiOn   m leXIcal acqUlsitiOn   Predicting  se­ 
mantics  from syntactic cues   In  Proc  of the  16th  In­ 
ternational Conference on Computational Lmguast&cs, 
pages 322-327, Copenhagen,  Denmark

Bonnie  Dorr    1997   Large-scale dictiOnary constructiOn 
for foreign language  tutonng and mterhngual  maclune 
translatwn   Machme Translat&on, 12 1-55

Hana  F1hp  tvhchael Tanenhaus, Greg Carlson,  Paul  Al­ 
lopenna,   and   Joshua   Blatt 	1999 	Reduced   rela­ 
tives  judged  hard  reqUire constraint-based analyses 
In P  Merlo and S  Stevenson,  editors,  Sentence Pro­ 
cessmg and  the  Lextcon    Formal,  Computatwnal,  and 
Expenmental  Perspectwes, John  Benjamms,  Holland

Ken  Hale  and  Jay  Keyser    1993    On  argument  struc­ 
ture  and  the le"<lcal  representatiOn  of S} ntact1c rela­ 
twns     In  I<    Hale and  J   Keyser,  editors,   The   hew 
from  8Uildmg 20. pages 53-110   MIT Press

Juillth  L   h.lavans  and  Martm  Chodorow     1992    De­ 
grees  of stativity   The  leXIcal representatiOn  of verb 
aspect    In Proceedmg•  of the  Fourteenth Inter natzonal 
Conference on  Computatwnal Lmgutsttcs

Juillth   h.lavans and  Mm- Yen Kan    1998   Role of \erbs 
m  document analysis     In  Proc   of  the  36th  Annual 
Meetmg of the  ACL  and  the  17th  lntematwnal  Con­ 
ference  on  Computatwnal LmgUist&cs (COLI:vG-4CL
'98}, pages 680-686, Montreal, Canada   Uruvers1te de
Montreal


Beth  Levm and  Maika Rappaport. Hovav   1995    unac­
cusatzvzty  MIT Press, Cambndge.  MA

Beth  Le\m 	1993    Engl&sh Verb  Clas•e•  and  4/terna­
t&ons Clucago  Umversity Press, Chicago, IL

Maryellen   C   MacDonald      1994      Probabi!Jstic  con- 
stramts and syntactic  amb1gwty resolution   Language 
and  Cogmtwe Processes, 9(2) 157-201

Paola Merlo and Suzanne Stevenson   1998  What gram­ 
mars  tell us about  corpora   the case of reduced  rela­ 
tive clauses   In  Proceedmgs of the S&xth Work.hop  or1
Very  Large Corpora,  pages 134-142, Montreal, CA

George Miller, R  Bed.w1th, C  Fellbaum, D  Gross, and 
h  tvhller   1990   Five papers on Wordnet   Techmcal 
report,  Cognitive  Science Lab, Prmceton  llnnersit\

:V[artha Palmer    1999   Consistent  cntena for sense dls­
tmctwns   Computmg  for the  Humamlles

Fernando  Pereira,  Naftah T1shby, and  Lillian Lee  1993
Distnbutwnal clustermg  of enghsh words   In Proc   of 
the  31th   4nnual Meetmg  of the  4CL,  pages 183-190

Fernando   Pereira,   !do  Dagan,  and  Lillian  Lee	1997
Similarity-based methods  for word sense disambigua­
tiOn     In  Proc    of  the  J5th   Annual  Meetmg   of  the
4CL  and the 8th Conf  of theE 4.CL (ACL/EACL '97)
pages 56 -63

Geoffrey  K   Pullum      1996     Learnab11Ity, hyperlearn- 
mg,  and  the  poverty  of the stimulus     In Jan  John­ 
son,  Matthew L   Juge,  and  Jen  L  Moxley, ed1tors,
22nd  Annual Meetmg of the  Berkeley  Lmgu&st&cs So­ 
c&ety  General Sesswn and  Parasess&on on the  Role of 
Learnabalzty  m Grammatzcal Theory, pages 498-513, 
Berkeley, Cahforma   Berkeley LmguJstics Society

James  Pustejovsky    1995   The  Generatwe Lexacon  MIT 
Press

J   Ross Qumlan     1992    C4 5     Programs  for  Machme 
Learnmg   Senes  m Machme Leammg   Morgan hauf­ 
mann,  San  Mateo,  C-\

Ph1hp Resmk    1992    Wordnet  and  d1stnbutwnal   anal- 
ysis	a  class-based   approach   to  lexical  d1sco,en In   
4 4 4. I  Work.hop m Statl.l!cally-baoed  N LP  Teci!­ 
mque>, pages 56-6-1

Doug Roland and Dan Jmafsk}   1998   How \eJb subcat­
egonzatwn f1equenc1es are affected  bj  corpuchoice
In Proc  of the  16th  4nnual \/eetmg of the  4CL, \Ion­
treal,  CA

Suzanne   Ste\enson  and  Paola  \lerlo      199i      Lex1cal 
structure and  parsmg complexit\    Language  and  rog­ 
mtwe  Proce»e>, 12(2/3) 319-399

Suzanne  Stevenson  and  Paola  Nlerlo   1999    -\utomat1c 
verb classificatiOn usmg d1stnbutwns of grammatical 
features     In  Proc   of the  9th  Conference of the   Eu­ 
ropean  Chapter of the   A CL,  Bergen,  Norwa\,   pages
-15-52

John  Trueswell      1996     The  role of lexiCal frequency 
m syntactic amb1gmty resolutwn    J  of Memory  and 
Language, Jj 566-585



