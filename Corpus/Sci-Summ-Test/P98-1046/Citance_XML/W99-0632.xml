<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Levin&apos;s (1993) taxonomy of verbs and their classes is a widely used resource for lexical semantics.</S>
		<S sid ="2" ssid = "2">In her framework, some verbs, such as give exhibit no class ambiguity.</S>
		<S sid ="3" ssid = "3">But other verbs, such as write, can inhabit more than one class.</S>
		<S sid ="4" ssid = "4">In some of these am­ Chris Brew HCRC Language Technology Group Division of Informatics University of Edinburgh 2 Buccleuch Place Edinburgh EH8 9LW, UK chrisbr@cogsci.ed.ac.uk (cf.</S>
		<S sid ="5" ssid = "5">(3a)) and the prepositional frame NP-V-NP­ PP10, (cf.</S>
		<S sid ="6" ssid = "6">(3b)).</S>
		<S sid ="7" ssid = "7">(l) a. Janet broke the cup.</S>
		<S sid ="8" ssid = "8">b. The cup broke.</S>
		<S sid ="9" ssid = "9">(2) a. Bill sold a car to Tom.</S>
		<S sid ="10" ssid = "10">b. Bill sold Tom a car.</S>
		<S sid ="11" ssid = "11">biguous cases the appropriate class for a particular token of a verb is immediately obvious from inspec­ tion of the surrounding context.</S>
		<S sid ="12" ssid = "12">In others it is not, (3) a. b. Martha carved the baby a toy.</S>
		<S sid ="13" ssid = "13">Martha carved a toy for the baby.</S>
		<S sid ="14" ssid = "14">and an application which wants to recover this infor­ mation will be forced to rely on some more or Jess elaborate process of inference.</S>
		<S sid ="15" ssid = "15">We present a simple statistical model of verb class ambiguity and show how it can be used to carry out such inference.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="16" ssid = "16">The relation between the syntactic realization of a verb&apos;s arguments and its meaning has been exten­ sively studied in Levin (1993).</S>
			<S sid ="17" ssid = "17">Levin&apos;s work re­ lies on the hypothesis that &quot;the behavior of a verb, particularly with respect to the expression and in­ terpretation of its arguments, is to a large extent determined by its meaning&quot; (Levin, 1993, p. I).</S>
			<S sid ="18" ssid = "18">Verbs which display the same diathesis alterna­ tions-alternations in the realization of their argu­ ment structure-are assumed to share certain mean­ ing components and are organized into a semanti­ cally coherent class.</S>
			<S sid ="19" ssid = "19">As an example consider sentences (1)-(3) taken from Levin.</S>
			<S sid ="20" ssid = "20">Example (l) iiiustrates the causative/inchoative alternation.</S>
			<S sid ="21" ssid = "21">Verbs undergoing this alternation can be manifested either as transi­ tive with a causative reading (cf.</S>
			<S sid ="22" ssid = "22">(I a)) or as intransi­ tive with an inchoative reading (cf.</S>
			<S sid ="23" ssid = "23">(lb)).</S>
			<S sid ="24" ssid = "24">Examples (2) and (3) illustrate the dative and benefactive al­ ternations respectively.</S>
			<S sid ="25" ssid = "25">Verbs which license the for­ mer alternate between the prepositional frame NP­ V-NP-PPro (cf.</S>
			<S sid ="26" ssid = "26">(2a)) and the double object frame V-NP-NP (cf.</S>
			<S sid ="27" ssid = "27">(2b)), whereas verbs which undergo the latter alternate between the double object frame Verbs like crack and chip pattern with break in li­ censing the causative/inchoative alternation and are associated with the semantic class of BREAK verbs.</S>
			<S sid ="28" ssid = "28">Verbs make and build behave similar to carve in licensing the benefactive alternation and are mem­ bers of the class of BUILD verbs, whereas sell and give undergo the dative alternation and participate in the GIVE class.</S>
			<S sid ="29" ssid = "29">By grouping together verbs which pattern together with respect to diathesis alterna­ tions Levin defines approximately 200 verb classes, which she argues reflect important semantic regu­ larities.</S>
	</SECTION>
	<SECTION title="Motivation. " number = "2">
			<S sid ="30" ssid = "1">Levin provides an index of 3,024 verbs for which she lists the semantic classes and diathesis alterna­ tions.</S>
			<S sid ="31" ssid = "2">The mapping between verbs and classes is not one-to-one.</S>
			<S sid ="32" ssid = "3">Of the 3,024 verbs which she cov­ ers, 784 are listed as having more than one class.</S>
			<S sid ="33" ssid = "4">Even though Levin&apos;s monosemous verbs outnumber her polysemous verbs by a factor of nearly four to one, the total frequency of the former (4,252,715) is comparable to the total frequency of the latter (3,986,014).</S>
			<S sid ="34" ssid = "5">This means that close to half of the cases processed by a hypothetical semantic tagger would manifest some degree of ambiguity.</S>
			<S sid ="35" ssid = "6">The fre­ quencies are detailed in table I and were compiled from a lemmatized version of the British National Corpus (BNC), a widely distributed 100 million word collection of samples of written and spoken English (Burnard, 1995).</S>
			<S sid ="36" ssid = "7">Classes Verbs BNC frequency I 2 3 4 5 6 7 lO 2,239 536 173 43 23 7 2 I 4,252,715 2,325,982 738.854 395,212 222,747 272,669 26,123 4,427 Table I: Polysemous verbs according to Levin 100 90 80 70 -•e 60 and FULFILLING.</S>
			<S sid ="37" ssid = "8">Each of these classes can in tum license four distinct syntactic frames.</S>
			<S sid ="38" ssid = "9">As shown in the examples 1 below, in (4a) serve appears ditran­ sitively and belongs to the semantic class of GIVE verbs, in (4b) it occurs transitively and is a mem­ ber of the class of FIT verbs, in ( 4c) it takes the predicative complement as minister of the interior and is a member of MASQUERADE verbs.</S>
			<S sid ="39" ssid = "10">Finally, in sentence (4d) serve is a FULFILLING verb and takes two complements, a noun phrase (an appren­ ticeship) and a prepositional phrase headed by to.</S>
			<S sid ="40" ssid = "11">In the case of verbs like serve we can guess their semantic class solely on the basis of the frame with which they appear.</S>
			<S sid ="41" ssid = "12">0 &quot; so 40 0.</S>
			<S sid ="42" ssid = "13">30 20 10 0 I 2 3 4 S 6 7 8 9 10 II 12 Number of alternations Figure 1: Relation between number of classes and alternations Furthermore, as shown in figure 1, the number of alternations licensed by a given verb increases with the number of classes it inhabits.</S>
			<S sid ="43" ssid = "14">Consider for example verbs participating in one alternation only: of these, 90.4% have one semantic class, 8.6% have two classes, 0.7% have three classes and 0.3% have four classes.</S>
			<S sid ="44" ssid = "15">In contrast, of the verbs licensing six different alternations, 14% have one class, I 7% have two classes, 12.4% have three classes, 53.6% have four classes, 2% have six classes and 1% has seven classes.</S>
			<S sid ="45" ssid = "16">Palmer (1999) and Dang et a!.</S>
			<S sid ="46" ssid = "17">(1998) argue that the use of syntactic frames and verb classes can sim­ plify the definition of different verb senses.</S>
			<S sid ="47" ssid = "18">Beyond this, we claim that information about the argument structure of a polysemous verb can often help dis­ ambiguating it.</S>
			<S sid ="48" ssid = "19">Consider for instance the verb serve which is a member of four classes: GIVE, FIT, MASQUERADE But sometimes we do not have the syntactic infor­ mation that would provide cues for semantic disam­ biguation.</S>
			<S sid ="49" ssid = "20">Consider sentence (5a).</S>
			<S sid ="50" ssid = "21">The verb write is a member of three Levin classes, two of which (MESSAGE TRANSFER, PERFORMANCE) take the ditransitive frame NP-V-NPNP.</S>
			<S sid ="51" ssid = "22">In this case we have the choice between the &quot;message transfer&quot; reading (cf.</S>
			<S sid ="52" ssid = "23">(5a)) and the &quot;performance&quot; reading (cf.</S>
			<S sid ="53" ssid = "24">(5b)).</S>
			<S sid ="54" ssid = "25">This is an instance of the common prob­ lem of inferring the value of a hidden variable (in this case the &quot;true class&quot; of a particular instance of write).</S>
			<S sid ="55" ssid = "26">The same situation arises with the verb phone which is listed as a GET verb and an INSTRU­ MENT OF COMMUNICATION verb and in both cases can take the frame NP-V-NPNP.</S>
			<S sid ="56" ssid = "27">In sentence (5c) the preferred reading is that of &quot;get&quot; instead of &quot;in­ strument of communication&quot; (cf.</S>
			<S sid ="57" ssid = "28">sentence (5d)).</S>
			<S sid ="58" ssid = "29">(5) a. A solicitor wrote him a letter at the air­ b. port.</S>
			<S sid ="59" ssid = "30">I want you to write me a screenplay called &quot;The Trip&quot;.</S>
			<S sid ="60" ssid = "31">1 Unless stated otherwise the example sentences were taken from the BNC and simplified for clarification purposes.</S>
			<S sid ="61" ssid = "32">c. I&apos;II phone you a taxi.</S>
			<S sid ="62" ssid = "33">d. As I entered the room I wished I&apos;d thought of phoning a desperate SOS to James.</S>
			<S sid ="63" ssid = "34">The objective of this paper is to address the verb class disambiguation problem by developing a probabilistic framework which combines linguis­ By substituting (7) and (8) into (6), P (verb, class ,frame) can be written as: (9) P(verb,frame, class), P (verb) P (frame Iverb) P (frame Iclass) P (class) P(jrame) tic knowledge (i.e., Levin&apos;s classification) and frame frequencies acquired from the BNC.</S>
			<S sid ="64" ssid = "35">Our initial ex­ periments focus on the syntactic frames characteris­ tic for the dative and benefactive alternations (cf.</S>
			<S sid ="65" ssid = "36">ex­ We estimate P(jramelverb), as follows: the probabilities P(jramelclass) and f(verb) P(verb), P(class) amples (2) and (3)).</S>
			<S sid ="66" ssid = "37">These frames are licensed by a fairly large number of classes: 19 classes license the double object frame, 22 license the NP-V-NP­ PP10 frame and 14 classes license the NP-V-NP PP1,&quot; frame.</S>
			<S sid ="67" ssid = "38">The semantic and syntactic properties of these alternations have been extensively studied and are well understood (see Levin (1993) and the references therein).</S>
			<S sid ="68" ssid = "39">Furthermore, they are fairly pro­ ductive and one would expect them to be well rep­ resented in a large corpus.</S>
			<S sid ="69" ssid = "40">(10) P(verb)&quot;&quot;&apos; &quot; L..</S>
			<S sid ="70" ssid = "41">f(verb;) f (verb.jrame) (I I) P(jramelverb)&quot;&quot;&apos; &quot; L..</S>
			<S sid ="71" ssid = "42">j(verb.frame;) f(class,frame) (12) P(jramelclass) &quot;&quot;&apos; &quot; L..</S>
			<S sid ="72" ssid = "43">j(c/ass.frame;) In section 3 we describe the statistical model and the estimation of the various model parameters, sec­ tion 4 presents some preliminary results and sec­ tion 5 contains some discussion and concluding re­ (13) P(class) &quot;&quot;&apos; j(class) &quot; L..</S>
			<S sid ="73" ssid = "44">f(class;) f(jrame) marks.</S>
	</SECTION>
	<SECTION title="The Model. " number = "3">
			<S sid ="74" ssid = "1">We view the choice of a class for a polysemous verb in a given frame as the joint probability P(verb,Jrame, class) which we rewrite using the chain rule in (6).</S>
			<S sid ="75" ssid = "2">(6) P(verb,frame, class)= P(verb) P (frame I verb) P(classlverb,frame) We also make the following independence assump­ tion: (7) P(classlverb,frame) P(classlframe) The independence assumption reflects Levin&apos;s hy­ pothesis that the argument structure of a given verb is a direct reflection of its meaning.</S>
			<S sid ="76" ssid = "3">Accordingly we assume that the semantic class determines the argu­ ment structure of its members without making ref­ erence to the individual verbs.</S>
			<S sid ="77" ssid = "4">By applying Bayes Law we write P(classlframe) as: . P(jramelclass)P(class) (14) P (frame) &quot;&quot;&apos; &quot; L..</S>
			<S sid ="78" ssid = "5">f(jrame;) It is easy to obtain f (verb) from the lemmatized BNC.</S>
			<S sid ="79" ssid = "6">For the experiments reported here, syntactic frames for the dative and benefactive alternations were automatically extracted from the BNC using Gsearch (Keller et al., 1999), a tool which facilitates search of arbitrary POS-tagged corpora for shallow syntactic patterns based on a user-specified context­ free grammar and a syntactic query.</S>
			<S sid ="80" ssid = "7">The acquisition and filtering process is detailed in Lapata (1999).</S>
			<S sid ="81" ssid = "8">We rely on Gsearch to provide moderately accu­ rate information about verb frames in the same way that Hindle and Rooth (1993) relied on Fidditch to provide moderately accurate information about syn­ tactic structure, and Ratnaparkhi ( 1998) relied on simple heuristics defined over part-of-speech tags to deliver information nearly as useful as that pro­ vided by Fidditch.</S>
			<S sid ="82" ssid = "9">We estimated f(verb,frame) as the number of times a verb co-occurred with a par­ ticular frame in the corpus.</S>
			<S sid ="83" ssid = "10">We cannot read off P (jramelclass) from the cor­ pus, because it is not annotated with verb classes.</S>
			<S sid ="84" ssid = "11">Nevertheless we can use the information listed in Levin with respect to the syntactic frames exhib­ (8) P(c lass rame) = -- -&apos;&apos;--- --&apos;--- -&apos;-- .:_ P ( j r a m e ) ited by the verbs of a given class.</S>
			<S sid ="85" ssid = "12">For each class I Class Frames NP-V-NPPP10 , NP-V-NPPPJltr• Table 2: Sample of verb classes and their syntactic frames we recorded the syntactic frames it licenses (cf.</S>
			<S sid ="86" ssid = "13">ta­ ble 2).</S>
			<S sid ="87" ssid = "14">Levin&apos;s description of the argument struc­ ture of various verbs goes beyond the simple list­ ing of their subcategorization.</S>
			<S sid ="88" ssid = "15">Useful information is provided about the thematic roles of verbal argu­ ments and their interpretation.</S>
			<S sid ="89" ssid = "16">Consider the exam­ ples in (15): in (15a) the verb present is a member of the FULFILLING class and its theme is expressed by the prepositional phrase with an award, in (15b) the PP headed by with receives a locative interpretation and the verb load inhabits the SPRAY/LOAD class, whereas in (15c) the prepositional phrase is instru­ mental and hit inhabits the HIT class.</S>
			<S sid ="90" ssid = "17">None of the information concerning thematic roles was retained.</S>
			<S sid ="91" ssid = "18">All three classes (FULFILLING, SPRAY/LOAD and HIT) were assigned the frame NP-V-NPPPwiri.&apos;.</S>
			<S sid ="92" ssid = "19">I Class si-e(class) p(c/asslamb_c/ass) f(verb class) I THROW 27 0.40 7783.6 SEND 20 0.27 5253.9 GIVE 15 0.20 3891.8 MARRY 10 0.13 2529.6 Table 3: Estimation of .f(verb.</S>
			<S sid ="93" ssid = "20">class) for the verb pas s The estimate of f(verb, class) for monosemous verbs reduces to the count of the verb in the cor­ pus.</S>
			<S sid ="94" ssid = "21">Once again we cannot estimate .f(verb, class) for polysemous verbs directly.</S>
			<S sid ="95" ssid = "22">All we have is the overall frequency of a given verb in the BNC and the number of classes it is a member of according to Levin.</S>
			<S sid ="96" ssid = "23">We rewrite f(verb, class) as: (17) .f(verb, class)= .f(verb)p(classlverb) We approximate p(classlverb) by collapsing across all verbs that have the appropriate pattern of ambi­ guity: (18) .f(verb, class) &quot;&apos;=&apos; .f(verb)p(c/asslamb_class) Here amb_c/ass, the ambiguity class of a verb, is the set of classes that it might inhabit 2 We collapse verbs into ambiguity classes in order to reduce the number of parameters which must be estimated: we certainly lose information, but the approximation makes it easier to get reliable estimates from limited data.</S>
			<S sid ="97" ssid = "24">In future work we plan to use the EM algo­ rithm (Dempster et al., 1977) to uncover the hidden class, but for the present study, we simply approxi­ mate p(classlamb_class) using a heuristic based on (15) a. b. c. John presented the student with an award.</S>
			<S sid ="98" ssid = "25">J o h n l o a d e d t h e tr u c k w it h b ri c k s. J o h n h it t h e w al l w it h a h a m m e r. class size: (19) p(classla mb..class ) &quot;&apos;=&apos; s i z e ( c l a s s ) = L = .,i ze( .,.</S>
			<S sid ="99" ssid = "26">c) 5 Because we didn&apos;t have corpus counts for the quantity .f(class,frame) we simply assumed that all frames for a given class are equally likely.</S>
			<S sid ="100" ssid = "27">This means, for instance, that the estimate for P(NP-V-NPNP10 IGIVE) is and similarly the es­ timate for P(NPVIPERFORMANCE) is (cf.</S>
			<S sid ="101" ssid = "28">ta­ ble 2).</S>
			<S sid ="102" ssid = "29">This is clearly a simplification, since one would expect .f(class,.frame) to be different for dif­ ferent corpora, and to vary with respect to class size and the frequency of class members.</S>
			<S sid ="103" ssid = "30">In order to estimate P(class) we first estimate .f (class) which we rewrite as follows: (16) .f(class) = L.f(verb;, class) r.: E amb...class For each class we recorded the number of its mem­ bers after discarding verbs whose frequency was less than 1 per 1M in the BNC.</S>
			<S sid ="104" ssid = "31">This gave us a first approximation of the size of each class.</S>
			<S sid ="105" ssid = "32">We then computed, for each polysemous verb, the total size of the classes of which it was a member.</S>
			<S sid ="106" ssid = "33">We calcu­ lated p(classlamb_class) by dividing the former by the latter (cf.</S>
			<S sid ="107" ssid = "34">equation (19)).</S>
			<S sid ="108" ssid = "35">We obtained an esti­ mate for the class frequency .f(class) by multiply­ ing p(classlamb_c/ass) by the observed frequency of the verb in the BNC (cf.</S>
			<S sid ="109" ssid = "36">equation (18)).</S>
			<S sid ="110" ssid = "37">2our use of ambiguity classes is inspired by a similar use in HMM based part-of-speech tagging (Kupiec.</S>
			<S sid ="111" ssid = "38">1992).</S>
			<S sid ="112" ssid = "39">6e+05 ., •= 100 80 •=..</S>
			<S sid ="113" ssid = "40">J! &lt;.&gt; 4e+05 2e+0 5 • 60 .E - 40 2 0 0 ..</S>
			<S sid ="114" ssid = "41">..1 ..</S>
			<S sid ="115" ssid = "42">t..</S>
			<S sid ="116" ssid = "43">..; ..I i ., ..</S>
			<S sid ="117" ssid = "44">• .l! . z &apos;.i. s &quot;&apos; I I s ! !</S>
			<S sid ="118" ssid = "45">&apos;.i. I . 1 . 1 I ..</S>
			<S sid ="119" ssid = "46">z d. I I I z z I z I I I ·c ! • J!</S>
			<S sid ="120" ssid = "47">= .g ·;o I I I .!&lt; · E c z I z &apos;i f ...</S>
			<S sid ="121" ssid = "48">.•..</S>
			<S sid ="122" ssid = "49">• E .!l .I. z .I. d. z &apos;.i. I z dz.</S>
			<S sid ="123" ssid = "50">.•..</S>
			<S sid ="124" ssid = "51">e .a 1 i dz.</S>
			<S sid ="125" ssid = "52">z z z z &apos;6 e Figure 2: The ten most frequent classes As an example consider the verb pass which has the classes THROW, SEND, GIVE and MARRY.</S>
			<S sid ="126" ssid = "53">The respective p(classiamb_c/ass) for these classes are Figure 3: Ten most frequent frames in Levin (e.g., Thameslink presently carries 20,000 passen­ gers daily) is larger than the CARRY class, it will be given a higher probability (0.45 versus 0.4).</S>
			<S sid ="127" ssid = "54">This is 7272• 7202• 7125 and w . By muIu.pIym.g these by the fre clearly wrong, but it is an empirical question how quency of pass in the BNC (19,559) we obtain the estimates for j(verb, class) given in table 3.</S>
			<S sid ="128" ssid = "55">Note that simply relying on class size, without re­ gard to frequency, would give quite different results.</S>
			<S sid ="129" ssid = "56">For example the class of MANNER OF SPEAKING verbs has 76 members, of which 30 have frequen­ cies which are less than 1 per 1M, and is the sev­ enth largest class in Levin&apos;s classification.</S>
			<S sid ="130" ssid = "57">Accord­ ing to our estimation scheme MANNER OF SPEAK­ ING verbs are the !16th largest class.</S>
			<S sid ="131" ssid = "58">The estimates for the ten most frequent classes are shown in fig­ ure 2.</S>
			<S sid ="132" ssid = "59">The estimation process described above in­ volves at least one gross simplification, since p(classiamb_cfass) is calculated without reference to the identity of the verb in question.</S>
			<S sid ="133" ssid = "60">For any two verbs which fall into the same set of classes p(classlamb_cfass) will be the same, even though one or both may be atypical in its distribution across the classes.</S>
			<S sid ="134" ssid = "61">Furthermore, the estimation tends to favour large classes, again irrespectively of the iden­ tity of the verb in question.</S>
			<S sid ="135" ssid = "62">For example the verb carry has three classes, CARRY, FIT and COST.</S>
			<S sid ="136" ssid = "63">In­ tuitively speaking, the CARRY class is the most fre­ quent (e.g., Smoking can impair the blood which carries oxygen to the brain, I carry sugar lumps around with me).</S>
			<S sid ="137" ssid = "64">However, since the FIT class much it matters.</S>
			<S sid ="138" ssid = "65">Finally, we wanted to estimate the probability of a given frame, P(jrame).</S>
			<S sid ="139" ssid = "66">We could have done this by acquiring Levin compatible subcategoriza­ tion frames from the BNC.</S>
			<S sid ="140" ssid = "67">Techniques for the auto­ matic acquisition of subcategorization dictionaries have been developed by Manning (1993), Briscoe and Carroll (1997) and Carroll and Rooth (1998).</S>
			<S sid ="141" ssid = "68">But the present study was less ambitious, and nar­ rowly focused on the frames representing the da­ tive and the benefactive alternation.</S>
			<S sid ="142" ssid = "69">In default of the more ambitious study, which we plan for the future, the estimation of P(jrame) was carried out on types and not on tokens.</S>
			<S sid ="143" ssid = "70">The mapping of Levin&apos;s linguis­ tic specifications into surface syntactic information resulted in 79 different frame types.</S>
			<S sid ="144" ssid = "71">By counting the number of times a given frame is licensed by several semantic classes we get a distribution of frames, a sample of which is shown in figure 3.</S>
			<S sid ="145" ssid = "72">The probabilities P(jrameiclass) and P(jrameiverb) will be unreliable when the frequency estimates for f(verb,frame) and f(class.frame) are small, and ill-defined when the frequency estimates are zero.</S>
			<S sid ="146" ssid = "73">Following Hindle and Rooth (1993) we smooth the ob­ served frequencies in the following way, where f(V.frame) = Li .f(verb;.frame), f(V) = :L1 f(verh,), f(C,frame) = :L, f(class;,frame) and f(C) = Li f(c/ass,).</S>
			<S sid ="147" ssid = "74">We redefine the probability estimates as follows: f(verh,Jrame) + fWt &apos;;&quot;&lt;l data.</S>
			<S sid ="148" ssid = "75">Given the restriction that these verbs are se­ mantically ambiguous in a specific syntactic frame we could not simply sample from the entire BNC, since this would decrease the chances of finding the verb in the frame we are interested in. Instead, for (20) P(ji&lt;t melve rh)&quot;&quot;&apos; L f(verh ,fram e i J&lt; 1 ) +I 31 clas s am big uou s ver bs we ran do mly sele cted ap­ pro xim atel y 100 tok ens fro m the data use d for the acq uisi tion of fra me freq uen cies for the dati ve and f(class,frame) + f&quot;&lt;Cf mtel (21) P(jramelclass)&quot;&quot;&apos; L J&lt; 1 f(class,frame 1 ) +I When f(verh,frame) is zero, the estimate used is proportional to the average /( :1 &apos;;&quot;•1 across all verbs.</S>
			<S sid ="149" ssid = "76">Similarly, when f(class,frame) is zero, our estimate is proportional to the average f(C.tr&quot;me) f(C) across all classes.</S>
			<S sid ="150" ssid = "77">We don&apos;t claim that this scheme is perfect, but any deficiencies it may have are almost certainly masked by the effects of approximations and simplifications elsewhere in the system.</S>
	</SECTION>
	<SECTION title="Results. " number = "4">
			<S sid ="151" ssid = "1">We evaluated the performance of the model on all verbs listed in Levin which are polysemous and take frames characteristic for the dative and benefactive alternations.</S>
			<S sid ="152" ssid = "2">This resulted in 154 verbs which take the NP-V-NPNP frame, 135 verbs which take the NP-V-NPPP111 frame and 84 verbs which take the NP-V-NPPPp, frame.</S>
			<S sid ="153" ssid = "3">The verbs were all polyse­ mous and had an average of 3.8 classes.</S>
			<S sid ="154" ssid = "4">Each class had an average of 3.4 frames.</S>
			<S sid ="155" ssid = "5">Furthermore, we di­ vided these verbs in two categories: verbs which can be disambiguated solely on the basis of their frame (e.g., serve; category A) and verbs which are gen­ uinely ambiguous, i.e., they inhabit a single frame and yet can be members of more than one semantic class (e.g., write; category B).</S>
			<S sid ="156" ssid = "6">The task was the following: given that we know the frame of a given verb can we predict its se­ mantic class?</S>
			<S sid ="157" ssid = "7">In other words by varying the class in the term P(verh,frame, class) we are trying to see whether the class which maximizes it is the one predicted by the lexical semantics and the argument structure of the verb in question.</S>
			<S sid ="158" ssid = "8">For the verbs belonging to category A (306 in total) we used Levin&apos;s own classification in eval­ uation.</S>
			<S sid ="159" ssid = "9">The model&apos;s performance was considered correct if it agreed with Levin in assigning a verb the appropriate class given a particular frame.</S>
			<S sid ="160" ssid = "10">For class ambiguous verbs (category B) we compared the model&apos;s predictions against manually annotated benefactive alternation.</S>
			<S sid ="161" ssid = "11">Verbs with frame frequency less than I 00 were not used in the evaluation.</S>
			<S sid ="162" ssid = "12">The selected tokens were annotated with class in­ formation by two judges.</S>
			<S sid ="163" ssid = "13">The judges were given an­ notation guidelines but no prior training.</S>
			<S sid ="164" ssid = "14">We mea­ sured the judges&apos; agreement on the annotation task using the Kappa coefficient (Siegel and Castellan, 1988) which is the ratio of the proportion of times, P(A), that k raters agree to the proportion of times, P(E), that we would expect the raters to agree by chance (cf.</S>
			<S sid ="165" ssid = "15">(22)).</S>
			<S sid ="166" ssid = "16">If there is a complete agreement among the raters, then K = I, whereas if there is no agreement among the raters (other than the agree­ ment which would be expected to occur by chance), then K = 0.</S>
			<S sid ="167" ssid = "17">) K = P(A)- P(E) 22 1 - P(E) We counted the performance of our model as cor­ rect if it agreed with the &quot;most preferred&quot;, i.e., most frequent verb class as determined in the manually annotated corpus sample by taking the average of the responses of both judges.</S>
			<S sid ="168" ssid = "18">We also compared the results for both categories to a naive baseline which relies only on class in­ formation and does not take subcategorization into account.</S>
			<S sid ="169" ssid = "19">For a given polysemous verb, the baseline was computed by defaulting to its most frequent class, where class frequency was determined by the estimation procedure described in the previous sec­ tion.</S>
			<S sid ="170" ssid = "20">As shown in table 4, in all cases our model out­ performs the baseline.</S>
			<S sid ="171" ssid = "21">It achieves a combined pre­ cision of 91.8% for category A verbs.</S>
			<S sid ="172" ssid = "22">One might expect a precision of 100% since these verbs can be disambiguated solely on the basis of the frame.</S>
			<S sid ="173" ssid = "23">However, the performance of our model is Jess, mainly because of the way we estimated the terms P(class) and P(jramelclass): we overemphasize the importance of frequent classes without taking into account how individual verbs distribute across classes.</S>
			<S sid ="174" ssid = "24">The model achieves a combined precision of83.9% for category B verbs (cf.</S>
			<S sid ="175" ssid = "25">table 4).</S>
			<S sid ="176" ssid = "26">Further I I Category A Category B Fr a m e V er bs Ba sel in e M od el Ve rb s Ba sel in e M od el NPV NP N P 1 2 3 61 .8 % 87 .8 % 14 42 .8 % 85 .7 % NPV NP PP ,0 1 1 3 67 .2 % 92 % 15 73 .4 % 86 .6 % NPV NP P Pr or 7 0 70 % 98 .5 % 2 0 % 50 % [COmbmed 11 306 1 65.7% 1 91.8% 1 31 I 61.3% 83.9% Table 4: Model accuracy against baseline I Verb Frame Preferences save NP-V-NPNP GET, BILL call NP-V-NPNP GET, DUB write NP-V-NPNP MESSAGE TRANSFER, PERFORMANCE make NP-V-NPNP DUB, BUILD extend NP-V-NPPP,o FUTURE HAVING, CONTRIBUTE present NP-V-NPPPw FULFILLING, REFLEXIVE APPEARANCE take NP-V-NPPPJi r STEAL, PERFORMANCE produce NP-V-NPPP1&apos;&quot; PERFORMANCE, CREATE Table 5: Random sample of eight verbs and their semantic preferences as ranked by the model more, our model makes interesting predictions with respect to the semantic preferences of a given verb.</S>
			<S sid ="177" ssid = "27">In table 5 we show the class preferences the model came up with for eight randomly selected verbs (class preferences are ranked from left to right, with the leftmost class being the most preferred one).</S>
			<S sid ="178" ssid = "28">Ta­ ble 6 summarizes the average class frequencies for the same eight verbs as assigned to corpus tokens by the two judges together with inter-judge agree­ ment ( K).</S>
			<S sid ="179" ssid = "29">The category OTHER is reserved for cor­ pus tokens which either have the wrong frame or for which the classes in question are not applicable.</S>
			<S sid ="180" ssid = "30">In general agreement on the class annotation task was good with Kappa values ranging from 0.68 to I. As shown in table 6, with the exceptions of call and produce the model&apos;s predictions are borne out in corpus data.</S>
	</SECTION>
	<SECTION title="Discussion. " number = "5">
			<S sid ="181" ssid = "1">This papen explores the degree to which syntactic frame information can be used to disambiguate verb semantic classes.</S>
			<S sid ="182" ssid = "2">In doing so, we cast the task of verb class disambiguation in a probabilistic frame­ work which exploits Levin&apos;s semantic classification and frame frequencies acquired from the BNC.</S>
			<S sid ="183" ssid = "3">The approach is promising in that it achieves high preci­ sion with a simple model and can be easily extended to incorporate other sources of information which Table 6: Random sample of eight verbs and their semantic preferences as ranked by two judges can influence the class selection process (i.e., selec­ tional restrictions).</S>
			<S sid ="184" ssid = "4">The semantic preferences which we generate can be thought of as default semantic knowledge, to be used in the absence of any explicit contextual or lexico-semantic information to the contrary (cf.</S>
			<S sid ="185" ssid = "5">ta­ ble 5).</S>
			<S sid ="186" ssid = "6">Consider the verb write for example.</S>
			<S sid ="187" ssid = "7">The model comes up with an intuitively reasonable rank­ ing: we more often write things to people (&quot;message transfer&quot; reading) than for them (&quot;performance&quot; reading).</S>
			<S sid ="188" ssid = "8">However, faced with a sentence like Max wrote Elisabeth a book pragmatic knowledge forces us to prefer the &quot;performance&quot; reading versus the the &quot;message transfer&quot; reading.</S>
			<S sid ="189" ssid = "9">In other cases the model comes up with a counterintuitive ranking.</S>
			<S sid ="190" ssid = "10">For the verb call, for instance, the &quot;get&quot; reading (e.g., I will call you a cab) is preferred over the more natu­ ral &quot;dub&quot; reading (e.g., John called me a fool).</S>
			<S sid ="191" ssid = "11">We still rely heavily on the verb class informa­ tion provided by Levin.</S>
			<S sid ="192" ssid = "12">But part of original aim was to infer class information for verbs not listed by Levin.</S>
			<S sid ="193" ssid = "13">For such a verb, P(class), and hence P(verb,frame, class) will be zero, which is not what we want.</S>
			<S sid ="194" ssid = "14">Recent work in computational lin­ guistics (e.g., Schiitze (1993)) and cognitive psy­ chology (e.g., Landauer and Dumais (1997)) has shown that large corpora implicitly contain seman­ tic information, which can be extracted and manipu­ lated in the form of co-occurrence vectors.</S>
			<S sid ="195" ssid = "15">The idea would be to compute the centroid (geometric mean) of the vectors of all members of a semantic class.</S>
			<S sid ="196" ssid = "16">Given an unknown verb (i.e., a verb not listed in Levin) we can decide its semantic class by compar­ ing its semantic vector to the centroids of all seman­ tic classes.</S>
			<S sid ="197" ssid = "17">We could (for example) determine class membership on the basis of the closest distance to the centroid representing a semantic class (cf.</S>
			<S sid ="198" ssid = "18">Patel et a!.</S>
			<S sid ="199" ssid = "19">(1998) for a proposal similar in spirit).</S>
			<S sid ="200" ssid = "20">Once we have chosen a class for an unknown verb, we are entitled to assume that it will share the broad syn­ tactic and semantic properties of that class.</S>
			<S sid ="201" ssid = "21">We also intend to experiment with a full scale subcategorization dictionary acquired from the BNC.</S>
			<S sid ="202" ssid = "22">We believe this will address issues such as: (a) relations between frames and classes (what are the frames for which the semantic class is predicted most accurately) and (b) relations between verbs and classes (what are the verbs for which the seman­ tic class is predicted most accurately).</S>
			<S sid ="203" ssid = "23">We also plan to experiment with different classification schemes for verb semantics such as WordNet (Miller et al., 1990) and intersective Levin classes (Dang et al., 1998).</S>
	</SECTION>
</PAPER>
