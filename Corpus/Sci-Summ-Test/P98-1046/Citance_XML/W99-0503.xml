<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We report a number of computational ex­ periments in supervised learnig whose goal IS to automatically classify a set of verbs mto lexrcal semantic classes, based on frequency drstrrbut1on approx1mat1ons of grammatical features extracted from a very large annotated corpus D1strrbutrons of five syntactic features that approx1mate trans1trv1ty alternations and thematic role ass1gnments are sufficient to reduce error rate by 56% over chance We conclude that corpus data IS a usable repos1tory of verb class mformation, and that corpus­ drrven extractiOn of grammatical features IS a promismg methodology for automatic lexical acquisition</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="2" ssid = "2">Recent years have Witnessed a shift m grammar de­ velopment methodology, from craftmg large gram­ mars, to annotation of corpora Correspondmgly, there has been a change from developmg rule-based parsers to developmg stat1st1cal methods for mduc­ mg grammatical knowledge from annotated corpus data The sh1ft has mostly occurred because bu!ld­ mg wrde-coverage grammars 1s t1meconsummg, er­ ror prone, and difficult The same can be sa1d for craftmg the nch lexrcal representatiOns that are a central component of hngu1strc knowledge, and re­ search m automatic le-..1cal acqu1s1t1on has sought to address th1s ((Dorr and Jones, 1996, Dorr, 1997), among others) Yet there have been few attempts to learn fine-gramed lexical classificatiOns from the sta­ tistical analysiS of d1stnbutwnal data, analogously to the mduct1on of syntactic knowledge (though see, e g, (Brent, 1993, Klavans and Chodorow, 1992, Resml.., 1992)) In th1s paper.</S>
			<S sid ="3" ssid = "3">we propose uth an approach for the automatic classlficatwn of \erb mto lex1cal semantic classes 1 We can express the Issues raised by th1s approach as follows Wh1ch hngu1st1c d1stmctwns among le\.Ical classes can we e\.pect to find m a corpus&gt;</S>
	</SECTION>
	<SECTION title="How easily can  we extract  the frequency drstn­. " number = "2">
			<S sid ="4" ssid = "1">butlons that approx1mate the relevant hngutstiC properties?</S>
	</SECTION>
	<SECTION title="Wh1ch frequency  d1stnbut1ons work best to dls­. " number = "3">
			<S sid ="5" ssid = "1">tmgmsh the verb classes?</S>
			<S sid ="6" ssid = "2">In explormg these quest1ons, we focus on verb clas­ Sificatwn for several reasons Verbs are very Impor­ tant sources of knowledge m many language eng1neermg tasks, and the relat10nsh1ps among verbs ap­ pear to play a maJor role m the orgamzatwn and use of this knowledge h.nowledge about verb classe 1s cruc1al for lexical acqu1srt10n m support of language generatiOn and machme translatiOn (Dorr, 1997) and document clC!bsrficatwn (Klavans and Kan, 1998), :yet manual class1ficatwn of large numbers of verb&apos;S 1s a d1fficult and resource mtens1ve task (Levm, 1993 MJ!ler et a!</S>
			<S sid ="7" ssid = "3">, 1990, Dang et al , 1998) To address these 1ssues, we suggest that one can tram an automatic classifier for verbs on the bast&apos;S of stattst1cal apprm..</S>
			<S sid ="8" ssid = "4">tmatwns to verb dtatheses We use drathesesalternattOns m the e\.presswn of the ar­ guments of the verb-followmg Levm and Dorr, for two reasons Fnst, verb dratheses are syntacttc cue&apos;&gt; 1 We are aware that a d!stnbuttonal approach rests on one strong assumptiOn regardmg the nature of the repre­ sentatiOns under study semantic not10ns and syntact1c notions are correlated, at least m part Tlus assumptton IS under debate (Bnscoe and Copestake, 1995, Levm, 1993, Dorr and Jones, 1996, Dorr, 1997), but we adopt 1t here w1thout further d1scuss1on 15 to semantic classes, hence they can be more eas1ly captured by corpus-based techn ques Second, usmg verb diatheses reduces no1se There IS a certam con­ sensus (Bnscoe and Copestake, 1995, Pustejovsky, 1995, Palmer, 1999) that verb d1atheses are regular sense extensions Hence focussmg on th1s type of classlficatton allows one to abstract from the prob­ lem of word sense d1sambiguatton and treat residual differences m word senses as no1se m the classifica­ tiOn task We present an m-depth case study, m wh1ch we apply machme learmng techn ques to automatically class1fy a set of verbs based on d1stnbutwns of gram­ matical md1cators of diatheses, extracted from a very large corpus We look at three very mterest­ mg classes of verbs unergat1ves, unaccusat1ves, and object-drop verbs (Levm, 1993) These are mterest­ mg classes because they all participate m the transi­ tiVIty alternatiOn, and they are m1n1mal pa1rs- that 1s, a small number of well-defined d1stmct10ns differ­ entiate then transltlve/mtransJtlve behaviOr Thus, we expect the d1fferences m the1r d1stnbutwns to be small, entallmg a fine-gramed d1scrlmmatwn task that prov1des a challengmg testbed for automat1c class1ficat10n The spec1fic theoretical questwn we mvest1gate IS whether the factors underlymg the verb class d!s­ tmcttons are reflected m the statistical d1stnbut10ns of lex1cal features related to diatheses presented by the mdivJdual verbs m the corpus In domg th1s, we address the questwns above by determmmg what are the lex1cal features that could d1stmgmsh the behav­ Ior of the classes of verbs wtth respect to the relevant diatheses, &apos;Nh1ch of those features can be gleaned from the corpus, and wh1ch of those, once the sta­ tistical d1stnbut10ns are available, can be used suc­ cessfully by an automatic classifier In Initial work (Stevenson and Merlo, 1999), \\e found that hngmst1cally mot1vated features that d1s­ tmgu1sh the verb classes can be extracted from an annotated, and m one case parsed, corpus These features are sufficient to almost halve the error rate compared to chance (45% reductwn) m auto­ matic verb class1ficat10n, suggestmg that dtstnbu­ twnal data provtdes knowledge useful to the classt­ ficatwn of verbs The focus of our ongmal studj was thP demonstration m pnnctple of IPc&gt;•nmg verb classes from frequency d1stnbutwns of syntactic fea­ tures, and an analysis of the relative contnbutwn of the vanous features to learnmg Th1s paper turns to the Important ne\.t steps of rephcatmg our find­ mgs usmg other trammg methods and learnmg al­ gonthms, and analyzmg the performance on each of the three classes of verbs Th1s more detalied anal­ ysis of accuracy w1thm each class 111 turn leads to the development of a new dtstnbutwnal featme m­ tended to 1m prove dJscrlmmabthty among t\\O of the classes The addttiOn of the ne\\ feature successfully reduces the error rate of ou1 Initial results m classi­ ficatiOn by 19%, for a 56% overall reductiOn m error rate compared to chance 2 Determining the.</S>
			<S sid ="9" ssid = "5">Features In th1s sectwn, we present mottvatwn for the llllttal features that we mvest1gated m terms of thetr wle m learnmg the verb classes \Ve first present the lmgmst1cally denved features then turn toe\ tdence from e\.penmental psychohngutsttcs to e\.tend the set of potenttally relevant features 2.1 Features of the Vetb.</S>
			<S sid ="10" ssid = "6">Classes The three verb classes under mvesttgatwnunerga­ tJves, unaccusattves, and object-drop - dtffer 111 the properttes of the1r transtttve/mtranstttve alterna­ tiOns, wh1ch are exemphfied below Unergat1 ve ( 1a) The horse raced past the barn ( 1b) The Jockey raced the horse past the batn Unaccusat1 ve (2a) The butter melted m the pan (2b) The cook melted the butter m the panObject drop (3a) The boy washed the hall (3b) The boy washed The sentences m ( 1) use an unergattve Vl&apos;t b. weed Unergattves are mt1anstttve actton verbs whose tran­ SitiVe form ts the causattve counterpart of the m­ transttlve form Thus, the subject of the mttanst­ tne (1a) becomes the obJect of the transttl\e (lb) (Brousseau and Rttter 1991, Hale and h.ejset 1993 Levm and Rappaport Hovav, 1995) The sentences m (2) use an unaccusattve verb, melt :cl (_ nac­ cusattves are mtranstttve change of statl&apos; \et bs (2a) hke unergattves, the transttl\e countetpart fot thh&lt;&apos; verbs ts also causattve (2b) The sentenc&lt;&apos;tn ( J) use an obJect-dlOp vet b u·u hed, thee vet b-; ha1 c a non-causatne tran ttl\e/mtranstttve altettM\lon tn 11 luch the obJect ts stmplopttonal Both unergattves and unaccusatn I&apos;S hm e a causative transtttve form.</S>
			<S sid ="11" ssid = "7">but dtffer tn the semanttc roles that they asstgn to the parttctpants m thl&apos; e1 ent descnbed In an mtranstttve unetgattve, the ubJect ts an 1\.gent {the doer of the event), and Ill an tnttan­ stttve unaccusattve, the subject ts a Theme (ome­ thmg affected by the event) The role asstgnments to the correspondmg semanttc arguments of the t1an­ stttve forms-t e , the duect obJects-;:ue th&lt;&gt; amc 16 wtth the additiOn of a Causal Agent (the causer of the event) as subject m both cases Object-drop verbs s1mply assign Agent to the subject and Theme to the optiOnal object We expect the dlffermg semantic role assignments of the verb classes to be reflected m their syntac­ tic behaviOr, and consequently m the distributiOnal data we collect from a corpus The three classes can be characterized by their occurrence m two alter­ natiOns the transittve/mtransitive alternatiOn and the causative alternatiOn Unergatives are dJstm­ gUished from the other classes m bemg rare m the transitive form (see (Stevenson and Merlo, 1997) for an e\.planatiOn of this fact) Both unergattves and unaccusat1ves are distmgUished from object-drop m bemg causatiVe m the1r transitive form, and sun­ tlarly we expect th1s to be reflected m amount of detectable causat1ve use Furthermore, smce the causative IS a transitive use, and the transitive use of unergat1ves 1s expected to be rare, causatlvity should pnmanly distmgUish unaccusatives from object­ drops In conclusion, we expect the definmg features of the verb classes-the mtransitive/transitive and causatiVe alternatiOns-to lead to distribUtiOnal dif­ ferences m the observed usages of the verbs m these alternatiOns 2 2 Psycholingwstlcally Relevant Features The verbs under study not only differ m their thematic properties, they also differ m their pro­ cessmg properties Because these verbs can occur both m a transitive and an mtransittve form, they have been particularly studied m the conte\.t of the mam verb/reduced relative (MV /RR) ambigUity Il­ lustrated below (Bever, 1970) The horse raced past the barn fell The verb weed can be mterpreted as either a past tense mam verb, or as a past participle wtthm a re­ duced relat1ve clause (1 e , the horse (that was] raced past the barn) Because fellts the mam verb, the I e­ duced relative InterpretatiOn of raced IS reqUired for a coherent analysts of the complete sentence But the mam verb mterpretatton of raced 1s so strongly preferred that people expenence great dtfficulty at the verb fell.</S>
			<S sid ="12" ssid = "8">unable to mtegrate It w1th the Inter­ pretatiOn that has been developed to that pomt However, the reduced relat1ve mterpretatton ts not dtfficult for all verbs, as m the follO\ mg example The boy washed m the tub was angry The dtfference m ease of mterpretmg the tesolu­ tiOns of thts ambtgmty has been shown to be sen­ stttve to both frequency dtfferenttals (MacDonald 1994, Trueswell, 1996) and to verb class d1stmct10ns (Stevenson and Merlo, 1997, F1ltp et al , 1999) Constder the features that dtstmgutsh the t\\O 1 e ­ olutiOns of the Mv /RR ambtgutty MV The horse raced past the barn quickly RR The horse raced past the barn fell In the maiO verb resolutiOn, the ambiguous verb raced IS used m Its mtransttlve form, wh1le m the re­ duced relat1ve, It IS used m 1ts transitive, causative form These features correspond directly to the definmg alternatiOns of the three verb classes un­ der study (mtransttlve/transittve, causattve) -\ddt­ tlOnally, we see that other related featureto t hPse usages serve to dtstmgutsh the two resolut10ns of the ambiguity The mam verb form IS active and a mam verb part-of-speech (labeled as VBD by automatic POS taggers), by contrast, the reduced relatne foun IS passive and a past participle (tagged as \ B:&apos;-1) Smce these features (acttvefpasstve and VBD/\&apos;BN) are related to the mtranstttve/transttlve alte111at10 n, we expect them to also exhibit dtstrtbutlOnal differ­ ences among the verb classes Specifically, \\e e\.pect the unergattves to yteld a htgher proportiOn of actl\e and \tBD usage, smce, as noted above, the tianstt1 ve use of unergattves IS rare 3 Frequency Distributions of the.</S>
			<S sid ="13" ssid = "9">Features We assume that currently available large co1po1a are a reasonable approximatiOn to language (Pul­ lum, 1996) Usmg a combmed corpus of 65mtlhon words, we measured the relative frequenc} d1stnbu­ tiOns of the four hngUisttc features (VBD/\ B\ ac­ tive/passive, mtranstttve/transtttve, causatt\P/non­ causattve) over a sample of verbfrom the thtPe Ie,­ tcal semantic classes 3 1 Matenals \Ve chose a set of 20 verbs from each class based pit­ mat tly on the classtficatiOn of verbs m ( Le\ m 191).3) (see AppendiX A.)</S>
			<S sid ="14" ssid = "10">The unetgattves ate marmet of motiOn verbs The unaccusatnes ate \erbs of thitnge of state The object-drop verbs are un pectfted ob­ ject alternatiOn verbs The vetbs \\ere selected f10m Le\m&apos;s classes based on thetr absolute ftequPnc FUI thermore, they do not generally shO\ m l\ f&apos; de­ pat tures from the mtended verb sense Ill the co1 pu., (Though note that there are only 19 unaccu att\ f&apos;&apos;&gt; because rzpped.</S>
			<S sid ="15" ssid = "11">\ luch \\as tnittally counted 111 thP unaccusattves.</S>
			<S sid ="16" ssid = "12">was then e\cluded from the anal\­ SIS as It occurred mostly 1n a dtfferent usagp 111 tl;e corpus, as a ve1 b plus pat t1cle ) Most of the ve 1 b can occur Ill the transtttve and m the pa lve Earh verb presents the arne f01m m the stmple pat and m the past patttctple In order to Simphf} the count mg procedure, we made the assumptiOn that counts on this smgle verb form would appro\.Imate the dis­ tnbutiOn of the features across all forms of the verb Most counts were performed on the tagged version of the Brown Corpus and on the portiOn of the Wall Street Journal distributed by the ACL/DCI (years 1987, 1988, 1989), a combmed corpus m excess of 65 mdhon words, With the exceptiOn of causativ­ Ity which was counted only for the 1988 year of the WSJ, a corpus of 29 million words 3 2 Method We counted the occurrences of each verb token m a transitive or mtiansltlve use (INTR), m an act1ve or passive use (ACT), m a past paiticlple or s1mple past use (vao), and m a causative or non-causat1ve use ( CAUS) More prec1sely, features were counted as follows INTR a verb occurrence was counted as trans1t1ve 1f Immediately followed by a nommal group, else 1t was counted as mtrans1t1ve ACT mam verbs (tagged VBD) were counted as active, partiCiples (tagged vBN) counted as actiVe If the closest precedmg aux1hary was have, as passive 1f the closest precedmg aux1liary was be VBD occurrences tagged VBD were s1mple past, VBN were past partiCiple (Each of the above three counts was normalized over all occurrences of the verb, y1eldmg a smgle relat1ve frequency measure for each verb for that fea­ ture) CAUS The causative feature was approximated by the followmg steps FirSt, for each verb, all cooc­ cumng subjects and objects were e\.tracted from a parsed corpus (Collms, 1997) Then the propor­ d1menswn, the set of 59 vectors constitute the data for our machme learnmg expenments Template (verb, VBD, ACT, INTR, CAliS, class) Example (opened, 79, 91, 31, 16, unacc] Our goal was to determme whether automatic clas­ SificatiOn techmques could determme the class of a verb from the dtstnbutwnal properties represented m this vector In related work (Stevenson and Merlo, 1999) 11e descnbe lllltial unsupervised and superv1sed lea1 n111o- e\.penments on th1s data, and d1scuss the contllbutlOn of the four different features (the frequenL} d1s­ tnbutwns) to accuracy m verb classificatiOn In th 1s paper, we extend the work m several \\ays Fu-,t, 11e report further analys1s of rephcat10ns of our uut1al supervised learnmg results Next, we demonstrate s1miiar performance usmg different trammg methods and learmng algonthms, md1catmg that the perfor­ mance IS mdependent of the particular learmng ap­ proach Furthermore, these additiOnal expenments allow us to evaluate the performance separately on each of the three verb classes Fmally, based on th1s evaluatwn, we suggest a new feature to better d1s­ tmgUish the thematic properties of the classes, and present experimental results showmg that Its use 1m­ proves our origmal accuracy rate 4.1 lnit1al Experiments Imt1al experiments were earned out usmg a decision tree mductwn algonthm, the C5 0 system available from http / jwww rulequest com/ (Qumlan, 1992), to automatically create a classificatiOn program ftom a trammg set of verb vecto1s w1th known classlf1ca­ 2 tiOn of overlap bet....,een the two mult1sets of nouns tJOn In our earhe1 e\.pellments 11e ran 10-fold was calculated, meant to capture the causat1ve al­ ternatiOn, \here the subject of the mtrans1t1ve can occur as the object of the transitive \ve define overlap as the largest mult1set of elements belong­ mg to both the subjects and the object mult1sets, eg {a,a,a,b}n {a}= {a,a,a} The proportiOn IS the rat1o between the 0\erlap and the sum of the subject and object mult1sets (For \.ample, for the s1mple sets above, the ratiO would be 3/5 or 60 ) All ral\ and normalized corpus data a1e available from the authors, and more deta1l concernmg data collectiOn can be found m (Stevenson and !Vlerlo, 1999) cross-vahdatwns repeated 10 times he1e 11e tepeat the CJossvahdatwns 50 t1mes.</S>
			<S sid ="17" ssid = "13">and the numbe1s 1e­ p01 ted are averages over all the 1un&apos;3 3 Table 1 shows the re&apos;3ult&apos;&gt; of our e\.penment&apos;&gt; 011 the four features we counted m the co1po1 a (\so ACT, I&apos;&lt;TR, CAUS), as well as all three-featu1e &apos;&gt;ubsets of those four The basel me (chance) pe1 fo1 mance 111 thl&apos;3 task 1s 33 8%, smce the1e are 59 lector&apos;&gt; and 2 The S)stem generates both decision trees and rule sets fm use m classification Smce the d1fferenct 111 per_ fonnance between the t\\O IS ne\er sigmficant \le report here on!}</S>
			<S sid ="18" ssid = "14">the results usmg the extracted rules The rules prov1de a confidence level for each classificatiOn 11 hJCh IS unavailable With the decision tree data structure 3</S>
	</SECTION>
	<SECTION title="Experiments in Verb  Classification. " number = "4">
			<S sid ="19" ssid = "1">The frequency d1stnbut10ns of the verb alternatiOn features y1eld a vector for each verb that reprebents the relat1ve frequency values for the verb on each .\ 10-fold cross-vahdat10n means that the S\ stem randomly divides the data mto 10 parts, and runs 10 times on a different 90%-traimng-data/ 10%-test-data spht, y1eldmg an average accuracy and standard enor Th1s procedure IS then repeated for 50 different random diVISions of the.</S>
			<S sid ="20" ssid = "2">data and accurac) and standard error are agam averaged across the 50 runs II Features Ace% SE% II II Classes Percent -\ccuracy II II All Classes 61 o 11 Table 1 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0 (33 8% baseline) 3 poss1ble classes (That 1s, ass1gmng one of the two most common classes-of 20 verbs each-to all cases would yield 20 out of 59 correct, or 33 8% ) As seen m the table, classificatiOn based on the four fea­ tures performs at 63 7%, or 30% over chance The true mean of the sample cross-vahdatiOnS hes Within plus or mmus two standard errors of the reported mean (df=49, t=2 01, p&lt; 05) In all cases, the range 1s plus or mmus 1 0 or 1 2, y1eldmg a very nai­ row predicted accuracy range Furthermore, we per­ formed t-tests companng the results of the 50 cross­ validatiOns for each of the different feature subsets All pairs were s1gmficantly different (p&lt; 05) except for the results usmg all four features (first row m the table) and those excludmg ACT (second row m the table) We conclude that all features except ACT contnbute pOSitively to classificatiOn performance, and that ACT does not degrade performance In our rephcat10ns, then, we focus on all four features 4 2 Rephcat10n with Different Trammg and Learmng Methods There are conceptual and practical reasons for m­ vestlgatmg the performance of other trammg ap­ proaches and learnmg algonthms apphed to our verb d1stnbut10n data Conceptually.</S>
			<S sid ="21" ssid = "3">1t IS des1rable to know whether a particular learnmg algonthm or trammg techmque affects the level of performance Practically, different methods enable us to evalu­ ate more eas1ly the performance of the classificatiOn method w1thm each verb class (When we run re­ peated cross-validatiOns With t {:&apos;5 0.</S>
			<S sid ="22" ssid = "4">system, we don&apos;t have access to the accuracy rate for each class, the sy&lt;&gt;tem only outputs an overall mean error rate ) To preview, we find that the different trammg and learnmg methods we tned alL gave similar perfor­ mance to our ongmal results, and m addition al­ lowed us to evaluate the accuracy w1thm each verb class In one set of expenments, we used the same C5 0 system, but employed a trammg and testmg method­ ology that used a smgle holdout case We held om a smgle verb vector, tramed on the remammg .58 cases, then tested the resultmg cla&lt;&gt;slfier on the Table 2 Percentage Accuracy of C5 0 Wtth Smgle HoldOut Trammg smgle holdout case, and recorded the co!tect and ass1gned classes for that verb Th1s was then 1 e­ peated for each of the 59 ve1 bs Th1s approach }1elds both an overall accuracy rate (when the tesultare averaged across all 59 tnals), as well as p!O\ 1dmg the data necessary for determmmg accuracy f01 each verb class (because Y&lt;e have the classificatiOn of each verb when 1t 1s the test case) The results a1e pre­ sented m Table 2 The overall accuracy IS a little less than that ach1eved w1th the 10-fold cross-vdhdatwn methodology (61 0% versus 63 7%) However.</S>
			<S sid ="23" ssid = "5">we can see clearly now that the unergat1ve verbare classified w1th much greater accuracy (75%), wlule the unaccusattve and object-drop verbs are class1fied w1th much lower accuracy (57 9% and 50% respec­ tively) The d!stnbutiOnal features we have appear to be much better at d1stmgmshmg unergat1ves than una.ccusatJve or object-drop verbs To test th1s directly under our ongmal t1ammg assumptiOns, we ran two different expenment-s, u::.­ mg 10-fold cross-validatiOn repeated 10 tane» The first expeument tested the ab1lity of the classtfiet to d1stmgmsh between unergatlves and the other (\\O verb types, wrthout havmg to dtstmgursh bet\\een the latter two The data mcluded the 20 unerga­ tive verbs and a random sample of 10 unaccu5attve and 10 object-drop verbs, 10 different random am­ pies were selected to form 10 such data set In these data sets, the \erbs were labeled as unerga­ tt ve or &quot;other&quot; The basel me (chance) clas tficatton accuracy fot th1s data ts 50%, the mean acrut ac\ ach1eved across all data sets was i8 5% (standard e;­ !Or 0 8%), a srzable Improvement o\er chance The second e\.peument \\as mtended to deter mmP ltm\ well the classifier can d1stmgut»h. unaccu-&gt;att&apos;e from object-drop verbs The data consrsted of one et that mcluded all the unaccusatrve and object-drop verbs, w1th no unergat1ves Because there ate only 19 unaccusat1ve verbs, the basehne accuracy 1ate 1s 51% (20/39), here the classrfier achreved an dCC&apos;uracy only slightly above chance, at 58 3% (standard er10r 1 8%) These results, summanzed m Table 3 rlea.rlY confirm the h1gher accuracy of cla5 tfymg unergattv verbs wtth the current feature set Thts pattern of results \\as tepeated unc!Pt &quot;\PI) Classes Ace% SE% II Classes I VBD I ACT I INTR I CAUS II Unergat1ve vs Other 78 5 08 Unerg vs Unacc *** *** * *** Unaccusat1ve vs ObjectDrop 58 3 1 8 Table 3 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0 (5051% baseline) Unerg vs ObjDrop *** *** Unacc vs ObjDrop ns ns *** p$ 001 ** p&lt; 01 * p$ 05 *** * ** * II Classes PCA% FMP% II II ns non-s1gmficant Table 5 S1gmficance Levels ofT-Tests Comparmg Feature Values Between Verb Classes Table 4 Percentage Accuracy of PCA (PCA%) and Feature Map (FMP%) Neural Networks different type of learnmg algorithm as well We per­ formed a set of neural network expenments, usmg NeuroSolutwns 3 0 (see http/ jwww nd com), and report here on the networks that achieve the best performance on our data These are prmc1pal com­ ponents analysis and automatic feature map net­ works, which are essentially feed-forward percep­ trons w1th preprocessmg umts that transform the ex1stmg features mto a more useful format In our tests, both methods performed best overall when there were no hidden layer umts, and the networks were tramed for 1000 epochs The mean accuracy rates of 10-fold cross-vahdatwns With these param­ eter settmgs are summanzed m Table 4 Agam, the overall percentage accuracy ISm the low sixties, w1th better performance on the unergat1ves than on the other two verb classes, the difference was particu­ larly stnkmg w1th the PCA networks Th1s overall pattern doesn&apos;t change w1th further trammg, m fact, trammg up to 10,000 epochs resulted m very low accuracy (of 45%) for either unaccusat1ves, object­ drops, or both To summanze, followmg a different trammg ap­ proach \Hth C5 0 (the smgle holdout method), and applymg very different learnmg approaches (two kmds of neural networks), resulted m smula1 O\er­ all performance to our ongmal C5 0 results Th15 md1cates that the accurac) achieved IS at lea.5t somewhat mdependent of specific learnmg or tram­ mg techmques Moreover, these different methods, along with experiments directly testmg unergat1ve versus unaccusativefobject-drop classificatwn, allow us to examme more closely where the resultmg clas­ sifiers have the most senous problems In d.ll cases, the accuracy IS best for unergat1ves, and the accu­ racy of unaccusat1ves, object-drops, or both, IS de­ graded If thts performance IS mdeed a reliable mdt catwn of the mherent discnnunabiiity of the distn­ butwnal data, then we must e\.amme more closely the properties of the data Itself to understand (and potentially Improve) the performance 4 3 DJscr1mmatmg UnaccusatJve and ObJect-Drop Verbs To understand why the data d1scnmmates unerga­ tives reasonably well, but not unaccusat1ves and object-drops, we need to directly test the discnm­ mabihty of the features across the classes We do so by usmg t-tests to compare the values of the differ­ ent features-VBD, ACT, INTR, CAUS-for unergat1ve and unaccusattve verbs, unergatlve and object-drop verbs, and unaccusat1ve and object-drop verbs In each case, the t-test ts gtvmg the hkehhood that the two sets of values-e g , the VBD feature values for unergattves and for unaccusatives-are dra\lrn from different populatiOns Table 5 shows that d.ll seto; of features are s1g,mficantly different for unerg,at1ve and unaccusattve verbs, and for unergat1ve and object­ drop verbs Hm\ever, only INTR and CAUS a1e sig­ mficantly different for unaccusat1ve and object-diOp verbs, md1catmg that we need additiOnal fectlUle5 that have different values across these two clas5es In SectiOn 2 1, we noted the d1ffenng semantic role assignments for the verb classes, and hypothesized that these differences would affect the expre&apos;5siOn of syntactic features that a1e countable m a co1 pus For e\.ample, the c -I.LS feature approximates seman­ tic role mfounat1on bj encodmg, the 0\erlap bet\\een nouns that can occu1 111 the -,ubject and obJPCt po­ SitiOns of a cau-,ative \el b He1e \\e &apos;&gt;ug,g,e&apos;&gt;t anothe1 featUie, that of animacy of subject, that 1s mtended to dtstmgUish nouns that recetve an Agent role f10m those that receive a Theme role Recall that object­ drop verbs assign Agent to their subject m both the trans1t1ve aRd mtranstttve alternatwns, wh1le unac­ cusatives asstgn Agent to their subject only m the transitive, and Theme m the mtrans1t1ve \Ve P\.pect then that object-drop verbs will occur more often with an ammate subject &apos;\/ote ag,am that \\P are Features VBO ACT INTR CAUS VBO ACT INTR CAUS PRO Ace% SE% 63 7 06 70 7 04 wtthm the verb classes of thts new set of features to see whether accuracy has also tmproved for unerg,a­ ttve verbs 5 C o n c l u s i o n s Table 6 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0, Wtth and Wtthout New PRO Feature, All Verb Classes (33 8% baselme) makmg use of frequency dtstnbuttons-the clatm ts not that only Agents can be ammate, but rather that nouns that recetve the Agent role wtll more often be ammate than nouns that recetve the Theme role A problem wtth a feature ltke ammacy ts that tt requtres etther manual determmat10n of the ammacy of extracted subjects, or reference to an on-hne re­ source such as WordNet for determmmg antmacy To approxtmate ammacy wtth a feature that can be extracted automattcally, and wtthout reference to a resource external to the corpus, we mstead count pronouns (other than zt) m subject posttton The assumptton ts that the words I, we 1 you, she 1 he, and they most often refer to ammate enttttes The values for the new feature, PRO, were determm.ed · · by automatically extractmg all subJect/verb tuples mcludmg our 59 examples verbs (from the WSJ88 parsed corpus), and computmg the rat10 of occur­ rences of pronouns to all subjects We agam apply t-tests to our new data to deter­ rome whether the sets of PRO values dtffer across the verb classes Interestmgly, we find that the PRO values for unaccusattve verbs (the only class to as­ stgn Theme role to the subject tn one of tts alterna­ tiOns) are stgmficantly dtffetent from those for both unergattve and object-drop verbs (p&lt; 05) More­ over, the PRO values for unergattve and object-drop verbs (whose subjects are Agents m both alterna­ tiOns) are not stgmficantly dtfferent Thts pattern confirms the abtltty of the feature to capture the themattc dtstmctton bet.,.,een unaccusattve verbs and the other two classes Table 6 shows the result of applymg C5 0 (10-fold cross-vahdatton repeated 50 ttmes) to the three-\\ay classtficatton task usmg the PRO feature m conjunc­ tiOn wtth the four prevtous features -\ccuracy tm­ proves to over 70%, a teductton m the etrot rate of almost 20% due to thts smgle ne\v feature :\Iote­ over, classtfymg the unaccusattve a.1object-drop verbs usmg the new feature m conJunctiOn wtth the prev10us four leads to accuracy of over 68% (com­ pared to 58% wtthout PRO) We conclude that thts feature IS tmportant m dtstmgmshmg unaccusattve and object-drop verbs, and likely contnbutes to the Improvement m the three-way classtficatton because of thts Future work will exam me the pet fot mance In thts paper, we have presented an m-depth case study, m wh1ch we mvest1gate vanous machme learn­ mg techmques to automatically class1fy a set of verbs, based on dtstrtbutiOnal features e\.tracted from a very large corpus Results show that a small number of lmgmsttcally mottvated grammatical fea­ tures are suffictent to reduce the error rate bv 11101e than 50% ovez chance, acluevmg a 70% a cutacy rate m a three-way classtficatton tash.</S>
			<S sid ="24" ssid = "6">Tim leads us to conclude that corpus data ts a usable repost­ tory of verb class mformatton On one hand \\e ob­ serve that semantiC properties of verb classe( uch as causattvzty, or ammacy of subject) may be use­ fully approxtmated through countable syntacttc fea­ tures Even wtth some nOise, lexzcal properttes are reflected m the corpus robustly enough to postttvely contnbute m classtficatzon On the other hand, how­ ever, we remark that deep hngUistzc analysts cannot be eltmmated-m our approach, 1t ts embedded 111 the selectton of the features to count We also thmk that usmg lmguzstlcally motzvated features makes the approach very effective and eastly scalable we report a 56% reductton m error rate, w1th only five features that are relatively stratghtforward to count</S>
	</SECTION>
	<SECTION title="Acknowledgements">
			<S sid ="25" ssid = "7">Thts research was partly sponsored by the S\HS-&gt; Na­tiOnal Sctence Foundatton, under fello\ slup 8210 46569 to Paola :Vlerlo, by the US Nattonal Sctence Found at ton, under grants #9702331 and #918 322 to Suzanne Stevenson, and by the Infounatton &apos;)c1ences Counctl of Rutgers Umverszty \&apos;ve thank Martha Palmer for gettmg us started on tlus \\ ork and :\hchael Collins for gtvmg us access to the out­ put of hts parser We gratefully acknowledge the help of h.tva Dtckmson, \\ ho calculated not maltza­ ttons of the corpus data Appendix A The une1gatnes are manner of motion \erh Jtm1 pul ruohed, marched, !taped floated, raced, lwrl!cd uan­ dered, vaulted, paraded, galloped, glzded, hz!..ed hvpptd Jogged, ocooted, ocurned, ol..zpped, tzptoed, trotted The unaccusati\eS are verbs of change of state opened, exploded, flooded, dzsoolved, cracked, hmdtned bozled, melted, fractured, oolzdzfied, collapoed cooled folded, wzdened, changed, cleared, dzvzded, &gt;lllllnered stabzlzzed The object-dtop verbs are unspecified object alter­ natiOn verbs played, pmnted, kzc!..ed, carved, reaptd, washed, danced, yelled, typed, !..nttted borrowed rnh r &amp;ted, orgamzed, rented, sketched, cleaned, packed, stud­ zed, swallowed, called</S>
	</SECTION>
</PAPER>
