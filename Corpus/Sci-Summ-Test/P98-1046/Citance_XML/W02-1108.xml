<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We propose a method for semiautomatic classification of verbs to Levin classes via the semantic network of WordNet.</S>
		<S sid ="2" ssid = "2">The method involvesfirst classifying entire WordNet senses to semantic classes and then classifying individual verbs on the basis of their WordNet senses.</S>
		<S sid ="3" ssid = "3">We report evaluation which shows that the method can be used to build a verb classification accurateenough for practical NLP use.</S>
		<S sid ="4" ssid = "4">The WordNetLevin mapping produced as a byproduct, may, in turn, be used to supplement WordNet with novel information.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">Linguistic research has shown that verbs fallinto classes distinctive in terms of their syntac tic and semantic properties (Jackendoff, 1990; Hale and Keyser, 1993; Levin, 1993; Pinker, 1989).</S>
			<S sid ="6" ssid = "6">For example, verbs which share the meaning component of &amp;apos;motion&amp;apos; (e.g. fly and walk) tend to behave similarly also in terms of subcategorization and can thus be grouped to a linguistically coherent class.</S>
			<S sid ="7" ssid = "7">While the correspondence between the syntax and semantics of verbs is arguably not perfect and while the whole notion of a verb class is somewhat elusive&amp;apos;, verb classifications can be constructed which provide a generalization over a range of syntactic and semantic properties of verbs.</S>
			<S sid ="8" ssid = "8">Such classifications are particularly useful from a practical NLP point of view.</S>
			<S sid ="9" ssid = "9">They can be used as a means of reducing redundancy inthe lexicon and for filling gaps in lexical knowl edge.</S>
			<S sid ="10" ssid = "10">To a certain extent, they enable inferring 1-For example, as most verbs can be characterized byseveral meaning components, there is potential for crossclassification.</S>
			<S sid ="11" ssid = "11">Therefore different, equally viable classifi cation schemes can be constructed.the semantics of a word on the basis of its syn tactic behaviour, and the syntax of a word on the basis of its semantic behaviour.</S>
			<S sid ="12" ssid = "12">Verb classifications have, in fact, been usedto support various NLP tasks, including ma chine translation, language generation (Dorr, 1997), document classification (Klavans and Kan, 1998), lexicography (Sanfilippo, 1994) andlexical acquisition, such as word sense disambiguation (Dorr and Jones, 1996) and subcate gorization acquisition (Korhonen, 2002b).</S>
			<S sid ="13" ssid = "13">The verb classification employed most widely in NLP is Levin&amp;apos;s taxonomy of verbs and their classes (Levin, 1993).</S>
			<S sid ="14" ssid = "14">Levin classes are based onthe ability of a verb to occur in specific diathe sis alternations, i.e. specific pairs of syntacticframes which are assumed to be meaning re tentive.</S>
			<S sid ="15" ssid = "15">The classification covers a substantial number of diathesis alternations occurring in English.</S>
			<S sid ="16" ssid = "16">It is not, however, exhaustive.</S>
			<S sid ="17" ssid = "17">More work is required on extending and refining it until a comprehensive resource can be obtained suitable for large-scale NLP use (Dorr and Jones, 1996; Dorr, 1997; Korhonen, 2002b).Perhaps the most challenging task is to ex tend the classification with new participants.</S>
			<S sid ="18" ssid = "18">Manual classification of verbs to semanticclasses yields accurate results but is time con suming (Levin, 1993; Dang et al., 1998).</S>
			<S sid ="19" ssid = "19">Fully automatic classification, on the other hand, is fast but suffers from low accuracy (Dorr, 1997; Stevenson and Merlo, 1999).</S>
			<S sid ="20" ssid = "20">In this paper, we propose combining the strengths of theseapproaches.</S>
			<S sid ="21" ssid = "21">We present a method for semi automatic semantic classification of verbs which exploits automatic techniques but also allows for some manual intervention.The method involves classifying verbs seman tically via the semantic network of WordNet (Miller, 1990).</S>
			<S sid ="22" ssid = "22">Unlike Levin&amp;apos;s source, Wordnet is a comprehensive lexical database.</S>
			<S sid ="23" ssid = "23">Although it classifies verbs on a purely semantic basis, the syntactic regularities studied by Levin are to some extent reflected by semantic relatedness asit is represented by WordNet&amp;apos;s particular struc ture (Dorr, 1997; Fellbaum, 1999).</S>
			<S sid ="24" ssid = "24">Our methodmakes use of this partial overlap between WordNet and Levin classes.</S>
			<S sid ="25" ssid = "25">It involves first classify ing entire WordNet senses to semantic classesand then classifying individual verbs on the ba sis of their WordNet senses.We use this method to classify verbs in a num ber of WordNet files and report experimental evaluation which shows that the method is fairlyaccurate and can also be used to build a clas sification suitable for practical NLP use.</S>
			<S sid ="26" ssid = "26">The classification built using our method can alsobe used to benefit linguistic research, as knowledge about novel verb and verb class associa tions can be used to test and enrich linguistic theory (e.g.</S>
			<S sid ="27" ssid = "27">(Levin, 1993)).As a byproduct, the method produces a map ping between WordNet senses and Levin classes.</S>
			<S sid ="28" ssid = "28">This mapping — once comprehensive — can actas a useful supplement to WordNet which incorporates information about diathesis alterna tions and semantic verb classes.</S>
			<S sid ="29" ssid = "29">Currently this information is absent in WordNet.</S>
			<S sid ="30" ssid = "30">We discuss the background for our work in section 2.</S>
			<S sid ="31" ssid = "31">In section 3, we describe the method for classifying verbs semantically via WordNet.</S>
			<S sid ="32" ssid = "32">The details of the experimental evaluation of our method are supplied in section 4.</S>
			<S sid ="33" ssid = "33">Section 5 concludes with directions for future work.</S>
	</SECTION>
	<SECTION title="Background. " number = "2">
			<S sid ="34" ssid = "1">In Levin (1993), verbs which display the same orsimilar set of diathesis alternations in the real ization of their argument structure are assumed to share certain meaning components and are organized into a semantically coherent class.</S>
			<S sid ="35" ssid = "2">For instance, the Levin class of &amp;amp;quot;Break Verbs&amp;amp;quot; (class 45.1) refers to actions that bring about a change in the material integrity of some entity.</S>
			<S sid ="36" ssid = "3">It is characterized by its participation (13) ornon-participation (46) in the following alterna tions: 1.</S>
			<S sid ="37" ssid = "4">Causative/inchoative alternation:.</S>
			<S sid ="38" ssid = "5">Tony broke the window ---&amp;gt; The window broke 2.</S>
			<S sid ="39" ssid = "6">Middle alternation:.</S>
			<S sid ="40" ssid = "7">Tony broke the window ---&amp;gt; The window broke easily</S>
	</SECTION>
	<SECTION title="Instrument subject alternation:. " number = "3">
			<S sid ="41" ssid = "1">Tony broke the window with the hammer ---&amp;gt; The hammer broke the window 4.</S>
			<S sid ="42" ssid = "2">* With/against alternation: Tony broke the cup against the wall ---&amp;gt; *Tony broke the wall with the cup 5.</S>
			<S sid ="43" ssid = "3">*Conative alternation: Tony broke the window ---&amp;gt; *Tony broke at the window6.</S>
			<S sid ="44" ssid = "4">*Body-Part possessor ascension alter nation: *Tony broke herself on the arm ---&amp;gt; Tony broke her armLevin&amp;apos;s classification is attractive in providing a summary of the variety of theoretical research done on semantic verb classes and a ref erence work extensive enough for NLP research.</S>
			<S sid ="45" ssid = "5">It is not, however, comprehensive in breadth or depth of coverage.</S>
			<S sid ="46" ssid = "6">It provides a classification of around 3200 verbs into 48 classes (some ofwhich are split further into more distinctive sub classes, making the total number of 191 classes)according to their participation in 79 alterna tions involving NP and PP complements only.</S>
			<S sid ="47" ssid = "7">Work on refining the existent semantic classes and composing novel ones is under way.</S>
			<S sid ="48" ssid = "8">Dang et al.</S>
			<S sid ="49" ssid = "9">(1998), for example, have refined the current classification by creating intersective classes for those verbs which share membership of more than one Levin class.</S>
			<S sid ="50" ssid = "10">Dorr (1997) has created new classes for verbs whose syntactic behaviour differs from the syntactic description of existing Levin classes.</S>
			<S sid ="51" ssid = "11">Korhonen (2002b) has proposednovel alternations not covered by Levin — par ticularly those involving sentential complements — with the aim to create new classes for further verb types.</S>
			<S sid ="52" ssid = "12">Attempts have also been made to extend the classification with new participants.</S>
			<S sid ="53" ssid = "13">Levin, for instance, associates only 13 verbs with the class of &amp;amp;quot;Break Verbs&amp;amp;quot; (break, chip, crack, crash,crush, fracture, rip, shatter, smash, snap, splin ter, split, and tear), while it is possible that other English verbs fall into this class as well.</S>
			<S sid ="54" ssid = "14">Stevenson and Merlo (1999) and Dorr (1997)have proposed methods for automatically infer ring participation in verb classes.</S>
			<S sid ="55" ssid = "15">Stevensonand Merlo have applied machine learning tech niques to automatically classify a set of verbs, based on distributional features extracted from a corpus.</S>
			<S sid ="56" ssid = "16">They achieve 70% accuracy on the task, but their method is applicable to three verb classes only.</S>
			<S sid ="57" ssid = "17">Dorr has proposed a methodapplicable to all Levin classes which relies heav ily on lexical resources.</S>
			<S sid ="58" ssid = "18">It uses grammatical information in the LDOCE dictionary (Procter,1978) alongside semantic information in WordNet.</S>
			<S sid ="59" ssid = "19">The method yields 61% accuracy in as signing verbs to (one of their) correct classes.</S>
			<S sid ="60" ssid = "20">Although fully automatic classification would be an ideal solution, the methods proposed so far have not led to a resource accurate enoughfor all-purpose practical NLP use (e.g.</S>
			<S sid ="61" ssid = "21">(Korhonen, 2002b)).</S>
			<S sid ="62" ssid = "22">On the other hand, manual classification is not an ideal solution as it is time con suming and thus costly.</S>
			<S sid ="63" ssid = "23">Here, we address this problem by proposing a semiautomatic method which uses automatic techniques to speed upthe classification task but allows for some manual intervention to maximise accuracy of classi fication.</S>
			<S sid ="64" ssid = "24">3 Classifying Verbs Semantically via.</S>
			<S sid ="65" ssid = "25">WordNetOur method involves assigning verbs to seman tic classes via WordNet.</S>
			<S sid ="66" ssid = "26">Section 3.1 provides a brief introduction to this semantic network and discusses its suitability for the task.</S>
			<S sid ="67" ssid = "27">Section 3.2 gives details of the classification algorithm.</S>
			<S sid ="68" ssid = "28">3.1 WordNet.</S>
			<S sid ="69" ssid = "29">In contrast to Levin&amp;apos;s classification, WordNetorganizes words on a purely semantic basis without regard to their syntactic properties.</S>
			<S sid ="70" ssid = "30">Its or ganization is that of a network of interlinked nodes representing word meanings.</S>
			<S sid ="71" ssid = "31">The nodesare sets of synonym sets (`synsets&amp;apos;), which con sist of all the word forms that can express a given concept (e.g. {snooze, drowse, doze}).</S>
			<S sid ="72" ssid = "32">While synonymy links individual words within synsets, the super-/subordinate relation linksentire synsets, resulting in hierarchical struc tures.</S>
			<S sid ="73" ssid = "33">WordNet has several qualities which make it suitable for our purposes.</S>
			<S sid ="74" ssid = "34">Unlike Levin&amp;apos;s source, it is a comprehensive lexical database.</S>
			<S sid ="75" ssid = "35">It alsoincludes useful information about semantic re lations and the frequency of word senses whichcan be exploited in the classification task.</S>
			<S sid ="76" ssid = "36">Al though WordNet&amp;apos;s semantic organization doesnot always go hand in hand with syntactic infor mation, Dorr and Jones (1996) and Dorr (1997) have demonstrated that synonymous verbs in WordNet exhibit syntactic behaviour similar to that characterised in the classification system of Levin.</S>
			<S sid ="77" ssid = "37">This enables association of verbs with semantic classes on the basis of their WordNet synonyms.</S>
			<S sid ="78" ssid = "38">We utilized the verb hierarchy of WordNet version 1.6.</S>
			<S sid ="79" ssid = "39">which contains 10,319 word forms whose 22,066 senses spread over 12,127 synsets.</S>
			<S sid ="80" ssid = "40">Most synsets in this hierarchy are interrelatedby a pointer standing for a manner relation tro ponymy2.</S>
			<S sid ="81" ssid = "41">They divide into 15 subhierarchieswhich represent different, mostly semantically driven domains (e.g. &amp;amp;quot;verbs of motion&amp;amp;quot;, &amp;amp;quot;verbs of perception&amp;amp;quot;).</S>
			<S sid ="82" ssid = "42">3.2 Classification Algorithm.</S>
			<S sid ="83" ssid = "43">In addition to WordNet, our classification algorithm employs the following set of lexical re sources: • Levin&amp;apos;s semantic classification of 3200 verbs • The LDOCE dictionary• Dorr&amp;apos;s (1997) source of LDOCE grammati cal codes for Levin classes.</S>
			<S sid ="84" ssid = "44">This source was obtained by extracting automatically basic syntactic patterns from all the sentences in Levin&amp;apos;s book, mapping these onto LDOCE grammatical codes and grouping them into canonical and prohibited codes for each class.Dorr (1997) employed the same set of lexical resources in her fully automatic classification approach.</S>
			<S sid ="85" ssid = "45">In Dorr&amp;apos;s approach, each un known verb was assigned to one of its semantic classes by examining the verb&amp;apos;s synonyms from WordNet and selecting those whose Levin classis associated with syntactic information match ing that of the unknown verb.</S>
			<S sid ="86" ssid = "46">The notion of 2For example, the synset {snooze, drowse, doze} is represented as one of the troponyms (subordinates) of the hypernym (superordinate) synset {rest, repose}, since snooze, drowse or doze mean to rest or repose in a particular manner.&amp;amp;quot;match&amp;amp;quot; was based on the degree of intersec tion between the verb&amp;apos;s LDOCE codes and the LDOCE codes for a candidate class.Our semiautomatic approach differs, how ever, essentially from Dorr&amp;apos;s. In our approach, entire WordNet senses (i.e. synsets) are firstassigned to semantic classes, using information in the lexical resources merely as a guid ance.</S>
			<S sid ="87" ssid = "47">After synsets are classified, individualverbs receive the classification of their respec tive synsets.</S>
			<S sid ="88" ssid = "48">By classifying entire synsets, our objective is to build a more static source where WordNet senses are associated with different Levin classes.</S>
			<S sid ="89" ssid = "49">Although static, the source will allow for updating and adding new verbs to WordNet.</S>
			<S sid ="90" ssid = "50">Our algorithm makes use of the hierarchicalstructure of WordNet.</S>
			<S sid ="91" ssid = "51">It classifies synsets sub hierarchy by subhierarchy, starting from the toplevel synsets, and going further down in the tax onomy only when required.</S>
			<S sid ="92" ssid = "52">This makes sense,as many of the top level synsets intersect directly with Levin classes.</S>
			<S sid ="93" ssid = "53">For example, &amp;amp;quot;Send ing and Carrying&amp;amp;quot; and &amp;amp;quot;Force Exerting&amp;amp;quot; verbs are all found under the same top level synset {move, displace}.</S>
			<S sid ="94" ssid = "54">Each synset is classified by first assigning the majority of its member verbs to a semantic class and then choosing the Levin class supported by the highest number of verbs.</S>
			<S sid ="95" ssid = "55">&amp;apos;Member verbs&amp;apos; refer here to those which are members of thesynset in question and of its hyponym (sub ordinate) synsets.</S>
			<S sid ="96" ssid = "56">Thus if a classified synset has hyponym synsets, the latter are classified according to their classified hypernym synset.At the present state of development, our algorithm classifies verbs according to their predominant (i.e. most frequent) sense in Word Net only3.</S>
			<S sid ="97" ssid = "57">Accordingly, synsets are classified byconsidering only those member verbs whose predominant sense belongs to the synset in question.</S>
			<S sid ="98" ssid = "58">The method is, however, generally applicable (i.e. fully suitable for classifying non predominant senses of verbs as well).</S>
			<S sid ="99" ssid = "59">The algorithm proceeds as follows: Step 1: If the majority of member verbs of a given synset S are Levin verbs from the same class, classify S directly.</S>
			<S sid ="100" ssid = "60">3The WordNet frequency data is derived from the SemCor corpus.</S>
			<S sid ="101" ssid = "61">Step 2: Otherwise, classify more memberverbs (according to Step 4a-d) until the ma jority are classified, and then go back to Step 1.</S>
			<S sid ="102" ssid = "62">Step 3: Otherwise, if the classified verbs point to different Levin classes, examine whetherS consists of hyponym synsets.</S>
			<S sid ="103" ssid = "63">If not, as sign S to the Levin class supported by the highest number of classified verbs.</S>
			<S sid ="104" ssid = "64">If yes,go one level down in the hierarchy and classify the hyponym synsets separately, start ing again from Step 1.</S>
			<S sid ="105" ssid = "65">Step 4: If S includes no Levin verbs, proceedas follows to classify the majority of mem ber verbs of S: (a) Extract the predominant sense of a given verb V from WordNet (b) Extract the syntactic codes from LDOCE relevant to this sense (c) Examine whether V could be assigned to a Levin class already associated with the other verbs in the (i) same synset, (i) possible hypernym synset or(iii) possible sister synsets by compar ing the LDOCE codes of the sense and Dorr&amp;apos;s LDOCE codes of the respectiveLevin class(es).</S>
			<S sid ="106" ssid = "66">Given the hypothesised classes, make the final class as signment manually.(d) If no suitable class is found, re examine the case after more verbs havebeen analysed.</S>
			<S sid ="107" ssid = "67">If the classification re mains unsolved, set V aside for later examination.The above algorithm is for the most part au tomatic, however, Step 4b and part of Step4c (the final class assignment) are done man ually to ensure accuracy of classification.</S>
			<S sid ="108" ssid = "68">The approach of classifying &amp;amp;quot;only&amp;amp;quot; the majority of verbs in synsets (as opposed to all verbs) aims, however, to minimise manual effort.</S>
			<S sid ="109" ssid = "69">The following examples illustrate the use of this algorithm to assign hyponym synsets of the top level synset {move, displace} to Levin classes4: 4As we only consider verbs whose predominant senses belong to the synsets in question, for clarity, we refer to synsets in these examples as WordNet synset identifier Example 1: The synset no. 01328437 has 5 member verbs, 3 of which are Levin verbs from the same verb class.</S>
			<S sid ="110" ssid = "70">It is assigned directly to the Levin class of &amp;amp;quot;Verbs of Sending and Carrying&amp;amp;quot; (Step 1).</S>
			<S sid ="111" ssid = "71">2.</S>
			<S sid ="112" ssid = "72">[X9 esp. OFF, AWAY] to remove b. by taking suddenly: &amp;amp;quot;She whisked the cups away / whisked him (off) home&amp;amp;quot; ship =&amp;gt; Verbs of Sending and Carrying despatch dispatch =&amp;gt; Verbs of Sending and Carrying route forward =&amp;gt; Verbs of Sending and CarryingExample 2: The synset no. 01278717 in cludes Levin verbs which point to different classes.</S>
			<S sid ="113" ssid = "73">Since it consists of hyponym synsets (as indicated by the synset identifiers below), we go one level down in the taxonomy and classify the hyponym synsets separately (Step 3).</S>
			<S sid ="114" ssid = "74">push =&amp;gt; Verbs of Exerting Force jab poke 01296169 =&amp;gt; Poke Verbs nudge prod 00838894 =&amp;gt; Verbs of Contact repel 01034588 shove 01278320 =&amp;gt; Verbs of Exerting Force ram 01296169 obtrude 01279473 thrust 01296169 =&amp;gt; Verbs of Exerting Force elbow shoulder 01278320Example 3: The synset no. 00994853 in cludes 13 member verbs, 4 of which are Levin &amp;amp;quot;Verbs of Sending and Carrying&amp;amp;quot;.</S>
			<S sid ="115" ssid = "75">We need toclassify more verbs to determine class assign ment (Step 2).</S>
			<S sid ="116" ssid = "76">We choose whisk and extract its predominant sense from WordNet (Step 4a): whisk -- (move somewhere quickly; &amp;amp;quot;The president was whisked away in his limo&amp;amp;quot;)In LDOCE the verb has three senses.</S>
			<S sid ="117" ssid = "77">That cor responding to the predominant WordNet sense is identified as (Step 4b): codes, rather than their actual names.</S>
			<S sid ="118" ssid = "78">To simplify the examples somewhat, we also refer to broad rather than fine-grained Levin classes.</S>
			<S sid ="119" ssid = "79">11 Levin classes are already matched with the.</S>
			<S sid ="120" ssid = "80">verbs in the same, hypernym and sister synsets.</S>
			<S sid ="121" ssid = "81">Those whose syntactic description includes the LDOCE code X9 are: Verbs of putting Verbs of removing Verbs of sending and carrying Verbs of exerting force Verbs of motion After verifying these options manually, whisk is assigned to &amp;amp;quot;Verbs of Sending and Carrying&amp;amp;quot; (Step 4c).Example 4: The synset no. 01527059 in cludes around 90 member verbs related to the transfer of messages.</S>
			<S sid ="122" ssid = "82">These spread over nearly 60 hyponym synsets.</S>
			<S sid ="123" ssid = "83">Seven of the verbs are Levin verbs from various classes which include verbs taking sentential complements.</S>
			<S sid ="124" ssid = "84">Two of them are listed by Dorr (1997) as members of her new semantic classes.</S>
			<S sid ="125" ssid = "85">The synset is set aside for future work (Step 4d).</S>
	</SECTION>
	<SECTION title="Experimental Evaluation. " number = "4">
			<S sid ="126" ssid = "1">We applied the verb classification algorithm tothree WordNet subhierarchies: contact, posses sion and motion verbs.</S>
			<S sid ="127" ssid = "2">1581 synsets in these files were assigned to one of 32 Levin classes and 148 were left unclassified.</S>
			<S sid ="128" ssid = "3">A small numberof synsets (35) from other verb files were classi fied as well.</S>
			<S sid ="129" ssid = "4">To evaluate the classification algorithm, wechose 60 synsets from among the 1616 classi fied.</S>
			<S sid ="130" ssid = "5">The synsets were chosen at random sothat 20 were taken from each of the three Word Net verb files (contact, possession and motion verbs).</S>
			<S sid ="131" ssid = "6">From the total of 501 verbs in these synsets, we chose for evaluation those 224 whichwere neither Levin verbs nor classified manu ally when linking synsets with Levin classes.</S>
			<S sid ="132" ssid = "7">For these verbs, the semantic classification (to a broad or — where applicable — to a fine-grained Levin class) was compared against a manually obtained gold standard classification.</S>
			<S sid ="133" ssid = "8">The algorithm classified correctly 181 verbs and incorrectly 43 verbs.</S>
			<S sid ="134" ssid = "9">Accuracy of the classassignment was thus 81%.5 All the misclas sifications corresponded to cases where there is a semantic mismatch between WordNet and Levin, i.e. the majority, but not all verbs in a synset corresponded to the same Levin class.</S>
			<S sid ="135" ssid = "10">21% of the misclassifications concerned synsets which divide further into hyponym synsets.</S>
			<S sid ="136" ssid = "11">It is possible that better results could be obtained for these synsets if the classification algorithm was refined further (e.g. to classify more than &amp;amp;quot;just&amp;amp;quot; the majority of the member verbs in a synset, for example 70%, before classifying the entire synset).79% of the misclassifications concerned, how ever, synsets which do not divide further into hyponym synsets and whose analysis cannot be improved, if we maintain the idea of linking entire synsets with Levin classes.</S>
			<S sid ="137" ssid = "12">In the light of these results, it thus seems that the upper bound of our method is around 85%.</S>
			<S sid ="138" ssid = "13">The correspondence between WordNet synsets and Levin classes varies, however, considerably across WordNet and this affects the accuracy of our method.</S>
			<S sid ="139" ssid = "14">Further evaluation is therefore needed with a larger set of WordNet files to get a better idea of the performance of the algorithm.</S>
			<S sid ="140" ssid = "15">Our results are not directly comparable with those of Dorr (1997), as Dorr does not restrict her evaluation to a certain sense.</S>
			<S sid ="141" ssid = "16">She reports 61% accuracy in assigning a verb to any of its correct classes, while we report 81% accuracy in assigning a verb to the class corresponding to its predominant sense.Task-based evaluation of our classification al gorithm was reported in (Korhonen, 2002a).</S>
			<S sid ="142" ssid = "17">In this evaluation, a classification obtained usingour algorithm was employed in the task of automatic subcategorization acquisition.</S>
			<S sid ="143" ssid = "18">The algo rithm was adapted to classify verbs to (mainly)broad Levin classes as in subcategorization acquisition it was adequate to assume a broad no 5Korhonen (2002a) reported a smaller evaluation of this classification algorithm with 151 verbs which yielded93% accuracy.</S>
			<S sid ="144" ssid = "19">However, in this evaluation a broad no tion of Levin class was assumed which explains the higher accuracy.</S>
			<S sid ="145" ssid = "20">tion of a semantic class.</S>
			<S sid ="146" ssid = "21">The method for subcategorization acquisition involved first using the system of Briscoe andCarroll (1997) to acquire a putative subcate gorization frame (scF) distribution for a verb from corpus data.</S>
			<S sid ="147" ssid = "22">The system used a shallowparser to obtain the subcategorization information and employed a classification of 163 ver bal scFs.</S>
			<S sid ="148" ssid = "23">The putative distribution was thensmoothed with the back-off distribution corresponding to the semantic class of (the predom inant sense of) a verb.</S>
			<S sid ="149" ssid = "24">The semantic class was determined by our classification algorithm.</S>
			<S sid ="150" ssid = "25">This task-based evaluation is fairly sensitive to the accuracy of the class assigments.</S>
			<S sid ="151" ssid = "26">Wherethe predominant sense is assigned correctly, significant improvement can be reported in SCF ac quisition, as accurate back-off estimates help to correct the acquired SCF distribution and deal with sparse data.</S>
			<S sid ="152" ssid = "27">Incorrect class assignments can, however, degrade performance.</S>
			<S sid ="153" ssid = "28">On a test set of 91 verbs from 16 Levin classes,the method yielded 81% type precision (the per centage of SCF types that the method proposeswhich are correct) and 73% type recall (the per centage of SCF types in the gold standard thatthe method proposes).</S>
			<S sid ="154" ssid = "29">The method was com pared against a baseline method which assumed no semantic class and involved no smoothing.F measure6 was 76 for the method that as sumed a semantic class and 61 for the baseline.This result shows that our algorithm is accu rate enough to yield a classification which can benefit a practical NLP task.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "5">
			<S sid ="155" ssid = "1">We have proposed a method for semiautomatic semantic classification of verbs which combinesthe benefits of manual classification and auto matic techniques.</S>
			<S sid ="156" ssid = "2">The method assigns verbs tosemantic classes via WordNet, by first classifying entire WordNet senses and then classifying individual verbs according to their Word Net senses.</S>
			<S sid ="157" ssid = "3">We have reported evaluation which shows that method is fairly accurate and can beused to build a classification suitable for practi cal NLP use.</S>
			<S sid ="158" ssid = "4">In the future, we will apply the methodto other Wordnet files, perform more com prehensive evaluation and further refine the</S>
	</SECTION>
	<SECTION title="F 2.precision•recall" number = "6">
			<S sid ="159" ssid = "1">precision+recallclassification algorithm to consider also non predominant senses of verbs.</S>
			<S sid ="160" ssid = "2">Our long termgoal is to build a comprehensive semantic clas sification of verbs which can be useful for NLPas well as for linguistic research and — as a by product — a mapping between WordNet sensesand Levin classes which can act as a useful sup plement to WordNet.</S>
			<S sid ="161" ssid = "3">6 Acknowledgements.</S>
			<S sid ="162" ssid = "4">We thank Bonnie Dorr for the use of her source of LDOCE grammatical codes for Levin classes.</S>
			<S sid ="163" ssid = "5">This work was partly supported by UK EPSRCproject GR/N36462/93: &amp;apos;Robust Accurate Sta tistical Parsing (RASP)&amp;apos;.</S>
	</SECTION>
</PAPER>
