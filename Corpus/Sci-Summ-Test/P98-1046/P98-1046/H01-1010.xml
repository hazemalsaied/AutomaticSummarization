<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">None</S>
	</ABSTRACT>
	<SECTION title="INTRODUCTION" number = "1">
			<S sid ="2" ssid = "2">One of the primary tasks of Information Extraction is recognizing all of the different guises in which a particular type of event can appear.</S>
			<S sid ="3" ssid = "3">For instance, a meeting between two dignitaries can be referred to as A meets B or A and B meet, or a meeting between A and B took place/was held/opened/convened/finished/dragged on or A had/presided over a meeting/conference with B There are several different lexical items that can be used to refer to the same type of event, and several different predicate argument patterns that can be used to specify the participants.</S>
			<S sid ="4" ssid = "4">Correctly identifying the type of the event and the roles of the participants is a critical factor in accurate information extraction.</S>
			<S sid ="5" ssid = "5">In this paper we refer to the specific subtask of participant role identification as predicate argument tagging.</S>
			<S sid ="6" ssid = "6">The type of syntactic and semantic information associated with verbs in Levin’s Preliminary Classification of English verbs, [Levin,93] can be a useful resource for an automatic predicate argument tagging system.</S>
			<S sid ="7" ssid = "7">For instance, the ’meet’ class includes the following members, meet, consult, debate and visit, which can all be used to refer to the meeting event type described above.</S>
			<S sid ="8" ssid = "8">In addition, the following types of syntactic frames are associated with these verbs: A met/visited/debated/consulted B A met/visited/debated/consulted with B. A and B met/visited/debated/consulted (with each other).</S>
			<S sid ="9" ssid = "9">This type of frame information can be specified at the class level, but there is always a certain amount of verb-specific information that must still be associated with the individual lexical items, such as sense distinctions.</S>
			<S sid ="10" ssid = "10">For the purposes of this paper we will only be considering sense distinctions based on different predicate argument structures.</S>
			<S sid ="11" ssid = "11">We begin by giving more information about the Levin classes and then describe the system that automatically labels the arguments in a predicate argument structure.</S>
			<S sid ="12" ssid = "12">We end by giving the results of evaluating this system versus human annotators performing the same task.</S>
			<S sid ="13" ssid = "13">Our input to the tagger is the Penn TreeBank [Marcus, 94], so the sentences already have accurate syntactic parses associated with them.</S>
	</SECTION>
	<SECTION title="LEXICON GUIDELINES. " number = "2">
			<S sid ="14" ssid = "1">As mentioned above, Levin classes provide the theoretical underpinnings for many of our choices for basic predicate-argument structures [Levin, 93].</S>
			<S sid ="15" ssid = "2">Levin verb classes are based on the ability of a verb to occur or not occur in pairs of syntactic frames that are in some sense meaning preserving (diathesis alternations).</S>
			<S sid ="16" ssid = "3">The distribution of syntactic frames in which a verb can appear determines its class membership.</S>
			<S sid ="17" ssid = "4">The sets of syntactic frames associated with a particular Levin class are not intended to be arbitrary, and they are supposed to reflect underlying semantic components that constrain allowable arguments.</S>
			<S sid ="18" ssid = "5">For example, break verbs and cut verbs are similar in that they can all occur as transitives and in the middle construction, John broke the window, Glass breaks easily, John cut the bread, This loaf cuts easily.</S>
			<S sid ="19" ssid = "6">However, only break verbs can also occur in the simple intransitive, The window broke, *The bread cut.</S>
			<S sid ="20" ssid = "7">Notice that for all of these verbs, the subject of the intransitive, The window broke, plays the same role as the object of the transitive, John broke the window.</S>
			<S sid ="21" ssid = "8">Our goal is to capture this by using consistent argument labels, in this case Arg1 for the window in both sentences.</S>
			<S sid ="22" ssid = "9">So, for example, shake and rock would get the following annotation: The earthquake shook the building.</S>
			<S sid ="23" ssid = "10">Arg0 REL Arg1 The walls shook; Arg1 REL the building rocked.</S>
			<S sid ="24" ssid = "11">Arg1 REL VerbNet In a related project funded by NSF, NSFIIS98-00658, we are currently constructing a lexicon, VerbNet, that is intended to overcome some of the limitations of WordNet, an online lexical database of English, [Miller, 90], by addressing specifically the needs of natural language processing applications.</S>
			<S sid ="25" ssid = "12">This lexicon exploits the systematic link between syntax and semantics that motivates the Levin classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes, [Dang, et al, 98, 00, Kipper, et al. 00].</S>
			<S sid ="26" ssid = "13">Specific sets of syntactic configurations and appropriate selectional restrictions on arguments are associated with individual senses.</S>
			<S sid ="27" ssid = "14">This lexicon gives us a first approximation of sense distinctions that are reflected in varying predicate argument structures.</S>
			<S sid ="28" ssid = "15">As such these entries provide a suitable foundation for directing consistent predicate-argument labeling of training data.</S>
			<S sid ="29" ssid = "16">The senses in VerbNet are in turn linked to one or more WordNet senses.</S>
			<S sid ="30" ssid = "17">Since our focus is predicate-argument structure, we can rely on rigorous and objective sense distinction criteria based on syntax.</S>
			<S sid ="31" ssid = "18">Purely semantic distinctions, such as those made in WordNet, are subjective and potentially unlimited.</S>
			<S sid ="32" ssid = "19">Our senses are therefore much more coarse-grained than WordNet, since WordNet senses are purely semantically motivated and often cannot be distinguished syntactically.</S>
			<S sid ="33" ssid = "20">However, some senses that share syntactic properties can still be distinguished clearly by virtue of different selectional restrictions, which we will also be exploring in the NSF project.</S>
	</SECTION>
	<SECTION title="AUTOMATIC EXTRACTION OF. " number = "3">
			<S sid ="34" ssid = "1">PREDICATE-ARGUMENT RELATIONS FROM PARSED CORPORA The predicate-argument analysis of a parse tree from a corpus such as the Treebank corpus is performed in three main phases.</S>
			<S sid ="35" ssid = "2">First, root forms of inflected words are identified using a morphological analyzer derived from the WordNet stemmer and from inflectional information in machine-readable dictionaries such as the Project Gutenberg version of Webster.</S>
			<S sid ="36" ssid = "3">Also in this phase, phrasal items such as verb-particle constructions, idioms and compound nominals are identified.</S>
			<S sid ="37" ssid = "4">An efficient matching algorithm is used which is capable of recognizing both continuous and discontinuous phrases, and phrases where the order of words is not fixed.</S>
			<S sid ="38" ssid = "5">The matching algorithm makes use of hierarchical declarative constraints on the possible realizations of phrases in the lexicon, and can exploit syntactic contextual cues if a syntactic analysis of the input, such as the parse tree structure of the Treebank, is present.</S>
			<S sid ="39" ssid = "6">In the next phase, the explicit antecedents of empty constituents are read off from the Treebank annotation, and gaps are filled where implicit linkages have been left unmarked.</S>
			<S sid ="40" ssid = "7">This is done by heuristic examination of the local syntactic context of traces and relative clause heads.</S>
			<S sid ="41" ssid = "8">If no explicit markings are present (for automatically generated parses or old-style Treebank parses), they are inferred.</S>
			<S sid ="42" ssid = "9">Estimated accuracy of this phase of the algorithm is upwards of 90 percent.</S>
			<S sid ="43" ssid = "10">Finally, an efficient tree-template pattern matcher is run on the Treebank parse trees, to identify syntactic relations that signal a predicate- argument relationship between lexical items.</S>
			<S sid ="44" ssid = "11">The patterns used are fragmentary tree templates similar to the elementary and auxiliary trees of a Tree Adjoining Grammar [XTAG, 95].</S>
			<S sid ="45" ssid = "12">Each template typically corresponds to a predication over one or more arguments.</S>
			<S sid ="46" ssid = "13">There are approximately 200 templates for: transitive, intransitive and ditransitive verbs operating on their subjects, objects and indirect objects; prenominal and predicate adjectives, operating on the nouns they modify; subordinating conjunctions operating on the two clauses that they link; prepositions; determiners; and so on.</S>
			<S sid ="47" ssid = "14">The templates are organized into a compact network in which shared substructures need to be listed only once, even when they are present in many templates.</S>
			<S sid ="48" ssid = "15">Templates are matched even if they are not contiguous in the tree, as long as the intervening material is well-formed.</S>
			<S sid ="49" ssid = "16">This allows a transitive template for example to match a sentence where there is an intervening auxiliary verb between the subject and the main transitive verb, as in He was dropping it.</S>
			<S sid ="50" ssid = "17">The mechanism for handling such cases resembles the adjunction mechanism in Tree Adjoining Grammar.</S>
			<S sid ="51" ssid = "18">Tree grammar template for progressive auxiliary verb, licensing discontinuity in main verb tree When a template has been identified, it is instantiated with the lexical items that occur in its predicate and argument positions.</S>
			<S sid ="52" ssid = "19">Each template is associated with one or more annotated template sets, by means of which it is linked to a bundle of thematic or semantic features, and to a class of lexical items that license the template’s occurrence with those features.</S>
			<S sid ="53" ssid = "20">For instance, if the template is an intransitive verb tree, it will be associated both with an unergative feature bundle, indicating that its subject should have the label Arg0, and also with an unaccusative bundle where the subject is marked as Arg1.</S>
			<S sid ="54" ssid = "21">Which of the feature bundles gets used depends on the semantic class of the word that Recognition of progressive auxiliary tree which modifies and splits transitive-verb tree for drop in Treebank corpus appears in the predicate position of the template.</S>
			<S sid ="55" ssid = "22">If the predicate is a causative verb that takes the unaccusative alternation, the subject will be assigned the Arg1 label.</S>
			<S sid ="56" ssid = "23">If however it is a verb of creation, for example, the subject will be an Arg0.</S>
			<S sid ="57" ssid = "24">The verb semantics that inform the predicate-argument extractor are theoretically motivated by the Levin classes [Levin, 93], but the actual lexical information it uses is not derived from Levin’s work.</S>
			<S sid ="58" ssid = "25">Rather, it draws on information available in the WordNet 1.6 database [Miller, 90] and on frame codes are derived from the annotation scheme used in the Susanne corpus [Sampson, 95].</S>
			<S sid ="59" ssid = "26">For example, one entry for the verb develop specifies its WordNet synset membership, and indicates its participation in the unaccusative alternation with the code o_can_become_s develop SF:so_N_N+W:svJ3W_W:svIM2+o_can_become_s The prefix SF: signifies that this is a frame code derived from the Susanne corpus.</S>
			<S sid ="60" ssid = "27">Each frame code picks out a lexical class of the words that take it, and the frame codes are organized into an inheritance network as well.</S>
			<S sid ="61" ssid = "28">The frame codes in turn are linked to annotated template sets, which describe how these frames can actually appear in the syntactic bracketing format of the TreeBank.</S>
			<S sid ="62" ssid = "29">In the case of the above frame code for an alternating transitive verb, two template sets are linked: TG:V_so_N_N for the frame with a subject and an object (here notated with s and o); and TG:V_s_N+causative, for the unaccusative frame.</S>
			<S sid ="63" ssid = "30">Each of the template sets lists tree-grammar templates for all the variations of syntactic structure that its corresponding frame may take on.</S>
			<S sid ="64" ssid = "31">A template for the canonical structure of a simple declarative sentence involving that frame will be present in the set, but additional templates will be added for the forms the frame takes in relative clauses, questions, or passive constructions.</S>
			<S sid ="65" ssid = "32">The features for each set are listed separately from the templates, with indications of where they should be interpreted within the various template structures.</S>
			<S sid ="66" ssid = "33">Hence the template set TG:V_s_N+causative includes the feature TGC:subject+print_as=TGPL:arg1 as part of its feature bundle.</S>
			<S sid ="67" ssid = "34">This serves to associate the label Arg1 with the subject node in each template in the set.</S>
			<S sid ="68" ssid = "35">When the predicate-argument extractor is able to instantiate such a template, thereby connecting its subject node with a piece of a TreeBank tree, it knows to print that piece of the tree as Arg1 of the predicate for that template.</S>
			<S sid ="69" ssid = "36">If another annotated feature set were active instead, for instance in a case where the predicate of the template does not belong to a verb class which licenses the unaccusative frame code and its associated annotated template set (TG:V_s_N+causative), the label of the subject might be different.</S>
	</SECTION>
	<SECTION title="EVALUATION. " number = "4">
			<S sid ="70" ssid = "1">The current implementation of the tagger assigns predicate argument structures to all of the 6500 verbs that occur in the Penn Treebank.</S>
			<S sid ="71" ssid = "2">However, our evaluation of its accuracy is not yet so comprehensive.</S>
			<S sid ="72" ssid = "3">Our first preliminary evaluation of the performance of the tagger was based on a 5000 word section of the Penn TreeBank.</S>
			<S sid ="73" ssid = "4">The tagger was run on this, and the argument labeling was subsequently hand corrected by a linguistics graduate student, giving an accuracy rate of 81% out of 160 predicate argument structures.</S>
			<S sid ="74" ssid = "5">We have since automatically tagged and hand corrected an additional 660 predicate argument structures, with an accuracy rate of 86%, (556 structures), giving us a combined accuracy rate of 83.7%.</S>
			<S sid ="75" ssid = "6">There are over 100 verbs involved in the evaluation.</S>
			<S sid ="76" ssid = "7">The number of possible frames for the verbs in the second test ranges from 13 frames to 30, with the typical number being in the teens.</S>
			<S sid ="77" ssid = "8">Not all of these frames actually appear in the TreeBank data.</S>
			<S sid ="78" ssid = "9">These results compare favorably with the results reported by Gildea and Jurafsky of 80.7% on their development set, (76.9% on the test set.)</S>
			<S sid ="79" ssid = "10">Their data comes from the Framenet project, [Lowe, et al., 97], which has been in existence for several years, and consisted of over 900 verbs out of 1500 words and almost 50,000 sentences.</S>
			<S sid ="80" ssid = "11">The Framenet project also uses more fine-grained semantic role labels, although it should be possible to map from our Arg0, Arg1 labels to their labels.</S>
			<S sid ="81" ssid = "12">They used machine learning techniques applied to human annotated data, whereas our tagger does not currently use statistics at all, and is primarily rule- based.</S>
			<S sid ="82" ssid = "13">Once we have sufficient amounts of data annotated we plan to experiment with hybrid approaches.</S>
	</SECTION>
	<SECTION title="ACKNOWLEDGEMENTS. " number = "5">
			<S sid ="83" ssid = "1">We would like to thank Paul Kingsbury and Chris Walker for their annotation efforts, and Aravind Joshi, Mitch Marcus, Hoa Dang and Christiane Fellbaum for their comments on predicate-argument tagging as a task.</S>
			<S sid ="84" ssid = "2">This work has been funded by DARPA N6600100-18915 and NSF 9800658.</S>
	</SECTION>
	<SECTION title="REFERENCES. " number = "6">
</PAPER>
