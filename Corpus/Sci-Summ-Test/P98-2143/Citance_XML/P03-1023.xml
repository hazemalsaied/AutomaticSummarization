<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In this paper we propose a competition learning approach to coreference resolution.</S>
		<S sid ="2" ssid = "2">Traditionally, supervised machine learning approaches adopt the single- candidate model.</S>
		<S sid ="3" ssid = "3">Nevertheless the preference relationship between the antecedent candidates cannot be determined accurately in this model.</S>
		<S sid ="4" ssid = "4">By contrast, our approach adopts a twin-candidate learning model.</S>
		<S sid ="5" ssid = "5">Such a model can present the competition criterion for antecedent candidates reliably, and ensure that the most preferred candidate is selected.</S>
		<S sid ="6" ssid = "6">Furthermore, our approach applies a candidate filter to reduce the computational cost and data noises during training and resolution.</S>
		<S sid ="7" ssid = "7">The experimental results on MUC6 and MUC7 data set show that our approach can outperform those based on the single- candidate model.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="8" ssid = "8">Coreference resolution is the process of linking together multiple expressions of a given entity.</S>
			<S sid ="9" ssid = "9">The key to solve this problem is to determine the antecedent for each referring expression in a document.</S>
			<S sid ="10" ssid = "10">In coreference resolution, it is common that two or more candidates compete to be the antecedent of an anaphor (Mitkov, 1999).</S>
			<S sid ="11" ssid = "11">Whether a candidate is coreferential to an anaphor is often determined by the competition among all the candidates.</S>
			<S sid ="12" ssid = "12">So far, various algorithms have been proposed to determine the preference relationship between two candidates.</S>
			<S sid ="13" ssid = "13">Mitkov’s knowledge-poor pronoun resolution method (Mitkov, 1998), for example, uses the scores from a set of antecedent indicators to rank the candidates.</S>
			<S sid ="14" ssid = "14">And centering algorithms (Brennan et al., 1987; Strube, 1998; Tetreault, 2001), sort the antecedent candidates based on the ranking of the forward-looking or backward- looking centers.</S>
			<S sid ="15" ssid = "15">In recent years, supervised machine learning approaches have been widely used in coreference resolution (Aone and Bennett, 1995; McCarthy, 1996; Soon et al., 2001; Ng and Cardie, 2002a), and have achieved significant success.</S>
			<S sid ="16" ssid = "16">Normally, these approaches adopt a single-candidate model in which the classifier judges whether an antecedent candidate is coreferential to an anaphor with a confidence value.</S>
			<S sid ="17" ssid = "17">The confidence values are generally used as the competition criterion for the antecedent candidates.</S>
			<S sid ="18" ssid = "18">For example, the “Best-First” selection algorithms (Aone and Bennett, 1995; Ng and Cardie, 2002a) link the anaphor to the candidate with the maximal confidence value (above 0.5).</S>
			<S sid ="19" ssid = "19">One problem of the single-candidate model, however, is that it only takes into account the relationships between an anaphor and one individual candidate at a time, and overlooks the preference relationship between candidates.</S>
			<S sid ="20" ssid = "20">Consequently, the confidence values cannot accurately represent the true competition criterion for the candidates.</S>
			<S sid ="21" ssid = "21">In this paper, we present a competition learning approach to coreference resolution.</S>
			<S sid ="22" ssid = "22">Motivated by the research work by Connolly et al.</S>
			<S sid ="23" ssid = "23">(1997), our approach adopts a twin-candidate model to directly learn the competition criterion for the antecedent candidates.</S>
			<S sid ="24" ssid = "24">In such a model, a classifier is trained based on the instances formed by an anaphor and a pair of its antecedent candidates.</S>
			<S sid ="25" ssid = "25">The classifier is then used to determine the preference between any two candidates of an anaphor encountered in a new document.</S>
			<S sid ="26" ssid = "26">The candidate that wins the most comparisons is selected as the antecedent.</S>
			<S sid ="27" ssid = "27">In order to reduce the computational cost and data noises, our approach also employs a candidate filter to eliminate the invalid or irrelevant candidates.</S>
			<S sid ="28" ssid = "28">The layout of this paper is as follows.</S>
			<S sid ="29" ssid = "29">Section 2 briefly describes the single-candidate model and analyzes its limitation.</S>
			<S sid ="30" ssid = "30">Section 3 proposes in details the twin-candidate model and Section 4 presents our coreference resolution approach based on this model.</S>
			<S sid ="31" ssid = "31">Section 5 reports and discusses the experimental results.</S>
			<S sid ="32" ssid = "32">Section 6 describes related research work.</S>
			<S sid ="33" ssid = "33">Finally, conclusion is given in Section 7.</S>
	</SECTION>
	<SECTION title="The Single-Candidate Model. " number = "2">
			<S sid ="34" ssid = "1">The main idea of the single-candidate model for coreference resolution is to recast the resolution as a binary classification problem.</S>
			<S sid ="35" ssid = "2">During training, a set of training instances is generated for each anaphor in an annotated text.</S>
			<S sid ="36" ssid = "3">An instance is formed by the anaphor and one of its antecedent candidates.</S>
			<S sid ="37" ssid = "4">It is labeled as positive or negative based on whether or not the candidate is tagged in the same coreferential chain of the anaphor.</S>
			<S sid ="38" ssid = "5">After training, a classifier is ready to resolve the distribution 2 , but not the conditional probability when the candidate is concurrent with other competitors.</S>
			<S sid ="39" ssid = "6">Consequently, the confidence values are unreliable to represent the true competition criterion for the candidates.</S>
			<S sid ="40" ssid = "7">To illustrate this problem, just suppose a data set where an instance could be described with four exclusive features: F1, F2, F3 and F4.</S>
			<S sid ="41" ssid = "8">The ranking of candidates obeys the following rule: CSF1 &gt;&gt; CSF2 &gt;&gt; CSF3 &gt;&gt; CSF4Here CSFi (1 ≤ i ≤ 4 ) is the set of antecedent can didates with the feature Fi on.</S>
			<S sid ="42" ssid = "9">The mark of “&gt;&gt;” denotes the preference relationship, that is, the candidates in CSF1 is preferred to those in CSF2, and to those in CSF3 and CSF4.</S>
			<S sid ="43" ssid = "10">Let CF2 and CF3 denote the class value of a leaf node “F2 = 1” and “F3 = 1”, respectively.</S>
			<S sid ="44" ssid = "11">It is pos sible that CF2 &lt; CF3, if the anaphors whose candidates all belong to CSF3 or CSF4 take the majority in the training data set.</S>
			<S sid ="45" ssid = "12">In this case, a candidate in CSF3 would be assigned a larger confidence value than a candidate in CSF2.</S>
			<S sid ="46" ssid = "13">This nevertheless contradicts the ranking rules.</S>
			<S sid ="47" ssid = "14">If during resolution, the candidates of an anaphor all come from CSF2 orCSF3, the anaphor may be wrongly linked to a can NPs1 encountered in a new document.</S>
			<S sid ="48" ssid = "15">For each NP under consideration, every one of its antecedent didate in CSF3 rather than in CS F2.</S>
			<S sid ="49" ssid = "16">candidates is paired with it to form a test instance.</S>
			<S sid ="50" ssid = "17">The classifier returns a number between 0 and 1 that indicates the likelihood that the candidate is coreferential to the NP.</S>
			<S sid ="51" ssid = "18">The returned confidence value is commonly used as the competition criterion to rank the candidate.</S>
			<S sid ="52" ssid = "19">Normally, the candidates with confidences less than a selection threshold (e.g. 0.5) are discarded.</S>
			<S sid ="53" ssid = "20">Then some algorithms are applied to choose one of the remaining candidates, if any, as the antecedent.</S>
			<S sid ="54" ssid = "21">For example, “Closest-First” (Soon et al., 2001) selects the candidate closest to the anaphor, while “Best-First” (Aone and Bennett, 1995; Ng and Cardie, 2002a) selects the candidate with the maximal confidence value.</S>
			<S sid ="55" ssid = "22">One limitation of this model, however, is that it only considers the relationships between a NP encountered and one of its candidates at a time during its training and testing procedures.</S>
			<S sid ="56" ssid = "23">The confidence value reflects the probability that the candidate is coreferential to the NP in the overall 1 In this paper a NP corresponds to a Markable in MUC.</S>
			<S sid ="57" ssid = "24">coreference resolution tasks.</S>
	</SECTION>
	<SECTION title="The Twin-Candidate Model. " number = "3">
			<S sid ="58" ssid = "1">Different from the single-candidate model, the twin-candidate model aims to learn the competition criterion for candidates.</S>
			<S sid ="59" ssid = "2">In this section, we will introduce the structure of the model in details.</S>
			<S sid ="60" ssid = "3">3.1 Training Instances Creation.</S>
			<S sid ="61" ssid = "4">Consider an anaphor ana and its candidate set candidate_set, {C1, C2, …, Ck}, where Cj is closer to ana than Ci if j &gt; i. Suppose positive_set is the set of candidates that occur in the coreferential chain of ana, and negative_set is the set of candidates not in the chain, that is, negative_set = candidate_setpositive_set.</S>
			<S sid ="62" ssid = "5">The set of training instances based on ana, inst_set, is defined as follows: 2 Suppose we use C4.5 algorithm and the class value takes the.</S>
			<S sid ="63" ssid = "6">smoothed ration, p + 1 , where p is the number of positive t + 2 instances and t is the total number of instances contained in the corresponding leaf node.</S>
			<S sid ="64" ssid = "7">inst _ set = {inst(Ci, Cj, ana) | i &gt; j, Ci ∈ positve_ set, Cj ∈negative_ set} U {inst(Ci, Cj, ana) | i &gt; j, Ci ∈negative_ set , Cj ∈ positve_ set} From the above definition, an instance is formed by an anaphor, one positive candidate and one negative candidate.</S>
			<S sid ="65" ssid = "8">For each instance, inst ( ci, cj, ana ) , the candidate at the first position, Ci, is closer to the anaphor than the candidate at the second position, Cj.</S>
			<S sid ="66" ssid = "9">3.3 Classifier Generation.</S>
			<S sid ="67" ssid = "10">Based on the feature vectors generated for each anaphor encountered in the training data set, a classifier can be trained using a certain machine learning algorithm, such as C4.5, RIPPER, etc. Given the feature vector of a test instance inst ( ci, cj, ana ) (i &gt; j), the classifier returns the positive class indicating that Ci is preferred to Cj as the antecedent of ana; or negative indicating that Cj is preferred.</S>
			<S sid ="68" ssid = "11">A training instance inst ( ci, cj, ana ) is labeled as positive if Ci ∈ positive-set and Cj ∈ negative-set;or negative if Ci ∈ negative-set and Cj ∈ positive set.</S>
			<S sid ="69" ssid = "12">See the following example: Any design to link China&apos;s accession to the WTO with the missile tests1 was doomed to failure.“If some countries2 try to block China TO acces sion, that will not be popular and will fail to win the support of other countries3” she said.</S>
			<S sid ="70" ssid = "13">Although no governments4 have suggested formal sanctions5 on China over the missile tests6, the United States has called them7 “provocative and reckless” and other countries said they could threaten Asian stability.</S>
			<S sid ="71" ssid = "14">In the above text segment, the antecedent candidate set of the pronoun “them7” consists of six candidates highlighted in Italics.</S>
			<S sid ="72" ssid = "15">Among the candidates, Candidate 1 and 6 are in the coreferential chain of “them7”, while Candidate 2, 3, 4, 5 are not.</S>
			<S sid ="73" ssid = "16">Thus, eight instances are formed for “them7”: (2,1,7) (3,1,7) (4,1,7) (5,1,7) 3.4 Antecedent Identification.</S>
			<S sid ="74" ssid = "17">Let CR( inst ( ci, cj, ana ) ) denote the classification result for an instance inst ( ci, cj, ana ) . The antecedent of an anaphor is identified using the algorithm shown in Figure 1.</S>
			<S sid ="75" ssid = "18">Algorithm ANTE-SEL Input: ana: the anaphor under consideration candidate_set: the set of antecedent candidates of ana, {C1, C2,…,Ck} for i = 1 to K do Score[ i ] = 0; for i = K downto 2 do for j = i – 1 downto 1 do if CR( inst ( ci, cj, ana ) ) = = positive then Score[ i ]++; else Score[ j ] ++; endif SelectedIdx= arg max Score[i] Ci∈ _ set i candidate (6,5,7) (6,4,7) (6,3,7) (6,2,7) Here the instances in the first line are negative, while those in the second line are all positive.</S>
			<S sid ="76" ssid = "19">3.2 Features Definition.</S>
			<S sid ="77" ssid = "20">A feature vector is specified for each training or testing instance.</S>
			<S sid ="78" ssid = "21">Similar to those in the single- candidate model, the features may describe the lexical, syntactic, semantic and positional relationships of an anaphor and any one of its candidates.</S>
			<S sid ="79" ssid = "22">Besides, the feature set may also contain inter- candidate features characterizing the relationships between the pair of candidates, e.g. the distance between the candidates in the number distances or paragraphs.</S>
			<S sid ="80" ssid = "23">return CselectedIdx; Figure 1:The antecedent identification algorithm Algorithm ANTE-SEL takes as input an anaphor and its candidate set candidate_set, and returns one candidate as its antecedent.</S>
			<S sid ="81" ssid = "24">In the algorithm, each candidate is compared against any other candidate.</S>
			<S sid ="82" ssid = "25">The classifier acts as a judge during each comparison.</S>
			<S sid ="83" ssid = "26">The score of each candidate increases by one every time when it wins.</S>
			<S sid ="84" ssid = "27">In this way, the final score of a candidate records the total times it wins.</S>
			<S sid ="85" ssid = "28">The candidate with the maximal score is singled out as the antecedent.</S>
			<S sid ="86" ssid = "29">If two or more candidates have the same maximal score, the one closest to the anaphor would be selected.</S>
			<S sid ="87" ssid = "30">3.5 Single-Candidate Model: A Special Case.</S>
			<S sid ="88" ssid = "31">of Twin-Candidate Model?</S>
			<S sid ="89" ssid = "32">While the realization and the structure of the twin- candidate model are significantly different from the single-candidate model, the single-candidate model in fact can be regarded as a special case of the twin-candidate model.</S>
			<S sid ="90" ssid = "33">To illustrate this, just consider a virtual “blank” candidate C0 such that we could convert an instance inst ( ci, ana ) in the single-candidate model to rithm to choose the antecedent and then link the NP to it.</S>
			<SUBSECTION>4.1 Preprocessing To determine the boundary of the noun phrases, a pipeline of Nature Language Processing components are applied to an input raw text: z Tokenization and sentence segmentation z Named entity recognition z Part-of-speech tagging an instance inst ( ci, c0 , ana )in the twin candidate z Noun phrase chunking Among them, named entity recognition, part-of model.</SUBSECTION>
			<S sid ="91" ssid = "34">Let inst ( ci, c0 , ana ) have the same class label as inst ( ci, ana ) , that is, inst ( ci, c0 , ana ) is positive if Ci is the antecedent of ana; or negative if not.Apparently, the classifier trained on the in stance set { inst ( ci, ana ) }, T1, is equivalent to that trained on { inst ( ci, c0 , ana ) }, T2.</S>
			<S sid ="92" ssid = "35">T1 and T2 would assign the same class label for the test instances speech tagging and text chunking apply the same Hidden Markov Model (HMM) based engine with error-driven learning capability (Zhou and Su, 2000 &amp; 2002).</S>
			<S sid ="93" ssid = "36">The named entity recognition component recognizes various types of MUC-style named entities, i.e., organization, location, person, date, time, money and percentage.</S>
			<S sid ="94" ssid = "37">inst ( ci, ana ) and inst ( ci, c0 , ana ) , respectivel y. That is to say, determining whether Ci is coreferential to ana by T1 in the single-candidate model equals to determining whether Ci is better than C0 w.r.t ana by T2 in the twin-candidate model.</S>
			<S sid ="95" ssid = "38">Here we could take C0 as a “standard candidate”.</S>
			<S sid ="96" ssid = "39">While the classification in the single-candidate model can find its interpretation in the twin- candidate model, it is not true vice versa.</S>
			<S sid ="97" ssid = "40">Consequently, we can safely draw the conclusion that the twin-candidate model is more powerful than the single-candidate model in characterizing the relationships among an anaphor and its candidates.</S>
	</SECTION>
	<SECTION title="The Competition Learning Approach. " number = "4">
			<S sid ="98" ssid = "1">Our competition learning approach adopts the twin-candidate model introduced in the Section 3.</S>
			<S sid ="99" ssid = "2">The main process of the approach is as follows: 1.</S>
			<S sid ="100" ssid = "3">The raw input documents are preprocessed to.</S>
			<S sid ="101" ssid = "4">obtain most, if not all, of the possible NPs.</S>
			<S sid ="102" ssid = "5">2.</S>
			<S sid ="103" ssid = "6">During training, for each anaphoric NP, we.</S>
			<S sid ="104" ssid = "7">create a set of candidates, and then generate the training instances as described in Section 3.</S>
			<S sid ="105" ssid = "8">3. Based on the training instances, we make use.</S>
			<S sid ="106" ssid = "9">of the C5.0 learning algorithm (Quinlan, 1993) to train a classifier.</S>
			<S sid ="107" ssid = "10">4.</S>
			<S sid ="108" ssid = "11">During resolution, for each NP encountered,.</S>
			<S sid ="109" ssid = "12">we also construct a candidate set.</S>
			<S sid ="110" ssid = "13">If the set is empty, we left this NP unresolved; otherwise we apply the antecedent identification algo 4.2 Features.</S>
			<S sid ="111" ssid = "14">Selection For our study, in this paper we only select those features that can be obtained with low annotation cost and high reliability.</S>
			<S sid ="112" ssid = "15">All features are listed in Table 1 together with their respective possible values.</S>
			<S sid ="113" ssid = "16">4.3 Candidates.</S>
			<S sid ="114" ssid = "17">Filtering For a NP under consideration, all of its preceding NPs could be the antecedent candidates.</S>
			<S sid ="115" ssid = "18">Nevertheless, since in the twin-candidate model the number of instances for a given anaphor is about the square of the number of its antecedent candidates, the computational cost would be prohibitively large if we include all the NPs in the candidate set.</S>
			<S sid ="116" ssid = "19">Moreover, many of the preceding NPs are irrelevant or even invalid with regard to the anaphor.</S>
			<S sid ="117" ssid = "20">These data noises may hamper the training of a good- performanced classifier, and also damage the accuracy of the antecedent selection: too many comparisons are made between incorrect candidates.</S>
			<S sid ="118" ssid = "21">Therefore, in order to reduce the computational cost and data noises, an effective candidate filtering strategy must be applied in our approach.</S>
			<S sid ="119" ssid = "22">During training, we create the candidate set for each anaphor with the following filtering algorithm: 1.</S>
			<S sid ="120" ssid = "23">If the anaphor is a. pronoun, (a) Add to the initial candidate set all the preceding NPs in the current and the previous two sentences.</S>
			<S sid ="121" ssid = "24">Features describing the candidate: 1.</S>
			<S sid ="122" ssid = "25">ante_DefNp_1(2) 2.</S>
			<S sid ="123" ssid = "26">ante_IndefNP_1(2) 3.</S>
			<S sid ="124" ssid = "27">ante_Pron_1(2) 4.</S>
			<S sid ="125" ssid = "28">ante_ProperNP_1(2) 5.</S>
			<S sid ="126" ssid = "29">ante_M_ProperNP_1(2) 6.</S>
			<S sid ="127" ssid = "30">ante_ProperNP_APPOS_1(2) 7.</S>
			<S sid ="128" ssid = "31">ante_Appositive_1(2) 8.</S>
			<S sid ="129" ssid = "32">ante_NearestNP_1(2) 9.</S>
			<S sid ="130" ssid = "33">ante_Embeded_1(2) 1 if Ci (Cj) is a definite NP; else 0 1 if Ci (Cj) is an indefinite NP; else 0 1 if Ci (Cj) is a pronoun; else 0 1 if Ci (Cj) is a proper NP; else 0 1 if Ci (Cj) is a mentioned proper NP; else 0 1 if Ci (Cj) is a proper NP modified by an appositive; else 0 1 if Ci (Cj) is in a apposition structure; else 0 1 if Ci (Cj) is the nearest candidate to the anaphor; else 0 1 if Ci (Cj) is in an embedded NP; else 0 10 ante_Title_1(2) 1 if Ci (Cj) is in a title; else 0 Features describing the anaphor: 11.</S>
			<S sid ="131" ssid = "34">12.</S>
			<S sid ="132" ssid = "35">13.</S>
			<S sid ="133" ssid = "36">14.</S>
			<S sid ="134" ssid = "37">15.</S>
			<S sid ="135" ssid = "38">16.</S>
			<S sid ="136" ssid = "39">ana_Def NP ana_Ind efNP ana_Pro n ana_Pro perNP ana_Pro nType ana_Flexibl ePron 1 if ana is a definite NP; else 0 1 if ana is an indefinite NP; else 0 1 if ana is a pronoun; else 0 1 if ana is a proper NP; else 0 1 i f a n a i s a t h i r d p e r s o n p r o n o u n ; 2 i f a s i n g l e n e u t e r p r o n o u n ; 3 i f a p l u r a l n e u t e r p r o n o u n ; 4 i f o t h e r t y p e s 1 if ana is a flexible pronoun; else 0 Features describing the candidate and the anaphor: 17.</S>
			<S sid ="137" ssid = "40">18.</S>
			<S sid ="138" ssid = "41">18.</S>
			<S sid ="139" ssid = "42">20.</S>
			<S sid ="140" ssid = "43">ante_ana_S tringMatch _1(2) ante_ana_G enderAgree _1(2) ante_ana_ NumAgree _1(2) ante_ana_ Appositive _1(2) 1 if Ci (Cj) and ana match in string; else 0 1 if Ci (Cj) and ana agree in gender; else 0 if disagree; 1 if unknown 1 if Ci (Cj ) and ana agr ee in nu mb er; 0 if dis agr ee; -1 if unkn ow n 1 if Ci (Cj) and ana are in an appositive structure; else 0 21.</S>
			<S sid ="141" ssid = "44">ante_ana_Alias_1(2) 1 if Ci (Cj) and ana are in an alias of the other; else 0 Features describing the two candidates 22.</S>
			<S sid ="142" ssid = "45">23.</S>
			<S sid ="143" ssid = "46">inter_SDist ance inter_Pdista nce Distance between Ci and Cj in sentences Distance between Ci and Cj in paragraphs Table 1: Feature set for coreference resolution (Feature 22, 23 and features involving Cj are not used in the single-candidate model) (b) Remove from the candidate set those that disagree in number, gender, and person.</S>
			<S sid ="144" ssid = "47">(c) If the candidate set is empty, add the NPs in an earlier sentence and go to 1(b).</S>
			<S sid ="145" ssid = "48">2.</S>
			<S sid ="146" ssid = "49">If the anaphor is a non-pronoun,.</S>
			<S sid ="147" ssid = "50">(a) Add all the non-pronominal antecedents to the initial candidate set.</S>
			<S sid ="148" ssid = "51">(b) For each candidate added in 2(a), add the non-pronouns in the current, the previous and the next sentences into the candidate set.</S>
			<S sid ="149" ssid = "52">During resolution, we filter the candidates for each encountered pronoun in the same way as during training.</S>
			<S sid ="150" ssid = "53">That is, we only consider the NPs in the current and the preceding 2 sentences.</S>
			<S sid ="151" ssid = "54">Such a context window is reasonable as the distance between a pronominal anaphor and its antecedent is generally short.</S>
			<S sid ="152" ssid = "55">In the MUC6 data set, for example, the immediate antecedents of 95% pronominal anaphors can be found within the above distance.</S>
			<S sid ="153" ssid = "56">Comparatively, candidate filtering for non- pronouns during resolution is complicated.</S>
			<S sid ="154" ssid = "57">A potential problem is that for each non-pronoun under consideration, the twin-candidate model always chooses a candidate as the antecedent, even though all of the candidates are “low-qualified”, that is, unlikely to be coreferential to the non-pronoun under consideration.</S>
			<S sid ="155" ssid = "58">In fact, the twin-candidate model in itself can identify the qualification of a candidate.</S>
			<S sid ="156" ssid = "59">We can compare every candidate with a virtual “standard candidate”, C0.</S>
			<S sid ="157" ssid = "60">Only those better than C0 are deemed qualified and allowed to enter the “round robin”, whereas the losers are eliminated.</S>
			<S sid ="158" ssid = "61">As we have discussed in Section 3.5, the classifier on the pairs of a candidate and C0 is just a single- candidate classifier.</S>
			<S sid ="159" ssid = "62">Thus, we can safely adopt the single-candidate classifier as our candidate filter.</S>
			<S sid ="160" ssid = "63">The candidate filtering algorithm during resolution is as follows: 1.</S>
			<S sid ="161" ssid = "64">If the current NP is a pronoun, construct the.</S>
			<S sid ="162" ssid = "65">candidate set in the same way as during training.</S>
			<S sid ="163" ssid = "66">2.</S>
			<S sid ="164" ssid = "67">If the current NP is a non-pronoun,.</S>
			<S sid ="165" ssid = "68">(a) Add all the preceding non-pronouns to the initial candidate set.(b) Calculate the confidence value for each candi date using the single-candidate classifier.</S>
			<S sid ="166" ssid = "69">(c) Remove the candidates with confidence value less than 0.5.</S>
	</SECTION>
	<SECTION title="Evaluation and Discussion. " number = "5">
			<S sid ="167" ssid = "1">Our coreference resolution approach is evaluated on the standard MUC6 (1995) and MUC7 (1998) data set.</S>
			<S sid ="168" ssid = "2">For MUC6, 30 “dry-run” documents annotated with coreference information could be used as training data.</S>
			<S sid ="169" ssid = "3">There are also 30 annotated training documents from MUC7.</S>
			<S sid ="170" ssid = "4">For testing, we utilize the 30 standard test documents from MUC6 and the 20 standard test documents from MUC7.</S>
			<S sid ="171" ssid = "5">5.1 Baseline Systems.</S>
			<S sid ="172" ssid = "6">In the experiment we compared our approach with the following research works: 1.</S>
			<S sid ="173" ssid = "7">Strube’s S-list algorithm for pronoun resolu-.</S>
			<S sid ="174" ssid = "8">tion (Stube, 1998).</S>
			<S sid ="175" ssid = "9">2.</S>
			<S sid ="176" ssid = "10">Ng and Cardie’s machine learning approach to.</S>
			<S sid ="177" ssid = "11">coreference resolution (Ng and Cardie, 2002a).</S>
			<S sid ="178" ssid = "12">3.</S>
			<S sid ="179" ssid = "13">Connolly et al.’s machine learning approach to.</S>
			<S sid ="180" ssid = "14">anaphora resolution (Connolly et al., 1997).</S>
			<S sid ="181" ssid = "15">Among them, S-List, a version of centering algorithm, uses well-defined heuristic rules to rank the antecedent candidates; Ng and Cardie’s approach employs the standard single-candidate model and “Best-First” rule to select the antece dent; Connolly et al.’s approach also adopts the twin-candidate model, but their approach lacks of candidate filtering strategy and uses greedy linear search to select the antecedent (See “Related work” for details).</S>
			<S sid ="182" ssid = "16">We constructed three baseline systems based on the above three approaches, respectively.</S>
			<S sid ="183" ssid = "17">For comparison, in the baseline system 2 and 3, we used the similar feature set as in our system (see table 1).</S>
			<S sid ="184" ssid = "18">5.2 Results and Discussion.</S>
			<S sid ="185" ssid = "19">Table 2 and 3 show the performance of different approaches in the pronoun and non-pronoun resolution, respectively.</S>
			<S sid ="186" ssid = "20">In these tables we focus on the abilities of different approaches in resolving an anaphor to its antecedent correctly.</S>
			<S sid ="187" ssid = "21">The recall measures the number of correctly resolved anaphors over the total anaphors in the MUC test data set, and the precision measures the number of correct anaphors over the total resolved anaphors.</S>
			<S sid ="188" ssid = "22">The F-measure F=2*RP/(R+P) is the harmonic mean of precision and recall.</S>
			<S sid ="189" ssid = "23">The experimental result demonstrates that our competition learning approach achieves a better performance than the baseline approaches in resolving pronominal anaphors.</S>
			<S sid ="190" ssid = "24">As shown in Table 2, our approach outperforms Ng and Cardie’s single- candidate based approach by 3.7 and 5.4 in F- measure for MUC6 and MUC7, respectively.</S>
			<S sid ="191" ssid = "25">Besides, compared with Strube’s S-list algorithm, our approach also achieves gains in the F-measure by 3.2 (MUC6), and 1.6 (MUC7).</S>
			<S sid ="192" ssid = "26">In particular, our approach obtains significant improvement (21.1 for MUC6, and 13.1 for MUC7) over Connolly et al.’s twin-candidate based approach.</S>
			<S sid ="193" ssid = "27">M U C 6 M U C 7 R P F R P F Str ub e (19 98) 76.</S>
			<S sid ="194" ssid = "28">1 74.3 75.1 62.</S>
			<S sid ="195" ssid = "29">9 60.3 61.6 Ng an d Ca rdi e (20 02 a) 75.</S>
			<S sid ="196" ssid = "30">4 73.8 74.6 58.</S>
			<S sid ="197" ssid = "31">9 56.8 57.8 Co nn oll y et al.</S>
			<S sid ="198" ssid = "32">(19 97) 57.</S>
			<S sid ="199" ssid = "33">2 57.2 57.2 50.</S>
			<S sid ="200" ssid = "34">1 50.1 50.1 Ou r ap pro ach 79.</S>
			<S sid ="201" ssid = "35">3 77.5 78.3 64.</S>
			<S sid ="202" ssid = "36">4 62.1 63.2 Table 2: Results for the pronoun resolution M U C 6 M U C 7 R P F R P F Ng an d Ca rdi e (20 02 a) 51.</S>
			<S sid ="203" ssid = "37">0 89.9 65.0 39 .1 86.4 53.8 Co nn oll y et al.</S>
			<S sid ="204" ssid = "38">(19 97) 52.</S>
			<S sid ="205" ssid = "39">2 52.2 52.2 43 .7 43.7 43.7 Ou r ap pro ach 51.</S>
			<S sid ="206" ssid = "40">3 90.4 65.4 39 .7 87.6 54.6 Table 3: Results for the non-pronoun resolution M U C 6 M U C 7 R P F R P F Ng an d Ca rdi e (20 02 a) 62.</S>
			<S sid ="207" ssid = "41">2 78.8 69.4 48.</S>
			<S sid ="208" ssid = "42">4 74.6 58.7 Ou r ap pro ach 64.</S>
			<S sid ="209" ssid = "43">0 80.5 71.3 50.</S>
			<S sid ="210" ssid = "44">1 75.4 60.2 Table 4: Results for the coreference resolution Compared with the gains in pronoun resolution, the improvement in non-pronoun resolution is slight.</S>
			<S sid ="211" ssid = "45">As shown in Table 3, our approach resolves non-pronominal anaphors with the recall of 51.3 (39.7) and the precision of 90.4 (87.6) for MUC6 (MUC7).</S>
			<S sid ="212" ssid = "46">In contrast to Ng and Cardie’s approach, the performance of our approach improves only 0.3 (0.6) in recall and 0.5 (1.2) in precision.</S>
			<S sid ="213" ssid = "47">The reason may be that in non-pronoun resolution, the coreference of an anaphor and its candidate is usually determined only by some strongly indicative features such as alias, apposition, string-matching, etc (this explains why we obtain a high precision but a low recall in non-pronoun resolution).</S>
			<S sid ="214" ssid = "48">Therefore, most of the positive candidates are coreferential to the anaphors even though they are not the “best”.</S>
			<S sid ="215" ssid = "49">As a result, we can only see comparatively slight difference between the performances of the two approaches.</S>
			<S sid ="216" ssid = "50">Although Connolly et al.’s approach also adopts the twin-candidate model, it achieves a poor performance for both pronoun resolution and non- pronoun resolution.</S>
			<S sid ="217" ssid = "51">The main reason is the absence of candidate filtering strategy in their approach (this is why the recall equals to the precision in the tables).</S>
			<S sid ="218" ssid = "52">Without candidate filtering, the recall may rise as the correct antecedents would not be eliminated wrongly.</S>
			<S sid ="219" ssid = "53">Nevertheless, the precision drops largely due to the numerous invalid NPs in the candidate set.</S>
			<S sid ="220" ssid = "54">As a result, a significantly low F- measure is obtained in their approach.</S>
			<S sid ="221" ssid = "55">Table 4 summarizes the overall performance of different approaches to coreference resolution.</S>
			<S sid ="222" ssid = "56">Different from Table 2 and 3, here we focus on whether a coreferential chain could be correctly identified.</S>
			<S sid ="223" ssid = "57">For this purpose, we obtain the recall, the precision and the F-measure using the standard MUC scoring program (Vilain et al. 1995) for the coreference resolution task.</S>
			<S sid ="224" ssid = "58">Here the recall means the correct resolved chains over the whole coreferential chains in the data set, and precision means the correct resolved chains over the whole resolved chains.</S>
			<S sid ="225" ssid = "59">In line with the previous experiments, we see reasonable improvement in the performance of the coreference resolution: compared with the baseline approach based on the single-candidate model, the F-measure of approach increases from 69.4 to 71.3 for MUC6, and from 58.7 to 60.2 for MUC7.</S>
	</SECTION>
	<SECTION title="Related  Work. " number = "6">
			<S sid ="226" ssid = "1">A similar twin-candidate model was adopted in the anaphoric resolution system by Connolly et al.</S>
			<S sid ="227" ssid = "2">(1997).</S>
			<S sid ="228" ssid = "3">The differences between our approach and theirs are: (1) In Connolly et al.’s approach, all the preceding NPs of an anaphor are taken as the antecedent candidates, whereas in our approach we use candidate filters to eliminate invalid or irrelevant candidates.</S>
			<S sid ="229" ssid = "4">(2) The antecedent identification in Connolly et al.’s approach is to apply the classifier to successive pairs of candidates, each time retaining the better candidate.</S>
			<S sid ="230" ssid = "5">However, due to the lack of strong assumption of transitivity, the selection procedure is in fact a greedy search.</S>
			<S sid ="231" ssid = "6">By contrast, our approach evaluates a candidate according to the times it wins over the other competitors.</S>
			<S sid ="232" ssid = "7">Comparatively this algorithm could lead to a better solution.</S>
			<S sid ="233" ssid = "8">(3) Our approach makes use of more indicative features, such as Appositive, Name Alias, String-matching, etc. These features are effective especially for non-pronoun resolution.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "7">
			<S sid ="234" ssid = "1">In this paper we have proposed a competition learning approach to coreference resolution.</S>
			<S sid ="235" ssid = "2">We started with the introduction of the single- candidate model adopted by most supervised machine learning approaches.</S>
			<S sid ="236" ssid = "3">We argued that the confidence values returned by the single-candidate classifier are not reliable to be used as ranking criterion for antecedent candidates.</S>
			<S sid ="237" ssid = "4">Alternatively, we presented a twin-candidate model that learns the competition criterion for antecedent candidates directly.</S>
			<S sid ="238" ssid = "5">We introduced how to adopt the twin- candidate model in our competition learning ap proach to resolve the coreference problem.</S>
			<S sid ="239" ssid = "6">Particularly, we proposed a candidate filtering algorithm that can effectively reduce the computational cost and data noises.</S>
			<S sid ="240" ssid = "7">The experimental results have proved the effectiveness of our approach.</S>
			<S sid ="241" ssid = "8">Compared with the baseline approach using the single-candidate model, the F-measure increases by 1.9 and 1.5 for MUC6 and MUC7 data set, respectively.</S>
			<S sid ="242" ssid = "9">The gains in the pronoun resolution contribute most to the overall improvement of coreference resolution.</S>
			<S sid ="243" ssid = "10">Currently, we employ the single-candidate classifier to filter the candidate set during resolution.</S>
			<S sid ="244" ssid = "11">While the filter guarantees the qualification of the candidates, it removes too many positive candidates, and thus the recall suffers.</S>
			<S sid ="245" ssid = "12">In our future Ruslan Mitkov.</S>
			<S sid ="246" ssid = "13">1998.</S>
			<S sid ="247" ssid = "14">Robust pronoun resolution with limited knowledge.</S>
			<S sid ="248" ssid = "15">In Proceedings of the 17th Int.</S>
			<S sid ="249" ssid = "16">Conference on Computational Linguistics (COLINGACL&apos;98), Page 869875.</S>
			<S sid ="250" ssid = "17">Ruslan Mitkov.</S>
			<S sid ="251" ssid = "18">1999.</S>
			<S sid ="252" ssid = "19">Anaphora resolution: The state of the art.</S>
			<S sid ="253" ssid = "20">Technical report.</S>
			<S sid ="254" ssid = "21">University of Wolverhamp- ton, Wolverhampton.</S>
			<S sid ="255" ssid = "22">MUC6.</S>
			<S sid ="256" ssid = "23">1995.</S>
			<S sid ="257" ssid = "24">Proceedings of the Sixth Message Understanding Conference (MUC6).</S>
			<S sid ="258" ssid = "25">Morgan Kaufmann, San Francisco, CA.</S>
			<S sid ="259" ssid = "26">MUC7.</S>
			<S sid ="260" ssid = "27">1998.</S>
			<S sid ="261" ssid = "28">Proceedings of the Seventh Message Understanding Conference (MUC7).</S>
			<S sid ="262" ssid = "29">Morgan Kaufmann, San Francisco, CA.</S>
			<S sid ="263" ssid = "30">Vincent Ng and Claire Cardie.</S>
			<S sid ="264" ssid = "31">2002a.</S>
			<S sid ="265" ssid = "32">Improving machine learning approaches to coreference resolution.</S>
			<S sid ="266" ssid = "33">rd work, we intend to adopt a looser filter together In Proceedings of the 40Annual Meeting of the As with an anaphoricity determination module (Bean and Riloff, 1999; Ng and Cardie, 2002b).</S>
			<S sid ="267" ssid = "34">Only if an encountered NP is determined as an anaphor, we will select an antecedent from the candidate set generated by the looser filter.</S>
			<S sid ="268" ssid = "35">Furthermore, we would like to incorporate more syntactic features into our feature set, such as grammatical role or syntactic parallelism.</S>
			<S sid ="269" ssid = "36">These features may be helpful to improve the performance of pronoun resolution.</S>
	</SECTION>
</PAPER>
