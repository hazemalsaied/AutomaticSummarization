<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Vieira and Poesio (2000) proposed an algorithm for definite description (D D) resolution that incorporates a number of heuristics for detecting discourse- new descriptions.</S>
		<S sid ="2" ssid = "2">The inclusion of such detectors was motivated by the observation that more than 50% of definite descriptions (D Ds) in an average corpus are discourse new (Poesio and Vieira, 1998), but whereas the inclusion of detectors for non-anaphoric pronouns in algorithms such as Lap- pin and Leass’ (1994) leads to clear improvements in precision, the improvements in anaphoric D D resolution (as opposed to classification) brought about by the detectors were rather small.</S>
		<S sid ="3" ssid = "3">In fact, Ng and Cardie (2002a) challenged the motivation for the inclusion of such detectors, reporting no improvements, or even worse performance.</S>
		<S sid ="4" ssid = "4">We reexamine the literature on the topic in detail, and propose a revised algorithm, taking advantage of the improved discourse-new detection techniques developed by Uryupina (2003).</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">Although many theories of definiteness and many anaphora resolution algorithms are based on the assumption that definite descriptions are anaphoric, in fact in most corpora at least half of definite descriptions are D I S C O U R S E -N E W (Prince, 1992), as shown by the following examples, both of which are the first sentences of texts from the Penn Treebank.</S>
			<S sid ="6" ssid = "6">(1) a. Toni Johnson pulls a tape measure across the front of what was once a stately Victorian home.</S>
			<S sid ="7" ssid = "7">b. The Federal Communications Commission allowed American Telephone &amp; Telegraph Co. to continue offering discount phone services for large-business customers and said it would soon reexamine its Vieira and Poesio (2000) proposed an algorithm for definite description resolution that incorporates a number of heuristics for detecting discourse-new (henceforth: D N) descriptions.</S>
			<S sid ="8" ssid = "8">But whereas the inclusion of detectors for non-anaphoric pronouns (e.g., It in It’s raining) in algorithms such as Lappin and Leass’ (1994) leads to clear improvements in precision, the improvements in anaphoric D D resolution (as opposed to classification) brought about by the detectors were rather small.</S>
			<S sid ="9" ssid = "9">In fact, Ng and Cardie (2002a) challenged the motivation for the inclusion of such detectors, reporting no improvements or even worse performance.</S>
			<S sid ="10" ssid = "10">We reexamine the literature on the topic in detail, and propose a revised algorithm, taking advantage of the improved D N detection techniques developed by Uryupina (2003).</S>
	</SECTION>
	<SECTION title="Detecting Discourse-New Definite. " number = "2">
			<S sid ="11" ssid = "1">Descriptions 2.1 Vieira and Poesio.</S>
			<S sid ="12" ssid = "2">Poesio and Vieira (1998) carried out corpus studies indicating that in corpora like the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993), around 52% of D Ds are discourse-new (Prince, 1992), and another 15% or so are bridging references, for a total of about 6667% first- mention.</S>
			<S sid ="13" ssid = "3">These results led Vieira and Poesio to propose a definite description resolution algorithm incorporating independent heuristic strategies for recognizing D N definite descriptions (Vieira, 1998; Vieira and Poesio, 2000).</S>
			<S sid ="14" ssid = "4">The heuristics proposed by Vieira and Poesio assumed a parsed input (the Penn Treebank) and aimed at identifying five categories of D Ds licensed to occur as first mention on semantic or pragmatic grounds on the basis of work on definiteness including Loebner’s account (1987): scriptions (Loebner, 1987).</S>
			<S sid ="15" ssid = "5">This class included descriptions with modifiers like first or best that turned a possibly sortal predicate into a function (as in the first person to cross the Pacific on a row boat); as well as descriptions with predicates like fact or belief followed by a that-clause with the function of specifying the fact or belief under question.</S>
			<S sid ="16" ssid = "6">Both types of definites descriptions were recognized by consulting a hand-coded list of S P E C I A L P R E D I - C AT E S. 2.</S>
			<S sid ="17" ssid = "7">Descriptions serving as disguised P RO P E R. NA M E S, such as The Federal Communications Commission or the IranIraq war.</S>
			<S sid ="18" ssid = "8">The heuristics for recognizing these definite descriptions were primarily based on capitalization (of the head or the modifiers).</S>
			<S sid ="19" ssid = "9">semantically functioning as predicates rather than as referring.</S>
			<S sid ="20" ssid = "10">These include descriptions occurring in appositive position (as in Glenn Cox, the president of Phillips Petroleum) and in certain copular constructions (as in the man most likely to gain custody of all this is a career politician named Dinkins).</S>
			<S sid ="21" ssid = "11">The heuristics used to recognize these cases examined the syntactic structure of the N P and the clause in which it appeared.</S>
			<S sid ="22" ssid = "12">4.</S>
			<S sid ="23" ssid = "13">Descriptions E S TA B L I S H E D (i.e., turned.</S>
			<S sid ="24" ssid = "14">into functions in context) by restrictive modification, particularly by establishing relative clauses (Loebner, 1987) and prepositional phrases, as in The hotel where we stayed last night was pretty good.</S>
			<S sid ="25" ssid = "15">These heuristics, as well, examined the syntactic structure of the N P. 5.</S>
			<S sid ="26" ssid = "16">LA R G E R S I T UAT I O N definite descriptions.</S>
			<S sid ="27" ssid = "17">(Hawkins, 1978), i.e., definite descriptions like the sun, the pope or the long distance market which denote uniquely on the grounds of shared knowledge about the situation (these are Loebner’s ‘situational functions’).</S>
			<S sid ="28" ssid = "18">Vieira and Poesio’s system had a small list of such defi- nites.</S>
			<S sid ="29" ssid = "19">These heuristics were included as tests both of a decision tree concerned only with the task of D N detection, and of decision trees determining the classification of D Ds as anaphoric, bridging or discourse new.</S>
			<S sid ="30" ssid = "20">In both cases, the D N detection tests were intertwined with attempts to identify an antecedent for lan, 1986)) were used for the task of two-way classification into discourse-new and anaphoric.</S>
			<S sid ="31" ssid = "21">Vieira and Poesio found only small differences in the order of tests in the two decision trees, and small differences in performance.</S>
			<S sid ="32" ssid = "22">The hand-coded decision tree executes in the following order: 1.</S>
			<S sid ="33" ssid = "23">Try the D N heuristics with the highest accu-.</S>
			<S sid ="34" ssid = "24">racy (recognition of some types of semantically functional D Ds using special predicates, and of potentially predicative D Ds occurring in appositions); 2.</S>
			<S sid ="35" ssid = "25">Otherwise, attempt to resolve the D D as direct.</S>
			<S sid ="36" ssid = "26">anaphora;</S>
	</SECTION>
	<SECTION title="Otherwise, attempt the remaining D N  heuris-. " number = "3">
			<S sid ="37" ssid = "1">tics in the order: proper names, descriptions established by relatives and P Ps, proper name modification, predicative D Ds occurring in copular constructions.</S>
			<S sid ="38" ssid = "2">If none of these tests succeeds, the algorithm can either leave the D D unclassified, or classify it as D N. The automatically learned decision tree attempts direct anaphora resolution first.</S>
			<S sid ="39" ssid = "3">The overall results on the 195 D Ds on which the automatically trained decision tree was tested are shown in Table 1.</S>
			<S sid ="40" ssid = "4">The baseline is the result achieved by classifying every D D as discourse-new–with 99 discourse-new D Ds out of 195, this means a precision of 50.8%.</S>
			<S sid ="41" ssid = "5">Two results are shown for the hand-coded decision tree: in one version, the system doesn’t attempt to classify all D Ds; in the other, all unclassified D Ds are classified as discourse-new.</S>
			<S sid ="42" ssid = "6">Version of the System P R F Baseline 50.8 100 67.4 Discourse-new detection only 69 72 70 Hand-coded DT: partial Hand-coded DT: total 62 77 85 77 71.7 77 I D 3 75 75 75 Table 1: Overall results by Vieira and Poesio 2.2 Bean and Riloff.</S>
			<S sid ="43" ssid = "7">Bean and Riloff (1999) developed a system for identifying discourse-new D Ds1 that incorporates, in addition to syntax-based heuristics aimed at recognizing predicative and established D Ds using postmodification heuristics similar to those used by Vieira and Poesio, additional techniques for mining from corpora unfamiliar D Ds including proper names, larger situation, and semantically functional.</S>
			<S sid ="44" ssid = "8">Two such D Ds.</S>
			<S sid ="45" ssid = "9">Both hand-coded decision trees and auto- of the techniques proposed by Bean and Riloff are particularly worth noticing.</S>
			<S sid ="46" ssid = "10">The S E N T E N C E -O N E (S 1) E X T R AC T I O N heuristic identifies as discourse- new every D D found in the first sentence of a text.</S>
			<S sid ="47" ssid = "11">More general patterns can then be extracted from the D Ds initially found by S 1-extraction, using the E X I S T E N T I A L H E A D PAT T E R N method which, e.g., would extract the N+ Government from the Salvadoran Government and the Guatemalan Government.</S>
			<S sid ="48" ssid = "12">The D E FI N I T E O N LY (D O) list contained N Ps like the National Guard or the FBI with a high D E FI N I T E P RO BA B I L I T Y, i.e., whose nominal complex has been encountered at least 5 times with the definite article, but never with the indefinite.</S>
			<S sid ="49" ssid = "13">VAC - C I N E S were also developed that prevented the use of patterns identified by S 1-extraction or D O-list elements when the definite probability of the definite was too low.</S>
			<S sid ="50" ssid = "14">Overall, the algorithm proposed by Bean and Riloff is as follows: 1.</S>
			<S sid ="51" ssid = "15">If the head noun of the D D appeared earlier in. the text, classify as anaphoric.</S>
			<S sid ="52" ssid = "16">2.</S>
			<S sid ="53" ssid = "17">Otherwise, if the D D occurs in the S1 list, clas-.</S>
			<S sid ="54" ssid = "18">sify as discourse-new unless stopped by vaccine.</S>
			<S sid ="55" ssid = "19">3.</S>
			<S sid ="56" ssid = "20">Otherwise, classify the D D as D N if one of the.</S>
			<S sid ="57" ssid = "21">following tests applies: (a) it occurs in the D O list; (b) it matches one of the E H P patterns, and is not stopped by vaccine; (c) it matches one of the syntactic heuristics</S>
	</SECTION>
	<SECTION title="Otherwise, classify the D D as anaphoric.. " number = "4">
			<S sid ="58" ssid = "1">(Note that as in the machine-learned version of the Vieira and Poesio decision tree, a (simplified) direct anaphora test is tried first, followed by D N detectors in decreasing order of accuracy.)</S>
			<S sid ="59" ssid = "2">Bean and Riloff trained their system on 1600 articles from M U C-4, and tested it on 50 texts.</S>
			<S sid ="60" ssid = "3">The S 1 extraction methods produced 849 D Ds; the D O list contained 65 head nouns and 321 full N Ps.</S>
			<S sid ="61" ssid = "4">The overall results are shown in Table 2; the baseline are the results obtained when classifying all D Ds as discourse-new.</S>
			<S sid ="62" ssid = "5">Although the overall precision is not better than what obtained with the partial hand-coded decision tree used by Vieira and Poesio, recall is substantially improved.</S>
			<S sid ="63" ssid = "6">2.3 Ng and Cardie.</S>
			<S sid ="64" ssid = "7">Ng and Cardie (2002a) directly investigate the question of whether employing a discourse-new pre M et ho d R P Ba sel ine 10 0 72.</S>
			<S sid ="65" ssid = "8">2 Sy nta cti c He uri sti cs 4 3 93.</S>
			<S sid ="66" ssid = "9">1 Sy nt.</S>
			<S sid ="67" ssid = "10">He uri sti cs + S1 S y n t . H e u r i s t i c s + E H P S y n t . H e u r i s t i c s + D O 66.</S>
			<S sid ="68" ssid = "11">3 60.</S>
			<S sid ="69" ssid = "12">7 69.</S>
			<S sid ="70" ssid = "13">2 84.</S>
			<S sid ="71" ssid = "14">3 87.</S>
			<S sid ="72" ssid = "15">3 83.</S>
			<S sid ="73" ssid = "16">9 Sy nt.</S>
			<S sid ="74" ssid = "17">He uri sti cs + S1 + E HP + D O 81.</S>
			<S sid ="75" ssid = "18">7 82.</S>
			<S sid ="76" ssid = "19">2 Sy nt.</S>
			<S sid ="77" ssid = "20">He uri sti cs + S1 + E HP + D O + V 79.</S>
			<S sid ="78" ssid = "21">1 84.</S>
			<S sid ="79" ssid = "22">5 Table 2: Discourse-new prediction results by Bean and Riloff coreference resolution system (specifically, the system discussed in (Ng and Cardie, 2002b)).</S>
			<S sid ="80" ssid = "23">Ng and Cardie’s work differs from the work discussed so far in that their system attempts to deal with all types of N Ps, not just definite descriptions.</S>
			<S sid ="81" ssid = "24">The discourse-new detectors proposed by Ng and Cardie are statistical classifiers taking as input 37 features and trained using either C 4.5 (Quinlan, 1993) or R I P P E R (Cohen, 1995).</S>
			<S sid ="82" ssid = "25">The 37 features of a candidate anaphoric expression specify, in addition to much of the information proposed in previous work, a few new types of information about N Ps.</S>
			<S sid ="83" ssid = "26">• The four boolean so-called L E X I C A L features are actually string-level features: for example, str_match is Y if a preceding N P string-matches the anaphoric expression (except for the determiner), and head_match = Y if a preceding N P’s head string-matches the anaphoric expression’s. embedded=Y if the anaphoric expression is a prenominal modifier.</S>
			<S sid ="84" ssid = "27">• The second group of 11 (mostly boolean) features specifies the type of N P: e.g., pronoun is Y if the anaphoric expression is a pronoun, else N. • The third group of 7 features specifies syntactic properties of the anaphoric expression, including number, whether N Pj is the first of two N Ps in an appositive or predicative construction, whether N Pj is pre- or post-modified, whether it contains a proper noun, and whether it is modified by a superlative.</S>
			<S sid ="85" ssid = "28">• The next group of 8 features are mostly novel, and capture information not used by previous D N detectors about the exact composition of definite descriptions: e.g., the_2n=Y if the anaphoric expression starts with determiner the followed by exactly two common nouns, the_num_n=Y if the anaphoric ex by a cardinal and a common noun, and the_sing_n=Y if the anaphoric expression starts with determiner the followed by a singular N P not containing a proper noun.</S>
			<S sid ="86" ssid = "29">• The next group of features consists of 4 features capturing a variety of ‘semantic’ information, including whether a previous N P is an ‘alias’ of N Pj , or whether N Pj is the title of a person (the president).</S>
			<S sid ="87" ssid = "30">• Finally, the last three features capture information about the position in the text in which N Pj occurs: the header, the first sentence, or the first paragraph.</S>
			<S sid ="88" ssid = "31">Ng and Cardie’s discourse-new predictor was trained and tested over the M U C-6 and M U C-7 coreference data sets, achieving accuracies of 86.1% and 84%, respectively, against a baseline of 63.8% and 73.2%, respectively.</S>
			<S sid ="89" ssid = "32">Inspection of the top parts of the decision tree produced with the M U C-6 suggests that head_match is the most important feature, followed by the features specifying N P type, the alias feature, and the features specifying the structure of definite descriptions.</S>
			<S sid ="90" ssid = "33">Ng and Cardie discuss two architectures for the integration of a D N detector in a coreference system.</S>
			<S sid ="91" ssid = "34">In the first architecture, the D N detector is run first, and the coreference resolution algorithm is run only if the D N detector classifies that N P as anaphoric.</S>
			<S sid ="92" ssid = "35">In the second architecture, the system first computes str_match and alias, and runs the anaphoric resolver if any of them is Y; otherwise, it proceeds as in the first architecture.</S>
			<S sid ="93" ssid = "36">The results obtained on the M U C-6 data with the baseline anaphoric resolver, the anaphoric resolver augmented by a D N detector as in the first architecture, and as in the second architecture (using C 4.5), are shown in Table 3.</S>
			<S sid ="94" ssid = "37">The results for all N Ps, pronouns only, proper names only, and common nouns only are shown.2 As indicated in the Table, running the D N detector M U C 6 M U C 7 R P F R P F Bas elin e (no DN det ect or) P r o n o u n s P r o p e r n a m e s C o m m o n n o u n s 70.</S>
			<S sid ="95" ssid = "38">3 17.</S>
			<S sid ="96" ssid = "39">9 29.</S>
			<S sid ="97" ssid = "40">9 25.</S>
			<S sid ="98" ssid = "41">2 58.</S>
			<S sid ="99" ssid = "42">3 66.</S>
			<S sid ="100" ssid = "43">3 84.</S>
			<S sid ="101" ssid = "44">2 40.</S>
			<S sid ="102" ssid = "45">1 63.</S>
			<S sid ="103" ssid = "46">8 28.</S>
			<S sid ="104" ssid = "47">2 44.</S>
			<S sid ="105" ssid = "48">1 31.</S>
			<S sid ="106" ssid = "49">0 65.</S>
			<S sid ="107" ssid = "50">5 10.</S>
			<S sid ="108" ssid = "51">2 27.</S>
			<S sid ="109" ssid = "52">0 26.</S>
			<S sid ="110" ssid = "53">6 58.</S>
			<S sid ="111" ssid = "54">2 62.</S>
			<S sid ="112" ssid = "55">1 77.</S>
			<S sid ="113" ssid = "56">7 45.</S>
			<S sid ="114" ssid = "57">2 61.</S>
			<S sid ="115" ssid = "58">6 17.</S>
			<S sid ="116" ssid = "59">6 40.</S>
			<S sid ="117" ssid = "60">0 33.</S>
			<S sid ="118" ssid = "61">5 DN det ect or run s firs t P r o n o u n s P r o p e r n a m e s C o m m o n n o u n s 57.</S>
			<S sid ="119" ssid = "62">4 17.</S>
			<S sid ="120" ssid = "63">9 26.</S>
			<S sid ="121" ssid = "64">6 15.</S>
			<S sid ="122" ssid = "65">4 71.</S>
			<S sid ="123" ssid = "66">6 67.</S>
			<S sid ="124" ssid = "67">0 89.</S>
			<S sid ="125" ssid = "68">2 56.</S>
			<S sid ="126" ssid = "69">2 63.</S>
			<S sid ="127" ssid = "70">7 28.</S>
			<S sid ="128" ssid = "71">2 41.</S>
			<S sid ="129" ssid = "72">0 24.</S>
			<S sid ="130" ssid = "73">2 47.</S>
			<S sid ="131" ssid = "74">0 10.</S>
			<S sid ="132" ssid = "75">2 21.</S>
			<S sid ="133" ssid = "76">5 13.</S>
			<S sid ="134" ssid = "77">8 77.</S>
			<S sid ="135" ssid = "78">1 62.</S>
			<S sid ="136" ssid = "79">1 84.</S>
			<S sid ="137" ssid = "80">8 77.</S>
			<S sid ="138" ssid = "81">5 58.</S>
			<S sid ="139" ssid = "82">4 17.</S>
			<S sid ="140" ssid = "83">6 34.</S>
			<S sid ="141" ssid = "84">3 23.</S>
			<S sid ="142" ssid = "85">4 Sa me hea d run s firs t P r o n o u n s P r o p e r n a m e s C o m m o n n o u n s 63.</S>
			<S sid ="143" ssid = "86">4 17.</S>
			<S sid ="144" ssid = "87">9 27.</S>
			<S sid ="145" ssid = "88">4 20.</S>
			<S sid ="146" ssid = "89">5 68.</S>
			<S sid ="147" ssid = "90">3 67.</S>
			<S sid ="148" ssid = "91">0 88.</S>
			<S sid ="149" ssid = "92">5 53.</S>
			<S sid ="150" ssid = "93">1 65.</S>
			<S sid ="151" ssid = "94">8 28.</S>
			<S sid ="152" ssid = "95">2 41.</S>
			<S sid ="153" ssid = "96">9 29.</S>
			<S sid ="154" ssid = "97">6 59.</S>
			<S sid ="155" ssid = "98">7 10.</S>
			<S sid ="156" ssid = "99">2 26.</S>
			<S sid ="157" ssid = "100">1 21.</S>
			<S sid ="158" ssid = "101">7 69.</S>
			<S sid ="159" ssid = "102">3 62.</S>
			<S sid ="160" ssid = "103">1 84.</S>
			<S sid ="161" ssid = "104">7 59.</S>
			<S sid ="162" ssid = "105">0 64.</S>
			<S sid ="163" ssid = "106">2 17.</S>
			<S sid ="164" ssid = "107">6 40.</S>
			<S sid ="165" ssid = "108">0 31.</S>
			<S sid ="166" ssid = "109">7 Table 3: Evaluation of the three anaphoric resolvers discussed by Ng and Cardie.</S>
			<S sid ="167" ssid = "110">2.4 Uryupin a Uryupina (2003) trained two separate classifiers (using R I P P E R, (Cohen, 1995)): a D N detector and a U N I QU E N E S S D E T E C TO R, i.e., a classifier that determines whether an N P refers to a unique object.</S>
			<S sid ="168" ssid = "111">This is useful to identify proper names (like 1998, or the United States of America), semantic definites (like the chairman of Microsoft) and larger situation definite descriptions (like the pope).</S>
			<S sid ="169" ssid = "112">Both classifiers use the same set of 32 features.</S>
			<S sid ="170" ssid = "113">The features of an N P encode, first, of all, string-level information: e.g., whether the N P contains capitalized words, digits, or special symbols.</S>
			<S sid ="171" ssid = "114">A second group of features specifies syntactic information: whether the N P is postmodified, and whether it contains an apposition.</S>
			<S sid ="172" ssid = "115">Two types of appositions are distinguished, with and without commas.</S>
			<S sid ="173" ssid = "116">C O N T E X T features specify the distance between the N P and the previous N P with the same head, if any.</S>
			<S sid ="174" ssid = "117">Finally, Uryupina’s system computes four features specifying the N P’s definite probability.</S>
			<S sid ="175" ssid = "118">Unlike the definite probability used by Bean and Riloff, these features are computed from the Web, using Altavista.</S>
			<S sid ="176" ssid = "119">From each N P, its head H and entire N P without determiner Y are determined, and four ratios are then computed: first leads to worse results–this is because the detector misclassifies a number of anaphoric N Ps as non- anaphoric.</S>
			<S sid ="177" ssid = "120">However, looking first for a same-head #”the Y” #Y #”the H” #ff aH ff #”the Y” #ff aY ff #”the H” #H antecedent leads to a statistically significant improvement over the results of the baseline anaphoric resolver.</S>
			<S sid ="178" ssid = "121">This confirms the finding both of Vieira and Poesio and of Bean and Riloff that the direct anaphora should be called very early.</S>
			<S sid ="179" ssid = "122">2 It’s not clear to us why the overall performance of the algorithm is much better than the performance on the three individual types of anaphoric expressions considered–i.e., which other anaphoric expressions are handled by the coreference resolver.</S>
			<S sid ="180" ssid = "123">The classifiers were tested on 20 texts from M U C 7 (a subset of the second data set used by Ng and Cardie), parsed by Charniak’s parser.</S>
			<S sid ="181" ssid = "124">19 texts were used for training and for tuning R I P P E R’s parameters, one for testing.</S>
			<S sid ="182" ssid = "125">The results for the discourse new detection task are shown in Table 4, separating the results for all N Ps and definite N Ps only, and the results without definite probabilities and including them.</S>
			<S sid ="183" ssid = "126">The results for uniqueness detection are shown in Table 4, in which the results obtained by prioritizing precision and recall are shown separately.</S>
			<S sid ="184" ssid = "127">Fe at ur es P R F All NP s Str ing +S yn +C ont ext All 87.</S>
			<S sid ="185" ssid = "128">9 88.</S>
			<S sid ="186" ssid = "129">5 86.</S>
			<S sid ="187" ssid = "130">0 84.</S>
			<S sid ="188" ssid = "131">3 86.</S>
			<S sid ="189" ssid = "132">9 86.</S>
			<S sid ="190" ssid = "133">3 De f NP s Str ing +S yn +C ont ext All 82.</S>
			<S sid ="191" ssid = "134">5 84.</S>
			<S sid ="192" ssid = "135">8 79.</S>
			<S sid ="193" ssid = "136">3 82.</S>
			<S sid ="194" ssid = "137">3 80.</S>
			<S sid ="195" ssid = "138">8 83.</S>
			<S sid ="196" ssid = "139">5 Table 4: Results of Uryupina’s discourse new classifier Fe at ur es P R F Be st Pr ec Str ing +S yn +C ont ext All 94.</S>
			<S sid ="197" ssid = "140">0 95.</S>
			<S sid ="198" ssid = "141">0 84.</S>
			<S sid ="199" ssid = "142">0 83.</S>
			<S sid ="200" ssid = "143">5 88.</S>
			<S sid ="201" ssid = "144">7 88.</S>
			<S sid ="202" ssid = "145">9 Be st Re c Str ing +S yn +C ont ext All 86.</S>
			<S sid ="203" ssid = "146">7 87.</S>
			<S sid ="204" ssid = "147">2 96.</S>
			<S sid ="205" ssid = "148">0 97.</S>
			<S sid ="206" ssid = "149">0 91.</S>
			<S sid ="207" ssid = "150">1 91.</S>
			<S sid ="208" ssid = "151">8 Table 5: Results of Uryupina’s uniqueness classifier The first result to note is that both of Uryupina’s classifiers work very well, particularly the uniqueness classifier.</S>
			<S sid ="209" ssid = "152">These tables also show that the definite probability helps somewhat the discourse new detector, but is especially useful for the uniqueness detector, as one would expect on the basis of Loebner’s discussion.</S>
			<S sid ="210" ssid = "153">2.5 Summary.</S>
			<S sid ="211" ssid = "154">Quite a lot of consensus on many of the factors playing a role in D N detection for D Ds.</S>
			<S sid ="212" ssid = "155">Most of the algorithms discussed above incorporate methods for: • recognizing predicative D Ds; • recognizing discourse-new proper names; • identifying functional D Ds; • recognizing D Ds modified by establishing relatives (which may or may not be discourse- new).</S>
			<S sid ="213" ssid = "156">There is also consensus on the fact that D N detection cannot be isolated from anaphoric resolution (witness the Ng and Cardie results).</S>
			<S sid ="214" ssid = "157">One problem with some of the machine learning approaches to coreference is that these systems do not achieve very good results on pronoun and definite description resolution in comparison with specialized algorithms: e.g., although Ng and Cardie’s best version achieves F=65.8 on all anaphoric expressions, it only achieves F=29.6 for definite descriptions (cfr.</S>
			<S sid ="215" ssid = "158">Vieira and Poesio’s best result of F=77), and F=28.2 for pronouns (as opposed to results as high as F=80 obtained by the pronoun resolution algorithms evaluated in (Tetreault, 2001)).</S>
			<S sid ="216" ssid = "159">Clearly these systems can only be properly compared by evaluating them all on the same corpora and the same data, and discussion such as (Mitkov, 2000) suggest caution in interpreting some of the results discussed in the literature as pre- and post- processing often plays a crucial role, but we feel that evaluating D N detectors in conjunction with high- performing systems would give a better idea of the improvements that one may hope to achieve.</S>
			<S sid ="217" ssid = "160">3 Do Discourse-New Detectors Help?.</S>
			<S sid ="218" ssid = "161">Preliminary Evaluations Vieira and Poesio did not test their system without D N-detection, but Ng and Cardie’s results indicate that D N detection does improve results, if not dramatically, provided that the same_head test is run first–although their D N detector does not appear to improve results for pronouns, the one category for which detection of non-anaphoricity has been shown to be essential (Lappin and Leass, 1994).</S>
			<S sid ="219" ssid = "162">In order to evaluate how much improvement can we expect by just improving the D N detector, we did a few preliminary evaluations both with a reimplementation of Vieira and Poesio’s algorithm which does not include a discourse-new detector, running over treebank text as the original algorithm, and with a simple statistical coreference resolver attempting to resolve all anaphoric expressions and running over unparsed text, using Uryupina’s features for discourse-new detection, and over the same corpus used by Ng and Cardie (M U C-7).</S>
			<S sid ="220" ssid = "163">3.1 How much does DN-detection help the.</S>
			<S sid ="221" ssid = "164">Vieira / Poesio algorithm?</S>
			<S sid ="222" ssid = "165">G U I TA R (Poesio and AlexandrovKabadjov, 2004) is a general-purpose anaphoric resolver that includes an implementation of the Vieira / Poesio algorithm for definite descriptions and of Mitkov’s algorithm for pronoun resolution (Mitkov, 1998).</S>
			<S sid ="223" ssid = "166">It is implemented in Java, takes its input in X M L format and returns as output its input augmented with the anaphoric relations it has discovered.</S>
			<S sid ="224" ssid = "167">G U I TA R has been implemented in such a way as to be fully modular, making it possible, for example, to replace the D D resolution method with alternative implementations.</S>
			<S sid ="225" ssid = "168">It includes a pre-processor incorporating a chunker so that it can run over both hand-parsed and raw text.</S>
			<S sid ="226" ssid = "169">A version of G U I TA R without the D N detection aspects of the Vieira / Poesio algorithm was evaluated on the G N O M E corpus (Poesio, 2000; Poesio et al., 2004), which contains 554 definite descriptions, of which 180 anaphoric, and 305 third-person pronouns, of which 217 anaphoric.</S>
			<S sid ="227" ssid = "170">The results for definite descriptions over hand-parsed text are shown in Table 6.</S>
			<S sid ="228" ssid = "171">Tot al Res Cor r N M W M SM R P F 18 0 182 12 1 4 3 1 6 45 67.</S>
			<S sid ="229" ssid = "172">2 66.</S>
			<S sid ="230" ssid = "173">5 66.</S>
			<S sid ="231" ssid = "174">8 Table 6: Evaluation of the G U I TA R system without D N detection over a hand-annotated treebank G U I TA R without a D N recognizer takes 182 D Ds (Res) as anaphoric, resolving 121 of them correctly (Corr); of the 182 D Ds it attempts to resolve, only 16 are incorrectly resolved (WM); almost three times that number (45) are Spurious Matches (SM), i.e., discourse-new D Ds incorrectly interpreted as anaphoric.</S>
			<S sid ="232" ssid = "175">(Res=Corr+WM+SM.)</S>
			<S sid ="233" ssid = "176">The system can’t find an antecedent for 43 of the 180 anaphoric D Ds.</S>
			<S sid ="234" ssid = "177">When endowed with a perfect D N detector, G U I - TA R could achieve a precision P=88.3 which, assuming recall stays the same (R=67.2) would mean a F=76.3.</S>
			<S sid ="235" ssid = "178">Of course, these results are obtained assuming perfect parsing.</S>
			<S sid ="236" ssid = "179">For a fairer comparison with the results of Ng and Cardie, we report in Table 7 the results for both pronouns and definite descriptions obtained by running G U I TA R off raw text.</S>
			<S sid ="237" ssid = "180">R P F Pr on ou ns 65 .5 63 .0 64 .2 D Ds 56 .7 56 .1 56 .4 Table 7: Evaluation of the G U I TA R system without D N detection off raw text Notice that although these results are not particularly good, they are still better than the results reported by Ng and Cardie for pronouns and definite N Ps.</S>
			<S sid ="238" ssid = "181">3.2 How much might DN detection help a. simple statistical coreference resolver?</S>
			<S sid ="239" ssid = "182">In order to have an even closer comparison with the results of Ng and Cardie, we implemented a simple statistical coreference system, that, like Ng and Cardie’s system, would resolve all types of anaphoric expressions, and would run over unparsed text, but without D N detection.</S>
			<S sid ="240" ssid = "183">We ran the system over the M U C-7 data used by Ng and Cardie, and compared the results with those obtained by using perfect knowledge about discourse novelty.</S>
			<S sid ="241" ssid = "184">The results are shown in Table 8.</S>
			<S sid ="242" ssid = "185">W ith ou t D N de te cti on R 4 4.</S>
			<S sid ="243" ssid = "186">7 P 5 4.</S>
			<S sid ="244" ssid = "187">9 F 4 9.</S>
			<S sid ="245" ssid = "188">3 W ith D N de te cti on 41 .4 80 .0 54 .6 Table 8: Using an oracle These results suggest that a D N detector could lead to substantial improvements for coreference resolution in general: D N detection might improve precision by more than 30%, which more than makes up for the slight deterioration in recall.</S>
			<S sid ="246" ssid = "189">Of course, this test alone doesn’t tell us how much improvement D N detection would bring to a higher- performance anaphoric resolver.</S>
			<S sid ="247" ssid = "190">4 A New Set of Features for Discourse-New Detection Next, we developed a new set of features for discourse new detection that takes into account the findings of the work on D N detection discussed in the previous sections.</S>
			<S sid ="248" ssid = "191">This set of features will be input to an anaphoric resolver for D Ds working in two steps.</S>
			<S sid ="249" ssid = "192">For each D D, 1.</S>
			<S sid ="250" ssid = "193">The direct anaphora resolution algorithm from.</S>
			<S sid ="251" ssid = "194">(Vieira and Poesio, 2000) is run, which attempts to find an head-matching antecedent within a given window and taking premodification into account.</S>
			<S sid ="252" ssid = "195">The results of the algorithm (i.e., whether an antecedent was found) is used as one of the input features of the classifier in the next step.</S>
			<S sid ="253" ssid = "196">In addition, a number of features of the D D that may help recognizing the classes of D Ds discussed above are extracted from the input.</S>
			<S sid ="254" ssid = "197">Some of these features are computed accessing the Web via the Google A P I. 2.</S>
			<S sid ="255" ssid = "198">A decision tree classifier is used to classify the D D as anaphoric (in which case the antecedents identified at the first step are also returned) or discourse-new.</S>
			<S sid ="256" ssid = "199">The features input to the classifier can be categorized as follows: Anaphora A single feature, direct-anaphora, specifying the distance of the (same-head) antecedent from the D D, if any (values: none, zero, one, more) Predicative NPs Two boolean features: • apposition, if the D D occurs in appositive position; • copular, if the D D occurs in post-verbal position in a copular construction.</S>
			<S sid ="257" ssid = "200">Proper Names Three boolean features: • c-head: whether the head is capitalized; • c-premod: whether one of the premodifiers is capitalized; • S1: whether the D D occurs in the first sentence of a Web page.</S>
			<S sid ="258" ssid = "201">Functionality The four definite probabilities used by Uryupina (computed accessing the Web), plus a superlative feature specifying if one of the premodifiers is a superlative, extracted from the part of speech tags.</S>
			<S sid ="259" ssid = "202">Establishing relative A single feature, specifying whether N P is postmodified, and by a relative clause or a prepositional phrase; Text Position Whether the D D occurs in the title, the first sentence, or the first paragraph.</S>
			<S sid ="260" ssid = "203">We are testing several classifiers included in the Weka 3.4 library (http://www.cs.waikato.ac.nz/˜ml/) including an implementation of C 4.5 and a multi-layer perceptron.</S>
	</SECTION>
	<SECTION title="Evaluation. " number = "5">
			<S sid ="261" ssid = "1">Data We are using three corpora for the evaluation, including texts from different genres, in which all anaphoric relations between (all types of) N Ps are marked.</S>
			<S sid ="262" ssid = "2">The G N O M E corpus includes pharmaceutical leaflets and museum ’labels’ (i.e., descriptions of museum objects and of the artists that realized them).</S>
			<S sid ="263" ssid = "3">As said above, the corpus contains 554 definite descriptions.</S>
			<S sid ="264" ssid = "4">In addition, we are using the 14 texts from the Penn Treebank included in the corpus used by Vieira and Poesio.</S>
			<S sid ="265" ssid = "5">We transferred these texts to X M L format, and added anaphoric information for all types of N Ps according to the G N O M E scheme.</S>
			<S sid ="266" ssid = "6">Finally, we are testing the system on the M U C-7 data used by Ng and Cardie Methods We will compare three versions of the D D resolution component: 1.</S>
			<S sid ="267" ssid = "7">The baseline algorithm without D N detection.</S>
			<S sid ="268" ssid = "8">incorporated in G U I TA R described above (i.e., only the direct anaphora resolution part of (Vieira and Poesio, 2000)); 2.</S>
			<S sid ="269" ssid = "9">A complete implementation of the Vieira and Poesio algorithm, including also the D N detecting heuristics; 3.</S>
			<S sid ="270" ssid = "10">An algorithm using the statistical classifier dis-.</S>
			<S sid ="271" ssid = "11">cussed above.</S>
			<S sid ="272" ssid = "12">Results Regrettably, the system is still being tested.</S>
			<S sid ="273" ssid = "13">We will report the results at the workshop.</S>
	</SECTION>
	<SECTION title="Discussion and Conclusions. " number = "6">
			<S sid ="274" ssid = "1">Discussions and conclusions will be based on the final results.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="275" ssid = "2">Mijail AlexandrovKabadjov is supported by Conacyt.</S>
			<S sid ="276" ssid = "3">Renata Vieira and Rodrigo Goulart are partially supported by CNPq.</S>
	</SECTION>
</PAPER>
