<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In this paper, a resolution system is presented to tackle nominal and pronominal anaphora in biomedical literature by using rich set of syntactic and semantic features.</S>
		<S sid ="2" ssid = "2">Unlike previous researches, the verification of semantic association between anaphors and their antecedents is facilitated by exploiting more outer resources, including UMLS, WordNet, GENIA Corpus 3.02p and PubMed.</S>
		<S sid ="3" ssid = "3">Moreover, the resolution is implemented with a genetic algorithm on its feature selection.</S>
		<S sid ="4" ssid = "4">Experimental results on different biomedical corpora showed that such approach could achieve promising results on resolving the two common types of anaphora.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">Correct identification of antecedents for an anaphor is essential in message understanding systems as well as knowledge acquisition systems.</S>
			<S sid ="6" ssid = "6">For example, efficient anaphora resolution is needed to enhance protein interaction extraction from biomedical literature by mining more protein entity instances which are represented with pronouns or general concepts.</S>
			<S sid ="7" ssid = "7">In biomedical literature, pronominal and nominal anaphora are the two common types of anaphora.</S>
			<S sid ="8" ssid = "8">In past literature, different strategies to identify antecedents of an anaphor have been presented by using syntactic, semantic and pragmatic clues.</S>
			<S sid ="9" ssid = "9">For example, grammatical roles of noun phrases were used in [9] [10].</S>
			<S sid ="10" ssid = "10">In addition to the syntactic information, statistical information like co-occurring patterns obtained from a corpus is employed during antecedent finding in [3].</S>
			<S sid ="11" ssid = "11">However, a large corpus is needed for acquiring sufficient co-occurring patterns and for dealing with data sparseness.</S>
			<S sid ="12" ssid = "12">On the other hand, outer resources, like WordNet1, are applied in [4][12][15] and proved to be helpful to improve the system like the one described in [12] where ani- macy information is exploited by analyzing the hierarchical relation of nouns and verbs in the surrounding context learned from WordNet.</S>
			<S sid ="13" ssid = "13">Nevertheless, using Word- Net alone for acquiring semantic information is not sufficient for solving unknown words.</S>
			<S sid ="14" ssid = "14">To tackle this problem, a richer resource, the Web, was exploited in [16] 1 http://wordnet.princeton.edu/ where anaphoric information is mined from Google search results at the expense of less precision.</S>
			<S sid ="15" ssid = "15">The domain-specific ontologies like UMLS2 (Unified Medical Language System) has been employed in [2] in such a way that frequent semantic types associated to agent (subject) and patient (object) role of subject-action or action-object patterns can be extracted.</S>
			<S sid ="16" ssid = "16">The result showed such kind of patterns could gain increase in both precision (76% to 80%) and recall (67% to 71%).</S>
			<S sid ="17" ssid = "17">On the other hand, Kim and Park [11] built their BioAR to relate protein names to SWISSProt entries by using the centering theory presented by [7] and salience measures by [2].</S>
			<S sid ="18" ssid = "18">In this paper, a resolution system is presented for tackling both nominal anaphora and pronominal anaphora in biomedical literature by using various kinds of syntactic and semantic features.</S>
			<S sid ="19" ssid = "19">Unlike previous approaches, our verification of the semantic association between anaphors and their antecedents is facilitated with the help of both general domain and domain-specific resources.</S>
			<S sid ="20" ssid = "20">For example, the semantic type checking for resolving nominal anaphora can be done by the domain ontology UMLS and PubMed3, the search engine for MEDLINE databases.</S>
			<S sid ="21" ssid = "21">Here, UMLS is used not only for tagging the semantic type for the noun phrase chunks if they are in UMLS, but also for generating the key lexicons for each type so that we can use them to tag those chunks if they are not in UMLS.</S>
			<S sid ="22" ssid = "22">If no type information can be obtained from an chunk, then its type finding will be implemented through the web mining of PubMed.</S>
			<S sid ="23" ssid = "23">On the other hand, the domain corpus, GENIA 3.02p corpus [20] is exploited while we solve the semantic type checking for pronominal anaphora.</S>
			<S sid ="24" ssid = "24">With simple weight calculation, the key SA/AO (subject-action or action-object) patterns for each type can be mined from the corpus and they turn out to be helpful in resolution.</S>
			<S sid ="25" ssid = "25">Beside the semantic type agreement, the implicit resemblance between an anaphor and its antecedents is another evidence useful for verifying the semantic association.</S>
			<S sid ="26" ssid = "26">Hence, the general domain thesaurus, WordNet, which supporting more relationship between concepts and subconcepts, is also employed to enhance the resemblance extraction.</S>
			<S sid ="27" ssid = "27">The presented resolution system is constructed on a basis of a salience grading.</S>
			<S sid ="28" ssid = "28">In order to boost the system, we implemented a simple genetic algorithm on its selection of the rich feature set.</S>
			<S sid ="29" ssid = "29">The system was developed on the small evaluation corpus MedStract 4 . Nevertheless, we constructed a larger test corpus (denoted as ‘100MEDLINE’) so that more instances of anaphors can be resolved.</S>
			<S sid ="30" ssid = "30">Experimental results show that our resolution on MedStract can yield 92% and 78% F-Scores on resolving pronominal and nominal anaphora respectively.</S>
			<S sid ="31" ssid = "31">Promising results were also obtained on the larger corpus in terms of 87.43% and 80.61% F-scores on resloving pronominal and nominal anaphora respectively.</S>
	</SECTION>
	<SECTION title="Anaphora Resolution. " number = "2">
			<S sid ="32" ssid = "1">Figure 1 is the overview of the presented architecture, including the extraction of biomedical SA/AO patterns and semantic type lexicons in background processing 2 http://www.nlm.nih.gov/research/umls/ 3 http://www.pubmedcentral.nih.gov/ 4 http://www.medstract.org/ (indicated with dotted lines), as well as the document processing, anaphor recognition and antecedent selection in foreground processing (indicated with solid lines).</S>
			<S sid ="33" ssid = "2">Texts Document Processing UMLS 2003AC Metathesaurus GENIA Corpus 3.02p Semantic Type Lexicon Extraction Semantically-tagged SA/AO Extraction Anaphor Recognition Pronominal Anaphor Key lexicons for each type Semantic SA/AO Patterns Nominal Anaphor Antecedent Selection Number Agreement Check Salience Grading PubMed Search Results WordNet 2.0 Fig.</S>
			<S sid ="34" ssid = "3">1.</S>
			<S sid ="35" ssid = "4">System architecture overview 2.1 Syntactic Information Extraction.</S>
			<S sid ="36" ssid = "5">Being important features for anaphora resolution, syntactic information, like POS tags and base NP chunks, is extracted from each document by using the Tagger5.</S>
			<S sid ="37" ssid = "6">Meanwhile, each NP will be tagged with its grammatical role, namely, ‘Oblique’, ‘Direct object’, ‘Indirect object’, or ‘Subject’ by using the following rules which were adopted from [22] by adding rules 5 and 6.</S>
			<S sid ="38" ssid = "7">Rule1: Prep NP (Oblique) Rule2: Verb NP (Direct object) Rule3: Verb [NP]+ NP (Indirect object) Rule4: NP (Subject) [“,[^Verb], ”|Prep NP]* Verb Rule5: NP1 Conjunction NP2 (Role is same as NP1) Conjunction] Rule6: [Conjunction] NP1 ( Role is same as NP2 ) Conjunction NP2 5 http://tamas.nlm.nih.gov/tagger.html Rules 5 and 6 are presented for dealing those plural anaphors in such a way that the syntactic agreement between the first antecedent and its anaphora is used to find other antecedents.</S>
			<S sid ="39" ssid = "8">For example, without rules 5 and 6, ‘anti-CD4 mAb’ in Example 1 will not be found when resolving anaphora ‘they’.</S>
			<S sid ="40" ssid = "9">Example1: “Whereas different anti-CD4 mAb or HIV1 gp120 could all trigger activation of the ..., they differed…” 2.2 Semantic Information Extraction.</S>
			<S sid ="41" ssid = "10">Beside the syntactic clues, the semantic agreement between an anaphor and its antecedents can also facilitate anaphora resolution in domain-specific literature.</S>
			<S sid ="42" ssid = "11">In this paper, the semantic information for each target noun phrase chunk can be extracted with the help of the domain ontology, UMLS, which supports the semantic type for the chunk.</S>
			<S sid ="43" ssid = "12">However, the semantic types for those chunks which are not in UMLS are needed to be predicted.</S>
			<S sid ="44" ssid = "13">Therefore we need to extract the key lexicons from UMLS for each semantic type in background processing and use them to tag unknown chunk with predicted types.</S>
			<S sid ="45" ssid = "14">On the other hand, the semantic type checking for pronominal anaphors is done through the extraction of the key verbs for each semantic type.</S>
			<S sid ="46" ssid = "15">Hence, a domain corpus GENIA 3.02p is exploited in background processing.</S>
			<S sid ="47" ssid = "16">2.2.1 Key Lexicons for Each Semantic Type For each UMLS semantic type, its key lexicons are mined as the following steps in Figure 2: A. Collect all UMLS concepts and their corresponding synonyms as type lexicon candidates.</S>
			<S sid ="48" ssid = "17">B. Tokenize the candidates.</S>
			<S sid ="49" ssid = "18">For example, concept ‘interleukin-2’ has synonyms ‘Costimulator’, ‘Co-Simulator’, ‘IL 2’, and ‘interleukine 2’.</S>
			<S sid ="50" ssid = "19">Then ‘interleukin’, ‘costimulator’, ‘simulator’, ‘IL’, and ‘interleukine’ will be treated as lexicon candidates.</S>
			<S sid ="51" ssid = "20">C. For each candidate, calculate its weight wij for each type by using Eq.</S>
			<S sid ="52" ssid = "21">(1) which takes into account its concentration and distribution.</S>
			<S sid ="53" ssid = "22">A predefined threshold is given for the final selection of the candidates.</S>
			<S sid ="54" ssid = "23">w i , j = w i Max c j × 1 tw i (1 ) wi,j : score of word i in semantic type j wi : count of word i in semantic type j Max cj : Max count of word k in semantic type j twi : count of semantic types that word i occurs in Fig.</S>
			<S sid ="55" ssid = "24">2.</S>
			<S sid ="56" ssid = "25">Procedure to mine key lexicons for each semantic type 2.2.2 Semantic SA/AO Patterns As indicated previously in Section 2.2, the semantic type checking for pronominal anaphors can be done through the extraction of the co-occurring SA/AO patterns extracted from GENIA 3.02p.</S>
			<S sid ="57" ssid = "26">We tagged each base noun phrase chunk from the corpus with its grammatical role and tagged it with UMLS-semantic type.</S>
			<S sid ="58" ssid = "27">Then we used Eq. 2 to score each pattern.</S>
			<S sid ="59" ssid = "28">At resolution, an antecedent candidate is concerned if its scores are greater than a given threshold.</S>
			<S sid ="60" ssid = "29">Table 1 is an example to show the key lexicons and verbs for two semantic types when the semantically-typed chunk is tagged with the role of subject.</S>
			<S sid ="61" ssid = "30">frequency(typei , verbj ) 1 score(type , verb ) = × (2) frequency(verbj ) No.</S>
			<S sid ="62" ssid = "31">of types(verbj ) Table 1.</S>
			<S sid ="63" ssid = "32">Some key lexicons and verbs for two semantic types Se ma nti c typ es k e y l e x i c o n s f o r e a c h t y p e k e y v e r b s f o r e a c h t y p e A mi no Ac id, Pe pti de, or Pr ote in pro tei n, pro du ct, cer evi sia e, e n d o n u c l e a s e , k i n a s e , a n ti g e n , r e c e p t o r , s y n t h a s e , r e d u c t a s e , a r a b i d o p s i s bin d, fun cti on, der ive , rai se, a t t e n u a t e , a b o l i s h , p r e s e n t , s i g n a l , l o c a l i z e , r e l e a s e Ge ne or Ge no me ge ne, on co ge ne s a c t i v a t e , c o m p a r e , l o c a t e , re g ul at e, re m ai n, tr a ns cr ib e, e n c o d e, di st ri b ut e, in di c at e, o c c u p y 2.3 Anaphora Recognition.</S>
			<S sid ="64" ssid = "33">Anaphor recognition is to recognize the target anaphors by filtering strategies.</S>
			<S sid ="65" ssid = "34">Pro- nominal anaphora recognition is done by filtering pleonastic-it instances by using the set of handcraft rules presented in [12].</S>
			<S sid ="66" ssid = "35">On two corpora, namely, Medstract and the new 100Medline corpus, 100% recognition accuracy was achieved.</S>
			<S sid ="67" ssid = "36">The remaining noun phrases indicated with ‘it’, ‘its’, ‘itself’, ‘they’, ‘them’, ‘themselves’ or ‘their’ are considered as pronominal anaphor.</S>
			<S sid ="68" ssid = "37">Others like ‘which’ and ‘that’ used in relative clauses are treated as pronominal anaphors and are resolved by the following rules.</S>
			<S sid ="69" ssid = "38">Rule 1: ‘that’ is treated as pleonastic-that if it is paired with pleonastic-it.</S>
			<S sid ="70" ssid = "39">Rule 2: For a relative clause with ‘which’ or ‘that’, the antecedents will be the noun phrases preceding to ‘which’ or ‘that’.</S>
			<S sid ="71" ssid = "40">On the other hand, noun phrases shown with ‘either’, ‘this’, ‘both’, ‘these’, ‘the’, and ‘each’ are considered as nominal anaphor candidates.</S>
			<S sid ="72" ssid = "41">Nominal anaphora recognition is approached by filtering those anaphor candidates, which have no referent antecedents or which have antecedents but not in the target biomedical semantic types.</S>
			<S sid ="73" ssid = "42">Following are two rules used to filter out those non-target nominal anaphors.</S>
			<S sid ="74" ssid = "43">Rule 1: Filter out those anaphor candidates if they are not tagged with one of the target UMLS semantic types (the same types in [2]) Rule 2: Filter out ‘this’ or ‘the’ + proper nouns with capital letters or numbers.</S>
			<S sid ="75" ssid = "44">We treated all other anaphors indicated with ‘this’ or ‘the + singular-NP’ as singular anaphors which have one antecedent only.</S>
			<S sid ="76" ssid = "45">Others are treated as plural nominal anaphors and their numbers of antecedents are shown in Table 2.</S>
			<S sid ="77" ssid = "46">At antecedent selection, we can discard those candidates whose numbers differ from the corresponding anaphors.</S>
			<S sid ="78" ssid = "47">Table 2.</S>
			<S sid ="79" ssid = "48">Number of Antecedents An aph or An tec ede nts # Eit her 2 Bot h 2 Ea ch Ma ny Th ey, Th eir, Th em, Th em sel ves Ma ny Th e +N um ber + no un Nu mb er Th ose +N um ber + no un Nu mb er Th ese +N um ber + no un Nu mb er 2.4 Antecedent Selection.</S>
			<S sid ="80" ssid = "49">2.4.1 Salience Grading The antecedent selection is based on the salience grading as shown in Table 3 in which seven features, including syntactic and semantic information, are concerned.</S>
			<S sid ="81" ssid = "50">Table 3.</S>
			<S sid ="82" ssid = "51">Salience grading for candidate antecedents Features Sco re F1 rece ncy 0, if in two sent enc es awa y fro m ana pho r 1, if in one sent enc e awa y fro m ana pho r 2, if in sam e sent enc e as ana pho r 02 F2 Sub ject and Obj ect Pref eren ce 1 F3 Gra mm atic al fun ctio n agre eme nt 1 F4 Nu mbe r Agr eem ent 1 F5 Se man tic Lon gest Co mm on Sub seq uen ce 0 to 3 F6 Se man tic Typ e Agr eem ent1 to +2 F7 Bio med ical ante ced ent pref eren ce2 if not or +2 The first feature F1 is recency which measures the distance between an anaphor and candidate antecedents in number of sentences.</S>
			<S sid ="83" ssid = "52">From the statistics of the two corpora, most of antecedents and their corresponding anaphors are within in two sentence distance, so a window size for finding antecedent candidates is set to be two sentences in the proposed system.</S>
			<S sid ="84" ssid = "53">The second feature F2 concerns the grammatical roles that an anaphor plays in a sentence.</S>
			<S sid ="85" ssid = "54">Since many anaphors are subjects or objects so antecedents with such grammatical tags are preferred.</S>
			<S sid ="86" ssid = "55">Furthermore, the antecedent candidates will receive more scores if they have grammatical roles (feature F3) or number agreement (feature F4) with their anaphors.</S>
			<S sid ="87" ssid = "56">On the other hand, features 5, 6, and 7 are related to semantic association.</S>
			<S sid ="88" ssid = "57">Feature 5 concerns the fact that the anaphor and its antecedents are semantical variants of each other, so antecedents will receive different scores (as shown below) on the basis of their variation: If there is total match of the semantic lexicons between an antecedent’s head word and its anaphor Then salience score = salience score + 3 Else If any antecedent component, other than head word, is matched with its anaphor Then salience score = salience score + 2 Else If any antecedent component is matched with its anaphor’s hyponym by WordNet 2.0 Then salience score = salience score + 1 Following are examples to show the cases: Example 2 case 1: total match: &lt;anaphor: each inhibitor, antecedent: PAH alkyne metabolism-based in- hibitors&gt; case 2: partial match: &lt;Anaphor: both receptor types, antecedent: the ETB receptor antagonist BQ788&gt; case 3: component match by using WordNet 2.0: &lt;Anaphor: this protein (hyponym: growth factor), antecedent: Cleavage and polyadenylation specificity factor&gt; If the antecedent can be found by UMLS, Then record its semantic types; Else If the antecedent contains the mined key lexicons of the anaphor’s semantic type, then record the semantic type; Else mine the semantic type by web mining in such a way that searching PubMed by issuing {anaphor Ana, antecedent Ai } pair and applying Eq. 3 to grade its semantic agreement for Ai.</S>
			<S sid ="89" ssid = "58">⎡ # of pages containing( Ana, Ai ) Score( Ai ) = Score( Ai ) −1 + ⎢ ⎤ ×10⎥ × 0.3 (3) ⎢ # of pages containing( Ai ) ⎥ Fig.</S>
			<S sid ="90" ssid = "59">3.</S>
			<S sid ="91" ssid = "60">Procedure to find semantic types for antecedent candidates Feature 6 is the semantic type agreement between anaphors and antecedents.</S>
			<S sid ="92" ssid = "61">As described in figure 3, the type finding for each antecedent can implemented with the help of UMLS.</S>
			<S sid ="93" ssid = "62">When there is no type information can be obtained from an antecedent, the type finding can be implemented with the help of PubMed, and the grading on such antecedent will be as Eq. 3.</S>
			<S sid ="94" ssid = "63">Feature 7 is biomedical antecedent preference.</S>
			<S sid ="95" ssid = "64">That is an antecedent which can be tagged with UMLS or the key lexicons database will receive more score.</S>
			<S sid ="96" ssid = "65">2.4.2 Antecedent Selection Strategies The noun phrases which precede a recognized anaphor in the range of two sentences will be treated as candidates and will be assigned with zero at initial state by the presented salience grader.</S>
			<S sid ="97" ssid = "66">Antecedents can be selected by the following strategies.</S>
			<S sid ="98" ssid = "67">(1) Best First: select antecedents with the highest salience score that is greater than a threshold (2) Nearest First: select the nearest antecedents whose salience value is greater than a given threshold For plural anaphors, their antecedents are selected as follows: (1) If the number of the antecedents is known, then select the same number of top-score antecedents.</S>
			<S sid ="99" ssid = "68">(2) If the number of antecedents is unknown, then select those antecedent candidates whose scores are greater than a threshold and whose grammatical patterns are the same as the top-score candidate.</S>
			<S sid ="100" ssid = "69">2.5 Experiments and Analysis.</S>
			<S sid ="101" ssid = "70">As mentioned in previous sections, a larger corpus was used for testing the proposed system.</S>
			<S sid ="102" ssid = "71">The corpus, denoted as ‘100Medline’, contains 100 MEDLINE abstracts including 43 abstracts (denoted as ’43Genia’ in Table 6) randomly selected from GENIA 3.02p and another 57 abstracts (denoted as ’57PubMed’ in Table 6) collected from the search results of PubMed (by issuing ‘these proteins’ and ‘these receptors’ in order to acquire more anaphor instances).</S>
			<S sid ="103" ssid = "72">There is no common abstract in the public MedStract and the new corpus.</S>
			<S sid ="104" ssid = "73">Table 4 shows the statistics of pronominal and nominal anaphors for each corpus.</S>
			<S sid ="105" ssid = "74">Table 4.</S>
			<S sid ="106" ssid = "75">Statistics of anaphor and antecedent pairs Ab str act s Se nte nc es Pr on om ina l ins tan ces No mi nal ins tan ces To tal Me dSt rac t 32 26 8 26 47 7343 GE NI A 43 47 9 98 63 16 157 Pu b M ed 57 56 5 69 11 8 18 7 The proposed approach was verified with experiments in two ways.</S>
			<S sid ="107" ssid = "76">One is to investigate the impact of the features which are concerned in the resolution.</S>
			<S sid ="108" ssid = "77">Another is to compare different resolution approaches.</S>
			<S sid ="109" ssid = "78">In order to boost our system, a simple generic algorithm is implemented to yield the best set of features by choosing best parents to produce offspring.</S>
			<S sid ="110" ssid = "79">In the initial state, we chose features (10 chromosomes), and chose crossover feature to produce offspring randomly.</S>
			<S sid ="111" ssid = "80">We calculated mutations for each feature in each chromosome, and evaluated chromosome with maximal F-Score.</S>
			<S sid ="112" ssid = "81">Top 10 chromosomes were chosen for next generation and the algorithm terminated if two contiguous generations did not increase the F-score.</S>
			<S sid ="113" ssid = "82">The time complexity associated with such approach is O(MN) where M is the number of candidate antecedents, N is number of anaphors.</S>
			<S sid ="114" ssid = "83">Table 5.</S>
			<S sid ="115" ssid = "84">F-Score of Medstract and 100Medlines Medstract 100Medlines Nominal Pronominal Nominal Pronominal Tota l Feat ures P R F P R F P R F P R F 33/5 6 33/4 7 23/2 6 23/2 6 130/ 184 130/ 178 145/ 167 145/ 167 58.9 3 70.2 1 64.0 8 88.4 6 88.4 6 88.4 6 70.6 5 73.3 4 71.3 3 86.8 2 86.8 2 86.8 2 Gen etic Feat ures F5, F6, F7 All F 5 F5, F6, F7 A l l F 5 P R F P R F P R F P R F 37/4 7 37/4 7 24/2 6 24/2 6 156/ 212 156/ 178 146/ 167 146/ 167 78.7 2 78.7 2 78.7 2 92.3 1 92.3 1 92.3 1 73.5 8 87.6 4 80.6 1 87.4 3 87.4 3 87.4 3 Table 6.</S>
			<S sid ="116" ssid = "85">Feature impact experiments M e d s t r a c t 4 3 G E N I A 5 7 P u b M e d No min al Pro no min al No min al Pro no min al No min al Pro no min al All 64.</S>
			<S sid ="117" ssid = "86">08 % 88.</S>
			<S sid ="118" ssid = "87">46 % 67.</S>
			<S sid ="119" ssid = "88">69 % 93.</S>
			<S sid ="120" ssid = "89">58 % 73.</S>
			<S sid ="121" ssid = "90">28 % 76.</S>
			<S sid ="122" ssid = "91">81 % All – F1 61.</S>
			<S sid ="123" ssid = "92">05 % 73.</S>
			<S sid ="124" ssid = "93">08 % 60.</S>
			<S sid ="125" ssid = "94">14 % 83.</S>
			<S sid ="126" ssid = "95">87 % 75.</S>
			<S sid ="127" ssid = "96">44 % 75.</S>
			<S sid ="128" ssid = "97">36 % All – F2 65.</S>
			<S sid ="129" ssid = "98">96 % 88.</S>
			<S sid ="130" ssid = "99">00 % 70.</S>
			<S sid ="131" ssid = "100">22 % 93.</S>
			<S sid ="132" ssid = "101">58 % 78.</S>
			<S sid ="133" ssid = "102">40 % 76.</S>
			<S sid ="134" ssid = "103">81 % All – F3 72.</S>
			<S sid ="135" ssid = "104">00 % 80.</S>
			<S sid ="136" ssid = "105">77 % 69.</S>
			<S sid ="137" ssid = "106">68 % 84.</S>
			<S sid ="138" ssid = "107">46 % 73.</S>
			<S sid ="139" ssid = "108">45 % 76.</S>
			<S sid ="140" ssid = "109">81 % All – F4 64.</S>
			<S sid ="141" ssid = "110">65 % 81.</S>
			<S sid ="142" ssid = "111">48 % 68.</S>
			<S sid ="143" ssid = "112">33 % 91.</S>
			<S sid ="144" ssid = "113">54 % 73.</S>
			<S sid ="145" ssid = "114">73 % 76.</S>
			<S sid ="146" ssid = "115">81 % All – F5 48.</S>
			<S sid ="147" ssid = "116">00 % 92.</S>
			<S sid ="148" ssid = "117">31 % 52.</S>
			<S sid ="149" ssid = "118">55 % 93.</S>
			<S sid ="150" ssid = "119">58 % 56.</S>
			<S sid ="151" ssid = "120">59 % 78.</S>
			<S sid ="152" ssid = "121">26 % All – F6 44.</S>
			<S sid ="153" ssid = "122">04 % 88.</S>
			<S sid ="154" ssid = "123">46 % 46.</S>
			<S sid ="155" ssid = "124">42 % 81.</S>
			<S sid ="156" ssid = "125">63 % 57.</S>
			<S sid ="157" ssid = "126">14 % 78.</S>
			<S sid ="158" ssid = "127">26 % All – F7 38.</S>
			<S sid ="159" ssid = "128">26 % 59.</S>
			<S sid ="160" ssid = "129">26 % 47.</S>
			<S sid ="161" ssid = "130">19 % 71.</S>
			<S sid ="162" ssid = "131">96 % 60.</S>
			<S sid ="163" ssid = "132">44 % 50.</S>
			<S sid ="164" ssid = "133">72 % Table 5 shows that anaphora resolution implemented with the genetic algorithm indeed achieves higher F-scores than the one when all features are concerned.</S>
			<S sid ="165" ssid = "134">Table 5 also shows that the semantic features play more important role than the syntactic features for nominal anaphora resolution.</S>
			<S sid ="166" ssid = "135">Similar results can be also found in Table 6 where the impact of each feature is justified.</S>
			<S sid ="167" ssid = "136">Moreover, Table 6 indicates that the pronominal anaphora resolution on 43Genia is better than that on the other two corpora.</S>
			<S sid ="168" ssid = "137">It implies that the mined SA/AO patterns from GENIA 3.02p corpus are helpful for pronominal anaphora resolution.</S>
			<S sid ="169" ssid = "138">Moreover, Table 7 proves that the key lexicons mined from UMLS for semantic type finding indeed enhance anaphora resolution, yet a slight improvement is found with the usage of PubMed search results.</S>
			<S sid ="170" ssid = "139">One of the reasons is few unknown instances in our corpora.</S>
			<S sid ="171" ssid = "140">On the other hand, comparisons with evaluation corpus, Medstract, were shown in Table 8 where the best-first strategy yielded higher F-score than the results by the nearest-first strategy.</S>
			<S sid ="172" ssid = "141">It also shows that the best-first strategy with the best selection by genetic approach achieves higher F-scores than the approach presented in [2].</S>
			<S sid ="173" ssid = "142">Table 7.</S>
			<S sid ="174" ssid = "143">Impacts of the mined semantic lexicons and the use of PubMed With semanti c lexicon s w/o semanti c lexicon s M eds tra ct. 100 M edl ine s M eds tra ct. 100 M edl ine s Wi th Pu b M ed 78 % 80.</S>
			<S sid ="175" ssid = "144">62 % 59 % 72.</S>
			<S sid ="176" ssid = "145">16 % Wi tho ut Pu b M ed 76 % 80.</S>
			<S sid ="177" ssid = "146">13 % 58 % 71.</S>
			<S sid ="178" ssid = "147">33 % Table 8.</S>
			<S sid ="179" ssid = "148">Comparisons among different strategies on MedstractBest FirstNearest First Castaño et al. [2]F scor e No min al Pron omi nal No min al Pron omi nal No min al Pron omi nal Tota l Feat ures 64.0 8% 88.4 6% 50.4 9% 73.4 7% Gen etic Feat ures F5, F6, F7 All - F5 F5, F6, F7All (F2, F5) F4, F5, F6 F4, F6, F7 78.7 2% 92.3 1% 61.1 8% 79.1 7% 74.4 0% 75.2 3%</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "3">
			<S sid ="180" ssid = "1">In this paper, the resolution for pronominal and nominal anaphora in biomedical literature is addressed.</S>
			<S sid ="181" ssid = "2">The resolution is constructed with a salience grading on various kinds of syntactic and semantic features.</S>
			<S sid ="182" ssid = "3">Unlike previous researches, we exploit more resources, including both domain-specific and general thesaurus and corpus, to verify the semantic association between anaphors and their antecedents.</S>
			<S sid ="183" ssid = "4">Experimental results on different corpora prove that the semantic features provided with the help of the outer resources indeed can enhance anaphora resolution.</S>
			<S sid ="184" ssid = "5">Compared to other approaches, the presented best-first strategy with the genetic-algorithm based feature selection can achieve the best resolution on the same evaluation corpus.</S>
	</SECTION>
</PAPER>
