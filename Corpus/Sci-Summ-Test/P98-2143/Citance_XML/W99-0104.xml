<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In this paper we present a new empirical method for coreference resolution, imple­ mented in the COCKTAIL system.</S>
		<S sid ="2" ssid = "2">There­ sults of COCKTAIL are used for lightweight abduction of cohesion and coherence struc­ t es.</S>
		<S sid ="3" ssid = "3">We show that referential cohesion can be integrated with · lexical cohesion to produce pragmaijc knowledge.</S>
		<S sid ="4" ssid = "4">Upon this knowledge coherence abduction takes place.</S>
	</ABSTRACT>
	<SECTION title="Motivation" number = "1">
			<S sid ="5" ssid = "5">Coreference evaluation was introduced as a new domain:-independent task at the 6th Message Under· standing Conference (MUC6) in 1995.</S>
			<S sid ="6" ssid = "6">The task fo­ cused on a subset of coreference, namely the identity coreference, established between nouns, pronouns and noun phrases (including proper names) that re­ fer to the same entity.</S>
			<S sid ="7" ssid = "7">In defining the coreference task (cf.</S>
			<S sid ="8" ssid = "8">(Hirschman and Chinchor, 1997)) special care was taken to use the coreference output not only for supporting Information Extraction(IE), the central task of the MUCs, but aJso to create means for research on coreference and discourse phenomena independent of IE.</S>
			<S sid ="9" ssid = "9">Annotated corpora were made available, using SGML tagging within the text stream.</S>
			<S sid ="10" ssid = "10">The anno­ tated texts served as training examples for a variety of coreference resolution znethods, that had to focus not only on precision and recall, but also on robust­ ness.</S>
			<S sid ="11" ssid = "11">Two general classes of approaches were distin­ guished.</S>
			<S sid ="12" ssid = "12">The first class is characterized by adapta­ tions of previously known reference algorjthms (e.g.</S>
			<S sid ="13" ssid = "13">(Lappin and Leass, 1994), (Brennan et al., 1987)) the scarce syntactic and semantic knowledge avail­ able in an IE system (e.g.</S>
			<S sid ="14" ssid = "14">(Kameyama, 1997)).</S>
			<S sid ="15" ssid = "15">The second class is based on statistical and machine learning techniques that rely on the tagged corpora Steven J. Maiorano AA T Washington, D.C. 20505 stevejmGucia.go v to extract features of the coreferential relations (e.g.</S>
			<S sid ="16" ssid = "16">(Aone and Bennett, 1994) (Kehler, 1997)).</S>
			<S sid ="17" ssid = "17">In the past two MUC competitions, the high scor­ ing systems achieved a recall in the high 50&apos;s to low 60&apos;s and a precision in the low 70&apos;s (cf.</S>
			<S sid ="18" ssid = "18">(Hirschman et al., 1998)).</S>
			<S sid ="19" ssid = "19">A study1 of the contribution . of each form of coreference to the overall performance · shows that generally, proper name anaphora resolu­ tion have the highest precision (69%}, followed by pronominal reference (62%).</S>
			<S sid ="20" ssid = "20">The worse -precision is obtained by the resolution of definite nominals anaphors (46%).</S>
			<S sid ="21" ssid = "21">However, these results need to be contrasted with the distribution of coreferentiallinks on the tagged corpora.</S>
			<S sid ="22" ssid = "22">The majority of coreference links (38.42%) connect names of people, organiza­ tions or locations.</S>
			<S sid ="23" ssid = "23">In addition, 19.68% of the tagged coreference links are accounted by appositives.</S>
			<S sid ="24" ssid = "24">Only 16.35% of the tagged coreferences are pronominal.</S>
			<S sid ="25" ssid = "25">Nominal anaphors account for 25.55% of the coref ·.</S>
			<S sid ="26" ssid = "26">erence links, and th6&apos;r resolution is generally poorly represented in IE systems.</S>
			<S sid ="27" ssid = "27">Due to the distribution of coreference links in newswire texts, a coreference module that is merely capable of handling recognition of appositives with high· precision and incorporates rules of name alias identification can achieve a baseline coreference pre­ cision up to 58.1%, without sophisticated syntactic or discourse information.</S>
			<S sid ="28" ssid = "28">Precision increaseob.</S>
			<S sid ="29" ssid = "29">tained by extending high-performance pronoun res­ olution methods (e.g.</S>
			<S sid ="30" ssid = "30">(Lappin and Leass, 1994)) to nominal coreference as well.</S>
			<S sid ="31" ssid = "31">Such enhancements rely on semantic and discourse knowledge.</S>
			<S sid ="32" ssid = "32">In this paper we desaibe COCKTAIL, a high­ performance coreference resolution system that op­ erates on a mixture of heuristics that combine se­ mantic and discourse information.</S>
			<S sid ="33" ssid = "33">The resulting 1The study, reported in (Karneyaixaa, 1997), was per­ formed on the coreference module of SRI&apos;s FASTUS (Ap­ pelt et al., 1993), an IE system representative of today&apos;a IE technology.</S>
			<S sid ="34" ssid = "34">coreference chains are shown to contribute in the derivation of cohesive chains and coherence graphs.</S>
			<S sid ="35" ssid = "35">Both cohesive and coherence structures are consid­ ered, partly because of their incremental complex­ ity and partly because the tradition (started with (Hobbs, 1979)) of studying the interaction of coref­ erence and coherence.</S>
			<S sid ="36" ssid = "36">Section 2 presents COCKTAIL and the coreference methods it built upon.</S>
			<S sid ="37" ssid = "37">Sections 3 and 4 describe the derivation the cohesion and co­ herence structures.</S>
	</SECTION>
	<SECTION title="Coreference  Resolution. " number = "2">
			<S sid ="38" ssid = "1">Coreference resoiution relies on a combination of lin­ g_uistic ancognitive aspects of language.</S>
			<S sid ="39" ssid = "2">Linguis­ tic constramts are proyided mostly by the syntactic modeling of language, whereas computational mod­ of discourse bring forward the cognitive assump­ &quot;tlons of anaphora resolution.</S>
			<S sid ="40" ssid = "3">Three different meth­ ods of combining anaphoric constraints are known to date.</S>
			<S sid ="41" ssid = "4">The first one integrates anaphora resolution in computational models of discourse interpretation.</S>
			<S sid ="42" ssid = "5">Dynamic properties of discourse, especially focusing and centering are invoked as the primary basiS for.</S>
			<S sid ="43" ssid = "6">identifying antecedents.</S>
			<S sid ="44" ssid = "7">Such computational meth­ ods were presented in (Grosz et al., 1995) and (Web- ber, 1988).</S>
			<S sid ="45" ssid = "8">· A second category of approaches combines a va.­ riety of syntactic, semantic and discourse factors as a multidimensional metric for ranking antecedent candidates.</S>
			<S sid ="46" ssid = "9">Anaphora resolution is determined by a composite of several distinct scoring procedures each of which scores the prominence of the candi with respect to a specific . type of information.</S>
			<S sid ="47" ssid = "10">The systems described in (Asher and Wada, 1988) (Car­ bonell and Brown, 1988) and (Rich and Luperfoy, 1988) are examples of the mixed evaluation strat­ egy.</S>
			<S sid ="48" ssid = "11">Alternatively, other discourse-based methods con­ sider coreference resolution a byproduct of the recognition of coherence relations between sentences.</S>
			<S sid ="49" ssid = "12">Such methods were presented in (Hobbs et al., 1993) and {Wilensky, 1978).</S>
			<S sid ="50" ssid = "13">Although AI-complete, this approach has the appeal that it resolves the most compUcated cases of coreCerence, uncovered by syn­ tactic or semantic cues.</S>
			<S sid ="51" ssid = "14">We have revisited these methods by setting the relation between coreference and coherence on empirical grounds.</S>
			<S sid ="52" ssid = "15">2.1 Pronominal Coreference.</S>
			<S sid ="53" ssid = "16">Two tendencies characterize current pronominal coreference algorithms.</S>
			<S sid ="54" ssid = "17">The first one makes use of the advances in the parsing technology or on the availability of large parsed corpora (e.g. &apos;1\-eebank (Marcus et al.1993)) to&quot; produce algorithms inspired by Hobbs&apos; b eline method (Hobbs, 1978).</S>
			<S sid ="55" ssid = "18">For ex­ ample, .the Resolution of Anaphora Procedure (RAP) introduced in (Lappin and Leass, 1994) combines syntactic information with agreement and salience constraints.</S>
			<S sid ="56" ssid = "19">Recently, a probabilistic approach to pronominal coreference resolution was also devised (Ge et al., 1998), using the parsed data available from Treebank.</S>
			<S sid ="57" ssid = "20">The knowledge-based method of Lappin and Leass produces better results.</S>
			<S sid ="58" ssid = "21">Never­ theless, RAPSTAT,a version of RAP obtained by using statistically measured preference patterns for the an­ tecedents, produced a slight enhancem nt of perfor­ mance over RAP.</S>
			<S sid ="59" ssid = "22">Other pronominal resolution approaches promote knowledge-poor methods (Mitkov, 1998), eitper by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents.</S>
			<S sid ="60" ssid = "23">The CogNIAC algorithm {Baldwin, 1997) uses six heuristic rules to resalv.e coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, l cal reiteration or immediate reference).</S>
			<S sid ="61" ssid = "24">BOth these al­ gorithm rely only on part-of-sptagging of texts and on patterns for NP identification.</S>
			<S sid ="62" ssid = "25">Their per­ formance (close to 90% for certain types of pro­ nouns) indicates that full syntactic knowledge is not required by certain forms of pronominal coreference.</S>
			<S sid ="63" ssid = "26">The same claim is made in (Kennedy and Bogu . raev, 1996) and (Kameyama, 1997), where algo­ rithms approximating RAP for poorer syntactic input obtain precision of 75% and 71%, respectively, a sur­ prising small precision decay frdm RAP&apos;s 86%.</S>
			<S sid ="64" ssid = "27">These results prompted us to devise COCKTAIL, a corefer­ ence resolution system, as a mixture of heuristics·· performing on the various syntactic, semantic.</S>
			<S sid ="65" ssid = "28">and discourse cues.</S>
			<S sid ="66" ssid = "29">COCKTAIL is a composite of heuris­ tics learned from the tagged corpora, which has the following novel characteristics: 1.</S>
			<S sid ="67" ssid = "30">COCKTAIL covers both nominal and pronoUD coref-.</S>
			<S sid ="68" ssid = "31">ereace, bnt distinct sets of heuristics operate Cor different forms of anaphors.</S>
			<S sid ="69" ssid = "32">We have devised sepa­ rate heuristics for reflexive, possessive, relative, 3rd person and 1st person pronouns.</S>
			<S sid ="70" ssid = "33">Similarly, definite nominals are treated differently than bare en: indef­ inite nominals.</S>
			<S sid ="71" ssid = "34">2.</S>
			<S sid ="72" ssid = "35">coatm performs semantic checks between an­ tec:edents and anaphors.</S>
			<S sid ="73" ssid = "36">These chec:Jcs combine sor­ tal constraints from WordNet with cooccurance in­ formation from (a) Tceebank and (b) conceptual glosses of WordNet.</S>
			<S sid ="74" ssid = "37">·</S>
	</SECTION>
	<SECTION title="InCOCKTAIL antecedents are sought not only in the. " number = "3">
			<S sid ="75" ssid = "1">accessible text region, but we also throughout the current corefelence chains.</S>
			<S sid ="76" ssid = "2">In this way cohesive in­ formation, represented in corefet:enee chains, is em­ ployed in. the resolution process.</S>
	</SECTION>
	<SECTION title="The heuristics of COCKTAIL allow for lexiCaliza.tious. " number = "4">
			<S sid ="77" ssid = "1">(e.g. when the uaphor is an adjunct of a communi­ cation verbs) and of simplified coherence cues (e.g. when the anaphor is the subject of verb add, the antecedent may be a preceding subject of a com­ . munication Vei&apos;b).</S>
			<S sid ="78" ssid = "2">To exemplify some COCKTAIL heuristics that ra.</S>
			<S sid ="79" ssid = "3">solve pronominal coreference, we first present heuris­ tics applicable for reflexive pronoun and then we list heuristics for possessive pronouns and 3rd person pronoun resolution.</S>
			<S sid ="80" ssid = "4">Brevity imposes the omission of heuristics for other forms of pronoun resolution.</S>
			<S sid ="81" ssid = "5">COCKTAIL operates by successively applying the fol­ lowing heuristics to the pronoun Pron: &lt;&gt;if (Pron is reflexive) then apply successively: oHeuristic 1-Reflexive(HIR) Search for PN, the closest proper name from Prt}n in tht; same sentence, in right to left order.</S>
			<S sid ="82" ssid = "6">if (PN agrees in number and gender with Pron) if (PN belongs to coreference chain CC) then Pick the element from CC which is closest to Pron in Te:tt.</S>
			<S sid ="83" ssid = "7">else Pick PN.</S>
			<S sid ="84" ssid = "8">oHeuristic 2-Reflexive(H2R) Search for a sequence Noun-Relative...Pronoun, in the same sentence, in right to left order.</S>
			<S sid ="85" ssid = "9">if {Noun agrees in number and gender with Pron) if (Noun belongs to coreference chain CC) then Pick the element from CC which is closeat to Pron in Te:rt.</S>
			<S sid ="86" ssid = "10">else Pick Noun.</S>
			<S sid ="87" ssid = "11">oHeuristic 9-Reflexive(H3R) Search for Pron&apos;, the cloaest pronoun from Pron in the same sentence, in right to left order.</S>
			<S sid ="88" ssid = "12">if (Pron&apos; agrees in number and gender with Pron) if (Pron&apos; belonga to coreference chain CC) then Pick the element from CC which is closest to Pron in Te:rt.</S>
			<S sid ="89" ssid = "13">else Pick Pron&apos;.</S>
			<S sid ="90" ssid = "14">oHeuristic4·Refle:rive(H4R) Search for Noun.c, the cloaest noun from Pron in the same aentence, in right to left order.</S>
			<S sid ="91" ssid = "15">if (Noun.c agreu in number and gender with Pron) then Pick Noun.c. Resolution examples tor reflexive pronouns are il­ lustrated in Table 1.</S>
			<S sid ="92" ssid = "16">The antecedents produced by COCKTAIL are boldfaced, whereas the referring ex­ pressions are emphasized.</S>
			<S sid ="93" ssid = "17">Both referring expressions and resolved antecedents and underlined.</S>
			<S sid ="94" ssid = "18">Precision results are listed in Table 2.</S>
			<S sid ="95" ssid = "19">Antecedents of reflexive pronouns are always sought in the same sentence.</S>
			<S sid ="96" ssid = "20">Antecedents of other types of pronouns are sought in preceding sentences too, starting from the immediately preceding sen­ tence.</S>
			<S sid ="97" ssid = "21">Inside the sentence, the search for a specific word is performed from the current position towards the beginning of the sentence, whereas in the pre Table 1: Examples of reflexive pronouns }i eu ris tic tt lR H 2 R H 3 R Pr eci Sl on on a te st set of 10 0 ra nd o ml y sel ect ed pr on ou ns 95 % 92 % 98 % 89 % Table 2: Coreference precision (reflexive pronouns) ceding sentences, the search starts at the beginning of the sentence and proceeds in a left to right fash­ ion.</S>
			<S sid ="98" ssid = "22">The same search order was used in (Kameyama, 1997).</S>
			<S sid ="99" ssid = "23">From now on, we indicate this search by Search1• This search is employed by he tics for possessive pronoun resolution: &lt;&gt;if (Pron is posaessive) (i.e. we have a sequence [Pron nouno), where nouno is the head of the NP containing Pron) then applv succeuively: oHeuristic 1Posseuiye(HlPos) Search1 for a poasessive conatruct of the form [noun1&apos;a noun2], if ([Pron nouno] and [noun1&apos;s noufl2) agree in gender, number and are semantically consistent) then if (noun2 belongs to coreference chain CC) and there is an·element from CC which is closest to Pron in Tezt, Pick that element.</S>
			<S sid ="100" ssid = "24">Pick noufl2.</S>
			<S sid ="101" ssid = "25">oHeuristic 1Pouqrive(H2Pos) . Search1 for PN, the cloaest·proper name from Pron if (PN agreu in number.</S>
			<S sid ="102" ssid = "26">and gender with Pron) if (PN belongs to coreference chain CC) then Pick the element from CC which is cloaest to Pron in Te:tt.</S>
			<S sid ="103" ssid = "27">else Pick PN.oHeuristic 3 Possessive(H3Pos) · Search for Pron&apos;, the closest pronoun from Pron if (Pron&apos; agrees in number and gender with Pron) . if (Pron&apos; belongs to coreference chain CC) and there is an element from CC VJhich is closest to Pron in Te:tt, Pick that element.</S>
			<S sid ="104" ssid = "28">else Pick Pron&apos;oHeuristic .4 Possessive(H4Pos) ·Search for Noun, the closest common noun from Pron if (Noun agreu in number and gender with Pron) if (Noun belongs to coreference chain CC) and there is an element from CC which is closest to Pron in Text, Pick that element.</S>
			<S sid ="105" ssid = "29">else Pick Noun . Examples and precision results are listed in Ta­ ble 3 and Table 4, respectively.</S>
			<S sid ="106" ssid = "30">Table 3: Examples of possessive pronouns Table 4: Coreference precision {possessive pronouns) Given a po ve pronoin a sequence [Pron Nouno], the antecedent Ante of Pron is semanti­ cally consistent if the same possessive relationship can be established between Ante and Nouno.</S>
			<S sid ="107" ssid = "31">the problem is that the possessive relation semantically co esponds to an open list of relations.</S>
			<S sid ="108" ssid = "32">For exam­ ple, N ouno may be a feature of Ante, Ante may own Nouno or Ante may have performed the action lex­ icalized by the nominalization Noono.</S>
			<S sid ="109" ssid = "33">COCKTAIL&apos;s test of tic consistency blends to­ gether information available from WqrdNet and on statistics gathered from &apos;freebank.</S>
			<S sid ="110" ssid = "34">Different consis­ tency checks are modeled for each of the heuristics.</S>
			<S sid ="111" ssid = "35">· We detail here the check that applies to heuristic HlPos, that resolves the possessive·from the first ex­ ple.listed in Table 3.</S>
			<S sid ="112" ssid = "36">FOr thiS heuristic, we have to test whether from the possessive [Ante Noont) we can grant the possessive [Ante Noono) as well.</S>
			<S sid ="113" ssid = "37">There are three cases that allow us to do so: • CtUe 1 Noon1 and Noono corefer.</S>
			<S sid ="114" ssid = "38">• There is a sense •1of Noon1 and a sense so of Noono such that a synonym of Noon:• or of its immediate hypemym is found in the gloss of N or viceversa.</S>
			<S sid ="115" ssid = "39">• There is a sense1•of Naun1 and a sense so of N ouno such that a common concept is found in their glosses.</S>
			<S sid ="116" ssid = "40">Cases 2 and 3 extend to synsets obtained through derivational morphology as well (e.g. nominaliza..</S>
			<S sid ="117" ssid = "41">tions).</S>
			<S sid ="118" ssid = "42">For cases 2 and 3 COCKTAIL reinforces the coreference hypothesis by using a possessive­ similarity metric based on Resnik&apos;s similarity mea­ sures for noun groups (Resnik, 1995).</S>
			<S sid ="119" ssid = "43">From a subset of Treeba.Dk, we collect all possessives, and measure whether the similarity class of N oun0 , N oun 1 and their eventual common concept is above a threshold produced off-line.</S>
			<S sid ="120" ssid = "44">Other pronominal coreference heuristics employ Search2, a search procedure that enhances Searcht.</S>
			<S sid ="121" ssid = "45">since it prefers antecedents that are immediately succeeded by relative pronouns.</S>
			<S sid ="122" ssid = "46">This search is in­ corporated in COCKTAIL&apos;s heuristics that resolve 3rd person pronominal coreference: oHeuristic 1-Pronoun(HlPron) Search2 in the same sentence for the same 3rd person pronoun Pron&apos; if (Pron&apos; belongs to coreference chain CC) and there is an element from CC which is closest to Pron in Te:l:t, Pick that element.</S>
			<S sid ="123" ssid = "47">else Pick Pron&apos;.</S>
			<S sid ="124" ssid = "48">oHeuristic !-fronoun(H2Pron) Search2 for PN, the closest proper name from Pron if (PN agrees in number and gender with·pron} if (PN belongs&apos; to coreference chain CC) . then Pick the element from CC which is closest to Pron in.Te:l:t. else Pick PN.</S>
			<S sid ="125" ssid = "49">oHeuristic 3-Pronoun(H3Pron) if Pron collocates with a communication verb then Search1 for pronoun Pron&apos;=I if (Pron&apos; belongs to coreference chain CC) and there is an element from CO which is closest to Pron in Te:r:t, Pick that element.</S>
			<S sid ="126" ssid = "50">else Pick Pron&apos;.</S>
			<S sid ="127" ssid = "51">oHeuristic .j-Pronour&amp;(H4Pron) if Pron collocates with a communication ver6 th.Searc/&amp;1 communicator Noun if (Noim belongs to coreferent% chain CC)­ and there is an element from CC which is closest to Pron in Tut, Pick that element.</S>
			<S sid ="128" ssid = "52">else Pick Noun.</S>
			<S sid ="129" ssid = "53">oHeuristic 5Pronou!!(H5Pron) Searfor Pron&apos;; the clo•ut pronoun from Prtm if (Pron&apos; agrees in number and gender with Pron) if {Pron&apos; belongs to coreference chain CC) and there is an element from CC which is closut to Pron in Tat, Pick that element.</S>
			<S sid ="130" ssid = "54">else Pick Pron&apos; oHeuristic 6fronou!!(H6Pron) Searfor Noun, the closut noun from .Pron if (Noun agreu in number ond gender with Pron) if (Noun belongs to coreference chain 09) and there is an element from 00 which is cloaest to Pron in Te:r:t, Pick thot element.</S>
			<S sid ="131" ssid = "55">else Pick Noun COCKTAIL doesn&apos;t employ semantic consistency checks for this form of pronominal coreference res olution.</S>
			<S sid ="132" ssid = "56">From our initial experiments, we do not see the need for special semantic consistency checks, since&apos;&quot;all.</S>
			<S sid ="133" ssid = "57">heuristics performed with precision in ex­ cess of 90% Part of this is explained by our usage of pleonastic filters and of recognizers of idiomatic us­ age.</S>
			<S sid ="134" ssid = "58">Table 5 illustrates some of the successful coref­ erence resolutions.</S>
			<S sid ="135" ssid = "59">II§ says that in many years as a ban he as grown accustomed to &quot;dealing with honest people 99% of the time.</S>
			<S sid ="136" ssid = "60">en.</S>
			<S sid ="137" ssid = "61">yr t es pains to reassure e voter that wiD see to it that the trade J»icture improves.</S>
			<S sid ="138" ssid = "62">A nurse w o e wi t e new patient isn&apos;t afraid of her temper.</S>
			<S sid ="139" ssid = "63">Table 5: Examples of 3rd person pronouns 2.2 Nominal Coreference.</S>
			<S sid ="140" ssid = "64">Noun phrases can represent referring expressions in a variety of cases.</S>
			<S sid ="141" ssid = "65">For example, it is known that not all definite NPs are anaphoric.</S>
			<S sid ="142" ssid = "66">Conditions that define anaphoric NPs are still under research (d.</S>
			<S sid ="143" ssid = "67">(Poesio and Vieira, 1998)).</S>
			<S sid ="144" ssid = "68">In the tagged corpora, we have found only 20.93% of the nominal corefer­ ence cases to be definites, the majority (78.85%) be­ ing bare·nominals2, and only 1.32% were in(lefinites.</S>
			<S sid ="145" ssid = "69">However, more than 50% of the nominal referring expressions were names of people, organizations or locations.</S>
			<S sid ="146" ssid = "70">Adding to this, 15.22% of nominal coref­ erence links are accounted by appositives.</S>
			<S sid ="147" ssid = "71">Based on this evidence, COCKTAIL implements special rules for name alias identUication and for robust recog­ nition of appositions.</S>
			<S sid ="148" ssid = "72">Moreover, the heuristics for nominal coreference resolution apply Search,, and enhancement of Search1 that searches starting with the coreference chains, and then with the accessi­ ble text.</S>
			<S sid ="149" ssid = "73">To resolve nominal coreference, COCKTAIL successively applies the following heuristics: oHeuristic 1NomiMz(HlNom) if (Noun is the head of an appositive) then Pick the preceding NP.</S>
			<S sid ="150" ssid = "74">oHeuristic 8Nomin@(H2Nom) if (Noun belongs to an NP, Search3jor NP&apos; such that Noun&apos;=same..name(head{NP),head{NP&apos;)) or Noun&apos;=same..name(adj(NP),adj(NP&apos;))) then if (Noun&apos; belongs to corefchain CC} then Pick the element from CC which u closest to Noun in Test.</S>
			<S sid ="151" ssid = "75">else Pick Noun&apos;.</S>
			<S sid ="152" ssid = "76">oHeu&apos;f&apos;Utic 3Nominol(H3Nom) if Noun is the head of an NP.</S>
			<S sid ="153" ssid = "77">then Searchs for proper name PN 2We count as bare nominals coreferring adjunCts as well.</S>
			<S sid ="154" ssid = "78">such that head{PN)=Noun if (PN belongs to coreference chain CC) and there is an element from CC which is closest to Noun in Text, Pick that element.</S>
			<S sid ="155" ssid = "79">else Pick PN.</S>
			<S sid ="156" ssid = "80">oHeuristic 4Nominol(H4Nom) Search3 for a proper name PN with the same category as Noun if (PN belongs to coreference chain CC) and there is an element from CC which is closest to Noun in Text, Pick that element.</S>
			<S sid ="157" ssid = "81">else Pick PN.</S>
			<S sid ="158" ssid = "82">oHeuristic 5-Nominal(H5Nom) Search3 Noun&apos; a synonym .or hyponym of Noun if (Noun&apos; belongs to coreference chain CC) and there is an element from CC which u closest to Noun in Text, Pick that element.</S>
			<S sid ="159" ssid = "83">else Pick Noun&apos;.</S>
			<S sid ="160" ssid = "84">oHeuristic 6-Nominal(H6Nom) Search3 /or Noun either indefinites or . in NPs having adjuncts in coreference chain CC) if Ante semanticolly consistent with Noun if (Ante belongs to core/chain CC) and there is an element from CC which is closest to Noun in Te:r:t, Pick that element: else Pick Ante.</S>
			<S sid ="161" ssid = "85">oileuristic 1-Nominal(H7Nom) if (Noun or one of his hypernyms or holonyms is a nominalization N} then Seard&amp; for the verb V deriving N or one of its synonyms) then Pick NP, the closest adjunct of V if (NP belongs to coreference chain CC} . and there is an element from CC which is clost to Noun in T, Pick that element.</S>
			<S sid ="162" ssid = "86">else Pick NP oHeuristic 8Nomin!l(H8Nom) if (Noun is the head of a prepositional phro.se pm:eded by a nominolization N) then Seard&amp; for the verb V deriving N or one of its synonyms) if (Noun&apos; is an adjunct of V) and (Noun&apos; and Noun have the same CIJtegOf&apos;1/ if (Noun&apos; belonfll to coreference chain CC) and there is an element from CC which u closest to Noun in Te:r:t, Pick that element.</S>
			<S sid ="163" ssid = "87">else Pick Noun&apos; oHev.ristic 9-Nominal(H9Nom) Search3 for Noun&apos;, a metonymy whose coercion is Noun Pick Noun&apos; \Wis¥PJltilWSih PJaeflFJFcte&amp;\%&apos;lkt8/A by appositions, whereas heuristic H2Nom promotes (Harabagiu, 1998) discusses a coercion ethodol­ ogy based on WordNet and Tceebank.</S>
			<S sid ="164" ssid = "88">Since in our test corpus there we very few cases of metonymic anaphors, Table 7 lists the precision of the other heuristics only.</S>
			<S sid ="165" ssid = "89">· Table 6: Examples of nominal coreference the term repetition indicator, when consistency checks apply.</S>
			<S sid ="166" ssid = "90">For this heuristic, consistency checks are conservative, imposing that either the adjuncts be identical, coreferring or the adjunct of the ref· erent be less specific than the antecedent.</S>
			<S sid ="167" ssid = "91">Speci· ficity principles apply also to H5Nom, where hy· ponymy is promoted, similarly to (Poesio and Vieira, 1998).</S>
			<S sid ="168" ssid = "92">Heuristic H3Nom allows coreference between &quot;the Securities and &amp;change Commission&quot; and &quot;the commission&quot; but it bans links between &quot;Reardon Steel Co.• and &quot;tom of steel&quot;.</S>
			<S sid ="169" ssid = "93">Many times coreferring nominals share also se­ mantic relations (e.g. synonymy).</S>
			<S sid ="170" ssid = "94">Heuristic H5Nom identifies such cases, by applying consistency checks.</S>
			<S sid ="171" ssid = "95">Based on experiments with the coreference module of FASTUS, where this heuristic was initially imple.</S>
			<S sid ="172" ssid = "96">mented, we require that most frequent senses of nouns be promoted.</S>
			<S sid ="173" ssid = "97">The same precedence of fre.</S>
			<S sid ="174" ssid = "98">quent senses is implemented in the assignment of categories, defined as the immediate WordNet J,rr pernym.</S>
			<S sid ="175" ssid = "99">The category of proper names is dictated · by the proper name recognizer, assigning such cate.</S>
			<S sid ="176" ssid = "100">gories as Person, Organization or Location.</S>
			<S sid ="177" ssid = "101">&quot;In this way, coreference between •JBM&quot; and &quot;the wounded computer giant&quot; can be established, since sense 3 of noun giant is Organization, the category of &quot;IBM•..</S>
			<S sid ="178" ssid = "102">Similar category·based semantic· checks allow the recognition of the antecedent of proceeds from the second example listed in Table 6.</S>
			<S sid ="179" ssid = "103">The hypernym.</S>
			<S sid ="180" ssid = "104">of procttJda is gain, whose gloss genus is amount, the category of 11.78 billion.</S>
			<S sid ="181" ssid = "105">· Semantic checks are also required in H7Nom and H8Nom, heuristic that rely on derivational morphology.</S>
			<S sid ="182" ssid = "106">The first example from Table 6 is resolved by H7Nom, since discussion the nominalization of discuss has the category communication, a hypernym of subject.</S>
			<S sid ="183" ssid = "107">The antecedent is the object of the verb discuss.</S>
			<S sid ="184" ssid = "108">The last heuristic, H9Nom identifies coreferring links with coerced entities of nominals.</S>
			<S sid ="185" ssid = "109">Coercions are obtained as paths of meronyms or hypernyms.</S>
			<S sid ="186" ssid = "110">Table 7: Nominal ooreference precision The empirical methods employed ii1COCKTAIL are an alternative to the inductive approaches described in (Cardie and Wagstaff, 1999) and (McCarthy and Lehnert, 1995).</S>
			<S sid ="187" ssid = "111">Our results show that high·precision empirical techniques can be ported from pronominal coreference resolution to the more difficult problem of nominal coreference.</S>
			<S sid ="188" ssid = "112">3 Lexical Cohesion.</S>
			<S sid ="189" ssid = "113">The heuristics.</S>
			<S sid ="190" ssid = "114">encoded in COCKTAIL make light use of textual cohesion, i.e. the property of texts to &quot;stick together&quot;3 by using related words.</S>
			<S sid ="191" ssid = "115">Both pronominal and nominal coherence resolution heuristics use cohesion eues indicated by term rep­ etition while nominal coreference relies on semantic relations between anaphors and their antecedents.</S>
			<S sid ="192" ssid = "116">In addition, coreference chains are a form of textual cohesion, known as referential cohesion (d.</S>
			<S sid ="193" ssid = "117">(Halli· day and Hassan, 1976)).</S>
			<S sid ="194" ssid = "118">Until now, lezical cohesion, arising from semantic connections between words, was successfully used as ·the oply form of textual cohesive structure, known as leacal c!&amp;ains.</S>
			<S sid ="195" ssid = "119">At present there are three methods of generating lexical cbalns.</S>
			<S sid ="196" ssid = "120">The first one, imple­ mented in the TextTiling algorithm (Hearst, 1997),.</S>
			<S sid ="197" ssid = "121">counts the frequencies of term repetitions and is an ideal, lightweight tool for segmenting texts.</S>
			<S sid ="198" ssid = "122">The sec· ond method, adds owledge from semantic dictio­ naries (e.g. Roget&apos;s Thesaunu in the work of (Mor­ ris and HirSt, 1991) or WorrlNet in the methods presented in (Bariilay and Elhadad, 1997), (Hirst and StOnge, 1998)).</S>
			<S sid ="199" ssid = "123">Besides term repetition, this approach recogniZes relations between text words that are connected in the dictionaries with prede.</S>
			<S sid ="200" ssid = "124">fined patterns.</S>
			<S sid ="201" ssid = "125">This method was applied for gen­ eration of text summaries, the recognition of the intentional structure of texts and in the detection of malapropism.</S>
			<S sid ="202" ssid = "126">The third method is based on a path·finding algorithm detailed in (H8rabagiu and Moldovan, 1998).</S>
			<S sid ="203" ssid = "127">This method creates a richer 3Definition introduced in (Halliday and Hassan, 1976) and (Morris and Hirst, 1991) · . structure, useful for the abduction of coherere­ lations from the knowledge encoded in WordNet.</S>
			<S sid ="204" ssid = "128">Here we describe a new cohesion structure that (a) incorporates both lexical and referential cohesion and (b) produces a unique chain that contains not only single words, but also textual entities encom­ passing head-adjunct lists.</S>
			<S sid ="205" ssid = "129">We use the finite-state parses of FASTUS (Appelt et al., 1993) for recogniz­ ing these entities, but the method extends to any basic phrasal parser4 • We produce this novel cohesive structure to ex­ ploit the close relation between text cohesion and coherence.</S>
			<S sid ="206" ssid = "130">It is known (d.</S>
			<S sid ="207" ssid = "131">(Harabagiu, 1999)} that cohesion, as a surface indicator of the text coherence, can indicate the lexica-semantic lmowledge upon which coherence is inferred.</S>
			<S sid ="208" ssid = "132">Our aim is to use thiS cohesive chain for producing axiomatic knowledge for CICERO, a TACITUS-like system that abducts co­ herence relations.</S>
			<S sid ="209" ssid = "133">TACITUS (Hobbs et al., 1993) is a successful abductive system when provided with ex­ tensive pragiWJ.tic a,nd linguistic lmowledge.</S>
			<S sid ="210" ssid = "134">CICERO is designed as a lightweight version of TACITUS, that performs reliable abductions.</S>
			<S sid ="211" ssid = "135">with minimal knowl­ edge and eft&apos;ective searches.</S>
			<S sid ="212" ssid = "136">&apos;franslating all the lexi­ cal, morphological, sync and semantic ambigu­ ities from texts would make the search intractable.</S>
			<S sid ="213" ssid = "137">Out solution for CICERO is to use a cohesive chain to create manageable knowledge upon which the ab­ duction can be performed.</S>
			<S sid ="214" ssid = "138">Section 4 describes this knowledge and the operation of CICERO.</S>
			<S sid ="215" ssid = "139">Our cohesive chain is a linked structure consist­ ing of three parts: (1) the connected te:d entity, (2) its incoming and outgoing pointer6 and (3) a le:r;ico­ seman#c graph, containing paths of WordNet con-· cepts and relations.</S>
			<S sid ="216" ssid = "140">The lexico-semantic structure is later translated in the axiomatic knowledge that supports coherence inference.</S>
			<S sid ="217" ssid = "141">To exemplify the co­ hesion chain, we use the followirig text, spanned by the coreference chains produced with COCKTAIL: (Toys R Ush ncametl Miclu&amp;el Goldstein (chief ezecutive offic:eti2, ending ytorl of qeculations about who will succeed [Charlu .£Gzcuw]s, [the [toy retaileri1 &apos;• founder and chief l&apos;ln:hitect.]a (Robert Nakalone)4, [lonner vice chaimal&apos;ln and · widely regarded a· the other •mow contender for [the top eucutive}2 &apos;• job}4, wa nl&apos;lmed prerident and chief operating officer, both new politions.</S>
			<S sid ="218" ssid = "142">The indexes indicate the four coreference chains.</S>
			<S sid ="219" ssid = "143">This text has only two repeating terms, the verb name and the noun ezecutive, thus it generates little information with the TeztTiling algorithm.</S>
			<S sid ="220" ssid = "144">The co­ hesion method detailed in (Barzilay and Elh3dad, 1997) can detect one lexical chain: [chief execu­ tive officer, chairman, executive, president).</S>
			<S sid ="221" ssid = "145">We would like to obtain richer lexica semantic informa­ tion, thus we build a cohesion chain that contains larger textual entities.</S>
			<S sid ="222" ssid = "146">To recognize the entities, we use the coreference chains and the following parse,Q - J&apos;.J:!</S>
			<S sid ="223" ssid = "147">--------------------------------- I&lt;PBilSE(BlSIC):-a..e4&quot;&gt; I&lt;PBIASE(PEBSOIIAKE):&quot;Kichaal Goldateia&quot;&gt; I&lt;PBIASE(IC):•Cbief ezecutiYe officer&quot;&gt; I&lt;PIIUSE(COJIJIA):•&quot;.&gt; I&lt;PIUS£(CI!IIIID):&quot;•Ji4ia&amp;&quot;&gt; t&lt;PBUS£(10):•rean of apaculatiOA&quot;&gt; I&lt;PIIASE(PIEP):&quot;about&quot;&gt; I&lt;PBIASE(IELPIO):&quot;vbo&quot;&gt; I&lt;PBRlSE(BlSIC):&quot;vill .uccee4&quot;&gt; I&lt;PBRAS£(PEBSOIIAKE):•Cbarlea Laaaru8 , the toy retailer •a fowutar Ull chief arcbitect&quot;&gt; I&lt;PBIASE(PWOIIAKE):&quot;lo&apos;ban lakuoaa, fozurlJ dee cllainaa&quot;&gt; I&lt;PBIASE(COIJ):&quot;aa4&quot;&gt; I&lt;PBilS£(8lSIC):&quot;vi4ely resard•4&quot;&gt; I&lt;PBIASECPIEP):•aa•&gt; I&lt;PIUSE(IC):&quot;tlae other aerioa COJIUDdar&quot;&gt; I&lt;PIIUSE(PIEP):&quot;tor&quot;&gt; I&lt;PBIIS!(IC):e top ezecati••&apos;a job&quot;&gt; I&lt;PBRlSE(COJIJIA): &apos;•&gt; I&lt;PIIUSE(BlSlC):&quot;vaa ........., I&lt;PIUS£(10):&quot;pnaidaat Ul4 Cbief opentiJIC officer, both uw poaitiou&quot;&gt; - Textual entitieseither basic phrases contained in the coreference chains· or lists of phrases collected from the parse, by scanning for all NGs or NAME­ phrases directly connected to a verb phrase through a Subject, Object or prepositional relations.</S>
			<S sid ="224" ssid = "148">For ex­ ample, as phrase &quot;Toy1 R Us•is the antecedent from a coreference chain, its corresponding textual entity is:· mwo-p , - U J =--+ m e ------ -, ncame40bjectl-&quot;Michoel Goldstein &apos;1 raamef0bject2-&quot;chief eRCUtive ofli«r The cohesion chain for our text is illustrated in Figure 1.</S>
			<S sid ="225" ssid = "149">The algorithm that generates cohesion chains is: Algorithm Cohesion-Chain-Builder 1.</S>
			<S sid ="226" ssid = "150">if (current NG belong• to a coreference chain) . Create its teztual entity TE and place -it on the chain I. if {the antecedent il already in the chain) Place the coreference pointer between the two TE• 3.if (the corefer&apos;mce ilnot an appolitive) · · Populate the le:r;ico-semantic structure(TE) · The derivation of the lexica-semantic structure (LSS) follows the steps: l.for every relation r(Wt,w2) from a TB if (there il81 a sen.e of w1 and 82 a sen.e of q such that the same relation r&apos;(w3, w4) is found in a gloss from the hierarchies of 1 or 1 4Such a parser operates on part-of-sPeech tagged text, with several noun and verb grouping rules.</S>
			<S sid ="227" ssid = "151">Add relation r&apos; to LSS !.for every word w in a TB if (there is a concept C in LSS such that there is a collocation [w c) in a gloss from the hierorchy(w)) Add w to LSS 3.</S>
			<S sid ="228" ssid = "152">if {word w is already in LSS) Add new connection to w in LSS For example, in the first TE illustrated in Fig­ ure I, we have the relation Object(name,CEO).</S>
			<S sid ="229" ssid = "153">We find an Object relation also in the gloss of appoint, the hypemym of sense 3 of verb name.</S>
			<S sid ="230" ssid = "154">The new Ob­ ject relation connect verb assume with the synset . {duty, responsibility, obligation}.</S>
			<S sid ="231" ssid = "155">A hypemym of CEO is manager, collocating with position in the gloss of managership.</S>
			<S sid ="232" ssid = "156">Noun position belongs to the hierarchy of duty, thus the new Object relation can be added to the LSS.</S>
			<S sid ="233" ssid = "157">Po,,..</S>
			<S sid ="234" ssid = "158">WordNet.</S>
			<S sid ="235" ssid = "159">The complex structure of our cohesion chains help guiding these inferences.</S>
			<S sid ="236" ssid = "160">For each textual unit, defined from the parse of the text, axiomatic knowledge produced.</S>
			<S sid ="237" ssid = "161">The acquisi­ tion of axiomatic knowledge is cued by the concepts and relations from the LSS portion of the cohesion chain, and is mined from WordNet.</S>
			<S sid ="238" ssid = "162">CICERO, our sys­ tem, adds to this knowledge axioms that feature the characteristics of every coherence relation.</S>
			<S sid ="239" ssid = "163">CICERO&apos;s job is to abduct the coherence structure of a text.</S>
			<S sid ="240" ssid = "164">To do so, it follows the steps: l.Cor every textual unit TU;.</S>
			<S sid ="241" ssid = "165">f. Derive pmgmatic lmowledge for TU;.</S>
			<S sid ="242" ssid = "166">3.- for every pair (TU;,TUJ),i #:- j ,4.</S>
			<S sid ="243" ssid = "167">for every coherence relation &apos;R.1 5.</S>
			<S sid ="244" ssid = "168">hypothesize &apos;R.t.(TU;.,TUj) .........</S>
			<S sid ="245" ssid = "169">Tur EnliiiR (TB) Lufco.S--* Stnlclan ( LSS) Sub}«t :\&quot;Ob]«&lt;J 6.</S>
			<S sid ="246" ssid = "170">Pe rfonn abduction &apos;R.t.(TUit TUj} 7.</S>
			<S sid ="247" ssid = "171">Choo se cheapest abduction 0rpDizaiiOII \_ Pcn.l Objm2 cblefeiiCCUiiw o&apos;iiicci suaMd &apos; ()bJ«&lt; l&apos;cnoa2 11-- Illy raaller I... toy retailer&apos;s founder lllld cheif udlitecr Ob)posilioa )Obi= assume For the text illustrated in Section 3, this proce­ dure generates the coherence graph illustrated in: Figure 2.</S>
			<S sid ="248" ssid = "172">l b o U l w b o w i l l O t a d c s L a z a n a s . l b e r o y r e l l i J u &apos; f o u l l d e r U l d c h i e f a n : h i l e C L IIIIIIC4 I Raben Nakasone.</S>
			<S sid ="249" ssid = "173">former vice c:bainnan Uld lbe ocher $Cri0111 CODICJider for the wu names praidcat and cbief operllilla offic:cr.</S>
			<S sid ="250" ssid = "174">bolb positloai.</S>
			<S sid ="251" ssid = "175">lPas.]</S>
			<S sid ="252" ssid = "176">Ob}ft:tZ] presldea&amp;1- &apos;-I-- r- hlp aecuthe ..... adler--*rlar die aeclllift&apos;a Figure 1: Cohesion chain 4 Text Coherence.</S>
			<S sid ="253" ssid = "177">We base our consideration of textual coherence on the definitions introduced in (Hobbs, 1985).</S>
			<S sid ="254" ssid = "178">The formal definition of relations that capture the coher­ ence between textual assertions is based on the re­ lations between the states they infer, their changes and their logical connections.</S>
			<S sid ="255" ssid = "179">States, changes and logical connections can be retrieved from pragmatic knowledge, accessible in lexical knowledge bases like topeaeculiorc;sjob Figure 2: Coherence graph We exemplify the operation of CICERO on this text by presenting the way it derives the Elaboration rela­ tion between the textual unit from the first sentence that announces the nomination of Michael Goldstein (TU,.)</S>
			<S sid ="256" ssid = "180">and the textual unit from the same sentence that deals with the succession of Charles Lazarus (TU6) • F&apos;ltSt, CICERO generates the knowledge upon which the abductions can be pert&apos;ormed.</S>
			<S sid ="257" ssid = "181">This knowl­ edge is represented in axiomatic form,.</S>
			<S sid ="258" ssid = "182">using the no­ tation proposed in (Hobbs et al., 1993} and previ­ ously implemented in TACITUS.</S>
			<S sid ="259" ssid = "183">In this formalism each text unit represents·an event or a state, thus has a special variable ·e associated with it.</S>
			<S sid ="260" ssid = "184">Events are lexicalized by verbs, which are maped into pred­ icates verb(e,z,y), where% represents the subject of the event, and y represents its object (in the case of intransitive verbs, y is not attached to a predicate, 36 whereas in the case of bitransitive verbs, 11 is mapped· into Y1 and Y2).&quot;·Moreover, predicates from the text are related to other predicates, derived from a knowl­ edge base.</S>
			<S sid ="261" ssid = "185">These relations are captured in first or­ der predicate calculus.</S>
			<S sid ="262" ssid = "186">For example, the pragmatic knowledge used fe&gt;r the derivation of the Elaboration relation between TUa and TUbis:</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "5">
			<S sid ="263" ssid = "1">We have introduced a new empirical method for coreference resolution, implemented in the COCKTAIL system.</S>
			<S sid ="264" ssid = "2">The results of this algorithm are used to guide the abduction of coherence relations, as per­ formed in our CI&lt;;ERO system.</S>
			<S sid ="265" ssid = "3">In an intermediary step, a rich cohesion structure is produced.</S>
			<S sid ="266" ssid = "4">This novel relation between coreference and coh ce contrasts with the traditional.</S>
			<S sid ="267" ssid = "5">view that coreference is a byproduct of coherence resolution.</S>
			<S sid ="268" ssid = "6">Moreover, we reiterate the belief that coherence builds up from cohesion.</S>
	</SECTION>
</PAPER>
