<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We present UBIU, a language independent system for detecting full coreference chains, composed of named entities, pronouns, and full noun phrases which makes use of memory based learning and a feature model following Rahman and Ng</S>
	</ABSTRACT>
	<SECTION title="the task" number = "1">
			<S sid ="2" ssid = "2">“Coreference Resolution in Multiple Languages” (SemEval Task 1 (Recasens et al., 2010)) in the context of the 5th International Workshop on Semantic Evaluation.</S>
			<S sid ="3" ssid = "3">1 Introduction.</S>
			<S sid ="4" ssid = "4">Coreference resolution is a field in which major progress has been made in the last decade.</S>
			<S sid ="5" ssid = "5">After a concentration on rule-based systems (cf.</S>
			<S sid ="6" ssid = "6">e.g.</S>
			<S sid ="7" ssid = "7">(Mitkov, 1998; Poesio et al., 2002; Markert and Nissim, 2005)), machine learning methods were embraced (cf.</S>
			<S sid ="8" ssid = "8">e.g.</S>
			<S sid ="9" ssid = "9">(Soon et al., 2001; Ng and Cardie, 2002)).</S>
			<S sid ="10" ssid = "10">However, machine learning based coreference resolution is only possible for a very small number of languages.</S>
			<S sid ="11" ssid = "11">In order to make such resources available for a wider range of languages, language independent systems are often regarded as a partial solution.</S>
			<S sid ="12" ssid = "12">To this day, there have been only a few systems reported that work on multiple languages (Mitkov, 1999; Harabagiu and Maiorano, 2000; Luo and Zitouni, 2005).</S>
			<S sid ="13" ssid = "13">However, all of those systems were geared towards predefined language sets.</S>
			<S sid ="14" ssid = "14">In this paper, we present a language independent system that does require syntactic resources for each language but does not require any effort for adapting the system to a new language, except for minimal effort required to adapt the feature extractor to the new language.</S>
			<S sid ="15" ssid = "15">The system was completely developed within 4 months, and will be extended to new languages in the future.</S>
	</SECTION>
	<SECTION title="UBIU: System Structure. " number = "2">
			<S sid ="16" ssid = "1">The UBIU system aims at being a language- independent system in that it uses a combination of machine learning, in the form of memory-based learning (MBL) in the implementation of TiMBL (Daelemans et al., 2007), and language independent features.</S>
			<S sid ="17" ssid = "2">MBL uses a similarity metric to find the k nearest neighbors in the training data in order to classify a new example, and it has been shown to work well for NLP problems (Daelemans and van den Bosch, 2005).</S>
			<S sid ="18" ssid = "3">Similar to the approach by Rahman and Ng (2009), classification in UBUI is based on mention pairs (having been shown to work well for German (Wunsch, 2009)) and uses as features standard types of linguistic annotation that are available for a wide range of languages and are provided by the task.</S>
			<S sid ="19" ssid = "4">Figure 1 shows an overview of the system.</S>
			<S sid ="20" ssid = "5">In preprocessing, we slightly change the formatting of the data in order to make it suitable for the next step in which language dependent feature extraction modules are used, from which the training and test sets for the classification are extracted.</S>
			<S sid ="21" ssid = "6">Our approach is untypical in that it first extracts the heads of possible antecedents during feature extraction.</S>
			<S sid ="22" ssid = "7">The full yield of an antecedent in the test set is determined after classification in a separate module.</S>
			<S sid ="23" ssid = "8">During postprocessing, final decisions are made concerning which of the mention pairs are considered for the final coreference chains.</S>
			<S sid ="24" ssid = "9">In the following sections, we will describe feature extraction, classification, markable extraction, and postprocessing in more detail.</S>
			<S sid ="25" ssid = "10">2.1 Feature Extraction.</S>
			<S sid ="26" ssid = "11">The language dependent modules contain finite state expressions that detect the heads based on the linguistic annotations.</S>
			<S sid ="27" ssid = "12">Such a language module requires a development time of approximately 1 person hour in order to adapt the regular expressions 96 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 96–99, Uppsala, Sweden, 1516 July 2010.</S>
			<S sid ="28" ssid = "13">Qc 2010 Association for Computational Linguistics Figure 1: Overview of the system.</S>
			<S sid ="29" ssid = "14">to the given language data (different POS tagsets, differences in the provided annotations).</S>
			<S sid ="30" ssid = "15">This is the only language dependent part of the system.</S>
			<S sid ="31" ssid = "16">We decided to separate the task of finding heads of markables, which then serve as the basis for the generation of the feature vectors, from the identification of the scope of a markable.</S>
			<S sid ="32" ssid = "17">For the English sentence “Any details or speculation on who specifically, we don’t know that at this point.”, we first detect the heads of possible antecedents, for example “details”.</S>
			<S sid ="33" ssid = "18">However, the decision on the scope of the markable, i.e. the decision between “details” or “Any details or speculation on who specifically” is made in the postprocessing phase.</S>
			<S sid ="34" ssid = "19">One major task of the language modules is the check for cyclic dependencies.</S>
			<S sid ="35" ssid = "20">Our system relies on the assumption that cyclic dependencies do not occur, which is a standard assumption in dependency parsing (Ku¨ bler et al., 2009).</S>
			<S sid ="36" ssid = "21">However, since some of the data sets in the multilingual task contained cycles, we integrated a module in the preprocessing step that takes care of such cycles.</S>
			<S sid ="37" ssid = "22">After the identification of the heads of mark- ables, the actual feature extraction is performed.</S>
			<S sid ="38" ssid = "23">The features that were used for training a classifier (see Table 1) were selected from the feature pool # Feature Description 1 mj - the antecedent 2 mk - the mention to be resolved</S>
	</SECTION>
	<SECTION title="Y if mj  is pron.; else N" number = "3">
			<S sid ="39" ssid = "1">5 Y if mj is a nested NP; else N 6 number - Sg.</S>
			<S sid ="40" ssid = "2">or Pl. 7 gender - F(emale), M(ale), N(euter), U(nknown) 8 Y if mk is a pronoun; else N 9 Y if mk is a nested NP; else N 10 semantic class – extracted from the NEs in the data 11 the nominative case of mk if pron.; else NA 12 C if the mentions are the same string; else I 13 C if one mention is a substring of the other; else I 14 C if both mentions are pron.</S>
			<S sid ="41" ssid = "3">and same string; else I 15 C if both mentions are both non-pron.</S>
			<S sid ="42" ssid = "4">and same string; else I 16 C if both m. are pron.</S>
			<S sid ="43" ssid = "5">and either same pron.</S>
			<S sid ="44" ssid = "6">or diff.</S>
			<S sid ="45" ssid = "7">w.r.t. case; NA if at least one is not pron.; else I 17 C if the mentions agree in number; I if not; NA if the number for one or both is unknown 18 C if both m. are pron.</S>
			<S sid ="46" ssid = "8">I if neither 19 C if both m. are proper nouns; I if neither; else NA 20 C if the m. have same sem.</S>
			<S sid ="47" ssid = "9">class; I if not; NA if the sem.</S>
			<S sid ="48" ssid = "10">class for one or both m. is unknown 21 sentence distance between the mentions 22 concat.</S>
			<S sid ="49" ssid = "11">values for f. 6 for mj and mk 23 concat.</S>
			<S sid ="50" ssid = "12">values for f. 7 for mj and mk 24 concat.</S>
			<S sid ="51" ssid = "13">values for f. 3 for mj and mk 25 concat.</S>
			<S sid ="52" ssid = "14">values for f. 5 for mj and mk 26 concat.</S>
			<S sid ="53" ssid = "15">values for f. 10 for mj and mk 27 concat.</S>
			<S sid ="54" ssid = "16">values for f. 11 for mj and mk Table 1: The pool of features for all languages.</S>
			<S sid ="55" ssid = "17">presented by Rahman and Ng (2009).</S>
			<S sid ="56" ssid = "18">Note that not all features could be used for all languages.</S>
			<S sid ="57" ssid = "19">We extracted all the features in Table 1 if the corresponding type of annotation was available; otherwise, a null value was assigned.</S>
			<S sid ="58" ssid = "20">A good example for the latter concerns the gender information represented by feature 7 (for possible feature values cf.</S>
			<S sid ="59" ssid = "21">Table 1).</S>
			<S sid ="60" ssid = "22">Let us consider the following two entries - the first from the German data set and the second from English: 1.</S>
			<S sid ="61" ssid = "23">Regierung Regierung Regierung NN NN.</S>
			<S sid ="62" ssid = "24">cas=d|num=sg|gend=fem cas=d|num=sg|gend=fem 31 31 PN PN . . ..</S>
			<S sid ="63" ssid = "25">2.</S>
			<S sid ="64" ssid = "26">law law NN NN NN NN 2 2 PMOD PMOD . . .</S>
			<S sid ="65" ssid = "27">Extracting the value from entry 1, where gend=fem, is straightforward; the value being F. However, there is no gender information provided in the English data (entry 2).</S>
			<S sid ="66" ssid = "28">As a result, the value for feature 7 is U for the closed task.</S>
			<S sid ="67" ssid = "29">2.2 Classifier Training.</S>
			<S sid ="68" ssid = "30">Based on the features extracted with the feature extractors described above, we trained TiMBL.</S>
			<S sid ="69" ssid = "31">Then we performed a non-exhaustive parameter optimization across all languages.</S>
			<S sid ="70" ssid = "32">Since a full optimization strategy would lead to an unmanageable number of system runs, we concentrated on varying k, the number of nearest neighbors considered in classification, and on the distance metric.</S>
			<S sid ="71" ssid = "33">Furthermore, the optimization is focused on language independence.</S>
			<S sid ="72" ssid = "34">Hence, we did not optimize each classifier separately but selected parameters that lead to best average results across all languages of the shared task.</S>
			<S sid ="73" ssid = "35">In our opinion, this ensures an acceptable performance for new languages without further adaptation.</S>
			<S sid ="74" ssid = "36">The optimal settings for all the given languages were k=3 with the Overlap distance and gain ratio weighting.</S>
			<S sid ="75" ssid = "37">2.3 Markable Extraction.</S>
			<S sid ="76" ssid = "38">The markable extractor makes use of the dependency relation labels.</S>
			<S sid ="77" ssid = "39">Each syntactic head together with all its dependents is identified as a separate markable.</S>
			<S sid ="78" ssid = "40">This approach is very sensitive to incorrect annotations and to dependency cycles in the data set.</S>
			<S sid ="79" ssid = "41">It is also sensitive to differences between the syntactic annotation and markables.</S>
			<S sid ="80" ssid = "42">In the Dutch data, for example, markables for named entities (NE) often exclude the determiner, a nominal dependent in the dependency annotation.</S>
			<S sid ="81" ssid = "43">Thus, the markable extractor suggests the whole phrase as a markable, rather than just the NE.</S>
			<S sid ="82" ssid = "44">During the development phase, we determined experimentally that the recognition of markables is one of the most important steps in order to achieve high accuracy in coreference resolution: We conducted an ablation study on the training data set.</S>
			<S sid ="83" ssid = "45">We used the train data as training set and the devel data as testing set and investigated three different settings: 1.</S>
			<S sid ="84" ssid = "46">Gold standard setting: Uses gold markable.</S>
			<S sid ="85" ssid = "47">annotations as well as gold linguistic annotations (upper bound).</S>
			<S sid ="86" ssid = "48">2.</S>
			<S sid ="87" ssid = "49">Gold linguistic setting: Uses automatically.</S>
			<S sid ="88" ssid = "50">determined markables and gold linguistic annotations.</S>
			<S sid ="89" ssid = "51">3.</S>
			<S sid ="90" ssid = "52">Regular setting: Uses automatically deter-.</S>
			<S sid ="91" ssid = "53">mined markables and automatic linguistic information.</S>
			<S sid ="92" ssid = "54">Note that we did not include all six languages: we excluded Italian and Dutch because there is no gold-standard linguistic annotation provided.</S>
			<S sid ="93" ssid = "55">The results of the experiment are shown in Table 2.</S>
			<S sid ="94" ssid = "56">From those results, we can conclude that the.</S>
			<S sid ="95" ssid = "57">S La ng.</S>
			<S sid ="96" ssid = "58">IM CE AF M U C B3 BL AN C 1 S p a ni s h C at al a n E n gl is h G er m a n 85.</S>
			<S sid ="97" ssid = "59">8 85.</S>
			<S sid ="98" ssid = "60">5 96.</S>
			<S sid ="99" ssid = "61">1 93.</S>
			<S sid ="100" ssid = "62">6 52.</S>
			<S sid ="101" ssid = "63">3 56.</S>
			<S sid ="102" ssid = "64">0 68.</S>
			<S sid ="103" ssid = "65">7 70.</S>
			<S sid ="104" ssid = "66">0 12.</S>
			<S sid ="105" ssid = "67">8 11.</S>
			<S sid ="106" ssid = "68">6 17.</S>
			<S sid ="107" ssid = "69">9 19.</S>
			<S sid ="108" ssid = "70">7 60.</S>
			<S sid ="109" ssid = "71">0 59.</S>
			<S sid ="110" ssid = "72">4 74.</S>
			<S sid ="111" ssid = "73">9 73.</S>
			<S sid ="112" ssid = "74">4 56.</S>
			<S sid ="113" ssid = "75">9 51.</S>
			<S sid ="114" ssid = "76">9 52.</S>
			<S sid ="115" ssid = "77">7 64.</S>
			<S sid ="116" ssid = "78">5 2 S p a ni s h C at al a n E n gl is h G er m a n 61.</S>
			<S sid ="117" ssid = "79">0 60.</S>
			<S sid ="118" ssid = "80">8 72.</S>
			<S sid ="119" ssid = "81">1 57.</S>
			<S sid ="120" ssid = "82">7 41.</S>
			<S sid ="121" ssid = "83">5 40.</S>
			<S sid ="122" ssid = "84">5 54.</S>
			<S sid ="123" ssid = "85">1 45.</S>
			<S sid ="124" ssid = "86">5 11.</S>
			<S sid ="125" ssid = "87">3 9.6 11.</S>
			<S sid ="126" ssid = "88">6 12.</S>
			<S sid ="127" ssid = "89">2 42.</S>
			<S sid ="128" ssid = "90">4 41.</S>
			<S sid ="129" ssid = "91">4 57.</S>
			<S sid ="130" ssid = "92">3 45.</S>
			<S sid ="131" ssid = "93">7 48.</S>
			<S sid ="132" ssid = "94">7 48.</S>
			<S sid ="133" ssid = "95">3 50.</S>
			<S sid ="134" ssid = "96">3 44.</S>
			<S sid ="135" ssid = "97">3 3 S p a ni s h C at al a n E n gl is h G er m a n 61.</S>
			<S sid ="136" ssid = "98">2 61.</S>
			<S sid ="137" ssid = "99">3 71.</S>
			<S sid ="138" ssid = "100">9 57.</S>
			<S sid ="139" ssid = "101">5 41.</S>
			<S sid ="140" ssid = "102">8 40.</S>
			<S sid ="141" ssid = "103">9 54.</S>
			<S sid ="142" ssid = "104">7 45.</S>
			<S sid ="143" ssid = "105">4 10.</S>
			<S sid ="144" ssid = "106">3 11.</S>
			<S sid ="145" ssid = "107">3 13.</S>
			<S sid ="146" ssid = "108">3 12.</S>
			<S sid ="147" ssid = "109">0 42.</S>
			<S sid ="148" ssid = "110">3 41.</S>
			<S sid ="149" ssid = "111">9 57.</S>
			<S sid ="150" ssid = "112">4 45.</S>
			<S sid ="151" ssid = "113">6 48.</S>
			<S sid ="152" ssid = "114">5 48.</S>
			<S sid ="153" ssid = "115">5 50.</S>
			<S sid ="154" ssid = "116">3 44.</S>
			<S sid ="155" ssid = "117">2 Table 2: Experiment results (as F1 scores) where IM is identification of mentions and S - Setting.</S>
			<S sid ="156" ssid = "118">figures in Setting 2 and 3 are very similar.</S>
			<S sid ="157" ssid = "119">This means that the deterioration from gold to automatically annotated linguistic information is barely visible in the coreference results.</S>
			<S sid ="158" ssid = "120">This is a great advantage, since gold-standard data has always proved to be very expensive and difficult or impossible to obtain.</S>
			<S sid ="159" ssid = "121">The information that proved to be extremely important for the performance of the system is the one providing the boundaries of the markables.</S>
			<S sid ="160" ssid = "122">As shown in Table 2, the latter leads to an improvement of about 20%, which is observable in the difference in the figures of Setting 1 and 2.</S>
			<S sid ="161" ssid = "123">The results for the different languages show that it is more important to improve markable detection than the linguistic information.</S>
			<S sid ="162" ssid = "124">2.4 Postprocessing In Section 2.1, we described that we decided to separate the task of finding heads of markables from the identification of the scope of a markable.</S>
			<S sid ="163" ssid = "125">Thus, in the postprocessing step, we perform the latter (by the Markables Extractor module) as well as reformat the data for evaluation.</S>
			<S sid ="164" ssid = "126">Another very important step during postprocessing is the selection of possible antecedents.</S>
			<S sid ="165" ssid = "127">In cases where more than one mention pair is classified as coreferent, only the pair with highest confidence by TiMBL is selected.</S>
			<S sid ="166" ssid = "128">Since nouns can be discourse-new, they do not necessarily have a coreferent antecedent; pronouns however, require an antecedent.</S>
			<S sid ="167" ssid = "129">Thus, in cases where all possible antecedents for a given pronoun are classified as not coreferent, we select the closest subject as antecedent; or if this heuristic is not successful, the antecedent that has been classified as not coreferent with the lowest confidence score (i.e. the highest distance) by TiMBL.</S>
			<S sid ="168" ssid = "130">La ng.</S>
			<S sid ="169" ssid = "131">S IM CE AF M U C B3 BL AN C C at al a n E n gl is h G er m a n S p a ni sh It al ia n D u t c h G R G R G R G R R R 84.</S>
			<S sid ="170" ssid = "132">4 59.</S>
			<S sid ="171" ssid = "133">6 95.</S>
			<S sid ="172" ssid = "134">9 74.</S>
			<S sid ="173" ssid = "135">2 94.</S>
			<S sid ="174" ssid = "136">0 57.</S>
			<S sid ="175" ssid = "137">6 83.</S>
			<S sid ="176" ssid = "138">6 60.</S>
			<S sid ="177" ssid = "139">0 40.</S>
			<S sid ="178" ssid = "140">6 34.</S>
			<S sid ="179" ssid = "141">7 52.</S>
			<S sid ="180" ssid = "142">3 38.</S>
			<S sid ="181" ssid = "143">4 65.</S>
			<S sid ="182" ssid = "144">7 53.</S>
			<S sid ="183" ssid = "145">6 68.</S>
			<S sid ="184" ssid = "146">2 44.</S>
			<S sid ="185" ssid = "147">8 51.</S>
			<S sid ="186" ssid = "148">7 39.</S>
			<S sid ="187" ssid = "149">4 32.</S>
			<S sid ="188" ssid = "150">9 17.</S>
			<S sid ="189" ssid = "151">0 11.</S>
			<S sid ="190" ssid = "152">7 8.6 20.</S>
			<S sid ="191" ssid = "153">5 14.</S>
			<S sid ="192" ssid = "154">2 21.</S>
			<S sid ="193" ssid = "155">9 10.</S>
			<S sid ="194" ssid = "156">4 12.</S>
			<S sid ="195" ssid = "157">7 10.</S>
			<S sid ="196" ssid = "158">0 3.6 8.3 58.</S>
			<S sid ="197" ssid = "159">8 40.</S>
			<S sid ="198" ssid = "160">9 74.</S>
			<S sid ="199" ssid = "161">8 58.</S>
			<S sid ="200" ssid = "162">7 75.</S>
			<S sid ="201" ssid = "163">7 46.</S>
			<S sid ="202" ssid = "164">6 58.</S>
			<S sid ="203" ssid = "165">3 41.</S>
			<S sid ="204" ssid = "166">6 34.</S>
			<S sid ="205" ssid = "167">8 17.</S>
			<S sid ="206" ssid = "168">0 52.</S>
			<S sid ="207" ssid = "169">2 47.</S>
			<S sid ="208" ssid = "170">8 54.</S>
			<S sid ="209" ssid = "171">0 51.</S>
			<S sid ="210" ssid = "172">0 64.</S>
			<S sid ="211" ssid = "173">5 48.</S>
			<S sid ="212" ssid = "174">0 54.</S>
			<S sid ="213" ssid = "175">3 48.</S>
			<S sid ="214" ssid = "176">4 37.</S>
			<S sid ="215" ssid = "177">2 32.</S>
			<S sid ="216" ssid = "178">3 Table 3: Final system results (as F1 scores) where IM is identification of mentions and S - Setting.</S>
			<S sid ="217" ssid = "179">For more details cf.</S>
			<S sid ="218" ssid = "180">(Recasens et al., 2010).</S>
			<S sid ="219" ssid = "181">3 Results.</S>
			<S sid ="220" ssid = "182">UBIU participated in the closed task (i.e. only information provided in the data sets could be used), in the gold and regular setting.</S>
			<S sid ="221" ssid = "183">It was one of two systems that submitted results for all languages, which we count as preliminary confirmation that our system is language independent.</S>
			<S sid ="222" ssid = "184">The final results of UBIU are shown in Table 3.</S>
			<S sid ="223" ssid = "185">The figures for the identification of mentions show that this is an area in which the system needs to be improved.</S>
			<S sid ="224" ssid = "186">The errors in the gold setting result from an incompatibility of our two-stage markable annotation with the gold setting.</S>
			<S sid ="225" ssid = "187">We are planning to use a classifier for mention identification in the future.</S>
			<S sid ="226" ssid = "188">The results for coreference detection show that English has a higher accuracy than all the other languages.</S>
			<S sid ="227" ssid = "189">We assume that this is a consequence of using a feature set that was developed for English (Rahman and Ng, 2009).</S>
			<S sid ="228" ssid = "190">This also means that an optimization of the feature set for individual languages should result in improved system performance.</S>
	</SECTION>
	<SECTION title="Conclusion and Future Work. " number = "4">
			<S sid ="229" ssid = "1">We have presented UBIU, a coreference resolution system that is language independent (given different linguistic annotations for languages).</S>
			<S sid ="230" ssid = "2">UBIU is easy to maintain, and it allows the inclusion of new languages with minimal effort.</S>
			<S sid ="231" ssid = "3">For the future, we are planning to improve the system while strictly adhering to the language independence.</S>
			<S sid ="232" ssid = "4">We are planning to separate pronoun and definite noun classification, with the possibility of using different feature sets.</S>
			<S sid ="233" ssid = "5">We will also investigate language independent features and implement a markable classifier and a negative instance sampling module.</S>
	</SECTION>
</PAPER>
