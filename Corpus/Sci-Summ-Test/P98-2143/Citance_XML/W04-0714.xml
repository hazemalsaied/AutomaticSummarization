<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In this paper we are concerned with identifying the topics of sentences in Chinese texts.</S>
		<S sid ="2" ssid = "2">The key elements of the centering model of local discourse coherence are employed to identify the topic which is the most salient element in a Chinese sentence.</S>
		<S sid ="3" ssid = "3">Due to the phenomenon of zero anaphora occurring in Chinese texts frequently, in addition to the centering model, we further employ the constraint rules to identify the antecedents of zero anaphors.</S>
		<S sid ="4" ssid = "4">Unlike most traditional approaches to parsing sentences based on the integration of complex linguistic information and domain knowledge, we work on the output of a part-of-speech tagger and use shallow parsing instead of complex parsing to identify the topics from sentences.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">One of the most striking characteristics in a topic-prominent language like Chinese is the important element, “topic,” in a sentence which can represent what the sentence is about (Li and Thompson, 1981).</S>
			<S sid ="6" ssid = "6">That is, if we can identify topics from Chinese sentences, we can obtain the most information embedded in the text.</S>
			<S sid ="7" ssid = "7">In this paper, we tend to identify the topic of each utterance within a discourse based on the centering model.</S>
			<S sid ="8" ssid = "8">However, in many natural languages, elements that can be easily deduced by the reader are frequently omitted from expressions in texts.</S>
			<S sid ="9" ssid = "9">The elimination of anaphoric expressions is termed zero anaphor (ZA) which often occurs in topic position in a Chinese sentence, due to their prominence in discourse.</S>
			<S sid ="10" ssid = "10">Accordingly, to accomplish the task of topic identification, we have to solve the problem of zero anaphora resolution.</S>
			<S sid ="11" ssid = "11">There are several methods of anaphora resolution.</S>
			<S sid ="12" ssid = "12">One method is to integrate different knowledge sources or factors (e.g. gender and number agreement, c-command constraints, semantic information) that discount unlikely candidates until a minimal set of plausible candidates is obtained (Grosz et al., 1995; Lappin and Leass, 1994; Okumura and Tamura, 1996; Walker et al., 1998; Yeh and Chen, 2001).</S>
			<S sid ="13" ssid = "13">Anaphoric relations between anaphors and their antecedents are identified based on the integration of linguistic and domain knowledge.</S>
			<S sid ="14" ssid = "14">However, it is very labor-intensive and time-consuming to construct a domain knowledge base.</S>
			<S sid ="15" ssid = "15">Another method employs statistical models or AI techniques, such as machine learning, to compute the most likely candidate (Aone and Bennett, 1995; Connoly et al., 1994; Ge et al., 1998; Seki et al., 2002).</S>
			<S sid ="16" ssid = "16">This method can sort out the above problems.</S>
			<S sid ="17" ssid = "17">However, it heavily relies upon the availability of sufficiently large text corpora that are tagged, in particular, with referential information (Stuckardt, 2002).</S>
			<S sid ="18" ssid = "18">Our method is an inexpensive, fast and reliable procedure for anaphora resolution, which relies on cheaper and more reliable NLP tools such as part- of-speech (POS) tagger and shallow parsers (Baldwin, 1997; Ferrández et al., 1998; Kennedy and Boguraev, 1996; Mitkov, 1998; Yeh and Chen, 2003).</S>
			<S sid ="19" ssid = "19">The resolution process works from the output of a POS tagger enriched with annotations of grammatical function of lexical items in the input text stream.</S>
			<S sid ="20" ssid = "20">The shallow parsing technique is used to detect zero anaphors and identifies the noun phrases preceding the anaphors as antecedents.</S>
			<S sid ="21" ssid = "21">In the following sections we first describe the centering model which including the key elements of the centering model of local discourse coherence.</S>
			<S sid ="22" ssid = "22">In Section 3 we describe the details of shallow parsing we employed.</S>
			<S sid ="23" ssid = "23">In Section 4 we explain our ZA resolution method based on the centering model and the constraint rules.</S>
			<S sid ="24" ssid = "24">The method of topic identification in Chinese sentences is illustrated in Section 5.</S>
			<S sid ="25" ssid = "25">In the last section the conclusions are made.</S>
	</SECTION>
	<SECTION title="Centering Model. " number = "2">
			<S sid ="26" ssid = "1">In the centering theory (Grosz and Sidner, 1986; Grosz et al, 1995; Walker et al., 1994; Strube and Hahn, 1996), the &apos;attentional state&apos; was identified as a basic component of discourse structure that consisted of two levels of focusing: global and local.</S>
			<S sid ="27" ssid = "2">For Grosz and Sidner, the centering theory provided a model for monitoring local focus and yielded the centering model which was designed to account for the difference in the perceived coherence of discourses.</S>
			<S sid ="28" ssid = "3">In the centering model, each utterance U in a discourse segment has two structures associated with it, called forward- looking centers, Cf(U), and backward-looking center, Cb(U).</S>
			<S sid ="29" ssid = "4">The forward-looking centers of Un, Cf(Un), depend only on the expressions that constitute that utterance.</S>
			<S sid ="30" ssid = "5">They are not constrained by features of any previous utterance in the discourse segment (DS), and the elements of Cf(Un) retaining are to be preferred over sequences of shifting.</S>
			<S sid ="31" ssid = "6">Rule I represents one function of pronominal reference: the use of a pronoun to realize the Cb signals the hearer that the speaker is continuing to talk about the same thing.</S>
			<S sid ="32" ssid = "7">Psychological research and cross-linguistic research have validated that the Cb is preferentially realized by a pronoun in English and by equivalent forms (i.e. zero anaphora) in other languages (Grosz et al, 1995).</S>
			<S sid ="33" ssid = "8">Rule II reflect the intuition that continuation of the center and the use of retentions when possible to produce smooth transitions to a new center provide a basis for local coherence.</S>
			<S sid ="34" ssid = "9">For example in (1), the subjects of the utterance (1b) and (1d) are eliminated, and their antecedents are identified as the subjects of the preceding utterances (1a) and (1c) respectively1 according to the centering model.</S>
			<S sid ="35" ssid = "10">are partially ordered to reflect relative prominence in Un.</S>
			<S sid ="36" ssid = "11">Grosz et al., in their paper (Grosz et al, (1) a. i i 1995), assume that grammatical roles are the major Electronics stock receive USA high-tech determinant for ranking the forward-looking stock heavy-fall affect i centers, with the order “Subject &gt; Object(s) &gt; Electronics stockswere affected by high Others”.</S>
			<S sid ="37" ssid = "12">The superlative element of Cf(Un) may become the Cb of the following utterance, Cb(Un+1).</S>
			<S sid ="38" ssid = "13">tech stocks fallen heavily in America.</S>
			<S sid ="39" ssid = "14">b. i In addition to the structures for centers, Cb, and Cf, the centering model specifies a set of (Electronics stocks)i continue fall (Electronics stocks)i continued falling down.</S>
			<S sid ="40" ssid = "15">j constraints and rules (Grosz et al, 1995; Walker et c. al. 1994).</S>
			<S sid ="41" ssid = "16">Constraints For each utterance Ui in a discourse segment consisting of utterances U1, …, Um: Securities stocksj also have relative respondence Securities stocksj also had respondence.</S>
			<S sid ="42" ssid = "17">d. j j 1.</S>
			<S sid ="43" ssid = "18">Ui has exactly one Cb..</S>
			<S sid ="44" ssid = "19">2.</S>
			<S sid ="45" ssid = "20">Every element of Cf(Ui) must be realized in Ui..</S>
	</SECTION>
	<SECTION title="Ranking	of	elements	in	Cf(Ui)	guides. " number = "3">
			<S sid ="46" ssid = "1">determination of Cb(Ui+1).</S>
	</SECTION>
	<SECTION title="The choice of Cb(Ui) is from Cf(Ui-1), and can. " number = "4">
			<S sid ="47" ssid = "1">(Securities stocks) (Securities stocks) another.</S>
			<S sid ="48" ssid = "2">3 Shallow Parsing.</S>
			<S sid ="49" ssid = "3">continue fall by close.</S>
			<S sid ="50" ssid = "4">j fell by close one after not be from Cf(Ui2) or other prior sets of Cf.</S>
			<S sid ="51" ssid = "5">Backward-looking centers, Cbs, are often omitted or pronominalized and discourses that continue centering the same entity are more coherent than those that shift from one center to another.</S>
			<S sid ="52" ssid = "6">This means that some transitions are preferred over others.</S>
			<S sid ="53" ssid = "7">These observations are encapsulated in two rules: Shallow (or partial) parsing which is an inexpensive, fast and reliable method does not deliver full syntactic analysis but is limited to parsing smaller constituents such as noun phrases or verb phrases (Abney, 1996; Li and Roth, 2001; Mitkov, 1999).</S>
			<S sid ="54" ssid = "8">For example, the sentence (2) can be divided as follows: (2) Rules For each utterance Ui in a discourse segment consisting of utterances U1, …, Um: I. If any element of Cf(Ui) is realized by a pronoun in Ui+1 then the Cb(Ui+1) must be Hualien became the popular tourist attraction.</S>
			<S sid ="55" ssid = "9">Æ [NP ] [VP ] [NP ] 1 We use a  b to denote a zero anaphor, where the subscript a is the index of the zero anaphor itself and the superscript b is the index of the referent.</S>
			<S sid ="56" ssid = "10">A single realized by a pronoun also.</S>
			<S sid ="57" ssid = "11">without any script represents an intrasentential ¢ zero II.</S>
			<S sid ="58" ssid = "12">Sequences of continuation are preferred over sequence of retaining; and sequences of anaphor.</S>
			<S sid ="59" ssid = "13">Also note that a superscript attached to an NP is used to represent the index of the referent.</S>
			<S sid ="60" ssid = "14">[NP Hualien] [VP became] [NP the popular tourist attraction] Given a Chinese sentence, our method of shallow parsing is divided into the following steps: First the sentence is divided into a sequence of POS-tagged words by employing a segmentation program, AUTOTAG, which is a POS tagger developed by CKIP, Academia Sinica (CKIP, 1999).</S>
			<S sid ="61" ssid = "15">Second the sequence of words is parsed into smaller constituents such as noun phrases and verb phrases with phrase-level parsing.</S>
			<S sid ="62" ssid = "16">Each phrase is represented as a word list.</S>
			<S sid ="63" ssid = "17">Then the sequence of word lists is transformed into triples, [S,P,O].</S>
			<S sid ="64" ssid = "18">For example in (3), (3b) is the output of sentence (3a) produced by AUTOTAG, and (3c) is the triple representation.</S>
			<S sid ="65" ssid = "19">(3) a. [ (Nc) (VG) (VH) (DE) (VA) (Na)] b. [NP,[ ]], [VP,[ ]], [NP,[ , , Triple4(S,none,none) Æ np(S).</S>
			<S sid ="66" ssid = "20">The vtp(P) denotes the predicate is a transitive verb phrase, which contains a transitive verb in the rightmost position in the phrase; likewise the vip(P) denotes the predicate is an intransitive verb phrase, which contains an intransitive verb in the rightmost position in the phrase.</S>
			<S sid ="67" ssid = "21">In the rule Triple3, the prep(P) denotes the predicate is a preposition.</S>
			<S sid ="68" ssid = "22">The Triple4 is employed if only a sentence contains only one noun phrase and no other constituent.</S>
			<S sid ="69" ssid = "23">If all the rules in the Triple Rules failed, the ZA Triple Rules are employed to detect zero anaphor (ZA) candidates.</S>
			<S sid ="70" ssid = "24">ZA Triple Rules: Triple1z1(zero,P,O)Æ vtp(P), np(O).</S>
			<S sid ="71" ssid = "25">Triple1z2(S,P,zero)Æ np(S), vtp(P).</S>
			<S sid ="72" ssid = "26">Triple1z3(zero,P,zero)Æ vtp(P).</S>
			<S sid ="73" ssid = "27">z1 , ]] Triple2 (zero,P,none)Æ vip(P).</S>
			<S sid ="74" ssid = "28">c. [[ ], [ ], [ , , , ]] The definition of triple representation is illustrated in Definition 1.The triple here is a simple representation which consists of three elements: S, P and O which correspond to the Subject (noun phrase), Predicate (verb phrase) and Object (noun phrase) respectively in a clause.</S>
			<S sid ="75" ssid = "29">Definition 1: A Triple T is characterized by a 3tuple: T = [S, P, O] where z S is a list of nouns whose grammatical role is the subject of a clause.</S>
			<S sid ="76" ssid = "30">z P is a list of verbs or a preposition whose grammatical role is the predicate of a clause.</S>
			<S sid ="77" ssid = "31">z O is a list of nouns whose grammatical Triple3z1(zero,P,O) Æ prep(P), np(O).</S>
			<S sid ="78" ssid = "32">Triple4z1(zero,P,O) Æ coconj(P), np(O).</S>
			<S sid ="79" ssid = "33">The zero anaphora in Chinese generally occurs in the topic, subject or object position.</S>
			<S sid ="80" ssid = "34">The rules Triple1z1, Triple2z1, and Triple3z1 detect the zero anaphora occurring in the topic or subject position.</S>
			<S sid ="81" ssid = "35">The rule Triple1z2 detects the zero anaphora in the object position and Triple1z3 detect the zero anaphora occurring in both subject and object positions.</S>
			<S sid ="82" ssid = "36">In the Triple4, the coconj(P) denotes a coordinating conjunction appearing in the initial position of a clause.</S>
			<S sid ="83" ssid = "37">For example in (4), there are two triples generated.</S>
			<S sid ="84" ssid = "38">In the second triple, zero denotes a zero anaphor according to Triple1z1.</S>
			<S sid ="85" ssid = "39">(4) Zhangsan entered a competition and won the champion.</S>
			<S sid ="86" ssid = "40">role is the object of a clause.</S>
			<S sid ="87" ssid = "41">Æ [[[ ], [ ]], [[zero], [ ], [ In the step of triple transformation, the sequence of word lists as shown in (3b) is transformed into triples by employing the Triple Rules.</S>
			<S sid ="88" ssid = "42">The Triple Rules is built by referring to the Chinese syntax.</S>
			<S sid ="89" ssid = "43">There are four kinds of Triples in the Triple Rules, which corresponds to five basic clauses: subject + transitive verb + object, subject + intransitive verb, subject + preposition + object, and a noun phrase only.</S>
			<S sid ="90" ssid = "44">The rules listed below are employed in order: Triple Rules: Triple1(S,P,O) Æ np(S), vtp(P), np(O).</S>
			<S sid ="91" ssid = "45">Triple2(S,P,none) Æ np(S), vip(P).</S>
			<S sid ="92" ssid = "46">Triple3(S,P,O) Æ np(S), prep(P), np(O).</S>
			<S sid ="93" ssid = "47">]]] [[[Zhangsan], [enter], [competition]], [[zero], [win], [champion]]] 4 Zero Anaphora Resolution.</S>
			<S sid ="94" ssid = "48">4.1 ZA Resolution Method.</S>
			<S sid ="95" ssid = "49">The process of analyzing Chinese zero anaphora is different from general pronoun resolution in English because zero anaphors are not expressed in discourse.</S>
			<S sid ="96" ssid = "50">Therefore, the ZA resolution method we develop is divided into three phases.</S>
			<S sid ="97" ssid = "51">First each sentence of an input document is translated into triples as described in Section 3.</S>
			<S sid ="98" ssid = "52">Second is ZA identification that verifies each ZA candidates annotated in triples by employing ZA detected ZA using rules based on the centering model.</S>
			<S sid ="99" ssid = "53">In the ZA detection phase, we use the ZA Triple Rules described in the Section 3 to detect omitted cases as ZA candidates denoted by zero in triples.</S>
			<S sid ="100" ssid = "54">Table 1 shows some examples corresponding to the ZA Triple Rules.</S>
			<S sid ="101" ssid = "55">passive sentences or inverted sentences (Hu, 1995).</S>
			<S sid ="102" ssid = "56">ZA identification constraints For each ZA candidate c in a discourse: 1.</S>
			<S sid ="103" ssid = "57">c can not be in the first utterance in a discourse segment 2.</S>
			<S sid ="104" ssid = "58">ZA does not occur in the following case:.</S>
			<S sid ="105" ssid = "59">NP + bei + NP + VP + c NP (topic) + NP (subject) + VP + c In the antecedent identification phase, we employ the concept, ‘backward-looking center’ of centering model to identify the antecedent of each ZA.</S>
			<S sid ="106" ssid = "60">First we use noun phrase rules to obtain noun phrases in each utterance, and then the antecedent is identified as the most prominent noun phrase of the preceding utterance (Yeh and Chen, 2001): Antecedent identification rule: For each zero anaphor z in a discourse segment consisting of utterances U1, … , Um: If z occurs in Ui, and no zero anaphor occurs in Ui1 then choose the noun phrase with the corresponding grammatical role in Ui1 as the antecedent Else if only one zero anaphor occurs in Ui1 then choose the antecedent of the zero anaphor in Ui1 as the antecedent of z zai nabian Table 1: Examples of zero anaphora After ZA candidates are detected by employing the ZA Triple Rules, the ZA identification constraints are utilized to filter out non-anaphoric cases.</S>
			<S sid ="107" ssid = "61">In the ZA identification constraints, the constraint 1 is employed to exclude the exophora3 or cataphora4 which is different from anaphora in 2 We use a Q to denote a question (ma); a. ASPECT to denote aspect marker.</S>
			<S sid ="108" ssid = "62">3 Exophora is reference of an expression directly to an extralinguistic referent and the referent does not require another expression for its interpretation.</S>
			<S sid ="109" ssid = "63">4 Cataphora arises when a reference is made to an entity mentioned subsequently.</S>
			<S sid ="110" ssid = "64">Else if more than one zero anaphor occurs in Ui1 then choose the antecedent of the zero anaphor in Ui1 as the antecedent of z according to grammatical role criteria: Topic &gt; Subject &gt; Object &gt; Others End if Due to topic-prominence in Chinese (Li and Thompson, 1981), topic is the most salient grammatical role.</S>
			<S sid ="111" ssid = "65">In general, if the topic is omitted, the subject will be in the initial position of an utterance.</S>
			<S sid ="112" ssid = "66">If the topic and subject are omitted concurrently, the ZA occurs.</S>
			<S sid ="113" ssid = "67">Since the antecedent identification rule is corresponding to the concept of centering model.</S>
			<S sid ="114" ssid = "68">4.2 ZA Resolution Experiment.</S>
			<S sid ="115" ssid = "69">In the experiment of ZA resolution, we use a test corpus which is a collection of 150 news articles contained 998 paragraphs, 4631 utterances, and 40884 Chinese words.</S>
			<S sid ="116" ssid = "70">By employing the ZA Triple Rules and ZA identification constraints mentioned previously, zero anaphors occur in topic or subject, and object positions can be detected.</S>
			<S sid ="117" ssid = "71">Because the ZA Triple Rules cover each possible topic or subject, and object omission cases, the result shows that the zero anaphors are over detected and the precision rate (PR) is 84% calculated using equation 1.</S>
			<S sid ="118" ssid = "72">PR of ZA detection  No.</S>
			<S sid ="119" ssid = "73">of ZA correctly detected ....(1) No.</S>
			<S sid ="120" ssid = "74">of ZA candidates The main errors of ZA detection occur in the experiment when parsing inverted sentences and non-anaphoric cases (e.g. exophora or cataphora) (Hu, 1995; Mitkov, 2002).</S>
			<S sid ="121" ssid = "75">Cataphora is similar to anaphora, the difference being the direction of the can handle physical examinations of foreign laborers.</S>
			<S sid ="122" ssid = "76">The recall rates (RR) and precision rates (PR) of ZA resolution is 70% and 60.3% respectively calculated using equation 2 and equation 3.</S>
			<S sid ="123" ssid = "77">Errors occur in the phase when a zero anaphor refers to an entity other than the corresponding grammatical role or the antecedent of the zero anaphor in the preceding utterance.</S>
			<S sid ="124" ssid = "78">reference.</S>
			<S sid ="125" ssid = "79">In this paper, we do not deal with the case that the referent of a zero anaphor is in the RR of ZA resolution  No.</S>
			<S sid ="126" ssid = "80">of ant.</S>
			<S sid ="127" ssid = "81">correctly identified No.</S>
			<S sid ="128" ssid = "82">of ZA candidates ..</S>
			<S sid ="129" ssid = "83">(2) following utterances, but we can detect about 60% cataphora in the test corpus by employing ZA identification constraint 1.</S>
			<S sid ="130" ssid = "84">In the phase of antecedent identification, we take the output of employing the ZA Triple Rules and ZA identification constraints, and further to identify the antecedents of zero anaphors by using antecedent identification rule based on the centering model.</S>
			<S sid ="131" ssid = "85">For example, in the discourse segment (5), the zero anaphors are detected in the utterances (5b) and (5c).</S>
			<S sid ="132" ssid = "86">According to the antecedent identification rule, the noun phrase, PR of ZA resolution  No.</S>
			<S sid ="133" ssid = "87">of ant.</S>
			<S sid ="134" ssid = "88">correctly identified ...</S>
			<S sid ="135" ssid = "89">(3) No.</S>
			<S sid ="136" ssid = "90">of ZA occurred in text</S>
	</SECTION>
	<SECTION title="Topic Identification. " number = "5">
			<S sid ="137" ssid = "1">Topic identification is similar to theme identification in (Rambow, 1993).</S>
			<S sid ="138" ssid = "2">The theme clearly corresponds to the Cb: the theme, under a general definition, is what the current utterance is about; what utterances are about provides a link to previous discourse, since otherwise the text would be incoherent.</S>
			<S sid ="139" ssid = "3">The role of the Cb is precisely to ‘Kee-lung General Hospital,’ � whose provide such a link.</S>
			<S sid ="140" ssid = "4">In our approach, in addition to the centering grammatical role is corresponding to the zero anaphor  i in (5b) is identified as the antecedent.</S>
			<S sid ="141" ssid = "5">Subsequently, the antecedent of the zero anaphor model, we further employ the antecedent identification rule to identify the topic.</S>
			<S sid ="142" ssid = "6">When a ZA occurs in the utterance Ui, the antecedent of the ZA i i 2 in (5c) is identified as the antecedent of 1 in is identified as the topic of Ui.</S>
			<S sid ="143" ssid = "7">Otherwise, if the (5b), . � i transit ion relati on, center shifti ng, occur s, topic will not be identi fied as any of the eleme nt in the (5) a. preceding utterance but the element in the current Jilong yiyuan wei kuoda fuwu fanwei Kee-lung hospital for expand service coverage Keelungi General Hospital aims to increase service coverage.</S>
			<S sid ="144" ssid = "8">b.  i utterance according to grammatical role criteria.</S>
			<S sid ="145" ssid = "9">The topic identification rule is described below: Topic identification rule: For identifying each topic t in a discourse segment consisting of utterances U1, … , Um: 1 If at least one ZA occurs in Ui.</S>
			<S sid ="146" ssid = "10">jiji tisheng yiliao fuwu pinzhi ji biaozhunhua (Kee-lung General Hospital)i active improve medical-treatment service quality and standardization (Kee-lung General Hospital)i actively improves the service quality of medical treatment and standardization.</S>
			<S sid ="147" ssid = "11">c.  i then refer to grammatical role criteria to choose the antecedent of the ZA as the t Else if no ZA occurs in Ui then refer to grammatical role criteria to choose one element of Ui as the t End if We now take the discourse segment (1) as an 2 example to identify each topic of the utterances (1a) huo weishengshu renke wei banli wailao to (1d) by employing the topic identification rule.</S>
			<S sid ="148" ssid = "12">As illustrated in Table2, the topic of (1a) is tijian yiyuan (Kee-lung General Hospital)i obtain ‘Electronics stocks,’ and the topic of i �r)t (1b) is Department-of-Health certify to-be handle identified as the antecedent of ¢ , � r ) t foreign-laborer physical-examination hospital (Kee-lung General Hospital)i is certified by Department of Health as a hospital which ‘Electronics stocks.’ Similarly, the topic of (1d) is ‘Securities stocks,’ which is the same as ��)t the topic of (1c).</S>
			<S sid ="149" ssid = "13">CA, pages 122–129.</S>
			<S sid ="150" ssid = "14">Baldwin B. 1997.</S>
			<S sid ="151" ssid = "15">CogNIAC: high precision coreference with limited knowledge and linguistic resources.</S>
			<S sid ="152" ssid = "16">ACL/EACL workshop on Operational factors in practical, robust anaphor resolution.</S>
			<S sid ="153" ssid = "17">CKIP.</S>
			<S sid ="154" ssid = "18">1999.</S>
			<S sid ="155" ssid = "19">Version 1.0 Table 2: Examples of zero anaphora</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "6">
			<S sid ="156" ssid = "1">In this paper, we propose a method of topic identification in Chinese based on the centering model.</S>
			<S sid ="157" ssid = "2">Based on observations on real texts, we found that to identify the topics in Chinese context is much related to the issue of zero anaphora resolution.</S>
			<S sid ="158" ssid = "3">We use a zero anaphora resolution method to resolve the problem of ellipsis in Chinese text.</S>
			<S sid ="159" ssid = "4">The zero anaphora resolution method works on the output of a part-of-speech tagger and employs a shallow parsing instead of a complex parsing to resolve zero anaphors in Chinese text.</S>
			<S sid ="160" ssid = "5">Due to time limit, we have not applied the result of topic identification to applications for evaluation.</S>
			<S sid ="161" ssid = "6">We will further continue improving the accuracy of zero anaphora resolution and develop the applications based on topic identification, such as information extraction/retrieval and text categorization.</S>
	</SECTION>
	<SECTION title="Acknowledgements. " number = "7">
			<S sid ="162" ssid = "1">We give our special thanks to CKIP, Academia Sinica for making great efforts in computational linguistics and sharing the Autotag program to academic research.</S>
	</SECTION>
</PAPER>
