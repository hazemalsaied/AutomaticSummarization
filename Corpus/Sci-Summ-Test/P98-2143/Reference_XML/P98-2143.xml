<PAPER>
<S sid="0">Robust pronoun resolution with limited knowledge</S>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Most traditional approaches to anaphora resolution rely heavily on linguistic and domain knowledge.</S>
		<S sid ="2" ssid = "2">One of the disadvantages of developing a knowledge­ based system, however, is that it is a very labour­ intensive and time-consuming task.</S>
		<S sid ="3" ssid = "3">This paper pres­ ents a robust, knowledge-poor approach to resolving pronouns in technical manuals, which operates on texts pre-processed by a part-of-speech tagger.</S>
		<S sid ="4" ssid = "4">Input is checked against agreement and for a number of antecedent indicators.</S>
		<S sid ="5" ssid = "5">Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent.</S>
		<S sid ="6" ssid = "6">Evaluation reports a success rate of 89.7% which is better than the suc­ cess rates of the approaches selected for comparison and tested on the same data.</S>
		<S sid ="7" ssid = "7">In addition, preliminary experiments show that the approach can be success­ fully adapted for other languages with minimum modifications.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="8" ssid = "8">For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979).</S>
			<S sid ="9" ssid = "9">However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense.</S>
			<S sid ="10" ssid = "10">While various alternatives have been proposed, making use of e.g. neural networks, a situation se­ mantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Akman 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic pro­ cessing of growing language resources.</S>
			<S sid ="11" ssid = "11">Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or lin­ guistic knowledge (Baldwin 1997; Dagan &amp; ltai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996).</S>
			<S sid ="12" ssid = "12">Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaph­ ora resolution.</S>
			<S sid ="13" ssid = "13">It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing.</S>
			<S sid ="14" ssid = "14">Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic).</S>
	</SECTION>
	<SECTION title="The approach. " number = "2">
			<S sid ="15" ssid = "1">With a view to avoiding complex syntactic, seman­ tic and discourse analysis (which is vital for real­ world applications), we developed a robust, knowl­ edge-poor approach to pronoun resolution which does not parse and analyse the input in order to identify antecedents of anaphors.</S>
			<S sid ="16" ssid = "2">It makes use of only a part-of-speech tagger, plus simple noun phrase rules (sentence constituents are identified at the level of noun phrase at most) and operates on the basis of antecedent-tracking preferences (referred to hereafter as &quot;antecedent indicators&quot;).</S>
			<S sid ="17" ssid = "3">The approach works as follows: it takes as an input the output of a text processed by a part-of-speech tagger, identifies the noun phrases which precede the anaphor within a distance of 2 sentences, checks them for gender and number agreement with the anaphor and then applies the genre-specific antecedent indicators to the re­ maining candidates (see next section).</S>
			<S sid ="18" ssid = "4">The noun phrase with the highest aggregate score is proposed as antecedent; in the rare event of a tie, priority is given to the candidate with the higher score for im­ mediate reference.</S>
			<S sid ="19" ssid = "5">If immediate reference has not been identified, then priority is given to the candi date with the best collocation pattern score.</S>
			<S sid ="20" ssid = "6">If this does not help, the candidate with the higher score for indicating verbs is preferred.</S>
			<S sid ="21" ssid = "7">If still no choice is possible, the most recent from the remaining candi­ dates is selected as the antecedent.</S>
			<S sid ="22" ssid = "8">2.1 Antecedent indicators.</S>
			<S sid ="23" ssid = "9">Antecedent indicators (preferences) play a decisive role in tracking down the antecedent from a set of possible candidates.</S>
			<S sid ="24" ssid = "10">Candidates are assigned a score (-1, 0, 1 or 2) for each indicator; the candidate with the highest aggregate score is proposed as the ante­ cedent.</S>
			<S sid ="25" ssid = "11">The antecedent indicators have been identi­ fied empirically and are related to salience (definiteness, givenness, indicating verbs, lexical reiteration, section heading preference, &quot;non­ prepositional&quot; noun phrases), to structural matches (collocation, immediate reference), to referential distance or to preference of terms.</S>
			<S sid ="26" ssid = "12">Whilst some of the indicators are more genre-specific (term prefer­ ence) and others are less genre-specific (&quot;immediate reference&quot;), the majority appear to be genre­ independent.</S>
			<S sid ="27" ssid = "13">In the following we shall outline some the indicators used and shall illustrate them by ex­ amples.</S>
			<S sid ="28" ssid = "14">Definiteness Definite noun phrases in previous sentences are more likely antecedents of pronominal anaphors than indefinite ones (definite noun phrases score 0 and indefinite ones are penalised by -1).</S>
			<S sid ="29" ssid = "15">We regard a noun phrase as definite if the head noun is modified by a definite article, or by demonstrative or posses­ sive pronouns.</S>
			<S sid ="30" ssid = "16">This rule is ignored if there are no definite articles, possessive or demonstrative pro­ nouns in the paragraph (this exception is taken into account because some English user&apos;s guides tend to omit articles).</S>
			<S sid ="31" ssid = "17">Givenness Noun phrases in previous sentences representing the &quot;given information&quot; (theme) 1 are deemed good candidates for antecedents and score I (candidates not representing the theme score 0).</S>
			<S sid ="32" ssid = "18">In a coherent text (Firbas 1992), the given or known information, or theme, usually appears first, and thus forms a co­ referential link with the preceding text.</S>
			<S sid ="33" ssid = "19">The new information, or rheme, provides some information about the theme.</S>
			<S sid ="34" ssid = "20">1We use the simple heuristics that the given information is the first noun phrase in a non-imperative sentence.</S>
			<S sid ="35" ssid = "21">Indicating verbs If a verb is a member of the Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, re­ port, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, we consider the first NP following it as the preferred an­ tecedent (scores 1 and 0).</S>
			<S sid ="36" ssid = "22">Empirical evidence sug­ gests that because of the salience of the noun phrases which follow them, the verbs listed above are particularly good indicators.</S>
			<S sid ="37" ssid = "23">Lexical reiteration Lexically reiterated items are likely candidates for antecedent (a NP scores 2 if is repeated within the same paragraph twice or more, 1 if repeated once and 0 if not).</S>
			<S sid ="38" ssid = "24">Lexically reiterated items include re­ peated synonymous noun phrases which may often be preceded by definite articles or demonstratives.</S>
			<S sid ="39" ssid = "25">Also, a sequence of noun phrases with the same head counts as lexical reiteration (e.g. &quot;toner bottle&quot;, &quot;bottle of toner&quot;, &quot;the bottle&quot;).</S>
			<S sid ="40" ssid = "26">Section heading preference If a noun phrase occurs in the heading of the section, part of which is the current sentence, then we con­ sider it as the preferred candidate (1, 0).</S>
			<S sid ="41" ssid = "27">&quot;Non-prepositional&quot; noun phrases A &quot;pure&quot;, &quot;non-prepositional&quot; noun phrase is given a higher preference than a noun phrase which is part of a prepositional phrase (0, -1 ).</S>
			<S sid ="42" ssid = "28">Example: Insert the cassettei into the VCR making sure iti is suitable for the length of recording.</S>
			<S sid ="43" ssid = "29">Here &quot;the VCR&quot; is penalised (-1) for being part of the prepositional phrase &quot;into the VCR&quot;.</S>
			<S sid ="44" ssid = "30">This preference can be explained in terms of sali­ ence from the point of view of the centering theory.</S>
			<S sid ="45" ssid = "31">The latter proposes the ranking &quot;subject, direct ob­ ject, indirect object&quot; (Brennan et al. 1987) and noun phrases which are parts of prepositional phrases are usually indirect objects.</S>
			<S sid ="46" ssid = "32">Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun (2,0).</S>
			<S sid ="47" ssid = "33">The collocation preference here is restricted to the patterns &quot;noun phrase (pronoun), verb&quot; and &quot;verb, noun phrase (pronoun)&quot;.</S>
			<S sid ="48" ssid = "34">Owing to lack of syntactic information, this preference is somewhat weaker than the collocation preference described in (Dagan &amp; ltai 1990).</S>
			<S sid ="49" ssid = "35">Example: Press the keyi down and turn the volume up...</S>
			<S sid ="50" ssid = "36">Press iti again.</S>
			<S sid ="51" ssid = "37">Immediate reference In technical manuals the &quot;immediate reference&quot; clue can often be useful in identifying the antecedent.</S>
			<S sid ="52" ssid = "38">The heuristics used is that in constructions of the form &quot;...(You) V 1 NP ... con (you) V 2 it (con (you) V3 it)&quot;, where con e {and/or/before/after...}, the noun phrase immediately after V 1 is a very likely candidate for antecedent of the pronoun &quot;it&quot; imme­ diately following V2 and is therefore given preference (scores 2 and 0).</S>
			<S sid ="53" ssid = "39">This preference can be viewed as a modification of the collocation preference.</S>
			<S sid ="54" ssid = "40">It is also quite fre­ quent with imperative constructions.</S>
			<S sid ="55" ssid = "41">Example: To print the paper, you can stand the printeri up or lay iti flat.</S>
			<S sid ="56" ssid = "42">To turn on the printer, press the Power buttoni and hold iti down for a moment.</S>
			<S sid ="57" ssid = "43">Unwrap the paperi• form iti and align iti• then load iti into the drawer.</S>
			<S sid ="58" ssid = "44">Referential distance In complex sentences, noun phrases in the previous clause2 are the best candidate for the antecedent of an anaphor in the subsequent clause, followed by noun phrases in the previous sentence, then by nouns situated 2 sentences further back and finally nouns 3 sentences further back (2, 1, 0, -1).</S>
			<S sid ="59" ssid = "45">For anaphors in simple sentences, noun phrases in the previous sen­ tence are the best candidate for antecedent, followed by noun phrases situated 2 sentences further back and finally nouns 3 sentences further back {1, 0, -1).</S>
			<S sid ="60" ssid = "46">Term preference NPs representing terms in the field are more likely to be the antecedent than NPs which are not terms (score 1 if the NP is a term and 0 if not).</S>
			<S sid ="61" ssid = "47">21dentification of clauses in complex sentences is do e heuristically.</S>
			<S sid ="62" ssid = "48">As already mentioned, each of the antecedent in­ dicators assigns a score with a value {-1, 0, 1, 2}.</S>
			<S sid ="63" ssid = "49">These scores have been determined experimentally on an empirical basis and are constantly being up­ dated.</S>
			<S sid ="64" ssid = "50">Top symptoms like &quot;lexical reiteration&quot; as­ sign score &quot;2&quot; whereas &quot;non-prepositional&quot; noun phrases are given a negative score of &quot;-1&quot;.</S>
			<S sid ="65" ssid = "51">We should point out that the antecedent indicators are preferences and not absolute factors.</S>
			<S sid ="66" ssid = "52">There might be cases where one or more of the antecedent indicators do not &quot;point&quot; to the correct antecedent.</S>
			<S sid ="67" ssid = "53">For in­ stance, in the sentence &quot;Insert the cassette into the VCRi making sure iti is turned on&quot;, the indicator &quot;non-prepositional noun phrases&quot; would penalise the correct antecedent.</S>
			<S sid ="68" ssid = "54">When all preferences (antecedent indicators) are taken into account, however, the right antecedent is still very likely to be tracked down - in the above example, the &quot;non-prepositional noun phrases&quot; heuristics (penalty) would be overturned by the &quot;collocational preference&quot; heuristics.</S>
			<S sid ="69" ssid = "55">2.2 Informal description of the algorithm.</S>
			<S sid ="70" ssid = "56">The algorithm for pronoun resolution can be de­ scribed informally as follows: 1.</S>
			<S sid ="71" ssid = "57">Examine the current sentence and the two pre­.</S>
			<S sid ="72" ssid = "58">ceding sentences (if available).</S>
			<S sid ="73" ssid = "59">Look for noun phrases3 only to the left of the anaphor4 2.</S>
			<S sid ="74" ssid = "60">Select from the noun phrases identified only.</S>
			<S sid ="75" ssid = "61">those which agree in gender and numberS with the pronominal anaphor and group them as a set of potential candidates</S>
	</SECTION>
	<SECTION title="Apply  the antecedent  indicators  to each  poten­. " number = "3">
			<S sid ="76" ssid = "1">tial candidate and assign scores; the candidate with the highest aggregate score is proposed as 3A sentence splitter would already have segmented the text into sentences, a POS tagger would already have determined the parts of speech and a simple phrasal grammar would already have detected the noun phrases 4In this project we do not treat cataphora; non-anaphoric &quot;it&quot; occurring in constructions such as &quot;It is important&quot;, &quot;It is necessary&quot; is eliminated by a &quot;referential filter&quot; 5Note that this restriction may not always apply in lan­ guages other than English (e.g. German); on the other hand, there are certain collective nouns in English which do not agree in number with their antecedents (e.g. &quot;government&quot;, &quot;team&quot;, &quot;parliament&quot; etc. can be referred to by &quot;they&quot;; equally some plural nouns (e.g. &quot;data&quot;) can be referred to by &quot;it&quot;) and are exempted from the agree­ ment test.</S>
			<S sid ="77" ssid = "2">For this purpose we have drawn up a compre­ hensive list of all such cases; to our knowledge, no other computational treatment of pronominal anaphora resolu­ tion has addressed the problem of &quot;agreement excep­ tions&quot;.</S>
			<S sid ="78" ssid = "3">antecedent.</S>
			<S sid ="79" ssid = "4">If two candidates have an equal score, the candidate with the higher score for immediate reference is proposed as antecedent.</S>
			<S sid ="80" ssid = "5">If immediate reference does not hold, propose the candidate with higher score for collocational pattern.</S>
			<S sid ="81" ssid = "6">If collocational pattern suggests a tie or does not hold, select the candidate with higher score for indicating verbs.</S>
			<S sid ="82" ssid = "7">If this indicator does not hold again, go for the most recent candidate.</S>
			<S sid ="83" ssid = "8">3.</S>
			<S sid ="84" ssid = "9">Evaluation.</S>
			<S sid ="85" ssid = "10">For practical reasons, the approach presented does not incorporate syntactic and semantic information (other than a list of domain terms) and it is not real­ istic to expect its performance to be as good as an approach which makes use of syntactic and semantic knowledge in terms of constraints and preferences.</S>
			<S sid ="86" ssid = "11">The lack of syntactic information, for instance, means giving up c-cornmand constraints and subject preference (or on other occasions object preference, see Mitkov I995) which could be used in center tracking.</S>
			<S sid ="87" ssid = "12">Syntactic parallelism, useful in discrimi­ nating between identical pronouns on the basis of their syntactic function, also has to be forgone.</S>
			<S sid ="88" ssid = "13">Lack of semantic knowledge rules out the use of verb se­ mantics and semantic parallelism.</S>
			<S sid ="89" ssid = "14">Our evaluation, however, suggests that much less is lost than might be feared.</S>
			<S sid ="90" ssid = "15">In fact, our evaluation shows that the re­ sults are comparable to syntax-based methods (Lappin &amp; Leass I994).</S>
			<S sid ="91" ssid = "16">We believe that the good success rate is due to the fact that a number of ante­ cedent indicators are taken into account and no fac­ tor is given absolute preference.</S>
			<S sid ="92" ssid = "17">In particular, this strategy can often override incorrect decisions linked with strong centering preference (Mitkov &amp; Belguith I998) or syntactic and semantic parallelism prefer­ ences (see below).</S>
			<S sid ="93" ssid = "18">3.1 Evaluation A. Our first evaluation exercise (Mitkov &amp; Stys 1997) was based on a random sample text from a technical manual in English (Minolta 1994).</S>
			<S sid ="94" ssid = "19">There were 71 pronouns in the 140 page technical manual; 7 of the pronouns were non-anaphoric and 16 exophoric.</S>
			<S sid ="95" ssid = "20">The resolution of anaphors was carried out with a suc­ cess rate of 95.8%.</S>
			<S sid ="96" ssid = "21">The approach being robust (an attempt is made to resolve each anaphor and a pro­ posed antecedent is returned), this figure represents both &quot;precision&quot; and &quot;recall&quot; if we use the MUC terminology.</S>
			<S sid ="97" ssid = "22">To avoid any terminological confusion, we shall therefore use the more neutral term &quot;success rate&quot; while discussing the evaluation.</S>
			<S sid ="98" ssid = "23">In order to evaluate the effectiveness of the ap­ proach and to explore if I how far it is superior over the baseline models for anaphora resolution, we also tested the sample text on (i) a Baseline Model which checks agreement in number and gender and, where more than one candidate remains, picks as antece­ dent the most recent subject matching the gender and number of the anaphor (ii) a Baseline Model which picks as antecedent the most recent noun phrase that matches the gender and number of the anaphor.</S>
			<S sid ="99" ssid = "24">The success rate of the &quot;Baseline Subject&quot; was 29.2%, whereas the success rate of &quot;Baseline Most Recent NP&quot; was 62.5%.</S>
			<S sid ="100" ssid = "25">Given that our knowledge­ poor approach is basically an enhancement of a baseline model through a set of antecedent indica­ tors, we see a dramatic improvement in performance (95.8%) when these preferences are called upon.</S>
			<S sid ="101" ssid = "26">Typically, our preference-based model proved superior to both baseline models when the antece­ dent was neither the most recent subject nor the most recent noun phrase matching the anaphor in gender and number.</S>
			<S sid ="102" ssid = "27">Example: Identify the draweq by the lit paper port LED and add paper to itj.</S>
			<S sid ="103" ssid = "28">The aggregate score for &quot;the drawer&quot; is 7 (definiteness 1 + givenness 0 + term preference 1 + indicating verbs I + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer­ ence 2 = 7), whereas aggregate score for the most recent matching noun phrase (&quot;the lit paper port LED&quot;) is 4 (definiteness 1 + givenness 0 + term preference I + indicating verbs 0 + lexical reitera­ tion 0 + section heading 0 + collocation 0 + referen­ tial distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4).</S>
			<S sid ="104" ssid = "29">From this example we can also see that our knowledge-poor approach successfully tackles cases in which the anaphor and the· antecedent have not only different syntactic functions but also different semantic roles.</S>
			<S sid ="105" ssid = "30">Usually knowledge-based ap­ proaches have difficulties in such a situation because they use preferences such as &quot;syntactic parallelism&quot; or &quot;semantic parallelism&quot;.</S>
			<S sid ="106" ssid = "31">Our robust approach does not use these because it has no information about the syntactic structure of the sentence or about the syn­ tactic function/semantic role of each individual word.</S>
			<S sid ="107" ssid = "32">As far as the typical failure cases are concerned, we anticipate the knowledge-poor approach to have difficulties with sentences which have a more com­ plex syntactic structure.</S>
			<S sid ="108" ssid = "33">This should not be surpris ing, given that the approach does not rely on any syntactic knowledge and in particular, it does not produce any parse tree.</S>
			<S sid ="109" ssid = "34">Indeed, the approach fails on the sentence: The paper through key can be used to feed [a blank sheet of paper]j through the copier out into the copy tray without making a copy on itj.</S>
			<S sid ="110" ssid = "35">where &quot;blank sheet of paper&quot; scores only 2 as op­ posed to the &quot;the paper through key&quot; which scores 6.</S>
			<S sid ="111" ssid = "36">3.2 Evaluation B. We carried out a second evaluation of the approach on a different set of sample texts from the genre of technical manuals (47-page Portable Style-Writer User&apos;s Guide (Stylewriter 1994).</S>
			<S sid ="112" ssid = "37">Out of 223 pro­ nouns in the text, 167 were non-anaphoric (deictic and non-anaphoric &quot;it&quot;).</S>
			<S sid ="113" ssid = "38">The evaluation carried out was manual to ensure that no added error was gen­ erated (e.g. due to possible wrong sentence/clause detection or POS tagging).</S>
			<S sid ="114" ssid = "39">Another reason for doing it by hand is to ensure a fair comparison with Breck Baldwin&apos;s method, which not being available to us, had to be hand-simulated (see 3.3).</S>
			<S sid ="115" ssid = "40">The evaluation indicated 83.6% success rate.</S>
			<S sid ="116" ssid = "41">The &quot;Baseline subject&quot; model tested on the same data scored 33.9% recall and 67.9% precision, whereas &quot;Baseline most recent&quot; scored 66.7%.</S>
			<S sid ="117" ssid = "42">Note that &quot;Baseline subject&quot; can be assessed both in terms of recall and precision because this &quot;version&quot; is not robust: in the event of no subject being available, it is not able to propose an antecedent (the manual guide used as evaluation text contained many im­ perative zero-subject sentences).</S>
			<S sid ="118" ssid = "43">In the second experiment we evaluated the ap­ proach from the point of view also of its &quot;critical success rate&quot;.</S>
			<S sid ="119" ssid = "44">This measure (Mitkov 1998b) applies only to anaphors &quot;ambiguous&quot; from the point of view of number and gender (i.e. to those &quot;tough&quot; anaphors which, after activating the gender and number filters, still have more than one candidate for antecedent) and is indicative of the performance of the antecedent indicators.</S>
			<S sid ="120" ssid = "45">Our evaluation estab­ lished the critical success rate as 82%.</S>
			<S sid ="121" ssid = "46">A case where the system failed was when the anaphor and the antecedent were in the same sen­ tence and where preference was given to a candidate in the preceding sentence.</S>
			<S sid ="122" ssid = "47">This case and other cases suggest that it might be worthwhile reconsider­ ing/refining the weights for the indicator &quot;referential distance&quot;.</S>
			<S sid ="123" ssid = "48">Similarly to the first evaluation, we found that the robust approach was not very successful on sen­ tences with too complicated syntax - a price we have to pay for the &quot;convenience&quot; of developing a knowl­ edge-poor system.</S>
			<S sid ="124" ssid = "49">The results from experiment 1 and experiment 2 can be summarised in the following (statistically) slightly more representative figures.</S>
			<S sid ="125" ssid = "50">R ob ust aQ pr oa ch B a s el i n e s u b je ct B as eli ne m os t re ce nt Su cc es s rat e (= Pr ec isi on / Re ca ll) 8 9.</S>
			<S sid ="126" ssid = "51">7 % 31.</S>
			<S sid ="127" ssid = "52">55 % I 48 .5 5 % 6 5 . 9 5 % The lower figure in &quot;Baseline subject&quot; corresponds to &quot;recall&quot; and the higher figure- to &quot;precision&quot;.</S>
			<S sid ="128" ssid = "53">If we regard as &quot;discriminative power&quot; of each antecedent indicator the ratio &quot;number of successful antecedent identifications when this indicator was applied&quot;/&quot;number of applications of this indicator&quot; (for the non-prepositional noun phrase and definite­ ness being penalising indicators, this figure is calcu­ lated as the ratio &quot;number of unsuccessful antece­ dent identifications&quot;/&quot;number of applications&quot;), the immediate reference emerges as the most discrimi­ native indicator (100%), followed by non­ prepositional noun phrase (92.2%), collocation (90.9%), section heading (61.9%), lexical reiteration (58.5%), givenness (49.3%), term preference (35.7%) and referential distance (34.4%).</S>
			<S sid ="129" ssid = "54">The rela­ tively low figures for the majority of indicators should not be regarded as a surprise: firstly, we should bear in mind that in most cases a candidate was picked (or rejected) as an antecedent on the ba­ sis of applying a number of different indicators and secondly, that most anaphors had a relatively high number of candidates for antecedent.</S>
			<S sid ="130" ssid = "55">In terms of frequency of use (&quot;number of nonzero applications&quot;/&quot;number of anaphors&quot;), the most fre­ quently used indicator proved to be referential dis­ tance used in 98.9% of the cases, followed by term preference (97.8%), givenness (83.3%), lexical reit­ eration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) and colloca­ tion (11.1%).</S>
			<S sid ="131" ssid = "56">As expected, the most frequent indica­ tors were not the most discriminative ones.</S>
			<S sid ="132" ssid = "57">3.3 Comparison to similar approaches: compara­.</S>
			<S sid ="133" ssid = "58">tive evaluation of Breck Baldwin&apos;s CogNIAC We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin&apos;s Cog­ NIAC (Baldwin 1997) approach which features &quot;high precision coreference with limited knowledge and linguistics resources&quot;.</S>
			<S sid ="134" ssid = "59">The reason is that both our approach and Breck Baldwin&apos;s approach share common principles (both are knowledge-poor and use a POS tagger to provide the input) and therefore a comparison would be appropriate.</S>
			<S sid ="135" ssid = "60">Given that our approach is robust and returns an­ tecedent for each pronoun, in order to make the comparison as fair as possible, we used CogNIAC&apos;s &quot;resolve all&quot; version by simulating it manually on the same training data used in evaluation B above.</S>
			<S sid ="136" ssid = "61">CogNIAC successfully resolved the pronouns in 75% of the cases.</S>
			<S sid ="137" ssid = "62">This result is comparable with the results described in (Baldwin 1997).</S>
			<S sid ="138" ssid = "63">For the training data from the genre of technical manuals, it was rule 5 (see Baldwin 1997) which was most frequently used (39% of the cases, 100% success), followed by rule 8 (33% of the cases, 33% success), rule 7 (11%, 100%), rule I (9%, 100%) and rule 3 (7.4%, 100%).</S>
			<S sid ="139" ssid = "64">It would be fair to say that even though the results show superiority of our approach on the training data used (the genre of technical manuals), they cannot be generalised automatically for other genres or unrestricted texts and for a more accurate picture, further extensive tests are necessary.</S>
	</SECTION>
	<SECTION title="Adapting the robust  approach for other. " number = "4">
			<S sid ="140" ssid = "1">languages An attractive feature of any NLP approach would be its language &quot;universality&quot;.</S>
			<S sid ="141" ssid = "2">While we acknowledge that most of the monolingual NLP approaches are not automatically transferable (with the same degree of efficiency) to other languages, it would be highly desirable if this could be done with minimal adapta­ tion.</S>
			<S sid ="142" ssid = "3">We used the robust approach as a basis for devel­ oping a genre-specific reference resolution approach in Polish.</S>
			<S sid ="143" ssid = "4">As expected, some of the preferences had to be modified in order to fit with specific features of Polish (Mitkov &amp; Stys 1997).</S>
			<S sid ="144" ssid = "5">For the time being, we are using the same scores for Polish.</S>
			<S sid ="145" ssid = "6">The evaluation for Polish was based technical manuals available on the Internet (Internet Manual, 1994; Java Manual 1998).</S>
			<S sid ="146" ssid = "7">The sample texts con­ tained 180 pronouns among which were 120 in­ stances of exophoric reference (most being zero pro­ nouns).</S>
			<S sid ="147" ssid = "8">The robust approach adapted for Polish demonstrated a high success rate of 93.3% in resolv­ ing anaphors (with critical success rate of 86.2%).</S>
			<S sid ="148" ssid = "9">Similarly to the evaluation for English, we com­ pared the approach for Polish with (i) a Baseline Model which discounts candidates on the basis of agreement in number and gender and, if there were still competing candidates, selects as the antecedent the most recent subject matching the anaphor in gender and number (ii) a Baseline Model which checks agreement in number and gender and, if there were still more than one candidate left, picks up as the antecedent the most recent noun phrase that agrees with the anaphor.</S>
			<S sid ="149" ssid = "10">Our preference-based approach showed clear su­ periority over both baseline models.</S>
			<S sid ="150" ssid = "11">The first Base­ line Model (Baseline Subject) was successful in only 23.7% of the cases, whereas the second (Baseline Most Recent) had a success rate of 68.4%.</S>
			<S sid ="151" ssid = "12">There­ fore, the 93.3% success rate (see above) demon­ strates a dramatic increase in precision, which is due to the use of antecedent tracking preferences.</S>
			<S sid ="152" ssid = "13">We have recently adapted the approach for Ara­ bic as well (Mitkov &amp; Belguith 1998).</S>
			<S sid ="153" ssid = "14">Our evalua­ tion, based on 63 examples (anaphors) from a tech­ nical manual (Sony 1992), indicates a success rate of 95.2% (and critical success rate 89.3 %).</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "5">
			<S sid ="154" ssid = "1">We have described a robust, knowledge-poor ap­ proach to pronoun resolution which operates on texts pre-processed by a part-of-speech tagger.</S>
			<S sid ="155" ssid = "2">Evaluation shows a success rate of 89.7% for the genre of tech­ nical manuals and at least in this genre, the approach appears to be more successful than other similar methods.</S>
			<S sid ="156" ssid = "3">We have also adapted and evaluated the approach for Polish (93.3 % success rate) and for Arabic (95.2% success rate).</S>
	</SECTION>
</PAPER>
