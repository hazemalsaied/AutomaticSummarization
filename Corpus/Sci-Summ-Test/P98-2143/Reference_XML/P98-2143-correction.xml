<PAPER>
<S sid="0">Robust pronoun resolution with limited knowledge</S>
	<ABSTRACT>
		<S sid="1" ssid="1">Most traditional approaches to anaphora resolution rely heavily on linguistic and domain knowledge . </S>
		<S sid="2" ssid="2">One of the disadvantages of developing a knowledge&#194;&#173; based system , however , is that it is a very labour&#194;&#173; intensive and time-consuming task . </S>
		<S sid="3" ssid="3">This paper pres&#194;&#173; sent a robust , knowledge-poor approach to resolving pronouns in technical manuals , which operates on texts pre-processed by a part-of-speech tagger . </S>
		<S sid="4" ssid="4">Input is checked against agreement and for a number of antecedent indicators . </S>
		<S sid="5" ssid="5">Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent . </S>
		<S sid="6" ssid="6">Evaluation reports a success rate of 89.7 % which is better than the suc&#194;&#173; less rates of the approaches selected for comparison and tested on the same data . </S>
		<S sid="7" ssid="7">In addition , preliminary experiments show that the approach can be success&#194;&#173; fully adapted for other languages with minimum modifications . </S>
	</ABSTRACT>
	<SECTION number="1" title="Introduction">
			<S sid="8" ssid="8">For the most part , anaphora resolution has focused on traditional linguistic methods ( Carbonell &amp; Brown 1988 ; Carter 1987 ; Hobbs 1978 ; Ingria &amp; Stallard 1989 ; Lappin &amp; McCord 1990 ; Lappin &amp; Leass 1994 ; Mitkov 1994 ; Rich &amp; LuperFoy 1988 ; Sidner 1979 ; Webber 1979 ) . </S>
			<S sid="9" ssid="9">However , to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense . </S>
			<S sid="10" ssid="10">While various alternatives have been proposed , making use of e.g . neural networks , a situation se&#194;&#173; antics framework , or the principles of reasoning with uncertainty ( e.g . Connoly et al . 1994 ; Mitkov 1995 ; Tin &amp; Akman 1995 ) , there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems , and to enhance further the automatic pro&#194;&#173; cussing of growing language resources . </S>
			<S sid="11" ssid="11">Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain Andros linguistic knowledge ( Baldwin 1997 ; Dagan &amp; ital 1990 ; Kennedy &amp; Boguraev 1996 ; Mitkov 1998 ; Nasukawa 1994 ; Williams et al . 1996 ) . </S>
			<S sid="12" ssid="12">Our work is a continuation of these latest trends in the search for inexpensive , fast and reliable procedures for anaph&#194;&#173; ora resolution . </S>
			<S sid="13" ssid="13">It is also an example of how anaphora in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing . </S>
			<S sid="14" ssid="14">Finally , our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English , but also for other languages ( in our case Polish and Arabic ) . </S>
	</SECTION>
	<SECTION number="2" title="The approach. ">
			<S sid="15" ssid="1">With a view to avoiding complex syntactic , seman&#194;&#173; tic and discourse analysis ( which is vital for real&#194;&#173; world applications ) , we developed a robust , knowl&#194;&#173; edge-poor approach to pronoun resolution which does not parse and analysis the input in order to identify antecedents of anaphora . </S>
			<S sid="16" ssid="2">It makes use of only a part-of-speech tagger , plus simple noun phrase rules ( sentence constituents are identified at the level of noun phrase at most ) and operates on the basis of antecedent-tracking preferences ( referred to hereafter as `` antecedent indicators '' ) . </S>
			<S sid="17" ssid="3">The approach works as follows : it takes as an input the output of a text processed by a part-of-speech tagger , identifies the noun phrases which precede the anaphora within a distance of 2 sentences , checks them for gender and number agreement with the anaphora and then applies the genre-specific antecedent indicators to the re&#194;&#173; raining candidates ( see next section ) . </S>
			<S sid="18" ssid="4">The noun phrase with the highest aggregate score is proposed as antecedent ; in the rare event of a tie , priority is given to the candidate with the higher score for im&#194;&#173; mediate reference . </S>
			<S sid="19" ssid="5">If immediate reference has not been identified , then priority is given to the Candi date with the best collocation pattern score . </S>
			<S sid="20" ssid="6">If this does not help , the candidate with the higher score for indicating verbs is preferred . </S>
			<S sid="21" ssid="7">If still no choice is possible , the most recent from the remaining candi&#194;&#173; dates is selected as the antecedent . </S>
			<S sid="22" ssid="8">2.1 Antecedent indicators . </S>
			<S sid="23" ssid="9">Antecedent indicators ( preferences ) play a decisive role in tracking down the antecedent from a set of possible candidates . </S>
			<S sid="24" ssid="10">Candidates are assigned a score ( -1 , 0 , 1 or 2 ) for each indicator ; the candidate with the highest aggregate score is proposed as the ante&#194;&#173; cement . </S>
			<S sid="25" ssid="11">The antecedent indicators have been identi&#194;&#173; fie empirically and are related to salience ( definiteness , givenness , indicating verbs , lexical reiteration , section heading preference , `` non&#194;&#173; prepositional '' noun phrases ) , to structural matches ( collocation , immediate reference ) , to referential distance or to preference of terms . </S>
			<S sid="26" ssid="12">Whilst some of the indicators are more genre-specific ( term prefer&#194;&#173; enc and others are less genre-specific ( `` immediate reference '' ) , the majority appear to be genre&#194;&#173; independent . </S>
			<S sid="27" ssid="13">In the following we shall outline some the indicators used and shall illustrate them by ex&#194;&#173; ample . </S>
			<S sid="28" ssid="14">Definiteness Definite noun phrases in previous sentences are more likely antecedents of pronominal anaphora than indefinite ones ( definite noun phrases score 0 and indefinite ones are penalty by -1 ) . </S>
			<S sid="29" ssid="15">We regard a noun phrase as definite if the head noun is modified by a definite article , or by demonstrative or posses&#194;&#173; give pronouns . </S>
			<S sid="30" ssid="16">This rule is ignored if there are no definite articles , possessive or demonstrative pro&#194;&#173; nouns in the paragraph ( this exception is taken into account because some English user 's guides tend to omit articles ) . </S>
			<S sid="31" ssid="17">Givenness Noun phrases in previous sentences representing the `` given information '' ( theme ) 1 are deemed good candidates for antecedents and score I ( candidates not representing the theme score 0 ) . </S>
			<S sid="32" ssid="18">In a coherent text ( Firbas 1992 ) , the given or known information , or theme , usually appears first , and thus forms a co&#194;&#173; referential link with the preceding text . </S>
			<S sid="33" ssid="19">The new information , or heme provides some information about the theme . </S>
			<S sid="34" ssid="20">1We use the simple heuristics that the given information is the first noun phrase in a non-imperative sentence . </S>
			<S sid="35" ssid="21">Indicating verbs If a verb is a member of the Verb_set = { discuss , present , illustrate , identify , summarize examine , describe , define , show , check , develop , review , re&#194;&#173; port , outline , consider , investigate , explore , assess , analysis synthesis study , survey , deal , cover } , we consider the first NP following it as the preferred an&#194;&#173; antecedent scores 1 and 0 ) . </S>
			<S sid="36" ssid="22">Empirical evidence sug&#194;&#173; tests that because of the salience of the noun phrases which follow them , the verbs listed above are particularly good indicators . </S>
			<S sid="37" ssid="23">Lexical reiteration Lexically reiterated items are likely candidates for antecedent ( a NP scores 2 if is repeated within the same paragraph twice or more , 1 if repeated once and 0 if not ) . </S>
			<S sid="38" ssid="24">Lexically reiterated items include re&#194;&#173; pated synonymous noun phrases which may often be preceded by definite articles or demonstratives . </S>
			<S sid="39" ssid="25">Also , a sequence of noun phrases with the same head counts as lexical reiteration ( e.g . `` toner bottle '' , `` bottle of toner '' , `` the bottle '' ) . </S>
			<S sid="40" ssid="26">Section heading preference If a noun phrase occurs in the heading of the section , part of which is the current sentence , then we con&#194;&#173; sider it as the preferred candidate ( 1 , 0 ) . </S>
			<S sid="41" ssid="27">`` Non-prepositional '' noun phrases A `` pure '' , `` non-prepositional '' noun phrase is given a higher preference than a noun phrase which is part of a prepositional phrase ( 0 , -1 ) . </S>
			<S sid="42" ssid="28">Example : Insert the cassette into the VCR making sure iti is suitable for the length of recording . </S>
			<S sid="43" ssid="29">Here `` the VCR '' is penalty -1 ) for being part of the prepositional phrase `` into the VCR '' . </S>
			<S sid="44" ssid="30">This preference can be explained in terms of sali&#194;&#173; enc from the point of view of the centering theory . </S>
			<S sid="45" ssid="31">The latter proposes the ranking `` subject , direct ob&#194;&#173; sect indirect object '' ( Brennan et al . 1987 ) and noun phrases which are parts of prepositional phrases are usually indirect objects . </S>
			<S sid="46" ssid="32">Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun ( 2,0 ) . </S>
			<S sid="47" ssid="33">The collocation preference here is restricted to the patterns `` noun phrase ( pronoun ) , verb '' and `` verb , noun phrase ( pronoun ) '' . </S>
			<S sid="48" ssid="34">Owing to lack of syntactic information , this preference is somewhat weaker than the collocation preference described in ( Dagan &amp; ital 1990 ) . </S>
			<S sid="49" ssid="35">Example : Press the key down and turn the volume up ... </S>
			<S sid="50" ssid="36">Press iti again . </S>
			<S sid="51" ssid="37">Immediate reference In technical manuals the `` immediate reference '' clue can often be useful in identifying the antecedent . </S>
			<S sid="52" ssid="38">The heuristics used is that in constructions of the form `` ... ( You ) V 1 NP ... con ( you ) V 2 it ( con ( you ) V3 it ) '' , where con e { and/or/before/after ... } , the noun phrase immediately after V 1 is a very likely candidate for antecedent of the pronoun `` it '' imme&#194;&#173; mediately following V2 and is therefore given preference ( scores 2 and 0 ) . </S>
			<S sid="53" ssid="39">This preference can be viewed as a modification of the collocation preference . </S>
			<S sid="54" ssid="40">It is also quite fre&#194;&#173; Quent with imperative constructions . </S>
			<S sid="55" ssid="41">Example : To print the paper , you can stand the printer up or lay iti flat . </S>
			<S sid="56" ssid="42">To turn on the printer , press the Power button and hold iti down for a moment . </S>
			<S sid="57" ssid="43">Unwrap the paperiness form iti and align  then load iti into the drawer . </S>
			<S sid="58" ssid="44">Referential distance In complex sentences , noun phrases in the previous clause 2 are the best candidate for the antecedent of an anaphora in the subsequent clause , followed by noun phrases in the previous sentence , then by nouns situated 2 sentences further back and finally nouns 3 sentences further back ( 2 , 1 , 0 , -1 ) . </S>
			<S sid="59" ssid="45">For anaphora in simple sentences , noun phrases in the previous sen&#194;&#173; sentence are the best candidate for antecedent , followed by noun phrases situated 2 sentences further back and finally nouns 3 sentences further back { 1 , 0 , -1 ) . </S>
			<S sid="60" ssid="46">Term preference NPs representing terms in the field are more likely to be the antecedent than NPs which are not terms ( score 1 if the NP is a term and 0 if not ) . </S>
			<S sid="61" ssid="47"> 2 1dentification of clauses in complex sentences is do e heuristically . </S>
			<S sid="62" ssid="48">As already mentioned , each of the antecedent in&#194;&#173; indicators assigns a score with a value { -1 , 0 , 1 , 2 } . </S>
			<S sid="63" ssid="49">These scores have been determined experimentally on an empirical basis and are constantly being up&#194;&#173; dated . </S>
			<S sid="64" ssid="50">Top symptoms like `` lexical reiteration '' as&#194;&#173; sign score `` 2 '' whereas `` non-prepositional '' noun phrases are given a negative score of `` -1 '' . </S>
			<S sid="65" ssid="51">We should point out that the antecedent indicators are preferences and not absolute factors . </S>
			<S sid="66" ssid="52">There might be cases where one or more of the antecedent indicators do not `` point '' to the correct antecedent . </S>
			<S sid="67" ssid="53">For in&#194;&#173; stance , in the sentence `` Insert the cassette into the VCRi making sure iti is turned on '' , the indicator `` non-prepositional noun phrases '' would penalty the correct antecedent . </S>
			<S sid="68" ssid="54">When all preferences ( antecedent indicators ) are taken into account , however , the right antecedent is still very likely to be tracked down - in the above example , the `` non-prepositional noun phrases '' heuristics ( penalty ) would be overturned by the `` collocation preference '' heuristics . </S>
			<S sid="69" ssid="55">2.2 Informal description of the algorithm . </S>
			<S sid="70" ssid="56">The algorithm for pronoun resolution can be de&#194;&#173; scribed informally as follows : 1 . </S>
			<S sid="71" ssid="57">Examine the current sentence and the two pre&#194;&#173; . </S>
			<S sid="72" ssid="58">ceding sentences ( if available ) . </S>
			<S sid="73" ssid="59">Look for noun phrases 3 only to the left of the anaphor 4 2 . </S>
			<S sid="74" ssid="60">Select from the noun phrases identified only . </S>
			<S sid="75" ssid="61">those which agree in gender and numberS with the pronominal anaphora and group them as a set of potential candidates </S>
	</SECTION>
	<SECTION number="3" title="Apply  the antecedent  indicators  to each  poten&#194;&#173;. ">
			<S sid="76" ssid="1">ital candidate and assign scores ; the candidate with the highest aggregate score is proposed as 3A sentence splitter would already have segmented the text into sentences , a POS tagger would already have determined the parts of speech and a simple phrasal grammar would already have detected the noun phrases 4In this project we do not treat anaphora non-anaphoric `` it '' occurring in constructions such as `` It is important '' , `` It is necessary '' is eliminated by a `` referential filter '' 5Note that this restriction may not always apply in lan&#194;&#173; gages other than English ( e.g . German ) ; on the other hand , there are certain collective nouns in English which do not agree in number with their antecedents ( e.g . `` government '' , `` team '' , `` parliament '' etc . can be referred to by `` they '' ; equally some plural nouns ( e.g . `` data '' ) can be referred to by `` it '' ) and are exempted from the agree&#194;&#173; met test . </S>
			<S sid="77" ssid="2">For this purpose we have drawn up a compre&#194;&#173; tensive list of all such cases ; to our knowledge , no other computational treatment of pronominal anaphora resolu&#194;&#173; son has addressed the problem of `` agreement excep&#194;&#173; sons . </S>
			<S sid="78" ssid="3">antecedent . </S>
			<S sid="79" ssid="4">If two candidates have an equal score , the candidate with the higher score for immediate reference is proposed as antecedent . </S>
			<S sid="80" ssid="5">If immediate reference does not hold , propose the candidate with higher score for collocation pattern . </S>
			<S sid="81" ssid="6">If collocation pattern suggests a tie or does not hold , select the candidate with higher score for indicating verbs . </S>
			<S sid="82" ssid="7">If this indicator does not hold again , go for the most recent candidate . </S>
			<S sid="83" ssid="8">3 . </S>
			<S sid="84" ssid="9">Evaluation . </S>
			<S sid="85" ssid="10">For practical reasons , the approach presented does not incorporate syntactic and semantic information ( other than a list of domain terms ) and it is not real&#194;&#173; is tic to expect its performance to be as good as an approach which makes use of syntactic and semantic knowledge in terms of constraints and preferences . </S>
			<S sid="86" ssid="11">The lack of syntactic information , for instance , means giving up c-cornmand constraints and subject preference ( or on other occasions object preference , see Mitkov I995 ) which could be used in center tracking . </S>
			<S sid="87" ssid="12">Syntactic parallelism , useful in discrimi&#194;&#173; eating between identical pronouns on the basis of their syntactic function , also has to be forgone . </S>
			<S sid="88" ssid="13">Lack of semantic knowledge rules out the use of verb se&#194;&#173; antics and semantic parallelism . </S>
			<S sid="89" ssid="14">Our evaluation , however , suggests that much less is lost than might be feared . </S>
			<S sid="90" ssid="15">In fact , our evaluation shows that the re&#194;&#173; cults are comparable to syntax-based methods ( Lappin &amp; Leass I994 ) . </S>
			<S sid="91" ssid="16">We believe that the good success rate is due to the fact that a number of ante&#194;&#173; cement indicators are taken into account and no fac&#194;&#173; tor is given absolute preference . </S>
			<S sid="92" ssid="17">In particular , this strategy can often override incorrect decisions linked with strong centering preference ( Mitkov &amp; Belguith I998 ) or syntactic and semantic parallelism prefer&#194;&#173; hences see below ) . </S>
			<S sid="93" ssid="18">3.1 Evaluation A . Our first evaluation exercise ( Mitkov &amp; Stys 1997 ) was based on a random sample text from a technical manual in English ( Minolta 1994 ) . </S>
			<S sid="94" ssid="19">There were 71 pronouns in the 140 page technical manual ; 7 of the pronouns were non-anaphoric and 16 anaphoric . </S>
			<S sid="95" ssid="20">The resolution of anaphora was carried out with a suc&#194;&#173; less rate of 95.8 % . </S>
			<S sid="96" ssid="21">The approach being robust ( an attempt is made to resolve each anaphora and a pro&#194;&#173; posed antecedent is returned ) , this figure represents both `` precision '' and `` recall '' if we use the MUC terminology . </S>
			<S sid="97" ssid="22">To avoid any terminological confusion , we shall therefore use the more neutral term `` success rate '' while discussing the evaluation . </S>
			<S sid="98" ssid="23">In order to evaluate the effectiveness of the ap&#194;&#173; roach and to explore if I how far it is superior over the baseline models for anaphora resolution , we also tested the sample text on ( i ) a Baseline Model which checks agreement in number and gender and , where more than one candidate remains , picks as antece&#194;&#173; dent the most recent subject matching the gender and number of the anaphora ii ) a Baseline Model which picks as antecedent the most recent noun phrase that matches the gender and number of the anaphora </S>
			<S sid="99" ssid="24">The success rate of the `` Baseline Subject '' was 29.2 % , whereas the success rate of `` Baseline Most Recent NP '' was 62.5 % . </S>
			<S sid="100" ssid="25">Given that our knowledge&#194;&#173; poor approach is basically an enhancement of a baseline model through a set of antecedent indica&#194;&#173; tors , we see a dramatic improvement in performance ( 95.8 % ) when these preferences are called upon . </S>
			<S sid="101" ssid="26">Typically , our preference-based model proved superior to both baseline models when the antece&#194;&#173; dent was neither the most recent subject nor the most recent noun phrase matching the anaphora in gender and number . </S>
			<S sid="102" ssid="27">Example : Identify the drawer by the lit paper port LED and add paper to itj . </S>
			<S sid="103" ssid="28">The aggregate score for `` the drawer '' is 7 ( definiteness 1 + givenness 0 + term preference 1 + indicating verbs I + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate refer&#194;&#173; enc 2 = 7 ) , whereas aggregate score for the most recent matching noun phrase ( `` the lit paper port LED '' ) is 4 ( definiteness 1 + givenness 0 + term preference I + indicating verbs 0 + lexical reitera&#194;&#173; son 0 + section heading 0 + collocation 0 + referen&#194;&#173; ital distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4 ) . </S>
			<S sid="104" ssid="29">From this example we can also see that our knowledge-poor approach successfully tackles cases in which the anaphora and the&#194;&#183; antecedent have not only different syntactic functions but also different semantic roles . </S>
			<S sid="105" ssid="30">Usually knowledge-based ap&#194;&#173; roaches have difficulties in such a situation because they use preferences such as `` syntactic parallelism '' or `` semantic parallelism '' . </S>
			<S sid="106" ssid="31">Our robust approach does not use these because it has no information about the syntactic structure of the sentence or about the syn&#194;&#173; tactic functionalism role of each individual word . </S>
			<S sid="107" ssid="32">As far as the typical failure cases are concerned , we anticipate the knowledge-poor approach to have difficulties with sentences which have a more com&#194;&#173; lex syntactic structure . </S>
			<S sid="108" ssid="33">This should not be surprising , given that the approach does not rely on any syntactic knowledge and in particular , it does not produce any parse tree . </S>
			<S sid="109" ssid="34">Indeed , the approach fails on the sentence : The paper through key can be used to feed [ a blank sheet of paper ] j through the copier out into the copy tray without making a copy on itj . </S>
			<S sid="110" ssid="35">where `` blank sheet of paper '' scores only 2 as op&#194;&#173; posed to the `` the paper through key '' which scores 6 . </S>
			<S sid="111" ssid="36">3.2 Evaluation B . We carried out a second evaluation of the approach on a different set of sample texts from the genre of technical manuals ( 47-page Portable Style-Writer User 's Guide ( Stylewriter 1994 ) . </S>
			<S sid="112" ssid="37">Out of 223 pro&#194;&#173; nouns in the text , 167 were non-anaphoric ( deictic and non-anaphoric `` it '' ) . </S>
			<S sid="113" ssid="38">The evaluation carried out was manual to ensure that no added error was gen&#194;&#173; rated e.g . due to possible wrong sentence detection or POS tagging ) . </S>
			<S sid="114" ssid="39">Another reason for doing it by hand is to ensure a fair comparison with Breck Baldwin 's method , which not being available to us , had to be hand-simulated ( see 3.3 ) . </S>
			<S sid="115" ssid="40">The evaluation indicated 83.6 % success rate . </S>
			<S sid="116" ssid="41">The `` Baseline subject '' model tested on the same data scored 33.9 % recall and 67.9 % precision , whereas `` Baseline most recent '' scored 66.7 % . </S>
			<S sid="117" ssid="42">Note that `` Baseline subject '' can be assessed both in terms of recall and precision because this `` version '' is not robust : in the event of no subject being available , it is not able to propose an antecedent ( the manual guide used as evaluation text contained many im&#194;&#173; imperative sentences ) . </S>
			<S sid="118" ssid="43">In the second experiment we evaluated the ap&#194;&#173; roach from the point of view also of its `` critical success rate '' . </S>
			<S sid="119" ssid="44">This measure ( Mitkov 1998b applies only to anaphora ambiguous '' from the point of view of number and gender ( i.e . to those `` tough '' anaphora , after activating the gender and number filters , still have more than one candidate for antecedent ) and is indicative of the performance of the antecedent indicators . </S>
			<S sid="120" ssid="45">Our evaluation estab&#194;&#173; listed the critical success rate as 82 % . </S>
			<S sid="121" ssid="46">A case where the system failed was when the anaphora and the antecedent were in the same sen&#194;&#173; sentence and where preference was given to a candidate in the preceding sentence . </S>
			<S sid="122" ssid="47">This case and other cases suggest that it might be worthwhile reconsider&#194;&#173; interlining the weights for the indicator `` referential distance '' . </S>
			<S sid="123" ssid="48">Similarly to the first evaluation , we found that the robust approach was not very successful on sen&#194;&#173; sentences with too complicated syntax - a price we have to pay for the `` convenience '' of developing a knowl&#194;&#173; edge-poor system . </S>
			<S sid="124" ssid="49">The results from experiment 1 and experiment 2 can be summarized in the following ( statistically ) slightly more representative figures . </S>
			<S sid="125" ssid="50">R ob ust aQ pr oa ch B a s el i n e s u b je ct B as eli ne m os t re ce nt Su cc es s rat e ( = Pr ec isi on / Re ca ll ) 8 9 . </S>
			<S sid="126" ssid="51">7 % 31 . </S>
			<S sid="127" ssid="52">55 % I 48 .5 5 % 6 5 . 9 5 % The lower figure in `` Baseline subject '' corresponds to `` recall '' and the higher figure- to `` precision '' . </S>
			<S sid="128" ssid="53">If we regard as `` discriminative power '' of each antecedent indicator the ratio `` number of successful antecedent identifications when this indicator was applied '' / '' number of applications of this indicator '' ( for the non-prepositional noun phrase and definite&#194;&#173; less being penalizing indicators , this figure is calcu&#194;&#173; lated as the ratio `` number of unsuccessful antece&#194;&#173; dent identifications '' / '' number of applications '' ) , the immediate reference emerges as the most discrimi&#194;&#173; native indicator ( 100 % ) , followed by non&#194;&#173; prepositional noun phrase ( 92.2 % ) , collocation ( 90.9 % ) , section heading ( 61.9 % ) , lexical reiteration ( 58.5 % ) , givenness ( 49.3 % ) , term preference ( 35.7 % ) and referential distance ( 34.4 % ) . </S>
			<S sid="129" ssid="54">The rela&#194;&#173; lively low figures for the majority of indicators should not be regarded as a surprise : firstly , we should bear in mind that in most cases a candidate was picked ( or rejected ) as an antecedent on the ba&#194;&#173; sis of applying a number of different indicators and secondly , that most anaphora had a relatively high number of candidates for antecedent . </S>
			<S sid="130" ssid="55">In terms of frequency of use ( `` number of nonzero applications '' / '' number of anaphora ) , the most fre&#194;&#173; frequently used indicator proved to be referential dis&#194;&#173; stance used in 98.9 % of the cases , followed by term preference ( 97.8 % ) , givenness ( 83.3 % ) , lexical reit&#194;&#173; ration 64.4 % ) , definiteness ( 40 % ) , section heading ( 37.8 % ) , immediate reference ( 31.1 % ) and colloca&#194;&#173; son 11.1 % ) . </S>
			<S sid="131" ssid="56">As expected , the most frequent indica&#194;&#173; tors were not the most discriminative ones . </S>
			<S sid="132" ssid="57">3.3 Comparison to similar approaches : compara&#194;&#173; . </S>
			<S sid="133" ssid="58">tie evaluation of Breck Baldwin 's CogNIAC We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin 's Cog&#194;&#173; NIAC ( Baldwin 1997 ) approach which features `` high precision preference with limited knowledge and linguistics resources '' . </S>
			<S sid="134" ssid="59">The reason is that both our approach and Breck Baldwin 's approach share common principles ( both are knowledge-poor and use a POS tagger to provide the input ) and therefore a comparison would be appropriate . </S>
			<S sid="135" ssid="60">Given that our approach is robust and returns an&#194;&#173; antecedent for each pronoun , in order to make the comparison as fair as possible , we used CogNIAC 's `` resolve all '' version by simulating it manually on the same training data used in evaluation B above . </S>
			<S sid="136" ssid="61">CogNIAC successfully resolved the pronouns in 75 % of the cases . </S>
			<S sid="137" ssid="62">This result is comparable with the results described in ( Baldwin 1997 ) . </S>
			<S sid="138" ssid="63">For the training data from the genre of technical manuals , it was rule 5 ( see Baldwin 1997 ) which was most frequently used ( 39 % of the cases , 100 % success ) , followed by rule 8 ( 33 % of the cases , 33 % success ) , rule 7 ( 11 % , 100 % ) , rule I ( 9 % , 100 % ) and rule 3 ( 7.4 % , 100 % ) . </S>
			<S sid="139" ssid="64">It would be fair to say that even though the results show superiority of our approach on the training data used ( the genre of technical manuals ) , they can not be generalized automatically for other genres or unrestricted texts and for a more accurate picture , further extensive tests are necessary . </S>
	</SECTION>
	<SECTION number="4" title="Adapting the robust  approach for other. ">
			<S sid="140" ssid="1">languages An attractive feature of any NLP approach would be its language `` universality '' . </S>
			<S sid="141" ssid="2">While we acknowledge that most of the monolingual NLP approaches are not automatically transferable ( with the same degree of efficiency ) to other languages , it would be highly desirable if this could be done with minimal adapta&#194;&#173; son . </S>
			<S sid="142" ssid="3">We used the robust approach as a basis for devel&#194;&#173; oping a genre-specific reference resolution approach in Polish . </S>
			<S sid="143" ssid="4">As expected , some of the preferences had to be modified in order to fit with specific features of Polish ( Mitkov &amp; Stys 1997 ) . </S>
			<S sid="144" ssid="5">For the time being , we are using the same scores for Polish . </S>
			<S sid="145" ssid="6">The evaluation for Polish was based technical manuals available on the Internet ( Internet Manual , 1994 ; Java Manual 1998 ) . </S>
			<S sid="146" ssid="7">The sample texts con&#194;&#173; tined 180 pronouns among which were 120 in&#194;&#173; stances of anaphoric reference ( most being zero pro&#194;&#173; nouns ) . </S>
			<S sid="147" ssid="8">The robust approach adapted for Polish demonstrated a high success rate of 93.3 % in resolv&#194;&#173; ing anaphora with critical success rate of 86.2 % ) . </S>
			<S sid="148" ssid="9">Similarly to the evaluation for English , we com&#194;&#173; pared the approach for Polish with ( i ) a Baseline Model which discounts candidates on the basis of agreement in number and gender and , if there were still competing candidates , selects as the antecedent the most recent subject matching the anaphora in gender and number ( ii ) a Baseline Model which checks agreement in number and gender and , if there were still more than one candidate left , picks up as the antecedent the most recent noun phrase that agrees with the anaphora . </S>
			<S sid="149" ssid="10">Our preference-based approach showed clear su&#194;&#173; priority over both baseline models . </S>
			<S sid="150" ssid="11">The first Base&#194;&#173; line Model ( Baseline Subject ) was successful in only 23.7 % of the cases , whereas the second ( Baseline Most Recent ) had a success rate of 68.4 % . </S>
			<S sid="151" ssid="12">There&#194;&#173; fore , the 93.3 % success rate ( see above ) demon&#194;&#173; states a dramatic increase in precision , which is due to the use of antecedent tracking preferences . </S>
			<S sid="152" ssid="13">We have recently adapted the approach for Ara&#194;&#173; bic as well ( Mitkov &amp; Belguith 1998 ) . </S>
			<S sid="153" ssid="14">Our evalua&#194;&#173; son based on 63 examples ( anaphora from a tech&#194;&#173; finical manual ( Sony 1992 ) , indicates a success rate of 95.2 % ( and critical success rate 89.3 % ) . </S>
	</SECTION>
	<SECTION number="5" title="Conclusion. ">
			<S sid="154" ssid="1">We have described a robust , knowledge-poor ap&#194;&#173; roach to pronoun resolution which operates on texts pre-processed by a part-of-speech tagger . </S>
			<S sid="155" ssid="2">Evaluation shows a success rate of 89.7 % for the genre of tech&#194;&#173; finical manuals and at least in this genre , the approach appears to be more successful than other similar methods . </S>
			<S sid="156" ssid="3">We have also adapted and evaluated the approach for Polish ( 93.3 % success rate ) and for Arabic ( 95.2 % success rate ) . </S>
	</SECTION>
</PAPER>