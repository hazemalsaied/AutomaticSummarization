Citance Number: 1 | Reference Article:  J96-3004.xml | Citing Article:  A00-2032.xml | Citation Marker Offset:  ['142'] | Citation Marker:  1996 | Citation Offset:  ['141','142'] | Citation Text:  <S sid ="141" ssid = "10">Chinese According to Sproat et al.</S><S sid ="142" ssid = "11">(1996), most prior work in Chinese segmentation has exploited lexical knowledge bases; indeed, the authors assert that they were aware of only one previously pubÂ­ lished instance (the mutual-information method of Sproat and Shih (1990)) of a purely statistical apÂ­ proach.</S> | Reference Offset:  ['91', '101', '128', '227'] | Reference Text:  <S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S><S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S><S sid ="227" ssid = "91">4.4 Chinese Personal Names.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:  J96-3004.xml | Citing Article:  A00-2032.xml | Citation Marker Offset:  ['5'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['5'] | Citation Text:  <S sid ="5" ssid = "5">Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting optical character recognition (OCR) erÂ­ rors (Wu and Tseng, 1993; Nagao and Mori, 1994; Nagata, 1996a; Nagata, 1996b; Sproat et al., 1996; Fung, 1998).</S> | Reference Offset:  ['52', '408', '117', '50'] | Reference Text:  <S sid ="52" ssid = "13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng&apos;s (1993) discussion of the role of segmentation in information retrieval.</S><S sid ="408" ssid = "11">This is not to say that a set of standards by which a particular segmentation would count as correct and another incorrect could not be devised; indeed, such standards have been proposed and include the published PRCNSC (1994) and ROCLING (1993), as well as the unpublished Linguistic Data Consortium standards (ca.</S><S sid ="117" ssid = "55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost­ based scoring mechanism.</S><S sid ="50" ssid = "11">Given that part-of-speech labels are properties of words rather than morphemes, it follows that one cannot do part-of-speech assignment without having access to word-boundary information.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 3 | Reference Article:  J96-3004.xml | Citing Article:  C00-2095.xml | Citation Marker Offset:  ['80'] | Citation Marker:  Sproat ct a.l., 1996 | Citation Offset:  ['80'] | Citation Text:  <S sid ="80" ssid = "25">As (Sproat ct a.l., 1996) testify, several native Chinese speakers do not always agree on one unique tokeniza.tion for a. given sentence.</S> | Reference Offset:  ['33', '228', '458', '5'] | Reference Text:  <S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S><S sid ="228" ssid = "92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S><S sid ="458" ssid = "4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S><S sid ="5" ssid = "5">A moment&apos;s reflection will reveal that things are not quite that simple.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 4 | Reference Article:  J96-3004.xml | Citing Article:  C02-1049.xml | Citation Marker Offset:  ['58'] | Citation Marker:  Sproat et al, 1996 | Citation Offset:  ['58'] | Citation Text:  <S sid ="58" ssid = "39">Conventionally a word segmentation process identifies the words in input text by matching lexical entries and resolving the ambiguous matching (Chen &amp; Liu, 1992, Sproat et al, 1996).</S> | Reference Offset:  ['115', '150', '55', '116'] | Reference Text:  <S sid ="115" ssid = "53">Others depend upon various lexical heuris­ tics: for example Chen and Liu (1992) attempt to balance the length of words in a three-word window, favoring segmentations that give approximately equal length for each word.</S><S sid ="150" ssid = "14">This WFST represents the segmentation of the text into the words AB and CD, word boundaries being marked by arcs mapping between f and part-of-speech labels.</S><S sid ="55" ssid = "16">For novel texts, no lexicon that consists simply of a list of word entries will ever be entirely satisfactory, since the list will inevitably omit many constructions that should be considered words.</S><S sid ="116" ssid = "54">Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:  J96-3004.xml | Citing Article:  C02-1049.xml | Citation Marker Offset:  ['127'] | Citation Marker:  Sproat et al, 1996 | Citation Offset:  ['125','126','127'] | Citation Text:  <S sid ="124" ssid = "105">Mutu al infor matio n-like statist ics are very often adopt ed in meas uring assoc iation stren gth msi (?)</S><S sid ="127" ssid = "108">dsi +1 () combine (i, i + 1) 1993, Sproat et al, 1996)</S> | Reference Offset:  ['49', '101', '102', '251'] | Reference Text:  <S sid ="49" ssid = "10">It has been shown for English (Wang and Hirschberg 1992; Hirschberg 1993; Sproat 1994, inter alia) that grammatical part of speech provides useful information for these tasks.</S><S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="102" ssid = "40">However, the characterization given in the main body of the text is correct sufficiently often to be useful.</S><S sid ="251" ssid = "115">As we have noted in Section 2, the general semantic class to which a hanzi belongs is often predictable from its semantic radical.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 6 | Reference Article:  J96-3004.xml | Citing Article:  C02-1080.xml | Citation Marker Offset:  ['20'] | Citation Marker:  Sproat et al. 96 | Citation Offset:  ['20'] | Citation Text:  <S sid ="20" ssid = "20">Chinese NE recognition is much more difficult than that in English due to two major problems.</S><S sid ="21" ssid = "21">The first is the word segmentation problem (Sproat et al. 96, Palmer 97).</S> | Reference Offset:  ['137', '33', '106', '23'] | Reference Text:  <S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S><S sid ="106" ssid = "44">The first concerns how to deal with ambiguities in segmentation.</S><S sid ="23" ssid = "23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 7 | Reference Article:  J96-3004.xml | Citing Article:  C02-1143.xml | Citation Marker Offset:  ['107'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['107'] | Citation Text:  <S sid ="107" ssid = "48">We used a maximum- matching algorithm and a dictionary compiled from the CTB (Sproat et al., 1996; Xue, 2001) to do segmentation | Reference Offset:  ['305', '307', '135', '102'] | Reference Text:  <S sid ="305" ssid = "14">A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.</S><S sid ="307" ssid = "16">An anti-greedy algorithm, AG: instead of the longest match, take the.</S><S sid ="135" ssid = "73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S><S sid ="102" ssid = "40">However, the characterization given in the main body of the text is correct sufficiently often to be useful.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 8 | Reference Article:  J96-3004.xml | Citing Article:  E09-1063.xml | Citation Marker Offset:  ['107'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['107'] | Citation Text:  <S sid ="107" ssid = "4">First of all, it is really difficult to build a reliable and objective gold-standard given the fact that there is only 70% agreement between native speakers on this task (Sproat et al., 1996).</S> | Reference Offset:  ['93', '246', '264', '92'] | Reference Text:  <S sid ="93" ssid = "31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S><S sid ="246" ssid = "110">First, the model assumes independence between the first and second hanzi of a double given name.</S><S sid ="264" ssid = "128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S><S sid ="92" ssid = "30">In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 9 | Reference Article:  J96-3004.xml | Citing Article:  I05-3031.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['6','7'] | Citation Text:  <S sid ="6" ssid = "6">The Chinese word segmentation is a nontrivial task because no explicit delimiters (like spaces in English) are used for word separation.</S><S sid ="7" ssid = "7">As the task is an important precursor to many natural language processing systems, it receives a lot of attentions in the literature for the past decade (Wu and Tseng, 1993; Sproat et al., 1996).</S> | Reference Offset:  ['33', '88', '137', '124'] | Reference Text:  <S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S><S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 10 | Reference Article:  J96-3004.xml | Citing Article:  J00-3004.xml | Citation Marker Offset:  ['42'] | Citation Marker:  1996 | Citation Offset:  ['42'] | Citation Text:  <S sid ="42" ssid = "42">According to Sproat et al. {1996) and Wu and Fung {1994), experiments show that only about 75% agreement between native speakers is to be expected on the &quot;correct&quot; segmentation, and the figure reduces as more people become involved.</S> | Reference Offset:  ['136', '185', '129', '50'] | Reference Text:  <S sid ="136" ssid = "74">Furthermore, even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus: as Fung and Wu (1994) have shown, one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented.</S><S sid ="185" ssid = "49">Both of these analyses are shown in Figure 4; fortunately, the correct analysis is also the one with the lowest cost, so it is this analysis that is chosen.</S><S sid ="129" ssid = "67">However, it is almost universally the case that no clear definition of what constitutes a &quot;correct&quot; segmentation is given, so these performance measures are hard to evaluate.</S><S sid ="50" ssid = "11">Given that part-of-speech labels are properties of words rather than morphemes, it follows that one cannot do part-of-speech assignment without having access to word-boundary information.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 11 | Reference Article:  J96-3004.xml | Citing Article:  J00-3004.xml | Citation Marker Offset:  ['96'] | Citation Marker:  1996 | Citation Offset:  ['96'] | Citation Text:  <S sid ="96" ssid = "41">Sproat et al.</S><S sid ="97" ssid = "42">(1996) implement special recognizers not only for Chinese names and transliterated foreign names, but for components of morphologically obtained words as well.</S> | Reference Offset:  ['101', '128', '227', '280'] | Reference Text:  <S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S><S sid ="227" ssid = "91">4.4 Chinese Personal Names.</S><S sid ="280" ssid = "144">4.5 Transliterations of Foreign Words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 12 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['53'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['53'] | Citation Text:  <S sid ="53" ssid = "53">In Chinese text segmentation there are three basic approaches (Sproat et al. 1996): pure heuristic, pure statistical, and a hybrid of the two.</S> | Reference Offset:  ['91', '455', '90', '92'] | Reference Text:  <S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S><S sid ="455" ssid = "1">Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.</S><S sid ="90" ssid = "28">The present proposal falls into the last group.</S><S sid ="92" ssid = "30">In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 13 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['113'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['113'] | Citation Text:  <S sid ="113" ssid = "9">There are several commonly used segmentation methods such as forward maximum matching and backward maximum matching(Teahan et al. 2000; Dai, Loh, and Khoo 1999; Sproat et al. 1996).</S> | Reference Offset:  ['108', '112', '107', '109'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="112" ssid = "50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S><S sid ="107" ssid = "45">The second concerns the methods used (if any) to ex­ tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 14 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['211'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['211'] | Citation Text:  <S sid ="211" ssid = "32">In addition, there is no commonly accepted standard for evaluating the performance of word extraction methods, and it is very hard to decide whether a word is meaningful or not (Sproat et al. 1996).</S> | Reference Offset:  ['129', '412', '357', '411'] | Reference Text:  <S sid ="129" ssid = "67">However, it is almost universally the case that no clear definition of what constitutes a &quot;correct&quot; segmentation is given, so these performance measures are hard to evaluate.</S><S sid ="412" ssid = "15">Unfortunately, there is no standard corpus of Chinese texts, tagged with either single or multiple human judgments, with which one can compare performance of various methods.</S><S sid ="357" ssid = "66">Interestingly, Chang et al. report 80.67% recall and 91.87% precision on an 11,000 word corpus: seemingly, our system finds as many names as their system, but with four times as many false hits.</S><S sid ="411" ssid = "14">Second, comparisons of different methods are not meaningful unless one can eval­ uate them on the same corpus.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 15 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['321'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['321'] | Citation Text:  <S sid ="321" ssid = "7">As even human judges differ when facing the task of segmenting a text into words and test corpora differ from system to system (Sproat et al. 1996), it is very difficult to compare two methods.</S> | Reference Offset:  ['70', '130', '133', '69'] | Reference Text:  <S sid ="70" ssid = "8">This latter evaluation compares the performance of the system with that of several human judges since, as we shall show, even people do not agree on a single correct way to segment a text.</S><S sid ="130" ssid = "68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S><S sid ="133" ssid = "71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S><S sid ="69" ssid = "7">We will evaluate various specific aspects of the segmentation, as well as the overall segmentation per­ formance.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 16 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['88'] | Citation Marker:  1996 | Citation Offset:  ['88'] | Citation Text:  <S sid ="88" ssid = "24">A previous work along this line is Sproat et al.</S><S sid ="89" ssid = "25">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset:  ['67', '87', '91', '398'] | Reference Text:  <S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="87" ssid = "25">Previous Work.</S><S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S><S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 17 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['126'] | Citation Marker:  1996 | Citation Offset:  ['125','126'] | Citation Text:  <S sid ="125" ssid = "61">As shown in Sproat et al.</S><S sid ="126" ssid = "62">(1996), the rate of agreement between two human judges is less than 80%.</S> | Reference Offset:  ['49', '326', '346', '350'] | Reference Text:  <S sid ="49" ssid = "10">It has been shown for English (Wang and Hirschberg 1992; Hirschberg 1993; Sproat 1994, inter alia) that grammatical part of speech provides useful information for these tasks.</S><S sid ="326" ssid = "35">The result of this is shown in Figure 7.</S><S sid ="346" ssid = "55">Nonetheless, the results of the comparison with human judges demonstrates that there is mileage being gained by incorporating models of these types of words.</S><S sid ="350" ssid = "59">Under this scheme, n human judges are asked independently to segment a text.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 18 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['132'] | Citation Marker:  1996 | Citation Offset:  ['131','132'] | Citation Text:  <S sid ="131" ssid = "67">Similarly, Sproat et al.</S><S sid ="132" ssid = "68">(1996) also uses multiple human judges.</S> | Reference Offset:  ['101', '174', '350', '424'] | Reference Text:  <S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="174" ssid = "38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S><S sid ="350" ssid = "59">Under this scheme, n human judges are asked independently to segment a text.</S><S sid ="424" ssid = "27">In (1) the sequencema3lu4 cannot be resolved locally, but depends instead upon broader context; similarly in (2), the sequence :::tcai2neng2 cannot be resolved locally: 1.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 19 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['490'] | Citation Marker:  1996 | Citation Offset:  ['489','490'] | Citation Text:  <S sid ="489" ssid = "153">The Chinese person-name model is a modified version of that described in Sproat et al.</S><S sid ="490" ssid = "154">(1996).</S> | Reference Offset:  ['16', '458', '462', '244'] | Reference Text:  <S sid ="16" ssid = "16">com §Cambridge, UK Email: nc201@eng.cam.ac.uk © 1996 Association for Computational Linguistics (a) B ) ( , : &amp; ; ? &apos; H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? &apos; (b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : &amp; I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l &apos; J a p a n e s e &apos; &apos; o c t o p u s &apos; &apos; h o w &apos; &apos; s a y &apos; (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [§] lxI 1:&amp;I ri4 wen2 zhangl yu2zen3 me0 shuol &apos;Japan&apos; &apos;essay&apos; &apos;fish&apos; &apos;how&apos; &apos;say&apos; A Chinese sentence in (a) illustrating the lack of word boundaries.</S><S sid ="458" ssid = "4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S><S sid ="462" ssid = "8">21 In Chinese, numerals and demonstratives cannot modify nouns directly, and must be accompanied by.</S><S sid ="244" ssid = "108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 20 | Reference Article:  J96-3004.xml | Citing Article:  J11-1005.xml | Citation Marker Offset:  ['123'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['123'] | Citation Text:  <S sid ="123" ssid = "14">Experiments have shown that there is only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al. 1996).</S> | Reference Offset:  ['165', '352', '325', '136'] | Reference Text:  <S sid ="165" ssid = "29">The segmentation chosen is the best path through the WFST, shown in (d).</S><S sid ="352" ssid = "61">For a given &quot;word&quot; in the automatic segmentation, if at least k of the hu­ man judges agree that this is a word, then that word is considered to be correct.</S><S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis­ tance matrix, and plotting the first two most significant dimensions.</S><S sid ="136" ssid = "74">Furthermore, even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus: as Fung and Wu (1994) have shown, one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 21 | Reference Article:  J96-3004.xml | Citing Article:  J11-3001.xml | Citation Marker Offset:  ['326'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['326'] | Citation Text:  <S sid ="326" ssid = "279">Gold standards, however, 435 cannot be uniﬁed into a single standard (Fung and Wu 1994; Sproat et al. 1996).</S> | Reference Offset:  ['303', '348', '318', '358'] | Reference Text:  <S sid ="303" ssid = "12">(See also Wu and Fung [1994].)</S><S sid ="348" ssid = "57">However, this result is consistent with the results of ex­ periments discussed in Wu and Fung (1994).</S><S sid ="318" ssid = "27">computing the recall of the other&apos;s judgments relative to this standard.</S><S sid ="358" ssid = "67">However, we have reason to doubt Chang et al.&apos;s performance claims.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 22 | Reference Article:  J96-3004.xml | Citing Article:  J96-4004.xml | Citation Marker Offset:  ['24'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['24'] | Citation Text:  <S sid ="24" ssid = "24">Our ap . proach differs from existing work on Chinese word segmentation (Liang 1983; Wang, Wang, and Bai 1991; Fan and Tsai 1988; Chang, Chen, and Chen 1991; Chiang et al. 1992; Sproat and Shih 1990; Wu and Su 1993; Lua and Gan 1994; Lai et al. 1992; Sproat et al. 1994; Sproat et al. 1996) primarily in that our system performs sentence interÂ­ pretation, in addition to word boundary identification.</S> | Reference Offset:  ['88', '124', '367', '121'] | Reference Text:  <S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S><S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S><S sid ="367" ssid = "76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S><S sid ="121" ssid = "59">Note that Chang, Chen, and Chen (1991), in addition to word-frequency information, include a constraint-satisfication model, so their method is really a hybrid approach.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 23 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">Since in written Chinese there is no explicit word delimiter (equivalent to the blank space in written English), the problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made (e.g., Bai 1995; Zhang et al. 1994; Chen and Liu 1992; Chiang et al. 1992; Fan and Tsai 1988; Gan 1995; Gan, Palmer, and Lua 1996; Guo 1993; He, Xu, and Sun 1991; Huang 1989; Huang and Xia 1996; Jie 1989; Jie, Liu, and Liang 1991a, 1991b; Jin and Chen 1995; Lai et al. 1992; Li et al. 1995; Liang 1986, 1987, 1990; Liu 1986a, 1986b; Liu, Tan, and Shen 1994; Lua 1990, 1994, and 1995; Ma 1996; Nie, Jin, and Hannan 1994; Sproat and Shih 1990; Sproat et al. 1996;</S> | Reference Offset:  ['111', '116', '115', '132'] | Reference Text:  <S sid ="111" ssid = "49">(1991}, Gu and Mao (1994), and Nie, Jin, and Hannan (1994).</S><S sid ="116" ssid = "54">Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).</S><S sid ="115" ssid = "53">Others depend upon various lexical heuris­ tics: for example Chen and Liu (1992) attempt to balance the length of words in a three-word window, favoring segmentations that give approximately equal length for each word.</S><S sid ="132" ssid = "70">For example Chen and Liu (1992) report precision and recall rates of over 99%, but this counts only the words that occur in the test corpus that also occur in their dictionary.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 24 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['515'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['515'] | Citation Text:  <S sid ="515" ssid = "92">The three tokenization definitions in this section are essentially descriptive restatements of the corresponding constructive tokenization procedures, which in turn are realizaÂ­ tions of the widely followed principle of maximum tokenization (e.g., Liu 1986; Liang 1986a, 1986b; Wang 1989; Jie 1989; Wang, Su, and Mo 1990; Jie, Liu, and Liang 1991a, b; Yeh and Lee 1991; Webster and Kit 1992; Chen and Liu 1992; Guo 1993; Wu and Su 1993; Nie, Jin, and Hannan 1994; Sproat et al. 1996;</S> | Reference Offset:  ['111', '116', '367', '110'] | Reference Text:  <S sid ="111" ssid = "49">(1991}, Gu and Mao (1994), and Nie, Jin, and Hannan (1994).</S><S sid ="116" ssid = "54">Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).</S><S sid ="367" ssid = "76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S><S sid ="110" ssid = "48">Papers that use this method or minor variants thereof include Liang (1986), Li et al.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 25 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['613'] | Citation Marker:  1996 | Citation Offset:  ['612','613'] | Citation Text:  <S sid ="612" ssid = "54">The weighted finite-state transducer model developed by Sproat et al.</S><S sid ="613" ssid = "55">(1996) is another excellent representative example.</S> | Reference Offset:  ['67', '369', '398', '436'] | Reference Text:  <S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="369" ssid = "78">Examples are given in Table 4.</S><S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S><S sid ="436" ssid = "39">Consider first the examples in (2).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 26 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['621'] | Citation Marker:  1996 | Citation Offset:  ['621'] | Citation Text:  <S sid ="621" ssid = "63">While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching, they are apÂ­ parently employed neither in Sproat et al.</S><S sid ="622" ssid = "64">(1996) nor in Ma (1996).</S> | Reference Offset:  ['16', '67', '456', '293'] | Reference Text:  <S sid ="16" ssid = "16">com §Cambridge, UK Email: nc201@eng.cam.ac.uk © 1996 Association for Computational Linguistics (a) B ) ( , : &amp; ; ? &apos; H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? &apos; (b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : &amp; I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l &apos; J a p a n e s e &apos; &apos; o c t o p u s &apos; &apos; h o w &apos; &apos; s a y &apos; (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [§] lxI 1:&amp;I ri4 wen2 zhangl yu2zen3 me0 shuol &apos;Japan&apos; &apos;essay&apos; &apos;fish&apos; &apos;how&apos; &apos;say&apos; A Chinese sentence in (a) illustrating the lack of word boundaries.</S><S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="456" ssid = "2">The model we use provides a simple framework in which to incorporate a wide variety of lexical information in a uniform way.</S><S sid ="293" ssid = "2">The first is an evaluation of the system&apos;s ability to mimic humans at the task of segmenting text into word-sized units; the second evaluates the proper-name identification; the third measures the performance on morphological analysis.</S> | Discourse Facet:  ['Aim_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 27 | Reference Article:  J96-3004.xml | Citing Article:  N10-1068.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Many natural language models can be captured by weighted finite-state transducers (Pereira et al., 1994; Sproat et al., 1996; Knight and AlOnaizan, 1998; Clark, 2002; Kolak et al., 2003; Mathias and Byrne, 2006), which offer several benefits:â€¢ WFSTs provide a uniform knowledge represen tation.</S> | Reference Offset:  ['67', '244', '457', '245'] | Reference Text:  <S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="244" ssid = "108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S><S sid ="457" ssid = "3">The use of weighted transducers in particular has the attractive property that the model, as it stands, can be straightforwardly interfaced to other modules of a larger speech or natural language system: presumably one does not want to segment Chinese text for its own sake but instead with a larger purpose in mind.</S><S sid ="245" ssid = "109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 28 | Reference Article:  J96-3004.xml | Citing Article:  P03-1035.xml | Citation Marker Offset:  ['41'] | Citation Marker:  1996 | Citation Offset:  ['41'] | Citation Text:  <S sid ="41" ssid = "18">One example of such approaches is Sproat et al.</S><S sid ="42" ssid = "19">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset:  ['34', '67', '369', '398'] | Reference Text:  <S sid ="34" ssid = "34">For example, suppose one is building a ITS system for Mandarin Chinese.</S><S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="369" ssid = "78">Examples are given in Table 4.</S><S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 29 | Reference Article:  J96-3004.xml | Citing Article:  P03-1035.xml | Citation Marker Offset:  ['122'] | Citation Marker:  1996 | Citation Offset:  ['122'] | Citation Text:  <S sid ="122" ssid = "27">Because any character strings can be in principle named entities of one or more types, to limit the number of candidates for a more effective search, we generate named entity candidates, given an input string, in two steps: First, for each type, we use a set of constraints (which are compiled by 3 Sproat et al.</S> | Reference Offset:  ['230', '422', '229', '263'] | Reference Text:  <S sid ="230" ssid = "94">Given names are most commonly two hanzi long, occasionally one hanzi long: there are thus four possible name types, which can be described by a simple set of context-free rewrite rules such as the following: 1.</S><S sid ="422" ssid = "25">Two sets of examples from Gan are given in (1) and (2) (:::::: Gan&apos;s Appendix B, exx.</S><S sid ="229" ssid = "93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S><S sid ="263" ssid = "127">We of course also fail to identify, by the methods just described, given names used without their associated family name.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 30 | Reference Article:  J96-3004.xml | Citing Article:  P03-1035.xml | Citation Marker Offset:  ['155'] | Citation Marker:  1996 | Citation Offset:  ['155'] | Citation Text:  <S sid ="154" ssid = "59">5.2.4 Transliterations of foreign names As described in Sproat et al.</S><S sid ="155" ssid = "60">(1996): FNs are usually transliterated using Chinese character strings whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Reference Offset:  ['281', '24', '280', '399'] | Reference Text:  <S sid ="281" ssid = "145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S><S sid ="24" ssid = "24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S><S sid ="280" ssid = "144">4.5 Transliterations of Foreign Words.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 31 | Reference Article:  J96-3004.xml | Citing Article:  P06-1010.xml | Citation Marker Offset:  ['43'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['42','43'] | Citation Text:  <S sid ="42" ssid = "10">Candidate Chinese transliterations are generated by consulting a list of characters that are frequently used for transliterating foreign names.</S><S sid ="43" ssid = "11">As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese.</S> | Reference Offset:  ['161', '281', '399', '283'] | Reference Text:  <S sid ="161" ssid = "25">7 Big 5 is the most popular Chinese character coding standard in use in Taiwan and Hong Kong.</S><S sid ="281" ssid = "145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S><S sid ="283" ssid = "147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 &apos;Shamir,&apos; which is a legal Chi­ nese personal name, retains a foreign flavor because of liM.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 32 | Reference Article:  J96-3004.xml | Citing Article:  P06-1126.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Chinese word segmentation is the initial stage of many Chinese language processing tasks, and has received a lot of attention in the literature (Sproat et al., 1996; Sun and Tsou, 2001; Zhang et al., 2003; Peng et al., 2004).</S> | Reference Offset:  ['88', '137', '20', '21'] | Reference Text:  <S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 33 | Reference Article:  J96-3004.xml | Citing Article:  P07-1015.xml | Citation Marker Offset:  ['113'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['113'] | Citation Text:  <S sid ="113" ssid = "21">Using the 495 characters that are frequently used for transliterating foreign names (Sproat et al., 1996), a sequence of three of more characters from the list was taken as a possible candidate for Chinese.</S> | Reference Offset:  ['161', '281', '283', '284'] | Reference Text:  <S sid ="161" ssid = "25">7 Big 5 is the most popular Chinese character coding standard in use in Taiwan and Hong Kong.</S><S sid ="281" ssid = "145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S><S sid ="283" ssid = "147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 &apos;Shamir,&apos; which is a legal Chi­ nese personal name, retains a foreign flavor because of liM.</S><S sid ="284" ssid = "148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 34 | Reference Article:  J96-3004.xml | Citing Article:  P07-1016.xml | Citation Marker Offset:  ['70'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['70'] | Citation Text:  <S sid ="70" ssid = "42">As discussed elsewhere (Sproat et al., 1996), out of several thousand common Chinese characters, a subset of a few hundred characters tends to be used overwhelmingly for transliterating English names to Chinese, e.g. only 731 Chinese characters are adopted in the E-C corpus.</S> | Reference Offset:  ['33', '161', '23', '21'] | Reference Text:  <S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S><S sid ="161" ssid = "25">7 Big 5 is the most popular Chinese character coding standard in use in Taiwan and Hong Kong.</S><S sid ="23" ssid = "23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S><S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 35 | Reference Article:  J96-3004.xml | Citing Article:  P12-1110.xml | Citation Marker Offset:  ['105'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['105'] | Citation Text:  <S sid ="105" ssid = "53">3.3.1 Dictionary features Because segmentation using a dictionary alone can serve as a strong baseline in Chinese word segmentation (Sproat et al., 1996), the use of dictionaries is expected to make our joint model more robust and enables us to investigate the contribution of the syntactic dependency in a more realistic setting.</S> | Reference Offset:  ['398', '455', '134', '135'] | Reference Text:  <S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S><S sid ="455" ssid = "1">Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.</S><S sid ="134" ssid = "72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S><S sid ="135" ssid = "73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 36 | Reference Article:  J96-3004.xml | Citing Article:  P12-1111.xml | Citation Marker Offset:  ['91'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['91'] | Citation Text:  <S sid ="91" ssid = "31">In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996).</S> | Reference Offset:  ['108', '335', '244', '5'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="335" ssid = "44">16 As one reviewer points out, one problem with the unigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words.</S><S sid ="244" ssid = "108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S><S sid ="5" ssid = "5">A moment&apos;s reflection will reveal that things are not quite that simple.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 37 | Reference Article:  J96-3004.xml | Citing Article:  P97-1041.xml | Citation Marker Offset:  ['12'] | Citation Marker:  1996 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">For a discussion of recent Chinese segmentation work, see Sproat et al. {1996).</S> | Reference Offset:  ['101', '402', '23', '88'] | Reference Text:  <S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="402" ssid = "5">(For some recent corpus-based work on Chinese abbreviations, see Huang, Ahrens, and Chen [1993].)</S><S sid ="23" ssid = "23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S><S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 38 | Reference Article:  J96-3004.xml | Citing Article:  P97-1041.xml | Citation Marker Offset:  ['39'] | Citation Marker:  1996 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "5">It is rule-based, but relies on 2 See, for example, Sproat et al.</S><S sid ="40" ssid = "6">(1996)</S> | Reference Offset:  ['16', '101', '369', '459'] | Reference Text:  <S sid ="16" ssid = "16">com §Cambridge, UK Email: nc201@eng.cam.ac.uk © 1996 Association for Computational Linguistics (a) B ) ( , : &amp; ; ? &apos; H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? &apos; (b) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : &amp; I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l &apos; J a p a n e s e &apos; &apos; o c t o p u s &apos; &apos; h o w &apos; &apos; s a y &apos; (c) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [§] lxI 1:&amp;I ri4 wen2 zhangl yu2zen3 me0 shuol &apos;Japan&apos; &apos;essay&apos; &apos;fish&apos; &apos;how&apos; &apos;say&apos; A Chinese sentence in (a) illustrating the lack of word boundaries.</S><S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="369" ssid = "78">Examples are given in Table 4.</S><S sid ="459" ssid = "5">Furthermore, by inverting the transducer so that it maps from phonemic transcriptions to hanzi sequences, one can apply the segmenter to other problems, such as speech recognition (Pereira, Riley, and Sproat 1994).</S> | Discourse Facet:  ['Aim_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 39 | Reference Article:  J96-3004.xml | Citing Article:  P98-1076.xml | Citation Marker Offset:  ['145'] | Citation Marker:  1996 | Citation Offset:  ['144','145'] | Citation Text:  <S sid ="144" ssid = "11">The actual implementation of the weighted finiteÂ­ state transducer by Sproat et al.</S><S sid ="145" ssid = "12">(1996) can be taken as an evidence that the hypothesis of one tokenization per source has already in practical use.</S> | Reference Offset:  ['33', '138', '374', '398'] | Reference Text:  <S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S><S sid ="138" ssid = "2">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S><S sid ="374" ssid = "83">This is a rather important source of errors in name identifi­ cation, and it is not really possible to objectively evaluate a name recognition system without considering the main lexicon with which it is used.</S><S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 40 | Reference Article:  J96-3004.xml | Citing Article:  P98-1076.xml | Citation Marker Offset:  ['150'] | Citation Marker:  1996 | Citation Offset:  ['149','150'] | Citation Text:  <S sid ="149" ssid = "2">utilizing local and sentential constraints, what Sproat et al.</S><S sid ="150" ssid = "3">( 1996) implemented was simply a token unigram scoring function.</S> | Reference Offset:  ['47', '91', '101', '212'] | Reference Text:  <S sid ="47" ssid = "8">TIS systems in general need to do more than simply compute the.</S><S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S><S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="212" ssid = "76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 41 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['5','6'] | Citation Text:  <S sid ="5" ssid = "5">In Japanese, around 95% word segmentation acÂ­ curacy is reported by using a word-based lanÂ­ guage model and the Viterbi-like dynamic programÂ­ ming procedures (Nagata, 1994; Yamamoto, 1996; Takeuchi and Matsumoto, 1997; Haruno and MatÂ­ sumoto, 1997).</S><S sid ="6" ssid = "6">About the same accuracy is reported in Chinese by statistical methods (Sproat et al., 1996).</S> | Reference Offset:  ['124', '168', '329', '398'] | Reference Text:  <S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S><S sid ="168" ssid = "32">Word frequencies are estimated by a re-estimation procedure that involves apply­ ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.</S><S sid ="329" ssid = "38">This is to allow for fair comparison between the statistical method and GR, which is also purely dictionary-based.</S><S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 42 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['8'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['8'] | Citation Text:  <S sid ="8" ssid = "8">There are two approaches to solve this problem: to increase the coverage of the dictionary (Fung and Wu, 1994; Chang et al., 1995; Mori and Nagao, 1996) and to design a better model for unknown words (Nagata, 1996; Sproat et al., 1996).</S> | Reference Offset:  ['245', '415', '135', '244'] | Reference Text:  <S sid ="245" ssid = "109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S><S sid ="415" ssid = "18">The major problem for our seg­ menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S><S sid ="135" ssid = "73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S><S sid ="244" ssid = "108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 43 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">To improve word segmentaÂ­ tion accuracy, (Nagata, 1996) used a single general purpose unknown word model, while (Sproat et al., 1996) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.</S> | Reference Offset:  ['170', '399', '20', '169'] | Reference Text:  <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="169" ssid = "33">newspaper material, but also including kungfu fiction, Buddhist tracts, and scientific material.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 44 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['178'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['178'] | Citation Text:  <S sid ="178" ssid = "108">Word segmentation accuracy is expressed in terms of recall and precision as is done in the previous research (Sproat et al., 1996).</S> | Reference Offset:  ['128', '405', '357', '363'] | Reference Text:  <S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S><S sid ="405" ssid = "8">First of all, most previous articles report perfor­ mance in terms of a single percent-correct score, or else in terms of the paired measures of precision and recall.</S><S sid ="357" ssid = "66">Interestingly, Chang et al. report 80.67% recall and 91.87% precision on an 11,000 word corpus: seemingly, our system finds as many names as their system, but with four times as many false hits.</S><S sid ="363" ssid = "72">On the first of these-the B set-our system had 64% recall and 86% precision; on the second-the C set-it had 33% recall and 19% precision.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 45 | Reference Article:  J96-3004.xml | Citing Article:  W00-0803.xml | Citation Marker Offset:  ['29'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['29'] | Citation Text:  <S sid ="29" ssid = "29">Segmentation rutd morphological analysis related issues of both Chinese and Japanese are intensively addressed elsewhere (Sproat et al., 1996; MatsUIIt(ltO et al., 1997 and many others).</S> | Reference Offset:  ['186', '394', '23', '21'] | Reference Text:  <S sid ="186" ssid = "50">4.3 Morphological Analysis.</S><S sid ="394" ssid = "103">Evaluation of Morphological Analysis.</S><S sid ="23" ssid = "23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S><S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 46 | Reference Article:  J96-3004.xml | Citing Article:  W00-1207.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Sproat et al 1996 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Purely statistical methods of word segmentation (e.g. de Marcken 1996, Sproat et al 1996, Tung and Lee 1994, Lin et al (1993), Chiang et al (1992), Lua, Huang et al, etc.) often fail to identify those words because of the sparse data problem, as the likelihood for those words to appear in the training texts is extremely low.</S> | Reference Offset:  ['124', '125', '115', '116'] | Reference Text:  <S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S><S sid ="125" ssid = "63">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac­ tually tag the words as belonging to one or another class of expression.</S><S sid ="115" ssid = "53">Others depend upon various lexical heuris­ tics: for example Chen and Liu (1992) attempt to balance the length of words in a three-word window, favoring segmentations that give approximately equal length for each word.</S><S sid ="116" ssid = "54">Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 47 | Reference Article:  J96-3004.xml | Citing Article:  W01-0513.xml | Citation Marker Offset:  ['41'] | Citation Marker:  Sproat, et al, 1996 | Citation Offset:  ['40','41'] | Citation Text:  <S sid ="40" ssid = "11">The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et.</S><S sid ="41" ssid = "12">al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others).</S> | Reference Offset:  ['20', '53', '357', '383'] | Reference Text:  <S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="53" ssid = "14">There are thus some very good reasons why segmentation into words is an important task.</S><S sid ="357" ssid = "66">Interestingly, Chang et al. report 80.67% recall and 91.87% precision on an 11,000 word corpus: seemingly, our system finds as many names as their system, but with four times as many false hits.</S><S sid ="383" ssid = "92">constitute names, since we have only their segmentation, not the actual classification of the segmented words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 48 | Reference Article:  J96-3004.xml | Citing Article:  W02-1117.xml | Citation Marker Offset:  ['13'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">For examples: these words should be obtained: The ambiguous string is .There are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [Guo 1997; Sproat et al. 1996; Gu and Mao 1994; Li et al. 1991; Wang et al. 1991b; Wang et al. 1990].</S> | Reference Offset:  ['112', '421', '22', '108'] | Reference Text:  <S sid ="112" ssid = "50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S><S sid ="421" ssid = "24">For example, as Gan (1994) has noted, one can construct examples where the segmen­ tation is locally ambiguous but can be determined on the basis of sentential or even discourse context.</S><S sid ="22" ssid = "22">Twentieth-century linguistic work on Chinese (Chao 1968; Li and Thompson 1981; Tang 1988,1989, inter alia) has revealed the incorrectness of this traditional view.</S><S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 49 | Reference Article:  J96-3004.xml | Citing Article:  W02-1808.xml | Citation Marker Offset:  ['5'] | Citation Marker:  1996 | Citation Offset:  ['5'] | Citation Text:  <S sid ="5" ssid = "5">Statistical approaches involve language mod els mostly finite-state ones trained on some large-scale corpora as showed in Fan and Tsai (1988) Chang et al (1991) Chiang et al (1992) Sproat et al (1996)</S> | Reference Offset:  ['120', '124', '119', '121'] | Reference Text:  <S sid ="120" ssid = "58">More complex approaches such as the relaxation technique have been applied to this problem Fan and Tsai (1988}.</S><S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S><S sid ="119" ssid = "57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S><S sid ="121" ssid = "59">Note that Chang, Chen, and Chen (1991), in addition to word-frequency information, include a constraint-satisfication model, so their method is really a hybrid approach.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 50 | Reference Article:  J96-3004.xml | Citing Article:  W03-1025.xml | Citation Marker Offset:  ['17'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['17'] | Citation Text:  <S sid ="17" ssid = "17">There are multiple studies (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper to lower</S> | Reference Offset:  ['245', '303', '348', '459'] | Reference Text:  <S sid ="245" ssid = "109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S><S sid ="303" ssid = "12">(See also Wu and Fung [1994].)</S><S sid ="348" ssid = "57">However, this result is consistent with the results of ex­ periments discussed in Wu and Fung (1994).</S><S sid ="459" ssid = "5">Furthermore, by inverting the transducer so that it maps from phonemic transcriptions to hanzi sequences, one can apply the segmenter to other problems, such as speech recognition (Pereira, Riley, and Sproat 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 51 | Reference Article:  J96-3004.xml | Citing Article:  W03-1025.xml | Citation Marker Offset:  ['180'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['180'] | Citation Text:  <S sid ="180" ssid = "4">Chinese word segmentation is a well-known problem that has been studied extensively (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) and it is known that human agreement is relatively low.</S> | Reference Offset:  ['51', '137', '136', '22'] | Reference Text:  <S sid ="51" ssid = "12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="136" ssid = "74">Furthermore, even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus: as Fung and Wu (1994) have shown, one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented.</S><S sid ="22" ssid = "22">Twentieth-century linguistic work on Chinese (Chao 1968; Li and Thompson 1981; Tang 1988,1989, inter alia) has revealed the incorrectness of this traditional view.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 52 | Reference Article:  J96-3004.xml | Citing Article:  W03-1025.xml | Citation Marker Offset:  ['187'] | Citation Marker:  1996 | Citation Offset:  ['186','187'] | Citation Text:  <S sid ="186" ssid = "10">Sproat et al.</S><S sid ="187" ssid = "11">(1996) employs stochastic finite state machines to find word boundaries.</S> | Reference Offset:  ['35', '101', '128', '137'] | Reference Text:  <S sid ="35" ssid = "35">For that application, at a minimum, one would want to know the phonological word boundaries.</S><S sid ="101" ssid = "39">(See Sproat and Shih 1995.)</S><S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 53 | Reference Article:  J96-3004.xml | Citing Article:  W03-1728.xml | Citation Marker Offset:  ['3'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['3'] | Citation Text:  <S sid ="3" ssid = "3">This may sound simple enough but in reality identifying words in Chinese is a nontrivial problem that has drawn a large body of research in the Chinese language processing community (Fan and Tsai, 1988; Gan et al., 1996; Sproat et al., 1996; Wu, 2003; Xue, 2003).</S> | Reference Offset:  ['23', '120', '20', '457'] | Reference Text:  <S sid ="23" ssid = "23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S><S sid ="120" ssid = "58">More complex approaches such as the relaxation technique have been applied to this problem Fan and Tsai (1988}.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="457" ssid = "3">The use of weighted transducers in particular has the attractive property that the model, as it stands, can be straightforwardly interfaced to other modules of a larger speech or natural language system: presumably one does not want to segment Chinese text for its own sake but instead with a larger purpose in mind.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 54 | Reference Article:  J96-3004.xml | Citing Article:  W04-3236.xml | Citation Marker Offset:  ['157'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['157'] | Citation Text:  <S sid ="157" ssid = "35">Much previous research on Chinese language processing focused on word segmentation (Sproat et al., 1996; Teahan et al., 2000; Sproat and Emerson, 2003).</S> | Reference Offset:  ['88', '137', '20', '23'] | Reference Text:  <S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="23" ssid = "23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 55 | Reference Article:  J96-3004.xml | Citing Article:  W05-0709.xml | Citation Marker Offset:  ['83'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['83'] | Citation Text:  <S sid ="83" ssid = "9">In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al., 1996).</S> | Reference Offset:  ['107', '134', '135', '418'] | Reference Text:  <S sid ="107" ssid = "45">The second concerns the methods used (if any) to ex­ tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.</S><S sid ="134" ssid = "72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S><S sid ="135" ssid = "73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S><S sid ="418" ssid = "21">This implies, therefore, that a major factor in the performance of a Chinese segmenter is the quality of the base dictionary, and this is probably a more important factor-from the point of view of performance alone-than the particular computational methods used.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 56 | Reference Article:  J96-3004.xml | Citing Article:  W06-1630.xml | Citation Marker Offset:  ['118'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['118'] | Citation Text:  <S sid ="118" ssid = "13">The words were stemmed all possible ways using simple hand-developed affix lists: for example, given a Hindi word c1 c2 c3 , if both c3 and c2 c3 are in our suffix and ending list, then this single word generates three possible candidates: c1 , c1 c2 , and c1c2 c3 . In contrast, Chinese candidates were extracted using a list of 495 characters that are frequently used for foreign names (Sproat et al., 1996).</S> | Reference Offset:  ['170', '228', '399', '20'] | Reference Text:  <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S><S sid ="228" ssid = "92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 57 | Reference Article:  J96-3004.xml | Citing Article:  W10-3212.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "2">In such languages, words are segmented using more advanced techniques, which can be categorized into three methods: (i) Dictionary/lexicon based approaches (ii) Linguistic knowledge based approaches (iii) Machine learning based approaches/statistical approaches (Haruechaiyasak et al., 2008) Longest matching (Poowarawan, 1986; Richard Sproat, 1996) and maximum matching (Sproat et al., 1996; Haizhou &amp; Baosheng, 1998) are examples of lexicon based approaches.</S> | Reference Offset:  ['67', '108', '117', '119'] | Reference Text:  <S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="117" ssid = "55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost­ based scoring mechanism.</S><S sid ="119" ssid = "57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 58 | Reference Article:  J96-3004.xml | Citing Article:  W10-3708.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996).</S> | Reference Offset:  ['165', '352', '325', '136'] | Reference Text:  <S sid ="165" ssid = "29">The segmentation chosen is the best path through the WFST, shown in (d).</S><S sid ="352" ssid = "61">For a given &quot;word&quot; in the automatic segmentation, if at least k of the hu­ man judges agree that this is a word, then that word is considered to be correct.</S><S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that dis­ tance matrix, and plotting the first two most significant dimensions.</S><S sid ="136" ssid = "74">Furthermore, even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus: as Fung and Wu (1994) have shown, one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 59 | Reference Article:  J96-3004.xml | Citing Article:  W11-0823.xml | Citation Marker Offset:  ['174'] | Citation Marker:  1996 | Citation Offset:  ['174'] | Citation Text:  <S sid ="174" ssid = "7">There are a number of popular dictionary-based solutions such as Cha Sen10 and Juman.11 Sproat et al (1996) proposed an alternative solution based on distributional statistics such as mutual information.</S> | Reference Offset:  ['93', '94', '92', '433'] | Reference Text:  <S sid ="93" ssid = "31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S><S sid ="94" ssid = "32">A related point is that mutual information is helpful in augmenting existing electronic dictionaries, (cf.</S><S sid ="92" ssid = "30">In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.</S><S sid ="433" ssid = "36">While Gan&apos;s system incorporates fairly sophisticated models of various linguistic information, it has the drawback that it has only been tested with a very small lexicon (a few hundred words) and on a very small test set (thirty sentences); there is therefore serious concern as to whether the methods that he discusses are scalable.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 60 | Reference Article:  J96-3004.xml | Citing Article:  W12-1011.xml | Citation Marker Offset:  ['41'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['41'] | Citation Text:  <S sid ="41" ssid = "5">Indeed, even native speakers can agree on word boundaries in modern Chinese only about 76% of the time (Sproat et al., 1996).</S> | Reference Offset:  ['24', '137', '20', '21'] | Reference Text:  <S sid ="24" ssid = "24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 61 | Reference Article:  J96-3004.xml | Citing Article:  W12-1011.xml | Citation Marker Offset:  ['204'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['204'] | Citation Text:  <S sid ="204" ssid = "9">No comparable figure has been reported for classical Chinese word segmentation, but this rate compares favorably with past attempts for modern Chinese, e.g., an average of 76% inter- human agreement rate in (Sproat et al., 1996).</S> | Reference Offset:  ['137', '304', '21', '22'] | Reference Text:  <S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="304" ssid = "13">Various segmentation approaches were then compared with human performance: 1.</S><S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion &quot;word&quot; has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S><S sid ="22" ssid = "22">Twentieth-century linguistic work on Chinese (Chao 1968; Li and Thompson 1981; Tang 1988,1989, inter alia) has revealed the incorrectness of this traditional view.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 62 | Reference Article:  J96-3004.xml | Citing Article:  W12-2303.xml | Citation Marker Offset:  ['12'] | Citation Marker:  1996 | Citation Offset:  ['11','12'] | Citation Text:  <S sid ="11" ssid = "11">An extension of this approach is the dynamic programming search of the most probable word combination on the word lattice, such as Ma (1996) and Sproat et al.</S><S sid ="12" ssid = "12">(1996), which utilize information such as word frequency statistics in a corpus to build the model and are less efficient but more accurate.</S> | Reference Offset:  ['171', '91', '320', '455'] | Reference Text:  <S sid ="171" ssid = "35">The best analysis of the corpus is taken to be the true analysis, the frequencies are re-estimated, and the algorithm is repeated until it converges.</S><S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S><S sid ="320" ssid = "29">from the subset of the United Informatics corpus not used in the training of the models.</S><S sid ="455" ssid = "1">Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 63 | Reference Article:  J96-3004.xml | Citing Article:  W12-2303.xml | Citation Marker Offset:  ['157'] | Citation Marker:  1996 | Citation Offset:  ['156','157'] | Citation Text:  <S sid ="155" ssid = "30">There are many other OOV recognition methods proposed in literature before the rise of machine learning in the field.</S><S sid ="156" ssid = "31">For example, the Sproat et al.</S><S sid ="157" ssid = "32">(1996) system can successfully recognize OOVs of strong patterns, such as Chinese personal names, transliterations, using finite-state techniques.</S> | Reference Offset:  ['369', '67', '227', '403'] | Reference Text:  <S sid ="369" ssid = "78">Examples are given in Table 4.</S><S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="227" ssid = "91">4.4 Chinese Personal Names.</S><S sid ="403" ssid = "6">We have argued that the proposed method performs well.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 64 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['26'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['26'] | Citation Text:  <S sid ="26" ssid = "26">One of the major problems in unsupervised word segmentation is the treatment of unseen word [Sproat et al., 1996] wrote lexical rules for each productive morphological process, such as plur noun formation, Chinese personal names, and transliterations of foreign words.</S> | Reference Offset:  ['134', '188', '399', '20'] | Reference Text:  <S sid ="134" ssid = "72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S><S sid ="188" ssid = "52">One class comprises words derived by productive morphologi­ cal processes, such as plural noun formation using the suffix ir, menD.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S><S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 65 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['69'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['69'] | Citation Text:  <S sid ="69" ssid = "5">We used a simple greedy algorithm described in [Sproat et al., 1996].</S> | Reference Offset:  ['305', '466', '102', '108'] | Reference Text:  <S sid ="305" ssid = "14">A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.</S><S sid ="466" ssid = "12">The model described here thus demonstrates great potential for use in widespread applications.</S><S sid ="102" ssid = "40">However, the characterization given in the main body of the text is correct sufficiently often to be useful.</S><S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 66 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['73'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['73'] | Citation Text:  <S sid ="73" ssid = "9">[Sproat et al., 1996] also proposed another method to estimate a set of initial word frequencies without segmenting the corpus.</S> | Reference Offset:  ['170', '173', '172', '67'] | Reference Text:  <S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S><S sid ="173" ssid = "37">In any event, to date, we have not compared different methods for deriving the set of initial frequency estimates.</S><S sid ="172" ssid = "36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic­ ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S><S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 67 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['86'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['86'] | Citation Text:  <S sid ="86" ssid = "22">The problem of the longest match string frequency method is that if a word W1 is a substring of other word w2 and if wl always appears as a substring of w2 in the training text, just like m 1Although (Sproat et al., 1996] calls it &quot;maximum matching&quot;, we call this method &quot;longest match&quot; according to a review on Chinese word segmentation [Wu and Tseng, 1993) and the literal translation of the Japanese name of the method Hi!:.</S> | Reference Offset:  ['88', '137', '239', '109'] | Reference Text:  <S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S><S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="239" ssid = "103">0 X u} &quot;&apos; o; .2 X X&gt;&lt;X X XX X X X X X X x X X X X X x X V X X X X .;t&apos;*- XXX:OX X X X X X X 9 x X X XX XX X X X X X X X XXX:&lt; X X&gt;O&lt;XX&gt;!KXX XI&lt;&gt;&lt; »C X X XX :X: X X &quot;&apos; X X XX &gt;OO&lt;X&gt;D&lt;XIK X X X X X X --XX»: XXX X X»C X X«X...C:XXX X Xll&lt; X X &gt;&lt;XX&gt;IIC:liiC:oiiiiCI--8!X:liiOC!I!S8K X X X 10 100 1000 10000 log(F)_base: R&quot;2=0.20 (p &lt; 0.005) X 100000 Figure 6 Plot of log frequency of base noun, against log frequency of plural nouns.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 68 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['121'] | Citation Marker:  Sproat et al., 1996 | Citation Offset: ['121'] | Citation Text:  <S sid ="121" ssid = "15">Word Segmentation accuracy is expressed in terms of recall and precision as is done for bracketing of partial parses [Nagata, 1994, Sproat et al., 1996).</S> | Reference Offset:  ['128', '357', '356', '362'] | Reference Text:  <S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S><S sid ="357" ssid = "66">Interestingly, Chang et al. report 80.67% recall and 91.87% precision on an 11,000 word corpus: seemingly, our system finds as many names as their system, but with four times as many false hits.</S><S sid ="356" ssid = "65">The performance was 80.99% recall and 61.83% precision.</S><S sid ="362" ssid = "71">However, they list two sets, one consisting of 28 fragments and the other of 22 fragments, in which they had 0% recall and precision.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 69 | Reference Article:  J96-3004.xml | Citing Article:  W97-0316.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['10','11'] | Citation Text:  <S sid ="10" ssid = "10">Automatic methods for correctly isolating words in a sentence -- a process called word segmentation -- is therefore an important and necessary first step to be taken before other analysis can begin.</S><S sid ="11" ssid = "11">Many researchers have proposed practical methods to resolve this problem such as (Nie et al., 1995, Wu and Tsang, 1995, Jin &amp; Chen, 1996, Ponte &amp; Croft, 1996, Sproat et al., 1996, Sun et al., 1997).</S> | Reference Offset:  ['116', '2', '53', '124'] | Reference Text:  <S sid ="116" ssid = "54">Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).</S><S sid ="2" ssid = "2">An initial step of any text­ analysis task is the tokenization of the input into words.</S><S sid ="53" ssid = "14">There are thus some very good reasons why segmentation into words is an important task.</S><S sid ="124" ssid = "62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |