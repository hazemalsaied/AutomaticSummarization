Citance Number: 1 | Reference Article:   P05-1004.xml | Citing Article:  C10-2101.xml | Citation Marker Offset:  ['74'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['74'] | Citation Text:  <S sid ="74" ssid = "44">Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).</S> | Reference Offset:  ['20', '68', '43', '108'] | Reference Text:  <S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="43" ssid = "17">They suggest that supersense tagging is similar to named entity recognition, which also has a very small set of categories with similar granularity (e.g. location and person) for labelling predominantly unseen terms.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:   P05-1004.xml | Citing Article:  E09-1045.xml | Citation Marker Offset:  ['23'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['23'] | Citation Text:  <S sid ="23" ssid = "23">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['71', '229', '69', '36'] | Reference Text:  <S sid ="71" ssid = "4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S><S sid ="229" ssid = "5">Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson (2003).</S><S sid ="69" ssid = "2">They use the common nouns that have been added to WORDNET 1.7.1 since WORDNET 1.6 and compare this evaluation with a standard cross-validation approach that uses a small percentage of the words from their WORDNET 1.6 training set for evaluation.</S><S sid ="36" ssid = "10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 3 | Reference Article:   P05-1004.xml | Citing Article:  J07-4005.xml | Citation Marker Offset:  ['229'] | Citation Marker:  2005 | Citation Offset:  ['229'] | Citation Text:  <S sid ="229" ssid = "72">Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.</S> | Reference Offset:  ['36', '68', '73', '19'] | Reference Text:  <S sid ="36" ssid = "10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="73" ssid = "6">The WORD- NET 1.6 test set consists of several cross-validation sets of 755 nouns randomly selected from the BLLIP training set used by Ciaramita and Johnson (2003).</S><S sid ="19" ssid = "19">Broad semantic classification is currently used by lexicographers to or- ganise the manual insertion of words into WORDNET, and is an experimental precursor to automatically inserting words directly into the WORDNET hierarchy.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 4 | Reference Article:   P05-1004.xml | Citing Article:  J09-3004.xml | Citation Marker Offset:  ['446'] | Citation Marker:  Curran 2005 | Citation Offset:  ['446'] | Citation Text:  <S sid ="446" ssid = "30">An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.</S> | Reference Offset:  ['11', '92', '12', '18'] | Reference Text:  <S sid ="11" ssid = "11">Bur- gun and Bodenreider (2001) compared an alignment of WORDNET with the UMLS medical resource and found only a very small degree of overlap.</S><S sid ="92" ssid = "6">Curran and Moens (2002b) compared several context extraction methods and found that the shallow pipeline and grammatical relation extraction used in SEXTANT was both extremely fast and produced high-quality results.</S><S sid ="12" ssid = "12">Also, lexical- semantic resources suffer from: bias towards concepts and senses from particular topics.</S><S sid ="18" ssid = "18">These problems demonstrate the need for automatic or semiautomatic methods for the creation and maintenance of lexical-semantic resources.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:   P05-1004.xml | Citing Article:  N06-1017.xml | Citation Marker Offset:  ['26'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['26'] | Citation Text:  <S sid ="26" ssid = "26">There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.</S> | Reference Offset:  ['62', '147', '1', '2'] | Reference Text:  <S sid ="62" ssid = "15">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S sid ="147" ssid = "1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S><S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S><S sid ="2" ssid = "2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 6 | Reference Article:   P05-1004.xml | Citing Article:  N06-1017.xml | Citation Marker Offset:  ['189'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['189'] | Citation Text:  <S sid ="189" ssid = "11">Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.</S> | Reference Offset:  ['62', '148', '72', '42'] | Reference Text:  <S sid ="62" ssid = "15">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S sid ="148" ssid = "2">This technique is similar to Hearst and Schu¨ tze (1993) and Widdows (2003).</S><S sid ="72" ssid = "5">The WORDNET 1.7.1 test set consists of 744 previously unseen nouns, the majority of which (over 90%) have only one sense.</S><S sid ="42" ssid = "16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 7 | Reference Article:   P05-1004.xml | Citing Article:  N07-1024.xml | Citation Marker Offset:  ['83'] | Citation Marker:  Curran 2005 | Citation Offset:  ['83'] | Citation Text:  <S sid ="83" ssid = "3">While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)</S> | Reference Offset:  ['62', '94', '2', '4'] | Reference Text:  <S sid ="62" ssid = "15">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S sid ="94" ssid = "8">The efficiency of the SEXTANT approach makes the extraction of contextual information from over 2 billion words of raw text feasible.</S><S sid ="2" ssid = "2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S><S sid ="4" ssid = "4">We describe an unsupervised approach, based on vector-space similarity, which does not require annotated examples but significantly outperforms their tagger.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 8 | Reference Article:   P05-1004.xml | Citing Article:  P12-2050.xml | Citation Marker Offset:  ['15'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.</S> | Reference Offset:  ['14', '68', '20', '21'] | Reference Text:  <S sid ="14" ssid = "14">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="21" ssid = "21">This paper describes an unsupervised approach to supersense tagging that does not require annotated sentences.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 9 | Reference Article:   P05-1004.xml | Citing Article:  S07-1032.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['42', '65', '70', '13'] | Reference Text:  <S sid ="42" ssid = "16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S><S sid ="70" ssid = "3">Their results suggest that the WORDNET 1.7.1 test set is significantly harder because of the large number of abstract category nouns, e.g. communication and cognition, that appear in the 1.7.1 data, which are difficult to classify.</S><S sid ="13" ssid = "13">Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 10 | Reference Article:   P05-1004.xml | Citing Article:  S10-1090.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['71', '229', '69', '36'] | Reference Text:  <S sid ="71" ssid = "4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S><S sid ="229" ssid = "5">Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson (2003).</S><S sid ="69" ssid = "2">They use the common nouns that have been added to WORDNET 1.7.1 since WORDNET 1.6 and compare this evaluation with a standard cross-validation approach that uses a small percentage of the words from their WORDNET 1.6 training set for evaluation.</S><S sid ="36" ssid = "10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 11 | Reference Article:   P05-1004.xml | Citing Article:  S12-1011.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).</S> | Reference Offset:  ['10', '108', '26', '211'] | Reference Text:  <S sid ="10" ssid = "10">Technical domains, such as medicine, require separate treatment since common words often take on special meanings, and a significant proportion of their vocabulary does not overlap with everyday vocabulary.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="26" ssid = "26">Qc 2005 Association for Computational Linguistics L E X -FI L E D E S C R I P T I O N act acts or actions animal animals artifact man-made objects attribute attributes of people and objects body body parts cognition cognitive processes and contents communication communicative processes and contents event natural events feeling feelings and emotions food foods and drinks group groupings of people or objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession and transfer of possession process natural processes quantity quantities and units of measure relation relations between people/things/ideas shape two and three dimensional shapes state stable states of affairs substance substances time time and temporal relations Table 1: 25 noun lexicographer files in WORDNET</S><S sid ="211" ssid = "9">Our preliminary experiments suggest that only combining the vectors for unambiguous words produces the best results.</S> | Discourse Facet:  ['Method_Citation', 'Hypothesis_Citation'] | Annotator:  CIST |


Citance Number: 12 | Reference Article:   P05-1004.xml | Citing Article:  S12-1011.xml | Citation Marker Offset:  ['50'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['50'] | Citation Text:  <S sid ="50" ssid = "2">Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.</S> | Reference Offset:  ['20', '68', '43', '108'] | Reference Text:  <S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="43" ssid = "17">They suggest that supersense tagging is similar to named entity recognition, which also has a very small set of categories with similar granularity (e.g. location and person) for labelling predominantly unseen terms.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 13 | Reference Article:   P05-1004.xml | Citing Article:  S12-1023.xml | Citation Marker Offset:  ['234'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['234'] | Citation Text:  <S sid ="234" ssid = "15">A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.</S> | Reference Offset:  ['108', '198', '60', '61'] | Reference Text:  <S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="198" ssid = "28">This is not surprising since these concrete words tend to have very fewer other senses, well constrained contexts and a relatively high frequency.</S><S sid ="60" ssid = "13">Schu¨ tze’s (1992) WordSpace system was used to add topical links, such as between ball, racquet and game (the tennis problem).</S><S sid ="61" ssid = "14">Further, they also use the same vector-space techniques to label previously unseen words using the most common class assigned to the top 20 synonyms for that word.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 14 | Reference Article:   P05-1004.xml | Citing Article:  W06-1670.xml | Citation Marker Offset:  ['94'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['94'] | Citation Text:  <S sid ="94" ssid = "12">Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.</S> | Reference Offset:  ['35', '68', '20', '21'] | Reference Text:  <S sid ="35" ssid = "9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="21" ssid = "21">This paper describes an unsupervised approach to supersense tagging that does not require annotated sentences.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |