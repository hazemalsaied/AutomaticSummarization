We used the hierarchical clustering command in Matlab, which implements bottom-up agglomerative clustering, for all our unsupervised experiments. Learning the argument structure properties of verbsÃḃÂÂthe semantic roles they assign and their mapping to syntactic positionsÃḃÂÂis both particularly important and difficult. Then for all verbs , consider to be classified correctly if Class( )=ClusterLabel( ), where Class( ) is the actual class of and ClusterLabel( ) is the label assigned to the cluster in which is placed. 4.2.1 Accuracy We can assign each cluster the class label of the majority of its members. We find that manual selection of a subset of features based on the known classification performs better than using a full set of noisy features, demonstrating the potential benefit of feature selection in our task. Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993). Each set of verbs was judged (by the authorsÃḃÂÂ intuition alone) to be ÃḃÂÂrepresentativeÃḃÂÂ of the class. is the number of classes (a simple linear function roughly approximating the number of features in the Seed sets). We then replaced 10 of the 260 verbs (4%) to enable us to have representative seed verbs for certain classes in our semi-supervised experiments (e.g., so that we could include wipe as a seed verb for the Wipe verbs, and fill for the Fill verbs). We also find that our semi-supervised method (Seed) is linguistically plausible, and performs as
