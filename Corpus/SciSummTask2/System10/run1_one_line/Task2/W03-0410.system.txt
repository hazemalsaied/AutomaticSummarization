We cluster verbs into lexical semantic classes, using a general set of noisy features that capture syntactic and semantic properties of the verbs.
In moving to a scenario of verb class discovery, using clustering, we face the problem of having a large number of irrelevant features for a particular clustering task.
In an unsupervised (clustering) scenario of verb class discovery, can we maintain the benefit of only needing noisy features, without the generality of the feature space leading to “the curse of dimensionality”?
We chose hierarchical clustering because it may be possible to find coherent subclusters of verbs even when there are not exactly good clusters, where is the number of classes.
Then for all verbs , consider to be classified correctly if Class( )=ClusterLabel( ), where Class( ) is the actual class of and ClusterLabel( ) is the label assigned to the cluster in which is placed.
As we have defined it, necessarily generally increases as the number of clusters increases, with the extreme being at the #verbs correctly classified #verbs total thus provides a measure of the usefulness in practice of a clustering—that is, if one were to use the clustering as a classification, this measure tells how accurate overall the class assignments would be.
” In some ways our current clustering task is too easy, because all of the verbs are from one of the target classes.
