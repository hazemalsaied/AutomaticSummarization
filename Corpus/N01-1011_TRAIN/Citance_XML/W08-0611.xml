<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Like text in other domains, biomedical documents contain a range of terms with morethan one possible meaning.</S>
		<S sid ="2" ssid = "2">These ambiguities form a significant obstacle to the automatic processing of biomedical texts.</S>
		<S sid ="3" ssid = "3">Previous approaches to resolving this problem havemade use of a variety of knowledge sources including linguistic information (from the context in which the ambiguous term is used) anddomain-specific resources (such as UMLS).</S>
		<S sid ="4" ssid = "4">Inthis paper we compare a range of knowledgesources which have been previously used andintroduce a novel one: MeSH terms.</S>
		<S sid ="5" ssid = "5">The bestperformance is obtained using linguistic features in combination with MeSH terms.</S>
		<S sid ="6" ssid = "6">Results from our system outperform publishedresults for previously reported systems on astandard test set (the NLMWSD corpus).</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="7" ssid = "7">The number of documents discussing biomedicalscience is growing at an ever increasing rate, makingit difficult to keep track of recent developments.</S>
			<S sid ="8" ssid = "8">Automated methods for cataloging, searching and navigating these documents would be of great benefitto researchers working in this area, as well as having potential benefits to medicine and other branchesof science.</S>
			<S sid ="9" ssid = "9">Lexical ambiguity, the linguistic phenomena where a word or phrase has more thanone potential meaning, makes the automatic processing of text difficult.</S>
			<S sid ="10" ssid = "10">For example, “cold” hassix possible meanings in the Unified Medical Language System (UMLS) Metathesaurus (Humphreys et al., 1998) including “common cold”, “cold sensation” and “Chronic Obstructive Airway Disease(COLD)”.</S>
			<S sid ="11" ssid = "11">The NLM Indexing Initiative (Aronson etal., 2000) attempted to automatically index biomedical journals with concepts from the UMLS Metathesaurus and concluded that lexical ambiguity was thebiggest challenge in the automation of the indexingprocess.</S>
			<S sid ="12" ssid = "12">Weeber et al.</S>
			<S sid ="13" ssid = "13">(2001) analysed MEDLINEabstracts and found that 11.7% of phrases were ambiguous relative to the UMLS Metathesaurus.</S>
			<S sid ="14" ssid = "14">Word Sense Disambiguation (WSD) is the process of resolving lexical ambiguities.</S>
			<S sid ="15" ssid = "15">Previous researchers have used a variety of approaches forWSD of biomedical text.</S>
			<S sid ="16" ssid = "16">Some of them have takentechniques proven to be effective for WSD of general text and applied them to ambiguities in thebiomedical domain, while others have created systems using domain-specific biomedical resources.However, there has been no direct comparison ofwhich knowledge sources are the most useful orwhether combining a variety of knowledge sources,a strategy which has been shown to be successful forWSD in the general domain (Stevenson and Wilks,2001), improves results.</S>
			<S sid ="17" ssid = "17">This paper compares the effectiveness of a variety of knowledge sources for WSD in the biomedical domain.</S>
			<S sid ="18" ssid = "18">These include features which havebeen commonly used for WSD of general text aswell as information derived from domain-specificresources.</S>
			<S sid ="19" ssid = "19">One of these features is MeSH terms,which we find to be particularly effective when combined with generic features.The next section provides an overview of variousapproaches to WSD in the biomedical domain.</S>
			<S sid ="20" ssid = "20">Sec 80 tion 3 outlines our approach, paying particular attention to the range of knowledge sources used by oursystem.</S>
			<S sid ="21" ssid = "21">An evaluation of this system is presentedin Section 4.</S>
			<S sid ="22" ssid = "22">Section 5 summarises this paper andprovides suggestions for future work.</S>
	</SECTION>
	<SECTION title="Previous Work. " number = "2">
			<S sid ="23" ssid = "1">WSD has been actively researched since the 1950sand is regarded as an important part of the processof understanding natural language texts.</S>
			<S sid ="24" ssid = "2">2.1 The NLMWSD data set.</S>
			<S sid ="25" ssid = "3">Research on WSD for general text in the last decadehas been driven by the SemEval evaluation frame-works1 which provide a set of standard evaluationmaterials for a variety of semantic evaluation tasks.At this point there is no specific collection for thebiomedical domain in SemEval, but a test collectionfor WSD in biomedicine was developed by Wee-ber et al.</S>
			<S sid ="26" ssid = "4">(2001), and has been used as a benchmarkby many independent groups.</S>
			<S sid ="27" ssid = "5">The UMLS Metathesaurus was used to provide a set of possible meanings for terms in biomedical text.</S>
			<S sid ="28" ssid = "6">50 ambiguousterms which occur frequently in MEDLINE werechosen for inclusion in the test set.</S>
			<S sid ="29" ssid = "7">100 instancesof each term were selected from citations added tothe MEDLINE database in 1998 and manually dis-ambiguated by 11 annotators.</S>
			<S sid ="30" ssid = "8">Twelve terms wereflagged as “problematic” due to substantial disagreement between the annotators.</S>
			<S sid ="31" ssid = "9">There are an averageof 2.64 possible meanings per ambiguous term andthe most ambiguous term, “cold” has five possiblemeanings.</S>
			<S sid ="32" ssid = "10">In addition to the meanings defined inUMLS, annotators had the option of assigning a special tag (“none”) when none of the UMLS meaningsseemed appropriate.</S>
			<S sid ="33" ssid = "11">Various researchers have chosen to evaluate theirsystems against subsets of this data set.</S>
			<S sid ="34" ssid = "12">Liu et al.(2004) excluded the 12 terms identified as problematic by Weeber et al.</S>
			<S sid ="35" ssid = "13">(2001) in addition to 16 forwhich the majority (most frequent) sense accountedfor more than 90% of the instances, leaving 22 termsagainst which their system was evaluated.</S>
			<S sid ="36" ssid = "14">Leroy andRindflesch (2005) used a set of 15 terms for whichthe majority sense accounted for less than 65% ofthe instances.</S>
			<S sid ="37" ssid = "15">Joshi et al.</S>
			<S sid ="38" ssid = "16">(2005) evaluated against 1http://www.senseval.org the set union of those two sets, providing 28 ambiguous terms.</S>
			<S sid ="39" ssid = "17">McInnes et al.</S>
			<S sid ="40" ssid = "18">(2007) used the setintersection of the two sets (dubbed the “commonsubset”) which contained 9 terms.</S>
			<S sid ="41" ssid = "19">The terms whichform these various subsets are shown in Figure 1.</S>
			<S sid ="42" ssid = "20">The 50 terms which form the NLMWSD data setrepresent a range of challenges for WSD systems.The Most Frequent Sense (MFS) heuristic has become a standard baseline in WSD (McCarthy et al.,2004) and is simply the accuracy which would beobtained by assigning the most common meaning ofa term to all of its instances in a corpus.</S>
			<S sid ="43" ssid = "21">Despite itssimplicity, the MFS heuristic is a hard baseline tobeat, particularly for unsupervised systems, becauseit uses hand-tagged data to determine which senseis the most frequent.</S>
			<S sid ="44" ssid = "22">Analysis of the NLMWSDdata set showed that the MFS over all 50 ambiguous terms is 78%.</S>
			<S sid ="45" ssid = "23">The different subsets have lowerMFS, indicating that the terms they contain are moredifficult to disambiguate.</S>
			<S sid ="46" ssid = "24">The 22 terms used by (Liuet al., 2004) have a MFS of 69.9% while the setused by (Leroy and Rindflesch, 2005) has an MFSof 55.3%.</S>
			<S sid ="47" ssid = "25">The union and intersection of these setshave MFS of 66.9% and 54.9% respectively.</S>
			<S sid ="48" ssid = "26">adjustmentblood pressureevaluationimmunosuppressionradiationsensitivity degreegrowthmanmosaicnutrition colddepressiondischargeextractionfatimplantation associationconditionculturedeterminationenergy failurefitfluidfrequencyganglion glucoseinhibition pressure resistancesecretion singlestrainssupportsurgerytransient transportvariation repairscaleweightwhite japaneseleadmolepathologyreductionsexultrasound NLMWSD data set Liu et.</S>
			<S sid ="49" ssid = "27">al.</S>
			<S sid ="50" ssid = "28">(2004) Leroy and Rindflesch (2005) Figure 1: The NLMWSD test set and some of its subsets.</S>
			<S sid ="51" ssid = "29">Note that the test set used by (Joshi et al., 2005)comprises the set union of the terms used by (Liu et al.,2004) and (Leroy and Rindflesch, 2005) while the “common subset” is formed from their intersection.</S>
			<S sid ="52" ssid = "30">2.2 WSD of Biomedical Text.</S>
			<S sid ="53" ssid = "31">A standard approach to WSD is to make use ofsupervised machine learning systems which aretrained on examples of ambiguous words in context along with the correct sense for that usage.</S>
			<S sid ="54" ssid = "32">The 81 models created are then applied to new examples ofthat word to determine the sense being used.</S>
			<S sid ="55" ssid = "33">Approaches which are adapted from WSD of general text include Liu et al.</S>
			<S sid ="56" ssid = "34">(2004).</S>
			<S sid ="57" ssid = "35">Their techniqueuses a supervised learning algorithm with a variety of features consisting of a range of collocationsof the ambiguous word and all words in the abstract.</S>
			<S sid ="58" ssid = "36">They compared a variety of supervised machine learning algorithms and found that a decisionlist worked best.</S>
			<S sid ="59" ssid = "37">Their best system correctly dis-ambiguated 78% the occurrences of 22 ambiguousterms in the NLMWSD data set (see Section 2.1).</S>
			<S sid ="60" ssid = "38">Joshi et al.</S>
			<S sid ="61" ssid = "39">(2005) also use collocations as featuresand experimented with five supervised learning algorithms: Support Vector Machines, Naive Bayes,decision trees, decision lists and boosting.</S>
			<S sid ="62" ssid = "40">The Support Vector Machine performed scoring 82.5% ona set of 28 words (see Section 2.1) and 84.9% onthe 22 terms used by Liu et al.</S>
			<S sid ="63" ssid = "41">(2004).</S>
			<S sid ="64" ssid = "42">Performanceof the Naive Bayes classifier was comparable to theSupport Vector Machine, while the other algorithmswere hampered by the large number of features.Examples of approaches which have made use ofknowledge sources specific to the biomedical domain include Leroy and Rindflesch (2005), who relied on information from the UMLS Metathesaurusassigned by MetaMap (Aronson, 2001).</S>
			<S sid ="65" ssid = "43">Their system used information about whether the ambiguous word is the head word of a phrase identified byMetaMap, the ambiguous word’s part of speech, semantic relations between the ambiguous words andsurrounding words from UMLS as well as semantictypes of the ambiguous word and surrounding word.Naive Bayes was used as a learning algorithm.</S>
			<S sid ="66" ssid = "44">Thisapproach correctly disambiguated 65.6% of word instances from a set of 15 terms (see Section 2.1).Humphrey et al.</S>
			<S sid ="67" ssid = "45">(2006) presented an unsupervisedsystem that also used semantic types.</S>
			<S sid ="68" ssid = "46">They constructed semantic type vectors for each word froma large collection of MEDLINE abstracts.</S>
			<S sid ="69" ssid = "47">This allowed their method to perform disambiguation at acoarser level, without the need for labeled trainingexamples.</S>
			<S sid ="70" ssid = "48">In most cases the semantic types can bemapped to the UMLS concepts but not for five of theterms in the NLMWSD data set.</S>
			<S sid ="71" ssid = "49">Humphrey et al.(2006) reported 78.6% accuracy over the remaining45.</S>
			<S sid ="72" ssid = "50">However, their approach could not be appliedto all instances of ambiguous terms and, in particu lar, is unable to model the “none” tag.</S>
			<S sid ="73" ssid = "51">Their systemcould only assign senses to an average of 54% of theinstances of each ambiguous term.</S>
			<S sid ="74" ssid = "52">McInnes et al.</S>
			<S sid ="75" ssid = "53">(2007) made use of ConceptUnique Identifiers (CUIs) from UMLS which arealso assigned by MetaMap.</S>
			<S sid ="76" ssid = "54">The information contained in CUIs is more specific than in the semantictypes applied by Leroy and Rindflesch (2005).</S>
			<S sid ="77" ssid = "55">Forexample, there are two CUIs for the term “culture”in UMLS: “C0010453: Anthropological Culture”and “C0430400: Laboratory Culture”.</S>
			<S sid ="78" ssid = "56">The semantic type for the first of these is “Idea or Concept” and“Laboratory Procedure” for the second.</S>
			<S sid ="79" ssid = "57">McInnes etal.</S>
			<S sid ="80" ssid = "58">(2007) were interested in exploring whether themore specific information contained in CUIs wasmore effective than UMLS semantic types.</S>
			<S sid ="81" ssid = "59">Theirbest result was reported for a system which represented each sense by all CUIs which occurred atleast twice in the abstract surrounding the ambiguous word.</S>
			<S sid ="82" ssid = "60">They used a Naive Bayes classifier as thelearning algorithm.</S>
			<S sid ="83" ssid = "61">McInnes et al.</S>
			<S sid ="84" ssid = "62">(2007) reportedan accuracy of 74.5% on the set of ambiguous termstested by Leroy and Rindflesch (2005) and 80.0% onthe set used by Joshi et al.</S>
			<S sid ="85" ssid = "63">(2005).</S>
			<S sid ="86" ssid = "64">They concludedthat CUIs are more useful for WSD than UMLS semantic types but that they are not as robust as features which are known to work in general English,such as unigrams and bigrams.</S>
	</SECTION>
	<SECTION title="Approach. " number = "3">
			<S sid ="87" ssid = "1">Our approach is to adapt a state-of-the-art WSD system to the biomedical domain by augmenting it withadditional domain-specific and domain-independentknowledge sources.</S>
			<S sid ="88" ssid = "2">Our basic system (Agirre andMarti´nez, 2004) participated in the Senseval3 challenge (Mihalcea et al., 2004) with a performanceclose to the best system for the English and Basquelexical sample tasks.</S>
			<S sid ="89" ssid = "3">The system is based on a supervised learning approach.</S>
			<S sid ="90" ssid = "4">The features used byAgirre and Marti´nez (2004) are derived from textaround the ambiguous word and are domain independent.</S>
			<S sid ="91" ssid = "5">We refer to these as linguistic features.This feature set has been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain-specific features: CUIs (as used by (McInnes et al.,2007)) and Medical Subject Heading (MeSH) terms.</S>
			<S sid ="92" ssid = "6">82 3.1 FeaturesOur feature set contains a number of parameterswhich were set empirically (e.g. threshold for unigram frequency in the linguistic features).</S>
			<S sid ="93" ssid = "7">In addition, we use the entire abstract as the context of theambiguous term for relevant features rather than justthe sentence containing the term.</S>
			<S sid ="94" ssid = "8">Effects of varyingthese parameters are consistent with previous results(Liu et al., 2004; Joshi et al., 2005; McInnes et al.,2007) and are not reported in this paper..</S>
			<S sid ="95" ssid = "9">Linguistic features: The system uses a widerange of domain-independent features which arecommonly used for WSD.</S>
			<S sid ="96" ssid = "10">• Local collocations: A total of 41 features whichextensively describe the context of the ambiguous word and fall into two main types:(1) bigrams and trigrams containing the ambiguous word constructed from lemmas, wordforms or PoS tags2 and (2) preceding/followinglemma/word-form of the content words (adjective, adverb, noun and verb) in the same sentence with the target word.</S>
			<S sid ="97" ssid = "11">For example, consider the sentence below with the target wordadjustment.</S>
			<S sid ="98" ssid = "12">“Body surface area adjustments ofinitial heparin dosing...” The features would include the following: left-content-word-lemma “area adjustment”, right-function-word-lemma “adjustment of ”, left-POS “NN NNS”, right-POS “NNS IN”, left-content-word-form “area adjustments”, right-function-word-form “adjustment of ”, etc. • Syntactic Dependencies: These features modellonger-distance dependencies of the ambiguous words than can be represented by the local collocations.</S>
			<S sid ="99" ssid = "13">Five relations are extracted:object, subject, noun-modifier, preposition andsibling.</S>
			<S sid ="100" ssid = "14">These are identified using heuristic patterns and regular expressions applied to PoS tagsequences around the ambiguous word.</S>
			<S sid ="101" ssid = "15">In theabove example, “heparin” is noun-modifier feature of “adjustment”.</S>
			<S sid ="102" ssid = "16">2A maximum-entropy-based part of speech tagger was used(Ratnaparkhi, 1996) without the adaptation to the biomedicaldomain.</S>
			<S sid ="103" ssid = "17">• Salient bigrams: Salient bigrams within the abstract with high log-likelihood scores, as described by Pedersen (2001).</S>
			<S sid ="104" ssid = "18">• Unigrams: Lemmas of unigrams which appearmore frequently than a predefined threshold inthe entire corpus, excluding those in a list ofstopwords.</S>
			<S sid ="105" ssid = "19">We empirically set the thresholdto 1.</S>
			<S sid ="106" ssid = "20">This feature was not used by Agirre andMarti´nez (2004), but Joshi et al.</S>
			<S sid ="107" ssid = "21">(2005) foundthem to be useful for this task.</S>
			<S sid ="108" ssid = "22">Concept Unique Identifiers (CUIs): We followthe approach presented by McInnes et al.</S>
			<S sid ="109" ssid = "23">(2007) togenerate features based on UMLS Concept UniqueIdentifiers (CUIs).</S>
			<S sid ="110" ssid = "24">The MetaMap program (Aron-son, 2001) identifies all words and terms in atext which could be mapped onto a UMLS CUI.MetaMap does not disambiguate the senses of theconcepts, instead it enumerates all the possible combinations of the concept names found.</S>
			<S sid ="111" ssid = "25">For example, MetaMap will segment the phrase “Body surface area adjustments of initial heparin dosing ...”into two chunks: “Body surface area adjustments”and “of initial heparin dosing”.</S>
			<S sid ="112" ssid = "26">The first chunkwill be mapped onto four CUIs with the conceptname “Body Surface Area”: “C0005902: Diagnostic Procedure” and “C1261466: Organism Attribute” and a further pair with the name “Adjustments”: “C0456081: Health Care Activity” and“C0871291: Individual Adjustment”.</S>
			<S sid ="113" ssid = "27">The final results from MetaMap for the first chunk will be eightcombinations of those concept names, e.g. first fourby second two concept names.</S>
			<S sid ="114" ssid = "28">CUIs which occurmore than three times in the abstract containing theambiguous word are included as features.</S>
			<S sid ="115" ssid = "29">Medical Subject Headings (MeSH): The final feature is also specific to the biomedical domain.</S>
			<S sid ="116" ssid = "30">Medical Subject Headings (MeSH) (Nelsonet al., 2002) is a controlled vocabulary for indexing biomedical and health-related information anddocuments.</S>
			<S sid ="117" ssid = "31">MeSH terms are manually assigned toabstracts by human indexers.</S>
			<S sid ="118" ssid = "32">The latest version ofMeSH contains over 24,000 terms organised into an11 level hierarchy.</S>
			<S sid ="119" ssid = "33">The terms assigned to the abstract in whicheach ambiguous word occurs are used as features.</S>
			<S sid ="120" ssid = "34">For example, the abstract containing ourexample phrase has been assigned 16 MeSH 83 terms including “M01.060.116.100: Aged”,“M01.060.116.100.080: Aged, 80 and over”,“D27.505.954.502.119: Anticoagulants” and“G09.188.261.560.150: Blood Coagulation”.</S>
			<S sid ="121" ssid = "35">Toour knowledge MeSH terms have not been previously used as a feature for WSD of biomedicaldocuments.</S>
			<S sid ="122" ssid = "36">3.2 Learning Algorithms.</S>
			<S sid ="123" ssid = "37">We compared three machine leaning algorithmswhich have previously been shown to be effectivefor WSD tasks.</S>
			<S sid ="124" ssid = "38">The Vector Space Model is a memory-basedlearning algorithm which was used by (Agirre andMarti´nez, 2004).</S>
			<S sid ="125" ssid = "39">Each occurrence of an ambiguousword is represented as a binary vector in which eachposition indicates the occurrence/absence of a feature.</S>
			<S sid ="126" ssid = "40">A single centroid vector is generated for eachsense during training.</S>
			<S sid ="127" ssid = "41">These centroids are comparedwith the vectors that represent new examples usingthe cosine metric to compute similarity.</S>
			<S sid ="128" ssid = "42">The senseassigned to a new example is that of the closest centroid.</S>
			<S sid ="129" ssid = "43">The Naive Bayes classifier is based on a probabilistic model which assumes conditional independence of features given the target classification.</S>
			<S sid ="130" ssid = "44">Itcalculates the posterior probability that an instancebelongs to a particular class given the prior probabilities of the class and the conditional probabilityof each feature given the target class.</S>
			<S sid ="131" ssid = "45">Support Vector Machines have been widelyused in classification tasks.</S>
			<S sid ="132" ssid = "46">SVMs map feature vectors onto a high dimensional space and construct aclassifier by searching for the hyperplane that givesthe greatest separation between the classes.</S>
			<S sid ="133" ssid = "47">We used our own implementation of the VectorSpace Model and Weka implementations (Wittenand Frank, 2005) of the other two algorithms.</S>
	</SECTION>
	<SECTION title="Results. " number = "4">
			<S sid ="134" ssid = "1">This system was applied to the NLMWSD data set.Experiments were carried out using each of the threetypes of features (linguistic, CUI and MeSH) bothalone and in combination.</S>
			<S sid ="135" ssid = "2">Tenfold cross validation was used, and the figures we report are averagedacross all ten runs.</S>
			<S sid ="136" ssid = "3">Results from this experiment are shown in Table 1 which lists the performance using combinations oflearning algorithm and features.</S>
			<S sid ="137" ssid = "4">The figure shownfor each configuration represents the percentage ofinstances of ambiguous terms which are correctlydisambiguated.</S>
			<S sid ="138" ssid = "5">These results show that each of the three typesof knowledge (linguistic, CUIs and MeSH) can beused to create a classifier which achieves a reasonable level of disambiguation since performance exceeds the relevant baseline score.</S>
			<S sid ="139" ssid = "6">This suggests thateach of the knowledge sources can contribute to thedisambiguation of ambiguous terms in biomedicaltext.</S>
			<S sid ="140" ssid = "7">The best performance is obtained using a combination of the linguistic and MeSH features, a patternobserved across all test sets and machine learningalgorithms.</S>
			<S sid ="141" ssid = "8">Although the increase in performancegained from using both the linguistic and MeSHfeatures compared to only the linguistic features ismodest it is statistically significant, as is the difference between using both linguistic and MeSH features compared with using the MeSH features alone(Wilcoxon Signed Ranks Test, p &lt; 0.01).</S>
			<S sid ="142" ssid = "9">Combining MeSH terms with other features generally improves performance, suggesting that theinformation contained in MeSH terms is distinctfrom the other knowledge sources.</S>
			<S sid ="143" ssid = "10">However, theinclusion of CUIs as features does not always improve performance and, in several cases, causes it tofall.</S>
			<S sid ="144" ssid = "11">This is consistent with McInnes et al.</S>
			<S sid ="145" ssid = "12">(2007)who concluded that CUIs were a useful information source for disambiguation of biomedical textbut that they were not as robust as a linguistic knowledge source (unigrams) which they had used for aprevious system.</S>
			<S sid ="146" ssid = "13">The most likely reason for this isthat our approach relies on automatically assignedCUIs, provided by MetaMap, while the MeSH termsare assigned manually.</S>
			<S sid ="147" ssid = "14">We do not have access to areliable assignment of CUIs to text; if we had WSDwould not be necessary.</S>
			<S sid ="148" ssid = "15">On the other hand, reliably assigned MeSH terms are readily available inMedline.</S>
			<S sid ="149" ssid = "16">The CUIs assigned by MetaMap are noisywhile the MeSH terms are more reliable and proveto be a more useful knowledge source for WSD.</S>
			<S sid ="150" ssid = "17">The Vector Space Model learning algorithm performs significantly better than both Support VectorMachine and Naive Bayes (Wilcoxon Signed RanksTest, p &lt; 0.01).</S>
			<S sid ="151" ssid = "18">This pattern is observed regardless 84 FeaturesCUI+ Linguistic Linguistic Linguistic+Data sets Linguistic CUI MeSHMeSH +MeSH +CUI MeSH+CUI Vector space modelAll words 87.2 85.8 81.9 86.9 87.8 87.3 87.6 Joshi subset 82.3 79.6 76.6 81.4 83.3 82.4 82.6Leroy subset 77.8 74.4 70.4 75.8 79.0 78.0 77.8 Liu subset 84.3 81.3 78.3 83.4 85.1 84.3 84.5Common subset 79.6 75.1 70.4 76.9 80.8 79.6 79.2 Naive BayesAll words 86.2 81.2 85.7 81.1 86.4 81.4 81.5 Joshi subset 80.6 73.4 80.1 73.3 80.9 73.7 73.8Leroy subset 76.4 66.1 74.6 65.9 76.8 66.3 66.3 Liu subset 81.9 75.4 81.7 75.3 82.2 75.5 75.6Common subset 76.7 66.1 74.7 65.8 77.2 65.9 65.9 Support Vector MachineAll words 85.6 83.5 85.3 84.5 86.1 85.3 85.6 Joshi subset 79.8 76.4 79.5 78.0 80.6 79.1 79.8Leroy subset 75.1 69.7 72.6 72.0 76.3 74.2 74.9 Liu subset 81.3 78.2 81.0 80.0 82.0 80.6 81.2Common subset 75.7 69.8 71.6 73.0 76.8 74.7 75.2 Previous ApproachesMFS Liu et.</S>
			<S sid ="152" ssid = "19">al. Leroy and Joshi et.</S>
			<S sid ="153" ssid = "20">McInnes et.</S>
			<S sid ="154" ssid = "21">baseline (2004) Rindflesch (2005) al.</S>
			<S sid ="155" ssid = "22">(2005) al.</S>
			<S sid ="156" ssid = "23">(2007)All words 78.0 – – – 85.3 Joshi subset 66.9 – – 82.5 80.0Leroy subset 55.3 – 65.5 77.4 74.5 Liu subset 69.9 78.0 – 84.9 82.0Common subset 54.9 – 68.8 79.8 75.7 Table 1: Results from WSD system applied to various sections of the NLMWSD data set using a variety of features and machine learning algorithms.</S>
			<S sid ="157" ssid = "24">Results from baseline and previously published approaches are included forcomparison.</S>
			<S sid ="158" ssid = "25">of which set of features are used, and it is consistent of the results in Senseval data from (Agirre andMarti´nez, 2004).</S>
			<S sid ="159" ssid = "26">4.1 Per-Word Analysis.</S>
			<S sid ="160" ssid = "27">Table 2 shows the results of our best performing system (combination of linguistic and MeSH featuresusing the Vector Space Model learning algorithm).Comparable results for previous supervised systemsare also reported where available.3 The MFS baseline for each term is shown in the leftmost column.The performance of Leroy and Rindflesch’s sys 3It is not possible to directly compare our results with Liuet al.</S>
			<S sid ="161" ssid = "28">(2004) or Humphrey et al.</S>
			<S sid ="162" ssid = "29">(2006).</S>
			<S sid ="163" ssid = "30">The first report onlyoptimal configuration for each term (combination of feature setsand learning algorithm) while the second do not assign sensesto all of the instances of each ambiguous term (see Section 2).</S>
			<S sid ="164" ssid = "31">tem is always lower than the best result for eachword.</S>
			<S sid ="165" ssid = "32">The systems reported by Joshi et al.</S>
			<S sid ="166" ssid = "33">(2005)and McInnes et al.</S>
			<S sid ="167" ssid = "34">(2007) are better than, or thesame as, all other systems for 14 and 12 words respectively.</S>
			<S sid ="168" ssid = "35">The system reported here achieves results equal to or better than previously reported systems for 33 terms.</S>
			<S sid ="169" ssid = "36">There are seven terms for which the performanceof our approach is actually lower than the MFS baseline (shown in italics) in Table 2.</S>
			<S sid ="170" ssid = "37">(In fact, the baseline outperforms all systems for four of these terms.)The performance of our system is within 1% of thebaseline for five of these terms.</S>
			<S sid ="171" ssid = "38">The remaining pair,“blood pressure” and “failure”, are included in theset of problematic words identified by (Weeber etal., 2001).</S>
			<S sid ="172" ssid = "39">Examination of the possible senses showthat they include pairs with similar meanings.</S>
			<S sid ="173" ssid = "40">For 85 MFS Leroy and Joshi et.</S>
			<S sid ="174" ssid = "41">McInnes et.</S>
			<S sid ="175" ssid = "42">Reportedbaseline Rindflesch (2005) al.</S>
			<S sid ="176" ssid = "43">(2005) al.</S>
			<S sid ="177" ssid = "44">(2007) system adjustment 62 57 71 70 74association 100 - - 97 100 blood pressure 54 46 53 46 46cold 8690 89 88 condition 90 - - 89 89culture 89 - - 94 95degree 63 68 89 79 95 depression 8586 81 88determination 79 - - 81 87 discharge 7495 96 95energy 99 - - 99 98 evaluation 50 57 69 73 81extraction 8284 86 85 failure 71 - - 73 67fat 7184 77 84fit 82 - - 87 88 fluid 100 - - 99 100frequency 94 - - 94 94ganglion 93 - - 94 96glucose 91 - - 90 91growth 63 62 71 69 68 immunosuppression 59 61 80 75 80implantation 8194 92 93 inhibition 98 - - 98 98japanese 7377 76 75 lead 7189 90 94man 58 80 89 80 90 mole 8395 87 93mosaic 52 66 87 75 87 nutrition 45 48 52 49 54pathology 8585 84 85 pressure 96 - - 93 95radiation 61 72 82 81 84reduction 8991 92 89 repair 52 81 87 93 88resistance 97 - - 96 98 scale 65 84 81 83 88secretion 99 - - 99 99 sensitivity 49 70 88 92 93sex 8088 87 87 single 99 - - 98 99strains 92 - - 92 93 support 90 - - 91 89surgery 98 - - 94 97 transient 99 - - 98 99transport 93 - - 93 93 ultrasound 8492 85 90variation 80 - - 91 95 weight 47 68 83 79 81white 49 62 79 74 76 Table 2: Per-word performance of best reported systems.</S>
			<S sid ="178" ssid = "45">example, the two senses which account for 98% ofthe instances of “blood pressure”, which refer to theblood pressure within an organism and the result obtained from measuring this quantity, are very closelyrelated semantically.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "5">
			<S sid ="179" ssid = "1">This paper has compared a variety of knowledgesources for WSD of ambiguous biomedical termsand reported results which exceed the performanceof previously published approaches.</S>
			<S sid ="180" ssid = "2">We found thataccurate results can be achieved using a combination of linguistic features commonly used for WSD 86 of general text and manually assigned MeSH terms.While CUIs are a useful source of information fordisambiguation, they do not improve the performance of other features when used in combinationwith them.</S>
			<S sid ="181" ssid = "3">Our approach uses manually assignedMeSH terms while the CUIs are obtained automatically using MetaMap.</S>
			<S sid ="182" ssid = "4">The linguistic knowledge sources used in this paper comprise a wide variety of features includingn-grams and syntactic dependencies.</S>
			<S sid ="183" ssid = "5">We have notexplored the effectiveness of these individually andthis is a topic for further work.</S>
			<S sid ="184" ssid = "6">In addition, our approach does not make use ofthe fact that MeSH terms are organised into a hierarchy.</S>
			<S sid ="185" ssid = "7">It would be interesting to discover whether thisinformation could be used to improve WSD performance.</S>
			<S sid ="186" ssid = "8">Others have developed techniques to makeuse of hierarchical information in WordNet for WSD(see Budanitsky and Hirst (2006)) which could beadapted to MeSH.</S>
	</SECTION>
</PAPER>
