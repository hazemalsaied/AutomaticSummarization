Citance Number: 1 | Reference Article:  E03-1020.txt | Citing Article:  W11-1104.txt | Citation Marker Offset:  ['12'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">Current approaches have used clustering (Dorow and Widdows, 2003; Klapaftis and Manandhar, 2008) or statistical graph models (Klapaftis and Manandhar, 2010) to identify sense-specific subgraphs.</S> | Reference Offset:  ['37'] | Reference Text:  <S sid ="37" ssid = "10">To detect the different areas of meaning in our local graphs, we use a cluster algorithm for graphs (Markov clustering, MCL) developed by van Dongen (2000).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 2 | Reference Article:  E03-1020.xml | Citing Article:  S13-2038.xml | Citation Marker Offset:  ['18'] | Citation Marker:  2003 | Citation Offset:  ['18','19'] | Citation Text:  <S sid ="18" ssid = "2">Dorow and Widdows (2003) use the BNC to build a cooccurrencegraph for nouns, based on a co-occurrence frequency threshold.</S><S sid ="19" ssid = "3">They perform Markov clustering on this graph.</S> | Reference Offset:  ['20','37'] | Reference Text:  <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S><S sid ="37" ssid = "10">To detect the different areas of meaning in our local graphs, we use a cluster algorithm for graphs (Markov clustering, MCL) developed by van Dongen (2000).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 3 | Reference Article:  E03-1020.xml | Citing Article:  W08-2207.xml | Citation Marker Offset:  ['37'] | Citation Marker:  DorowandWiddows,2003 | Citation Offset:  ['37'] | Citation Text:  <S sid ="37" ssid = "4">highly accurateTopicSignaturesfor all monosemous wordsin WordNet(forinstance,usingInfoMap(DorowandWiddows,2003)).</S> | Reference Offset:  ['84'] | Reference Text:  <S sid ="84" ssid = "7">We then determined the WordNet synsets which most adequately characterized the sense clusters.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 4 | Reference Article:  E03-1020.xml | Citing Article:  P04-1080.xml | Citation Marker Offset:  ['191'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['191'] | Citation Text:  <S sid ="191" ssid = "1">there are other related efforts on word sense discrimination (Dorow and Widdows, 2003; Fukumoto and Suzuki, 1999; Pedersen and Bruce, 1997).</S> | Reference Offset:  ['6'] | Reference Text:  <S sid ="6" ssid = "6">This paper describes an algorithm which automatically discovers word senses from free text and maps them to the appropriate entries of existing dictionaries or taxonomies.</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 5 | Reference Article:  E03-1020.xml | Citing Article:  P04-1080.xml | Citation Marker Offset:  ['199'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['199','200','201'] | Citation Text:  <S sid ="199" ssid = "9">The algorithm in (Dorow and Widdows, 2003) represented target noun word, its neighbors and their relationships using a graph in which each node denoted a noun and two nodes had an edge between them if they co-occurred with more than a given number of times.</S>	<S sid ="200" ssid = "10">Then senses of target word were iteratively learned by clustering the local graph of similar words around target word.</S><S sid ="201" ssid = "11">Their algorithm required a threshold as input, which controlled the number of senses.</S> | Reference Offset:  ['20'] | Reference Text:  <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 6 | Reference Article:  E03-1020.xml | Citing Article:  D10-1073.xml | Citation Marker Offset:  ['35'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['35','36','37'] | Citation Text:  <S sid ="35" ssid = "16">Another graph-based method is presented in(Dorow and Widdows, 2003).</S><S sid ="36" ssid = "17">They extract onlynoun neighbours that appear in conjunctions or dis-junctions with the target word.</S><S sid ="37" ssid = "18">Additionally, theyextract second-order co-occurrences.</S> | Reference Offset:  ['20'] | Reference Text:  <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 7 | Reference Article:  E03-1020.xml | Citing Article:  C04-1194.xml | Citation Marker Offset:  ['21'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['21'] | Citation Text: <S sid ="21" ssid = "21">The last trend, explored by (Véronis, 2003), (Dorow and Widdows, 2003) and (Rapp, 2003), starts from the cooccurrents of a word recorded from a corpus and builds its senses by gathering its cooccurrents according to their similarity or their dissimilarity.</S> | Reference Offset:  ['37'] | Reference Text:  <S sid ="37" ssid = "10">To detect the different areas of meaning in our local graphs, we use a cluster algorithm for graphs (Markov clustering, MCL) developed by van Dongen (2000).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 8 | Reference Article:  E03-1020.xml | Citing Article:  C04-1194.xml | Citation Marker Offset:  ['27'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['27'] | Citation Text:  <S sid ="27" ssid = "5">This method, as the ones presented in (Véronis, 2003), (Dorow and Widdows, 2003) and (Rapp, 2003), relies on the following hypothesis: in the subgraph gathering the cooccurrents of a word, the number of relations between the cooccurrents defining a sense is higher than the number of relations that these cooccurrents have with those defining the other senses of the considered word.</S> | Reference Offset:  ['2', '3'] | Reference Text:  <S sid ="2" ssid = "2">The algorithm is based on a graph model representing words and relationships between them.</S><S sid ="3" ssid = "3">Sense clusters are iteratively computed by clustering the local graph of similar words around an ambiguous word.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 9 | Reference Article:  E03-1020.xml | Citing Article:  C04-1194.xml | Citation Marker Offset:  ['157'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['157'] | Citation Text:  <S sid ="157" ssid = "1">As they rely on the detection of high-density areas in a network of cooccurrences, (Véronis, 2003) and (Dorow and Widdows, 2003) are the closest methods to ours.</S> | Reference Offset:  ['93'] | Reference Text:  <S sid ="93" ssid = "7">Preliminary observations show that the different neighbours in Table 1 can be used to indicate with great accuracy which of the senses is being used.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 10 | Reference Article:  E03-1020.xml | Citing Article:  C04-1194.xml | Citation Marker Offset:  ['160'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['160'] | Citation Text: <S sid ="160" ssid = "4">In our case, we chose a more general approach by working at the level of a simi­larity graph: when the similarity of two words is given by their relation of cooccurrence, our situa­tion is comparable to the one of (Véronis, 2003) and (Dorow and Widdows, 2003)</S> | Reference Offset:  ['20'] | Reference Text:  <S sid ="20" ssid = "3">Following the method in (Widdows and Dorow, 2002), we build a graph in which each node represents a noun and two nodes have an edge between them if they co-occur in lists more than a given number of times 1.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 11 | Reference Article:  E03-1020.xml | Citing Article:  C04-1194.xml | Citation Marker Offset:  ['165'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['165'] | Citation Text:  <S sid ="165" ssid = "9">From a global viewpoint, these two differences lead (Véronis, 2003) and (Dorow and Widdows, 2003) to build finer senses than ours.</S> | Reference Offset:  ['19'] | Reference Text:  <S sid ="19" ssid = "2">Based on the intuition that nouns which co-occur in a list are often semantically related, we extract contexts of the form Noun, Noun,... and/or Noun, e.g. &quot;genomic DNA from rat, mouse and dog&quot;.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 12 | Reference Article:  E03-1020.xml | Citing Article:  N07-3010.xml | Citation Marker Offset:  ['73'] | Citation Marker:  2003 | Citation Offset:  ['73'] | Citation Text:  <S sid ="73" ssid = "32">The methodology of Dorow and Widdows (2003) was adopted: for the focus word, obtain its graph neighborhood (all vertices that are connected via edges to the focus word vertex and edges between these).</S> | Reference Offset:  ['37'] | Reference Text:  <S sid ="37" ssid = "10">To detect the different areas of meaning in our local graphs, we use a cluster algorithm for graphs (Markov clustering, MCL) developed by van Dongen (2000).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 13 | Reference Article:  E03-1020.xml | Citing Article:  W11-2214.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['10'] | Citation Text: <S sid ="10" ssid = "10">This unsupervised discovery process produces a sense inventory where the number of senses is corpus-driven and where senses may reflect additional usages not present in a predefined sense inventory, such as those for medicine or law (Dorow and Widdows, 2003).</S> | Reference Offset:  ['72'] | Reference Text:  <S sid ="72" ssid = "28">The local graph in step 1 consists of w, the ni neighbours of w and the n9 neighbours of the neighbours of w. Since in each iteration we only attempt to find the &quot;best&quot; cluster, it suffices to build a relatively small graph in 1.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 14 | Reference Article:  E03-1020.xml | Citing Article:  W11-2214.xml | Citation Marker Offset:  ['80'] | Citation Marker:  2003 | Citation Offset:  ['80'] | Citation Text:  <S sid ="80" ssid = "10">We follow Pantel and Lin (2002) and Dorow and Widdows (2003) using the sentence as contexts and all words with a dependency path of length 3 or less, with the last word and its relation as a feature.</S> | Reference Offset:  ['90'] | Reference Text:  <S sid ="90" ssid = "4">This gives rise to an automatic, unsupervised word sense disambiguation algorithm which is trained on the data to be disambiguated.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankur Khanna, NUS |


Citance Number: 15 | Reference Article:  E03-1020.xml | Citing Article:  W06-3812.xml | Citation Marker Offset:  ['176'] | Citation Marker:  Dorow and Widdows, 2003 | Citation Offset:  ['176','178'] | Citation Text: <S sid ="176" ssid = "50">Similar to the approach as presented in (Dorow and Widdows, 2003) we construct a word graph.</S><S sid ="178" ssid = "52">Dorow and Widdows construct a graph for a target word w by taking the sub-graph induced by the neighborhood of w (without w) and clustering it with MCL.</S> | Reference Offset:  ['37', '2', '3'] | Reference Text:  <S sid ="37" ssid = "10">To detect the different areas of meaning in our local graphs, we use a cluster algorithm for graphs (Markov clustering, MCL) developed by van Dongen (2000).</S><S sid ="2" ssid = "2">The algorithm is based on a graph model representing words and relationships between them.</S><S sid ="3" ssid = "3">Sense clusters are iteratively computed by clustering the local graph of similar words around an ambiguous word.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankur Khanna, NUS |


