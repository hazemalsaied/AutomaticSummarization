Citance Number: 1 | Reference Article:  N01-1011.xml | Citing Article:  W02-0812.xml | Citation Marker Offset:  ['131'] | Citation Marker:  Pedersen, 2001a | Citation Offset:  ['131','132','133'] | Citation Text: <S sid ="131" ssid = "33">The frustration with models that lack an intuitive interpretation led to the development of decision trees based on bigram features (Pedersen, 2001a).</S><S sid ="132" ssid = "34">This is quite similar to the bagged decision trees of bigrams (B) presented here, except that the ear­lier work learns a single decision tree where training examples are represented by the top 100 ranked bi-grams, according to the log–likelihood ratio.</S><S sid ="133" ssid = "35">This earlier approach was evaluated on the SENSEVAL­1 data and achieved an overall accuracy of 64%, whereas the bagged decision tree presented here achieves an accuracy of 68% on that data.</S> | Reference Offset:  ['84', '101', '161'] | Reference Text:  <S sid ="84" ssid = "1">Our empirical study utilizes the training and test data from the 1998 SENSEVAL evaluation of word sense disambiguation systems.</S><S sid ="101" ssid = "3">Two feature sets are selected from the training data based on the top 100 ranked bigrams according to the power divergence statistic and the Dice CoeÆcient.</S><S sid ="161" ssid = "3">While the accuracy of this approach was as good as any previously published results, the learned models were complex and diÆcult to interpret, in e?ect acting as very accurate black boxes.</S> | Discourse Facet:  Method_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 2 | Reference Article:  N01-1011.xml | Citing Article:  W04-0813.xml | Citation Marker Offset:  ['43'] | Citation Marker:  Pedersen, 2001 | Citation Offset:  ['43'] | Citation Text:  <S sid ="43" ssid = "23">We also obtain salient bigrams in the con­text, with the methods and the software de­scribed in (Pedersen, 2001).</S> | Reference Offset:  ['18', '19', '61'] | Reference Text:  <S sid ="18" ssid = "18">The approach in this paper relies upon a feature set made up of bigrams, two word sequences that occur in a text.</S><S sid ="19" ssid = "19">The context in which an ambiguous word occurs is represented by some number of binary features that indicate whether or not a particular bigram has occurred within approximately 50 words to the left or right of the word being disambiguated.</S><S sid ="61" ssid = "35">We have developed the Bigram Statistics Package to produce ranked lists of bigrams using a range of tests.</S> | Discourse Facet:  Method_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 3 | Reference Article:  N01-1011.xml | Citing Article:  W02-1011.xml | Citation Marker Offset:  ['136'] | Citation Marker:  2001 | Citation Offset:  ['136'] | Citation Text:  <S sid ="136" ssid = "45">in fact, Pedersen (2001) found that bigrams alone can be e.ective features for word sense disambiguation.</S> | Reference Offset:  ['189'] | Reference Text:  <S sid ="189" ssid = "1">This paper shows that the combination of a simple feature set made up of bigrams and a standard decision tree learning algorithm results in accurate word sense disambiguation.</S> | Discourse Facet:  Results_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 4 | Reference Article:  N01-1011.xml | Citing Article:  N03-3004.xml | Citation Marker Offset:  ['49'] | Citation Marker:  Pedersen, 2001 | Citation Offset:  ['49'] | Citation Text:  <S sid ="49" ssid = "9">Bigrams have recently been shown to be very successful features in supervised word sense disambiguation (Peder­sen, 2001).</S> | Reference Offset:  ['189'] | Reference Text:  <S sid ="189" ssid = "1">This paper shows that the combination of a simple feature set made up of bigrams and a standard decision tree learning algorithm results in accurate word sense disambiguation.</S> | Discourse Facet:  Results_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 5 | Reference Article:  N01-1011.xml | Citing Article:  C02-1039.xml | Citation Marker Offset:  ['15'] | Citation Marker: Pedersen, 2001 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">Commonly used features include surrounding words and their part of speech(Bruce and Wiebe, 1999),context keywords (Ng and Lee, 1996) or context bigrams (Pedersen, 2001) </S> | Reference Offset:  ['18', '19'] | Reference Text:  <S sid ="18" ssid = "18">The approach in this paper relies upon a feature set made up of bigrams, two word sequences that occur in a text.</S><S sid ="19" ssid = "19">The context in which an ambiguous word occurs is represented by some number of binary features that indicate whether or not a particular bigram has occurred within approximately 50 words to the left or right of the word being disambiguated.</S> | Discourse Facet:  Method_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 6 | Reference Article:  N01-1011.xml | Citing Article:  C02-1039.xml | Citation Marker Offset:  ['15'] | Citation Marker:  Pedersen, 2001 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">As for the learning methodology, a large range ofalgorithms have been employed, including neu ral networks (Leacock et al., 1998), decision trees (Pedersen, 2001)</S> | Reference Offset:  ['1'] | Reference Text:  <S sid ="1" ssid = "1">This paper presents a corpus-based approach to word sense disambiguation where a decision tree assigns a sense to an ambiguous word based on the bigrams that occur nearby.</S> | Discourse Facet:  Method_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 7 | Reference Article:  N01-1011.xml | Citing Article:  J02-2003.xml | Citation Marker Offset:  ['148'] | Citation Marker:  2001 | Citation Offset:  ['148'] | Citation Text:  <S sid ="148" ssid = "54">In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic.</S> | Reference Offset:  ['40', '42'] | Reference Text:  <S sid ="40" ssid = "14">However, (Cressie and Read, 1984) suggest that there are cases where Pearson&apos;s statistic is more reliable than the likelihood ratio and that one test should not always be preferred over the other.</S><S sid ="42" ssid = "16">Unfortunately it is usually not clear which test is most appropriate for a particular sample of data.</S> | Discourse Facet:  Implication_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |


Citance Number: 8 | Reference Article:  N01-1011.xml | Citing Article:  W08-0611.xml | Citation Marker Offset:  ['103'] | Citation Marker:  2001 | Citation Offset:  ['103'] | Citation Text:  <S sid ="103" ssid = "17">• Salient bigrams: Salient bigrams within the abstract with high log-likelihood scores, as described by Pedersen (2001).</S> | Reference Offset:  ['18', '29', '37'] | Reference Text:  <S sid ="18" ssid = "18">The approach in this paper relies upon a feature set made up of bigrams, two word sequences that occur in a text.</S><S sid ="29" ssid = "3">Given the sparse and skewed nature of this data, the statistical methods used to select interesting bigrams must be carefully chosen.</S><S sid ="37" ssid = "11">A number of well known statistics belong to this family, including the likelihood ratio statisticG 2 and Pearson&apos;sX 2 statistic.</S> | Discourse Facet:  Method_Citation | Annotator:  Muthu Kumar Chandrasekaran, NUS |

