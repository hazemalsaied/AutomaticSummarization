2 Chinese ?l* han4zi4 'Chinese character'; this is the same word as Japanese kanji..
Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
There are thus some very good reasons why segmentation into words is an important task.
Morphologically derived words such as, xue2shengl+men0.
Personal names such as 00, 3R; zhoulenl-lai2 'Zhou Enlai.'
The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.
Previous Work.
There is a sizable literature on Chinese word segmentation recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).
Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.
Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.
(See Sproat and Shih 1995.)
The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.
(1991}, Gu and Mao (1994), and Nie, Jin, and Hannan (1994).
The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
Chinese word segmentation can be viewed as a stochastic transduction problem.
More formally, we start by representing the dictionary D as a Weighted Finite State TransÃÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).
Note also that the costs currently used in the system are actually string costs, rather than word costs.
We of course also fail to identify, by the methods just described, given names used without their associated family name.
Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.
Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.
Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.
Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.
Evaluation of the Segmentation as a Whole.
(See also Wu and Fung [1994].)
(See also Wu and Fung [1994].)
(See also Wu and Fung [1994].)
(See also Wu and Fung [1994].)
(See also Wu and Fung [1994].)
An anti-greedy algorithm, AG instead of the longest match, take the.
The result of this is shown in Figure 7.
This is to allow for fair comparison between the statistical method and GR, which is also purely dictionary-based.
Under this scheme, n human judges are asked independently to segment a text.
The performance was 80.99% recall and 61.83% precision.
The performance was 80.99% recall and 61.83% precision.
Examples are given in Table 4.
19 We note that it is not always clear in Wang, Li, and Chang's examples which segmented words.
constitute names, since we have only their segmentation, not the actual classification of the segmented words.
In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.
In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.
(For some recent corpus-based work on Chinese abbreviations, see Huang, Ahrens, and Chen [1993].)
We have argued that the proposed method performs well.
However, some caveats are in order in comparing this method (or any method) with other approaches to segÃÂ­ mentation reported in the literature.
For example, as Gan (1994) has noted, one can construct examples where the segmenÂ­ tation is locally ambiguous but can be determined on the basis of sentential or even discourse context.
In (1) the sequencema3lu4 cannot be resolved locally, but depends instead upon broader context; similarly in (2), the sequence tcai2neng2 cannot be resolved locally 1.
Consider first the examples in (2).
Consider first the examples in (2).
Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.
The model described here thus demonstrates great potential for use in widespread applications.
The model described here thus demonstrates great potential for use in widespread applications.
Chang of Tsinghua University, Taiwan, R.O.C., for kindly providing us with the name corpora.