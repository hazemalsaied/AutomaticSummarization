Semi-supervised Verb Class Discovery Using Noisy Features
Semi-supervised Verb Class Discovery Using Noisy Features
Learning the argument structure properties of verbsâthe semantic roles they assign and their mapping to syntactic positionsâis both particularly important and difficult.
Learning the argument structure properties of verbsâthe semantic roles they assign and their mapping to syntactic positionsâis both particularly important and difficult.
A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (Gildea and Jurafsky, 2002), selectional preferences (Resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (Dorr and Jones, 1996; Lapata and Brew, 1999; Merlo and Stevenson, 2001; Joanis and Stevenson, 2003).
A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (Gildea and Jurafsky, 2002), selectional preferences (Resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (Dorr and Jones, 1996; Lapata and Brew, 1999; Merlo and Stevenson, 2001; Joanis and Stevenson, 2003).
We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
Dorr and Jones, 1996; Schulte im Walde and Brew, 2002).
However, a general feature space means that most features will be irrelevant to any given verb discrimination task.
Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).
Thus, the features serve as approximations to the underlying distinctions among classes.
Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
Here we describe the selection of the experimental classes and verbs, and the estimation of the feature values.
Pairs or triples of verb classes from Levin were selected to form the test pairs/triples for each of a number of separate classification tasks.
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
We began with this same set of 20 verbs per class for our current work.
4.2.1 Accuracy We can assign each cluster the class label of the majority of its members.
Then accuracy has the standard definition2 2 is equivalent to the weighted mean precision of the clusters, weighted according to cluster size.
Because the achieved depends on the precise size of clusters, we calculated mean over the best scenario (with equal-sized clusters), yielding a conservative estimate (i.e., an upper bound) of the baseline.
The first subcolumn (Full) under each of the three clustering evaluation measures in Table 2 shows the results using the full set of features (i.e., no feature selection).
We extracted from the resulting decision trees the union of all features used, which formed the reduced feature set for that task.
Our feature set is essentially a generalization of theirs, but in scaling up the feature space to be useful across English verb classes in general, we necessarily face a dimensionality problem that did not arise in their research.
Schulte im Walde and Brew (2002) and Schulte im Walde (2003), on the other hand, use a larger set of features intended to be useful for a broad number of classes, as in our work.