Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.
Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.
Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.
Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.
Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.
Entities can be of five types persons, organizations, locations, facilities and geopolitical entities (GPE geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).
Entities can be of five types persons, organizations, locations, facilities and geopolitical entities (GPE geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).
Entities can be of five types persons, organizations, locations, facilities and geopolitical entities (GPE geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).
Entities can be of five types persons, organizations, locations, facilities and geopolitical entities (GPE geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).
Entities can be of five types persons, organizations, locations, facilities and geopolitical entities (GPE geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).
Entities can be of five types persons, organizations, locations, facilities and geopolitical entities (GPE geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).
Our study illustrates that the base phrase chunking information contributes to most of the performance inprovement from syntactic aspect while additional full parsing information does not contribute much, largely due to the fact that most of relations defined in ACE corpus are within a very short distance.
Our study illustrates that the base phrase chunking information contributes to most of the performance inprovement from syntactic aspect while additional full parsing information does not contribute much, largely due to the fact that most of relations defined in ACE corpus are within a very short distance.
The rest of this paper is organized as follows.
Section 3 and Section 4 describe our approach and various features employed respectively.
Section 3 and Section 4 describe our approach and various features employed respectively.
Section 3 and Section 4 describe our approach and various features employed respectively.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.
Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.
Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.
Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
It achieves 52.8 F- measure on the 24 ACE relation subtypes.
It achieves 52.8 F- measure on the 24 ACE relation subtypes.
Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.
Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.
Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.
Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.
Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.
This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.
Therefore, we must extend SVMs to multi-class (e.g. K) such as the ACE RDC task.
Moreover, we only apply the simple linear kernel, although other kernels can peform better.
Moreover, we only apply the simple linear kernel, although other kernels can peform better.
The semantic relation is determined between two mentions.
Since a pronominal mention (especially neutral pronoun such as ?it? and ?its?) contains little information about the sense of the mention, the co- reference chain is used to decide its sense.
In this paper, we separate the features of base phrase chunking from those of full parsing.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
The dependency tree is built by using the phrase head information returned by the Collins? parser and linking all the other fragments in a phrase to its head.
The dependency tree is built by using the phrase head information returned by the Collins? parser and linking all the other fragments in a phrase to its head.
Two features are defined to include this information ? ET1Country the entity type of M1 when M2 is a country name ? CountryET2 the entity type of M2 when M1 is a country name 5 http//ilk.kub.nl/~sabine/chunklink/ Personal Relative Trigger Word List This is used to differentiate the six personal social relation subtypes in ACE Parent, Grandparent, Spouse, Sibling, Other-Relative and Other- Personal.
Two features are defined to include this information ? ET1Country the entity type of M1 when M2 is a country name ? CountryET2 the entity type of M2 when M1 is a country name 5 http//ilk.kub.nl/~sabine/chunklink/ Personal Relative Trigger Word List This is used to differentiate the six personal social relation subtypes in ACE Parent, Grandparent, Spouse, Sibling, Other-Relative and Other- Personal.
Two features are defined to include this information ? ET1Country the entity type of M1 when M2 is a country name ? CountryET2 the entity type of M2 when M1 is a country name 5 http//ilk.kub.nl/~sabine/chunklink/ Personal Relative Trigger Word List This is used to differentiate the six personal social relation subtypes in ACE Parent, Grandparent, Spouse, Sibling, Other-Relative and Other- Personal.
Two features are defined to include this information ? ET1SC2 combination of the entity type of M1 and the semantic class of M2 when M2 triggers a personal social subtype.
Two features are defined to include this information ? ET1SC2 combination of the entity type of M1 and the semantic class of M2 when M2 triggers a personal social subtype.
This paper uses the ACE corpus provided by LDC to train and evaluate our feature-based relation extraction system.
This paper uses the ACE corpus provided by LDC to train and evaluate our feature-based relation extraction system.
