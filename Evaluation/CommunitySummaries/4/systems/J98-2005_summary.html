<html>
<head><title>J98-2005_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>a treebank PCFG whose simple relative frequency estimator corresponds to maximumlikelihood ( Chi and Geman 1998 ) , and which we shall refer to as `` MLPCFG '' . </a>
<a name="1">[1]</a> <a href="#1" id=1>Maximum likelihood from incomplete data via the EM algorithm . </a>
<a name="2">[2]</a> <a href="#2" id=2>Such maximization provides the estimator ( see for instance ( Chi and Geman , 1998 ) ) pG ( A ? a ) =f ( A ? a , T ) f ( A , T ) . </a>
<a name="3">[3]</a> <a href="#3" id=3>This result been firstly shown in ( Chaudhuri et al. , 1983 ) and later , with a different proof technique , in ( Chi and Geman , 1998 ) . </a>
<a name="4">[4]</a> <a href="#4" id=4>( Wetherell and others use the designation `` consistent '' instead of `` tight , '' but in statistics , consistency refers to the asymptotic correctness of an estimator . ) </a>
<a name="5">[5]</a> <a href="#5" id=5>impose proper probability distributions on D ( Chi and Geman 1998 ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>In the simple example here , the estimator converges in one step and is the same ~ as if we had observed the entire parse tree for each wi . </a>
<a name="7">[7]</a> <a href="#7" id=7>We will show that in both cases the estimated probability is tight . </a>
<a name="8">[8]</a> <a href="#8" id=8>Evidently the likelihood is unaffected by the particular assignment of fi ( B -- ~ fl ) . </a>
<a name="9">[9]</a> <a href="#9" id=9>Blum 1972 ] first introduced it for hidden Markov models ( regular grammars ) and Baker [ 1979 ] extended it to the problem addressed here ( estimation for context-free grammars ) . </a>
<a name="10">[10]</a> <a href="#10" id=10>If , however , the language of the grammar does not include the null string , then there is an equivalent grammar ( one with the same language ) that has no null productions and no unit productions ( cf . </a>
<a name="11">[11]</a> <a href="#11" id=11>This iteration procedure is an instance of the EM Algorithm . </a>
<a name="12">[12]</a> <a href="#12" id=12>This solves a problem that was left open in the literature ( Chi and Geman,1998 ) </a>
<a name="13">[13]</a> <a href="#13" id=13>Proof The proof is almost identical to the one given by Chi and Ceman ( 1998 ) . </a>
<a name="14">[14]</a> <a href="#14" id=14>What if the production probabilities are estimated from data ? </a>
<a name="15">[15]</a> <a href="#15" id=15>In the usual way , probabilities are introduced through the productions : P : R -- ~ [ 0,1 ] such that VA E V : p ( A -~ c~ ) = 1 . </a>
<a name="16">[16]</a> <a href="#16" id=16>This simple estimator , as shown by Chi and Geman ( 1998 ) , assigns proper production probÂ­ abilities for PCFGs . </a>
<a name="17">[17]</a> <a href="#17" id=17>Hence qs = 0 , completing the proof of the theorem . </a>
<a name="18">[18]</a> <a href="#18" id=18>( We use R in place of the more typical P to avoid confusion with probabilities . ) </a>
<a name="19">[19]</a> <a href="#19" id=19>Denote the maximum-likelihood estimator by fi : n B AB q- ~i=lf -- + /3 ; ca ; ) = 0 V ( S ~ /3 ) E R f , ( B +/3 ) Since ~ fi ( B+/3 ) =l ) fl sA . </a>
<a name="20">[20]</a> <a href="#20" id=20>Suppose B E V is unobserved among the parse tree cabc 0 2 -.. , can . </a></body>
</html>
