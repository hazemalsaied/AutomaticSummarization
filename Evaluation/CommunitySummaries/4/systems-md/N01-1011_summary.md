We believe that the approach in this paper is the ? rst time that decision trees based strictly on digram features have been employed . 
Learning continues until all the training examples are accounted for by the decision tree . 
The most dramatic difference occurred with amaze-v , where the SENSE- VAL average was 92.4 % and the decision tree accuracy was 58.6 % . 
In light of this , ( Pedersen , 1996 ) presents Fisher 's exact test as an alternative since it does not rely on the distributional assumptions that underly both Pearson 's test and the likelihood ratio . 
There is a further assumption that each feature is conditionally independent of all other features , given the sense of the ambiguous word . 
Each sense { tagged occurrence of an ambiguous word is converted into a feature vector , where each feature represents some property of the surrounding text that is considered to be relevant to the disambiguation process . 
These typically include the part { of { speech of surrounding words , the presence of certain key words within some window of context , and various syntactic properties of the sentence and the ambiguous word . 
Decision trees are among the most widely used machine learning algorithms . 
The following process is repeated for each task . 
A preliminary version of this paper appears in ( Pedersen , 2001 ) . 