The introduction of two new tasks into the MUC evaluations and the restructuring of information extraction into two separate tasks have infused new life into the evaluations . 
The other two tasks , Template Element and Scenario Template , were information extraction tasks that followed on from the MUC evaluations conducted in previous years . 
Many of the sites have emphasized their pattern-matching techniques in discussing the strengths of their MUC6 systems . 
Even the simplest of the tasks , Named Entity , occasionally requires in-depth processing , e.g. , to determine whether `` 60 pounds '' is an expression of weight or of monetary value . 
In short , the preliminary nature of the task design is reflected in the somewhat unmotivated boundaries between markable and remarkable and in weaknesses in the notation . 
All the participating sites also submitted systems for evaluation on the TE and NE tasks . 
This period comprised the `` evaluation epoch . '' 
The text filtering results for MUC6 , MUC4 ( TST4 ) and MUC3 ( TST2 ) are shown in figure 8 . 
MUC6 56.40 MUC5 EJV 52.75 MUC5 JJV 60.07 MUC5 EME 49.18 MUC5 JME 56.31 Table 4 . 
Finally , a change in administration of the MUC evaluations is occurring that will bring fresh ideas . 
Documentation of each of the tasks and summary scores for all systems evaluated can be found in the MUC6 proceedings [ 1 ] . 
As indicated in table 2 , all systems performed better on identifying person names than on identifying organization or location names , and all but a few systems performed better on location names than on organization names . 
The NE evaluation results serve mainly to document in the MUC context what was already strongly suspected : 1 . 
This capability has other useful applications as well , e.g. , it enables text highlighting in a browser . 
CORPUS Testing was conducted using Wall Street Journal texts provided by the Linguistic Data Consortium . 
Much less information about the event would be captured , but there would be a much stronger focus on the most essential information elements . 
Statistically , large differences of up to 15 points may not be reflected as a difference in the ranking of the systems . 
Systems scored approximately 1525 points lower ( F-measure ) on ST than on TE . 
Frequently , at least one can be found in close proximity to an organization 's name , e.g. , as an appositive ( `` Creative Artists Agency , the big Hollywood talent agency '' ) . 
OVERVIEW OF RESULTS OF THE MUC-6 EVALUATION 