<html>
<head><title>J98-2005_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>a treebank PCFG whose simple relative frequency estimator corresponds to maximumlikelihood ( Chi and Geman 1998 ) , and which we shall refer to as `` MLPCFG '' . </a>
<a name="1">[1]</a> <a href="#1" id=1>Evidently the likelihood is unaffected by the particular assignment of fi ( B -- ~ fl ) . </a>
<a name="2">[2]</a> <a href="#2" id=2>Such maximization provides the estimator ( see for instance ( Chi and Geman , 1998 ) ) pG ( A ? a ) =f ( A ? a , T ) f ( A , T ) . </a>
<a name="3">[3]</a> <a href="#3" id=3>This result been firstly shown in ( Chaudhuri et al. , 1983 ) and later , with a different proof technique , in ( Chi and Geman , 1998 ) . </a>
<a name="4">[4]</a> <a href="#4" id=4>Is it tight ? </a>
<a name="5">[5]</a> <a href="#5" id=5>a What if p is estimated from data ? </a>
<a name="6">[6]</a> <a href="#6" id=6>This simple estimator , as shown by Chi and Geman ( 1998 ) , assigns proper production probÂ­ abilities for PCFGs . </a>
<a name="7">[7]</a> <a href="#7" id=7>impose proper probability distributions on D ( Chi and Geman 1998 ) . </a>
<a name="8">[8]</a> <a href="#8" id=8>Dumpster Laird , and Rubin [ 1977 ] put the idea into a much more general setting and coined the Chi and Geman Probabilistic Context-Free Grammars term EM for Expectation-Maximization . </a>
<a name="9">[9]</a> <a href="#9" id=9>Blum 1972 ] first introduced it for hidden Markov models ( regular grammars ) and Baker [ 1979 ] extended it to the problem addressed here ( estimation for context-free grammars ) . </a>
<a name="10">[10]</a> <a href="#10" id=10>For each A E V , let F ( A ; w ) be the number of instances of A in w and let F ( A ; w ) be the number of non root instances of A in w. Given oz E ( V U T ) * , let nA ( cZ ) be the number of instances of A in the string o~ , and , finally , let ai be the ith component of the string o~ . </a>
<a name="11">[11]</a> <a href="#11" id=11>It is reasonable to hope that if the trees in the sample are finite , then an estimate of production probabilities based upon the sample will produce a system that assigns probability zero to the set of infinite trees . </a>
<a name="12">[12]</a> <a href="#12" id=12>This solves a problem that was left open in the literature ( Chi and Geman,1998 ) </a>
<a name="13">[13]</a> <a href="#13" id=13>Proof The proof is almost identical to the one given by Chi and Ceman ( 1998 ) . </a>
<a name="14">[14]</a> <a href="#14" id=14>What if the production probabilities are estimated from data ? </a>
<a name="15">[15]</a> <a href="#15" id=15>We show here that estimated production probabilities always yield proper distributions.</a>
<a name="16">[16]</a> <a href="#16" id=16>( A~c~ ) ER Chi and Geman Probabilistic Context-Free Grammars Given a set of finite parse trees cab ca2 , ... , can , drawn independently according to the distribution imposed by p , we wish to estimate p. In terms of the frequency function f , introduced in Section 1 , the likelihood of the data is L = L ( p ; cal , ca2 ... .. con ) n = II II p ( AY i=1 ( A~ ) ER Recall the derivation of the maximum-likelihood estimator of p : The log of the likelihood is : n ~ ~f ( A -- + a ; cai ) log A ~ a ) . </a>
<a name="17">[17]</a> <a href="#17" id=17>Proof Almost identical , except that we use ( 5 ) in place of ( 3 ) and end up with : n E qA EEG_1 [ F ( A ; wi ) -F ( A ; wi ) lw C fly ( w , ) ] ~ 0 . </a>
<a name="18">[18]</a> <a href="#18" id=18>Furthermore , CFG 's are readily fit with a probability distribution ( to make probabilistic CFG 's -- or PCFG 's ) , rendering them suitable for ambiguous languages through the maximum a posteriori rule of choosing the most probable parse . </a>
<a name="19">[19]</a> <a href="#19" id=19>Estimation of Probabilistic Context-Free Grammars</a>
<a name="20">[20]</a> <a href="#20" id=20>Suppose B E V is unobserved among the parse tree cabc 0 2 -.. , can . </a></body>
</html>
