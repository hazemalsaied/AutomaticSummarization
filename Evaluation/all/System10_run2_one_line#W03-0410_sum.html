<html>
<head><title>W03-0410_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</a>
<a name="1">[1]</a> <a href="#1" id=1>We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</a>
<a name="2">[2]</a> <a href="#2" id=2>We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</a>
<a name="3">[3]</a> <a href="#3" id=3>Dorr and Jones, 1996; Schulte im Walde and Brew, 2002).</a>
<a name="4">[4]</a> <a href="#4" id=4>Dorr and Jones, 1996; Schulte im Walde and Brew, 2002).</a>
<a name="5">[5]</a> <a href="#5" id=5>In an unsupervised (clustering) scenario of verb class discovery, can we maintain the benefit of only needing noisy features, without the generality of the feature space leading to ?the curse of dimensionality??</a>
<a name="6">[6]</a> <a href="#6" id=6>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="7">[7]</a> <a href="#7" id=7>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="8">[8]</a> <a href="#8" id=8>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="9">[9]</a> <a href="#9" id=9>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="10">[10]</a> <a href="#10" id=10>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="11">[11]</a> <a href="#11" id=11>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="12">[12]</a> <a href="#12" id=12>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="13">[13]</a> <a href="#13" id=13>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="14">[14]</a> <a href="#14" id=14>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="15">[15]</a> <a href="#15" id=15>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="16">[16]</a> <a href="#16" id=16>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="17">[17]</a> <a href="#17" id=17>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="18">[18]</a> <a href="#18" id=18>Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</a>
<a name="19">[19]</a> <a href="#19" id=19>Like others, we have assumed lexical semantic classes of verbs as defined in Levin (1993) (hereafter Levin), which have served as a gold standard in computational linguistics research (Dorr and Jones, 1996; Kipper et al., 2000; Merlo and Stevenson, 2001; Schulte im Walde and Brew, 2002).</a>
<a name="20">[20]</a> <a href="#20" id=20>Like others, we have assumed lexical semantic classes of verbs as defined in Levin (1993) (hereafter Levin), which have served as a gold standard in computational linguistics research (Dorr and Jones, 1996; Kipper et al., 2000; Merlo and Stevenson, 2001; Schulte im Walde and Brew, 2002).</a>
<a name="21">[21]</a> <a href="#21" id=21>Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.</a>
<a name="22">[22]</a> <a href="#22" id=22>Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.</a>
<a name="23">[23]</a> <a href="#23" id=23>Features over Syntactic Slots (120 features) One set of features encodes the frequency of the syntactic slots occurring with a verb (subject, direct and indirect object, and prepositional phrases (PPs) indexed by preposition), which collectively serve as rough approximations to the allowable syntactic frames for a verb.</a>
<a name="24">[24]</a> <a href="#24" id=24>In addition to verb POS (which often indicates tense) and voice (passive/active), we also include counts of modals, auxiliaries, and adverbs, which are partial indicators of these factors.</a>
<a name="25">[25]</a> <a href="#25" id=25>In addition to verb POS (which often indicates tense) and voice (passive/active), we also include counts of modals, auxiliaries, and adverbs, which are partial indicators of these factors.</a>
<a name="26">[26]</a> <a href="#26" id=26>3.3 Feature Extraction.</a>
<a name="27">[27]</a> <a href="#27" id=27>We chose hierarchical clustering because it may be possible to find coherent subclusters of verbs even when there are not exactly good clusters, where is the number of classes.</a>
<a name="28">[28]</a> <a href="#28" id=28>We use , the mean of the silhouette measure from Matlab, which measures how distant a data point is from other clusters.</a></body>
</html>
