<html>
<head><title>W03-0410_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Because we make the simplifying assumption of a single correct classification for each verb , we also removed any verb : that was deemed excessively polygamous that belonged to another class under consideration in our study ; or for which the class did not correspond to the main sense . </a>
<a name="1">[1]</a> <a href="#1" id=1>A number of supervised learning approaches have extracted such information about verbs from corpora , including their argument roles ( Gildea and Jurafsky , 2002 ) , selectional preferences ( Resnik , 1996 ) , and lexical semantic classification ( i.e. , grouping verbs according to their argument structure properties ) ( Dorr and Jones , 1996 ; Lapata and Brew , 1999 ; Merlo and Stevenson , 2001 ; Joanis and Stevenson , 2003 ) . </a>
<a name="2">[2]</a> <a href="#2" id=2>We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification ( Joanis and Stevenson , 2003 ) . </a>
<a name="3">[3]</a> <a href="#3" id=3>4.1 Clustering Parameters . </a>
<a name="4">[4]</a> <a href="#4" id=4>All experiments reported here were run on this same final set of 20 verbs per class ( including a replication of our earlier supervised experiments ) . </a>
<a name="5">[5]</a> <a href="#5" id=5>We started with a list of all the verbs in the given classes from Levin , removing any verb that did not occur at least 100 times in our corpus ( the BNC , described below ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>This confirms that appropriate feature selection , and not just a small number of features , is important for the task of verb class discovery . </a>
<a name="7">[7]</a> <a href="#7" id=7>Like others , we have assumed lexical semantic classes of verbs as defined in Levin ( 1993 ) ( hereafter Levin ) , which have served as a gold standard in computational linguistics research ( Dorr and Jones , 1996 ; Kipper et al. , 2000 ; Merlo and Stevenson , 2001 ; Schulte im Walde and Brew , 2002 ) . </a>
<a name="8">[8]</a> <a href="#8" id=8>Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . </a>
<a name="9">[9]</a> <a href="#9" id=9>The third column of Table 2 gives the baseline we calculated from random clusterings . </a>
<a name="10">[10]</a> <a href="#10" id=10>Currently , our only such feature is an extension of the animate feature of Merlo and Stevenson ( 2001 ) . </a>
<a name="11">[11]</a> <a href="#11" id=11>We then describe our clustering methodology , the measures we use to evaluate a clustering , and our experimental results . </a>
<a name="12">[12]</a> <a href="#12" id=12>In contrast to Merlo and Stevenson ( 2001 ) , we confirmed that a set of general features can be successfully used , without the need for manually determining the relevant features for distinguishing particular classes ( cf . </a>
<a name="13">[13]</a> <a href="#13" id=13>For example , the accuracy measure ( Stevenson and Joanis 2003 ; Korhonen , Krymolowski , and Marx 2003 ) evaluates whether a verb is assigned to a correct cluster with respect to the gold standard class of the majority of cluster members . </a>
<a name="14">[14]</a> <a href="#14" id=14>In recent work , Stevenson and Joanis ( 2003 ) compared their supervised method for verb classification with supervised and unsupervised techniques . </a>
<a name="15">[15]</a> <a href="#15" id=15>We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson ( 2003 ) to enable a comparison between the performance of the unsupervised and supervised methods . </a>
<a name="16">[16]</a> <a href="#16" id=16>However , creating a verb classification is highly resource intensive , in terms of both required time and linguistic expertise . </a>
<a name="17">[17]</a> <a href="#17" id=17>In these experiments , they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes , with a total of 841 verbs . </a>
<a name="18">[18]</a> <a href="#18" id=18>7 5 0 Table 1 : Verb classes ( see Section 3.1 ) , their Levin class numbers , and the number of experimental verbs in each ( see Section 3.2 ) . </a>
<a name="19">[19]</a> <a href="#19" id=19>Although our motivation is verb class discovery , we perform our experiments on English , for which we have an accepted classification to serve as a gold standard ( Levin , 1993 ) . </a>
<a name="20">[20]</a> <a href="#20" id=20>A plausible scenario is that researchers would have examples of verbs which they believe fall into different classes of interest , and they want to separate other verbs along the same lines . </a>
<a name="21">[21]</a> <a href="#21" id=21>Thus , the problem of dimensionality reduction is a key issue to be addressed in verb class discovery . </a>
<a name="22">[22]</a> <a href="#22" id=22>Here we describe the selection of the experimental classes and verbs , and the estimation of the feature values . </a>
<a name="23">[23]</a> <a href="#23" id=23>They found that a supervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 approach of Dash , Liu , and Yao ( 1997 ) , which used an entropy measure to organize data into a multidimensional space . </a>
<a name="24">[24]</a> <a href="#24" id=24>1 For practical reasons , as well as for enabling us to draw more general conclusions from the results , the classes also could neither be too small nor contain mostly infrequent verbs . </a>
<a name="25">[25]</a> <a href="#25" id=25>Low- frequency and ambiguous verbs were excluded from the classes . </a>
<a name="26">[26]</a> <a href="#26" id=26>Dorri and Jones , 1996 ; Schulte im Walde and Brew , 2002 ) . </a>
<a name="27">[27]</a> <a href="#27" id=27>We use , the mean of the silhouette measure from Matlab , which measures how distant a data point is from other clusters . </a>
<a name="28">[28]</a> <a href="#28" id=28>Table 1 above shows the number of verbs in each class at the end of this process . </a>
<a name="29">[29]</a> <a href="#29" id=29>We focus here on extending the applicability of unsupervised methods , as in ( Schulte im Walde and Brew , 2002 ; Stevenson and Merlo , 1999 ) , to the lexical semantic classification of verbs . </a>
<a name="30">[30]</a> <a href="#30" id=30>Unsupervised or semi-supervised approaches have been successful as well , but have tended to be more restrictive , in relying on human filtering of the results ( Riloff and Schmelzenbach , 1998 ) , on the hand- selection of features ( Stevenson and Merlo , 1999 ) , or on the use of an extensive grammar ( Schulte im Walde and Brew , 2002 ) . </a>
<a name="31">[31]</a> <a href="#31" id=31>Our second measure , the adjusted Rand measure used by Schulte im Walde ( 2003 ) , instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification . </a>
<a name="32">[32]</a> <a href="#32" id=32>We then replaced 10 of the 260 verbs ( 4 % ) to enable us to have representative seed verbs for certain classes in our semi-supervised experiments ( e.g. , so that we could include wipe as a seed verb for the Wipe verbs , and fill for the Fill verbs ) . </a>
<a name="33">[33]</a> <a href="#33" id=33>However , a general feature space means that most features will be irrelevant to any given verb discrimination task . </a>
<a name="34">[34]</a> <a href="#34" id=34>The scores of Schulte im Walde ( 2003 ) range from .09 to .18 , while ours range from .02 to .34 , with a mean of .17 across all tasks . </a>
<a name="35">[35]</a> <a href="#35" id=35>Rather than trying to separate a set of new verbs into coherent clusters , we suggest that it may be useful to perform a nearest-neighbour type of classification using a seed set , asking for each new verb âis it like these or not ? â In some ways our current clustering task is too easy , because all of the verbs are from one of the target classes . </a>
<a name="36">[36]</a> <a href="#36" id=36>In an unsupervised ( clustering ) scenario of verb class discovery , can we maintain the benefit of only needing noisy features , without the generality of the feature space leading to âthe curse of dimensionality </a>
<a name="37">[37]</a> <a href="#37" id=37>In the remainder of the paper , we first briefly review our feature space and present our experimental classes and verbs . </a>
<a name="38">[38]</a> <a href="#38" id=38>However , it gives important information about the quality of a clustering : The other measures being equal , a clustering with a higher value indicates tighter and more separated clusters , suggesting stronger inherent patterns in the data . </a>
<a name="39">[39]</a> <a href="#39" id=39>4.2.2 Adjusted Rand Measure Accuracy can be relatively high for a clustering when a few clusters are very good , and others are not good . </a>
<a name="40">[40]</a> <a href="#40" id=40>Since it is a general corpora , we do not expect any strong overall domains bias in Verb usage . </a></body>
</html>
