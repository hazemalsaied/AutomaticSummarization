<html>
<head><title>N01-1011_Gsummary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Decision trees have been used in supervised learning approaches to word sense disambiguation , and have fared well in a number of comparative studies ( e.g. , ( Mooney , 1996 ) , ( Pedersen and Bruce , 1997 ) ) . </a>
<a name="1">[1]</a> <a href="#1" id=1>We have presented an ensemble approach to word sense disambiguation ( Pedersen , 2000 ) where multiple Naive Bayesian class ers , each based on co { occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line . </a>
<a name="2">[2]</a> <a href="#2" id=2>In light of this , ( Pedersen , 1996 ) presents Fisher 's exact test as an alternative since it does not rely on the distributional assumptions that underly both Pearson 's test and the likelihood ratio . </a>
<a name="3">[3]</a> <a href="#3" id=3>A preliminary version of this paper appears in ( Pedersen , 2001 ) . </a>
<a name="4">[4]</a> <a href="#4" id=4>There is no search of the feature space performed to build a representative model as is the case with decision trees . </a>
<a name="5">[5]</a> <a href="#5" id=5>Learning continues until all the training examples are accounted for by the decision tree . </a>
<a name="6">[6]</a> <a href="#6" id=6>Column 10 shows the accuracy of the decision tree when the Dice Coe√Ücient selects the features . </a>
<a name="7">[7]</a> <a href="#7" id=7>Column 8 shows the accuracy of the decision tree using the J48 learning algorithm and the features identify ed by a power divergence statistic . </a>
<a name="8">[8]</a> <a href="#8" id=8>The most dramatic difference occurred with amaze-v , where the SENSE- VAL average was 92.4 % and the decision tree accuracy was 58.6 % . </a>
<a name="9">[9]</a> <a href="#9" id=9>The last line of Table 1 shows the win-tie-loss score of the decision thermopower divergence method relative to every other method . </a>
<a name="10">[10]</a> <a href="#10" id=10>Given the sparse and skewed nature of this data , the statistical methods used to select interesting bi grams must be carefully chosen . </a>
<a name="11">[11]</a> <a href="#11" id=11>We employ a ? ne grained scoring method , where a word is counted as correctly disambiguated only when the assigned sense tag exactly matches the true sense tag . </a>
<a name="12">[12]</a> <a href="#12" id=12>Each sense { tagged occurrence of an ambiguous word is converted into a feature vector , where each feature represents some property of the surrounding text that is considered to be relevant to the disambiguation process . </a>
<a name="13">[13]</a> <a href="#13" id=13>One of our long-term objectives is to identify a core set of features that will be useful for disambiguating a wide class of words using both supervised and unsupervised methodologies . </a>
<a name="14">[14]</a> <a href="#14" id=14>These typically include the part { of { speech of surrounding words , the presence of certain key words within some window of context , and various syntactic properties of the sentence and the ambiguous word . </a>
<a name="15">[15]</a> <a href="#15" id=15>It is not clear how much disambiguation accuracy is improved through the use of features that are identify ed by more complex pre { processing such as part { of { speech tagging , parsing , or anaphora resolution . </a>
<a name="16">[16]</a> <a href="#16" id=16>Then the decision tree learning algorithm is described , as are some benchmark learning algorithms that are included for purposes of comparison . </a>
<a name="17">[17]</a> <a href="#17" id=17>The following process is repeated for each task . </a>
<a name="18">[18]</a> <a href="#18" id=18>The number of test and training instances for each task are shown in columns 2 and 4 . </a>
<a name="19">[19]</a> <a href="#19" id=19>The evaluation at SENSEVAL was based on precision and recall , so we converted those scores to accuracy by taking their product . </a></body>
</html>
