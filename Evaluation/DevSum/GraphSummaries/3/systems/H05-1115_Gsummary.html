<html>
<head><title>H05-1115_Gsummary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>3.4 Experiments with topic-sensitive LexRank . </a>
<a name="1">[1]</a> <a href="#1" id=1>In ( Erkan and Radev , 2004 ) , we introduce method and successfully applied it generic multi-document summarization . </a>
<a name="2">[2]</a> <a href="#2" id=2>Finally , our best sentence retrieval system was applied to our test data set evaluate against the baseline . </a>
<a name="3">[3]</a> <a href="#3" id=3>3.1 The LexRank method . </a>
<a name="4">[4]</a> <a href="#4" id=4>In the new approach , the 916 score of a sentence is determined by a mixture model of the relevance of the sentence to the query and the similarity of the sentence to other high-scoring sentences . </a>
<a name="5">[5]</a> <a href="#5" id=5>With probability ( 1-d ) , a transition is made to the nodes that are lexically similar to the current node . </a>
<a name="6">[6]</a> <a href="#6" id=6>This is similar to snippet ( Wu eta 2004 ) . </a>
<a name="7">[7]</a> <a href="#7" id=7>Graph Figure 2 : LexRank example : sentence similarity graph with a cosine threshold of 0.15 . </a>
<a name="8">[8]</a> <a href="#8" id=8>To apply LexRank , a similarity graph is produce the sentences in an input document set . </a>
<a name="9">[9]</a> <a href="#9" id=9>Below , we describe a topic-sensitive version of LexRank , which is more appropriate for the question-focusedsentence retrieval problem . </a>
<a name="10">[10]</a> <a href="#10" id=10>As discussed in Section 2 , our goal wast develop a topic-sensitive version of LexRank and to use it to improve a baseline system , which previously been used successfully for query-basedsentence retrieval ( Allan et al. , 2003 ) . </a>
<a name="11">[11]</a> <a href="#11" id=11>Our goal is to build a question-focused sentence retrieval mechanism using a topic-sensitive version of the method . </a>
<a name="12">[12]</a> <a href="#12" id=12>As previously mentioned , the original LexRank method performed welling the context of generic summarization . </a>
<a name="13">[13]</a> <a href="#13" id=13>The stationary distribution of a Markov chain can be computed by a simple iterative algorithm , called power method. 1 A simpler version of Equation 5 , where A is uniform matrix andB is a normalized binary matrix , is known as PageRank ( Brin and Page , 1998 ; Pageet al. , 1998 ) and used to rank the web pages by theGoogle search engine . </a>
<a name="14">[14]</a> <a href="#14" id=14>In the training phase the experiment , we evaluated all combination with d in the range of [ 0 , 1 ] ( in increments of 0.10 ) and with a similarity threshold ranging from [ 0 , 0.9 ] ( in increments of 0.05 ) . </a></body>
</html>
