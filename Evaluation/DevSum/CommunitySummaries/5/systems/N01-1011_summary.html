<html>
<head><title>N01-1011_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The characteristics of the decision trees and decision stumps learned for each word are shown in Table 2 . </a>
<a name="1">[1]</a> <a href="#1" id=1>Learning continues until all the training examples are accounted for by the decision tree . </a>
<a name="2">[2]</a> <a href="#2" id=2>One of our original hypotheses was that accurate decision trees of bi grams will include a relatively small number of features . </a>
<a name="3">[3]</a> <a href="#3" id=3>A Decision Tree of Bigrams is an Accurate Predictor of Word Sense</a>
<a name="4">[4]</a> <a href="#4" id=4>Word sense disambiguation is the process of selecting the most appropriate meaning for a word , based on the context in which it occurs . </a>
<a name="5">[5]</a> <a href="#5" id=5>Bi grams have been used as features for word sense disambiguation , particularly in the form of collocations where the ambiguous word is one component of the digram e.g. , ( Bruce and Wiebe , 1994 ) , ( Ng and Lee , 1996 ) , ( Yarowsky , 1995 ) ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>These typically include the part { of { speech of surrounding words , the presence of certain key words within some window of context , and various syntactic properties of the sentence and the ambiguous word . </a>
<a name="7">[7]</a> <a href="#7" id=7>Finally , note that the smallest decision trees are functionally equivalent to our benchmark methods . </a>
<a name="8">[8]</a> <a href="#8" id=8>This paper presents a corpus-based approach to word sense disambiguation where a decision tree assigns a sense to an ambiguous word based on the bigrams that occur nearby.</a>
<a name="9">[9]</a> <a href="#9" id=9>For our purposes it is assumed that the set of possible meaning , i.e . , the Sense inventory , has already been determined . </a></body>
</html>
