<html>
<head><title>N01-1011_model</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>This paper presents a corpus-based approach to word sense disambiguation where a decision tree assigns a sense to an ambiguous word based on the bi grams that occur nearby . </a>
<a name="1">[1]</a> <a href="#1" id=1>The approach in this paper relies upon a feature set made up of bigrams , two word sequences that occur in a text . </a>
<a name="2">[2]</a> <a href="#2" id=2>The context in which an ambiguous word occurs is represented by some number of binary features that indicate whether or not a particular digram has occurred within approximately 50 words to the left or right of the word being disambiguated . </a>
<a name="3">[3]</a> <a href="#3" id=3>Given the sparse and skewed nature of this data , the statistical methods used to select interesting bi grams must be carefully chosen . </a>
<a name="4">[4]</a> <a href="#4" id=4>A number of well known statistics belong to this family , including the likelihood ratio statisticG 2 and Pearson'sX 2 statistic . </a>
<a name="5">[5]</a> <a href="#5" id=5>However , ( Cressie and Read , 1984 ) suggest that there are cases where Pearson 's statistic is more reliable than the likelihood ratio and that one test should not always be preferred over the other . </a>
<a name="6">[6]</a> <a href="#6" id=6>Unfortunately it is usually not clear which test is most appropriate for a particular sample of data . </a>
<a name="7">[7]</a> <a href="#7" id=7>We have developed the Bigram Statistics Package to produce ranked lists of bi grams using a range of tests . </a>
<a name="8">[8]</a> <a href="#8" id=8>Our empirical study utilizes the training and test data from the 1998 SENSEVAL evaluation of word sense disambiguation systems . </a>
<a name="9">[9]</a> <a href="#9" id=9>Two feature sets are selected from the training data based on the top 100 ranked bi grams according to the power divergence statistic and the Dice CoeÃcient . </a>
<a name="10">[10]</a> <a href="#10" id=10>While the accuracy of this approach was as good as any previously published results , the learned models were complex and diÃcult to interpret , in e ? ect acting as very accurate black boxes . </a>
<a name="11">[11]</a> <a href="#11" id=11>This paper shows that the combination of a simple feature set made up of bi grams and a standard decision tree learning algorithm results in accurate word sense disambiguation . </a></body>
</html>
