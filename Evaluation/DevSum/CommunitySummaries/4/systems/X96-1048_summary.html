<html>
<head><title>X96-1048_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The introduction of two new tasks into the MUC evaluations and the restructuring of information extraction into two separate tasks have infused new life into the evaluations . </a>
<a name="1">[1]</a> <a href="#1" id=1>The other two tasks , Template Element and Scenario Template , were information extraction tasks that followed on from the MUC evaluations conducted in previous years . </a>
<a name="2">[2]</a> <a href="#2" id=2>Many of the sites have emphasized their pattern-matching techniques in discussing the strengths of their MUC6 systems . </a>
<a name="3">[3]</a> <a href="#3" id=3>Even the simplest of the tasks , Named Entity , occasionally requires in-depth processing , e.g. , to determine whether `` 60 pounds '' is an expression of weight or of monetary value . </a>
<a name="4">[4]</a> <a href="#4" id=4>In short , the preliminary nature of the task design is reflected in the somewhat unmotivated boundaries between markable and remarkable and in weaknesses in the notation . </a>
<a name="5">[5]</a> <a href="#5" id=5>All the participating sites also submitted systems for evaluation on the TE and NE tasks . </a>
<a name="6">[6]</a> <a href="#6" id=6>This period comprised the `` evaluation epoch . '' </a>
<a name="7">[7]</a> <a href="#7" id=7>The text filtering results for MUC6 , MUC4 ( TST4 ) and MUC3 ( TST2 ) are shown in figure 8 . </a>
<a name="8">[8]</a> <a href="#8" id=8>MUC6 56.40 MUC5 EJV 52.75 MUC5 JJV 60.07 MUC5 EME 49.18 MUC5 JME 56.31 Table 4 . </a>
<a name="9">[9]</a> <a href="#9" id=9>Finally , a change in administration of the MUC evaluations is occurring that will bring fresh ideas . </a>
<a name="10">[10]</a> <a href="#10" id=10>Documentation of each of the tasks and summary scores for all systems evaluated can be found in the MUC6 proceedings [ 1 ] . </a>
<a name="11">[11]</a> <a href="#11" id=11>As indicated in table 2 , all systems performed better on identifying person names than on identifying organization or location names , and all but a few systems performed better on location names than on organization names . </a>
<a name="12">[12]</a> <a href="#12" id=12>The NE evaluation results serve mainly to document in the MUC context what was already strongly suspected : 1 . </a>
<a name="13">[13]</a> <a href="#13" id=13>This capability has other useful applications as well , e.g. , it enables text highlighting in a browser . </a>
<a name="14">[14]</a> <a href="#14" id=14>CORPUS Testing was conducted using Wall Street Journal texts provided by the Linguistic Data Consortium . </a>
<a name="15">[15]</a> <a href="#15" id=15>Much less information about the event would be captured , but there would be a much stronger focus on the most essential information elements . </a>
<a name="16">[16]</a> <a href="#16" id=16>Statistically , large differences of up to 15 points may not be reflected as a difference in the ranking of the systems . </a>
<a name="17">[17]</a> <a href="#17" id=17>Systems scored approximately 1525 points lower ( F-measure ) on ST than on TE . </a>
<a name="18">[18]</a> <a href="#18" id=18>Frequently , at least one can be found in close proximity to an organization 's name , e.g. , as an appositive ( `` Creative Artists Agency , the big Hollywood talent agency '' ) . </a>
<a name="19">[19]</a> <a href="#19" id=19>OVERVIEW OF RESULTS OF THE MUC-6 EVALUATION </a></body>
</html>
