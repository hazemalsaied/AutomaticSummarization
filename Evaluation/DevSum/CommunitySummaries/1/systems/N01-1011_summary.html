<html>
<head><title>N01-1011_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>They perform a general to spec c search of a feature space , adding the most informative features to a tree structure as the search proceeds . </a>
<a name="1">[1]</a> <a href="#1" id=1>The objective is to select a minimal set of features that e√Üciently partitions the feature space into classes of observations and assemble them into a tree . </a>
<a name="2">[2]</a> <a href="#2" id=2>A decision stump is a one node decision tree ( Holte , 1993 ) that is created by stopping the decision tree learner after the single most informative feature is added to the tree . </a>
<a name="3">[3]</a> <a href="#3" id=3>A Decision Tree of Bigrams is an Accurate Predictor of Word Sense</a>
<a name="4">[4]</a> <a href="#4" id=4>This paper presents a corpus-based approach to word sense disambiguation where a decision tree assigns a sense to an ambiguous word based on the bigrams that occur nearby.</a>
<a name="5">[5]</a> <a href="#5" id=5>This approach is evaluated using the sense-tagged corpora from the 1998 SENSEVAL word sense disambiguation exercise . </a>
<a name="6">[6]</a> <a href="#6" id=6>In general the total context available for each ambiguous word is less than 100 surrounding words . </a>
<a name="7">[7]</a> <a href="#7" id=7>Word sense disambiguation is the process of selecting the most appropriate meaning for a word , based on the context in which it occurs . </a>
<a name="8">[8]</a> <a href="#8" id=8>We included all 36 tasks from SENSEVAL for which training and test data were provided . </a>
<a name="9">[9]</a> <a href="#9" id=9>For our purposes it is assumed that the set of possible meaning , i.e . , the Sense inventory , has already been determined . </a></body>
</html>
