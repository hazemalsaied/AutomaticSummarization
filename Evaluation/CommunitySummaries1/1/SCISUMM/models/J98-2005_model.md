Estimation of Probabilistic Context-Free Grammars 
The assignment of probabilities to the productions of a context-free grammar may generate an improper distribution : the probability of all finite parse trees is less than one . 
We show here that estimated production probabilities always yield proper distributions . 
If the corpus is unparsed then there is an iterative approach to maximum-likelihood estimation ( the EM or Baum-Welsh algorithm -- again , see Section 2 ) and the same question arises : do we get actual probabilities or do the estimated PCFG 's assign some mass to infinite trees ? 
We will show that in both cases the estimated probability is tight . 
( 8~fl ) ea ~ ( B -- ~/3 ) = ~=lf ( B -- ~/3 ; cai ) ( 3 ) c~ s.t . H < B-~ ) e~ ~i=lf ( B -- -+o4cai ) The maximum-likelihood estimator is the natural , `` relative frequency , '' estimator . 
Letting ~y denote { w Efk Y ( w ) = Y } , the likelihood of the corpus becomes n H E H P ( A -- '~oL ) f ( A~ ; ~ ) '' i=1 ~OE~y ( ~i ) ( A -- -~o~ ) ER And the maximum-likelihood equation becomes + p ( B fl ) Ei=l EwEfly ( wi , I-I ( A -- . ) cR p ( A -~ a ) f ( A-~ '' ; ~ ) = 0 fT ( B ~ /3 ) = ~iL1 Ep~f ( B ~ fl ; w ) lw E ~y ( ~ , ) ] ( 4 ) , ~s , , , ~Ei=IEpV ( `` a ; w ) lw E ~Y ( o~ , ) ] E ( B_~ , E B ~ where E~ is expectation under fi and where `` ] w E~-~y ( wi ) '' means `` conditioned on 0.2E ~-~Y ( wi ) ' '' There is no hope for a closed form solution , but ( 4 ) does suggest an iteration scheme , which , as it turns out , `` climbs '' the likelihood surface ( though there are no guarantees about approaching a global maximum ) : Let P0 be an arbitrary assignment respecting ( 1 ) . 
Dempster , Laird , and Rubin [ 1977 ] put the idea into a much more general setting and coined the Chi and Geman Probabilistic Context-Free Grammars term EM for Expectation-Maximization . 
