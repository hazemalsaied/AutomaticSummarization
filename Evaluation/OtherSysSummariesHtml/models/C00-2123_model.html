<html>
<head><title>C00-2123_model</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</a>
<a name="1">[1]</a> <a href="#1" id=1>We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability</a>
<a name="2">[2]</a> <a href="#2" id=2>(1), Pr(eI 1) is the language model, which is a trigram language model in this case.</a>
<a name="3">[3]</a> <a href="#3" id=3>For the translation model Pr(fJ 1 jeI 1), we go on the assumption that each source word is aligned to exactly one target word.</S</a>
<a name="4">[4]</a> <a href="#4" id=4>What is important and is not expressed by the notation is the so-called coverage constraint: each source position j should be &apos;hit&apos; exactly once by the path of the inverted alignment bI 1 = b1:::bi:::bI . Using the inverted alignments in the maximum approximation</a>
<a name="5">[5]</a> <a href="#5" id=5>In order to handle the necessary word reordering as an optimization problem within our dynamic programming approach, we describe a solution to the traveling salesman problem (TSP) which is based on dynamic programming (Held, Karp, 1962).</a>
<a name="6">[6]</a> <a href="#6" id=6>The algorithm works due to the fact that not all permutations of cities have to be considered explicitly.4710</a>
<a name="7">[7]</a> <a href="#7" id=7>The type of alignment we have considered so far requires the same length for source and target sentence, i.e. I = J. Evidently, this is an unrealistic assumption, therefore we extend the concept of inverted alignments as follows: When adding a new position to the coverage set C, we might generate either Æ = 0 or Æ = 1 new target words.</a>
<a name="8">[8]</a> <a href="#8" id=8>When translating the sentence monotonically from left to right, the translation of the German finite verb &apos;kann&apos;, which is the left verbal brace in this case, is postponed until the German noun phrase &apos;mein Kollege&apos; is translated, which is the subject of the sentence.</a>
<a name="9">[9]</a> <a href="#9" id=9>This approach leads to a search procedure with complexity O(E3 J4).</a>
<a name="10">[10]</a> <a href="#10" id=10>A dynamic programming recursion similar to the one in Eq. 2 is evaluated.16525</a>
<a name="11">[11]</a> <a href="#11" id=11>This approach leads to a search procedure with complexity O(E3 J4).</a>
<a name="12">[12]</a> <a href="#12" id=12>This measure has the advantage of being completely automatic.</a>
<a name="13">[13]</a> <a href="#13" id=13>We apply a beam search concept as in speech recognition.</a>
<a name="14">[14]</a> <a href="#14" id=14>For each source word f, the list of its possible translations e is sorted according to p(fje) puni(e), where puni(e) is the unigram probability of the English word e. It is suÆcient to consider only the best 50 words.</a>
<a name="15">[15]</a> <a href="#15" id=15>For our demonstration system, we typically use the pruning threshold t0 = 5:0 to speed up the search by a factor 5 while allowing for a small degradation in translation accuracy.</a></body>
</html>
