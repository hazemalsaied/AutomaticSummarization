<html>
<head><title>C00-2123_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</a>
<a name="1">[1]</a> <a href="#1" id=1>Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃcient search algorithm.</a>
<a name="2">[2]</a> <a href="#2" id=2>Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃcient search algorithm.</a>
<a name="3">[3]</a> <a href="#3" id=3>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="4">[4]</a> <a href="#4" id=4>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="5">[5]</a> <a href="#5" id=5>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="6">[6]</a> <a href="#6" id=6>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="7">[7]</a> <a href="#7" id=7>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="8">[8]</a> <a href="#8" id=8>The alignment mapping is j ! i = aj from source position j to target position i = aj . The use of this alignment model raises major problems if a source word has to be aligned to several target words, e.g. when translating German compound nouns.</a>
<a name="9">[9]</a> <a href="#9" id=9>The alignment model uses two kinds of parameters alignment probabilities p(aj jajô1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajô1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</a>
<a name="10">[10]</a> <a href="#10" id=10>The alignment model uses two kinds of parameters alignment probabilities p(aj jajô1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajô1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</a>
<a name="11">[11]</a> <a href="#11" id=11>The alignment model uses two kinds of parameters alignment probabilities p(aj jajô1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajô1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</a>
<a name="12">[12]</a> <a href="#12" id=12>The alignment model uses two kinds of parameters alignment probabilities p(aj jajô1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajô1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</a>
<a name="13">[13]</a> <a href="#13" id=13>To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</a>
<a name="14">[14]</a> <a href="#14" id=14>To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</a>
<a name="15">[15]</a> <a href="#15" id=15>The details are given in (Och and Ney, 2000).</a>
<a name="16">[16]</a> <a href="#16" id=16>The resulting algorithm has a complexity of O(n!).</a>
<a name="17">[17]</a> <a href="#17" id=17>The details are given in (Tillmann, 2000).</a>
<a name="18">[18]</a> <a href="#18" id=18>The complexity of the quasimonotone search is O(E3 J (R2+LR)).</a>
<a name="19">[19]</a> <a href="#19" id=19>Restrictions We compare our new approach with the word reordering used in the IBM translation approach (Berger et al., 1996).</a>
<a name="20">[20]</a> <a href="#20" id=20>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a>
<a name="21">[21]</a> <a href="#21" id=21>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a>
<a name="22">[22]</a> <a href="#22" id=22>Depending on the threshold t0, the search algorithm may miss the globally optimal path which typically results in additional translation errors.</a>
<a name="23">[23]</a> <a href="#23" id=23>In this paper, we have presented a new, eÃcient DP-based search procedure for statistical machine translation.</a></body>
</html>
