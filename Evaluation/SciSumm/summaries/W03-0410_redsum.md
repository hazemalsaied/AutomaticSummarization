We gratefully acknowledge the financial support of NSERC of Canada and Bell University Labs . 
The results for these feature sets in clustering are given in the second sub column Ling ) under each of the , , and measures in Table 2 . 
We use this baseline in calculating reductions in error rate of . The remaining columns of the table give the , , and measures as described in Section 4.2 , for each of the feature sets we explored in clustering , which we discuss in turn below . 
We chose hierarchical clustering because it may be possible to find coherent clusters of verbs even when there are not exactly good clusters , where is the number of classes . 
7 5 0 Table 1 : Verb classes ( see Section 3.1 ) , their Levin class numbers , and the number of experimental verbs in each ( see Section 3.2 ) . 
In performing hierarchical clustering , both a vector distance measure and a cluster distance ( linkage measure are specified . 
Another striking result is the difference in values , which are very much higher than those for Ling ( which are in turn much higher than for Full ) . 
In our clustering experiments , we find that smaller subsets of features generally perform better than the full set of features . 
This capture what is reflected ins the deprogram 