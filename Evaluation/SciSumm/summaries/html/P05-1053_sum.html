<html>
<head><title>P05-1053_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The words between the two mentions are classified into three bins : the first word in between , the last word in between and other words in between . </a>
<a name="1">[1]</a> <a href="#1" id=1>Similar to word features , three categories of phrase heads are considered : 1 ) the phrase heads in between are also classified into three bins : the first phrase head in between , the last phrase head in between and other phrase heads in between ; 2 ) the phrase heads before M1 are classified into two bins : the first phrase head before and the second phrase head before ; 3 ) the phrase heads after M2 are classified into two bins : the first phrase head after and the second phrase head after . </a>
<a name="2">[2]</a> <a href="#2" id=2>This paper uses the ACE corpus provided by LDC to train and evaluate our feature-based relation extraction system . </a>
<a name="3">[3]</a> <a href="#3" id=3>The final decision of an instance in the multiple binary classification is determined by the class which has the maximal SVM output . </a>
<a name="4">[4]</a> <a href="#4" id=4>The training set consists of 674 annotated text documents ( ~300k words ) and 9683 instances of relations . </a>
<a name="5">[5]</a> <a href="#5" id=5>Support Vector Machines ( SVMs ) are a supervised machine learning technique motivated by the statistical learning theory ( Vapnik 1998 ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>It also shows that our system outperforms tree kernel-based systems ( Culotta et al 2004 ) by over 20 F-measure on extracting 5 ACE relation types . </a>
<a name="7">[7]</a> <a href="#7" id=7>['It', 'shows', 'that', '73', '%', '(']</a></body>
</html>
