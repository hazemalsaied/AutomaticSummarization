In the simple example here , the estimator converges in one step and is the same ~ as if we had observed the entire parse tree for each wi . 
Finally , let ~ be the maximum-likelihood estimator of p , as defined by ( 3 ) . 
( A~c~ ) ER Chi and Geman Probabilistic Context-Free Grammars Given a set of finite parse trees cab ca2 , ... , can , drawn independently according to the distribution imposed by p , we wish to estimate p. In terms of the frequency function f , introduced in Section 1 , the likelihood of the data is L = L ( p ; cal , ca2 ... .. con ) n = II II p ( AY i=1 ( A~ ) ER Recall the derivation of the maximum-likelihood estimator of p : The log of the likelihood is : n ~ ~f ( A -- + a ; cai ) log A ~ a ) . 
Denote the maximum-likelihood estimator by fi : n B AB q- ~i=lf -- + /3 ; ca ; ) = 0 V ( S ~ /3 ) E R f , ( B +/3 ) Since ~ fi ( B+/3 ) =l ) fl sA . 
2 * Division of Applied Mathematics , Brown University , Providence , RI 02912 USA 1 Note added in proof : An alternative proof of one of our main results ( see Corollary , Section 3 ) recently appeared in the IEEE Transactions on Pattern Analysis and Machine Intelligence ( S , Sanchez and Bened ( [ 1997 ] ) . 
Hence qs = 0 , completing the proof of the theorem . 
( 8~fl ea ~ ( B -- ~/3 ) = ~=lf B -- ~/3 ; cai ) ( 3 ) c~ s.t . H < B-~ ) e~ ~i=lf B -- -+o4cai ) The maximum-likelihood estimator is the natural , `` relative frequency , '' estimator . 
Given a set of finite parse trees wl , w2 ... .. w , , the maximum-likelihood estimator for p ( see Section 2 ) is , sensibly enough , the `` relative frequency '' estimator y'~nlf A ~ AA ; wi ) ~i=1 f ( A ~ AA ; wi ) + f ( A ~ a ; wi ) ] where f ( . ; w ) is the number of occurrences of the production `` . '' in the tree w. The sentence a m , although ambiguous ( there are multiple parses when m > 2 ) , always involves m - 1 of the A ~ AA productions and m of the A ~ a productions . 
Furthermore , CFG 's are readily fit with a probability distribution ( to make probabilistic CFG 's -- or PCFG 's ) , rendering them suitable for ambiguous languages through the maximum a posteriori rule of choosing the most probable parse . 
Context-free grammars ( CFG 's ) are useful because of their relatively broad coverage and because of the availability of efficient parsing algorithms . 
More generally , let G -- ( V , T , R , S ) denote a context-free grammar with finite variable set V , start symbol S E V , finite terminal set T , and finite production ( or rule ) set R . 
If , however , the language of the grammar does not include the null string , then there is an equivalent grammar ( one with the same language ) that has no null productions and no unit productions ( cf . 
This iteration procedure is an instance of the EM Algorithm . 
Dumpster Laird , and Rubin [ 1977 ] put the idea into a much more general setting and coined the Chi and Geman Probabilistic Context-Free Grammars term EM for Expectation-Maximization . 
What if the production probabilities are estimated from data ? 
For example , there is a simple maximum-likelihood prescription for estimating the production probabilities from a corpus of trees ( see Section 2 ) , resulting in a PCFG . 
It is reasonable to hope that if the trees in the sample are finite , then an estimate of production probabilities based upon the sample will produce a system that assigns probability zero to the set of infinite trees . 
Each production in R has the form A ~ oL , where A E V and o~ E ( VUT ) * . 
Proof Almost identical , except that we use ( 5 ) in place of ( 3 ) and end up with : n E qA EEG_1 [ F ( A ; wi ) -F ( A ; wi ) lw C fly ( w , ) ] ~ 0 . 
It is not hard to show that Sh is nondecreasing and converges to min ( 1 , I ) , meaning that a proper probability is obtained if and only if p < ~ . 
( Wetherell and others use the designation `` consistent '' instead of `` tight , '' but in statistics , consistency refers to the asymptotic correctness of an estimator . ) 
Suppose B E V is unobserved among the parse trees cabc 0 2 -.. , can . 
We will show that if f~ is the set of all ( finite ) parse tree generated by G , and if f~ ( ca ) is the probability of ca ff fl under the maximum-likelihood productions probability , then fi ( f~ ) = 1 . 