We used the simple graph model based on co-occurrences of nouns in lists ( cf . 
Based on the intuition that nouns which co-occur in a list are often semantically related , we extract contexts of the form Noun , Noun , ... Andros Noun , e.g . `` gnomic DNA from rat , mouse and dog '' . 
In our simple model based on noun co-occurrences in lists , step 5 corresponds to rebuilding the graph under the restriction that the nodes in the new graph not co-occur ( or at least not very often ) with any of the cluster members already extracted . 
In contrast to pure Markov clustering , we do n't try to find a complete clustering of G into senses at once . 
To detect the different areas of meaning in our local graphs , we use a cluster algorithm for graphs ( Markov clustering , MCL ) developed by van Dongen ( 2000 ) . 
We then determined the WordNet sunsets which most adequately characterized the sense clusters . 
Word Sense clusters Class-label arms knees trousers feet biceps hips elbows backs wings body part breasts shoulders thighs bones buttocks ankles legs inches wrists shoes necks horses muskets charges weapons methods firearms weapon knives explosives bombs bases mines projectiles drugs missiles uniforms jersey Israel guernsey Luxembourg maim European Greece swede , turkey Gibraltar ire- country land Mauritius Cyprus Norway Oralia japan Canada kingdom pain Zealand england franc Switzerland Poland a America Iceland Scotland crucifix bow apron sweater tie anorak hose bracelet garment helmet waistcoat jacket pullover equipment cap collar suit fleece tunic shirt scarf belt head voice torso back chest face abdomen side belly groin body part spine breast bill rump midair hat collar waist tail stomach skin throat neck specular treasurer justice chancellor principal founder pres- person dent commander deputy administrator constable li librarian secretary governor captain premier executive chief curator assistant committee patron ruler oil heat coal power water gas food wood fuel steam tax object heating kerosene fire petroleum dust sand light steel telephone timber supply drainage diesel electricity acid air insurance petrol tempera Goucher poster pastel collage paint acrylic lemon bread cheese [ flint butter jam cream pudding yogurt foodstuff sprinkling honey jelly toast ham chocolate pie syrup milk meat beef cake yogurt grain hazel elder holly family virgin hawthorn shrub cherry cedar larch mahogany water sycamore lime teak ash wood hornbeam oak walnut hazel pine beech alder thorn poplar birch chestnut blackthorn spruce holly yew lau rel maple elm fir hawthorn willow bacon cream honey pie grape blackcurrant cake ha- foodstuff mama Table 1 : Output of word sense clustering . 
On the other hand , if the local graph is too big , we will get a lot of noise . 
We then recompute the local graph Gw by discriminating against c 's features . 
If the local graph handed over to the MCL process is small , we might miss some of w 's meanings in the corpus . 
The family of such algorithms is described in ( Widdows , 2003 ) . 
Instead we link each word to its top n neighbors where n can be determined by the user ( cf . 
An appropriate choice of the inflation para 80 meter r can depend on the ambiguous word w to be clustered . 
Usually , one sense of an ambiguous word w is much more frequent than its other senses present in the corpus . 
The same corpus evidence which supports a clustering of an ambiguous word into distinct senses can be used to decide which sense is referred to in a given context ( Schiitze , 1998 ) . 
However , there are ambiguous words with more closely related senses which are metaphorical or metonymy variations of one another . 
Therefore , even after removal of the wing-node , the two areas of meaning are still linked via tail . 
sz44 CD miltrA , literate h , ) Cik Figure 1 : Local graph of the word mouse 
Output the list of class-labels which best represent the different senses of w in the corpus . 
Let G , denote the local graph around the ambiguous word w. The adjacency matrix MG 4111 ) 11 41 4Wit ler,1110.1/.17 cgtoserek¦Ilt Figure 2 : Local graph of the word wing of a graph G , is defined by setting ( 111G ) pq equal to the weight of the edge between nodes v and v q . Normalizing the columns of A/G results in the Markov Matrix Taw whose entries ( Thi , ) pq can be interpreted as transition probability from v q to vv . It can easily be shown that the k-th power of TG lists the probabilities ( TL ) pq of a path of length k starting at node vq and ending at node V. The MCL-algorithm simulates flow in Gw by iteratively recomputing the set of transition probabilities via two steps , expansion and inflation . 
They often contain many rare senses , but not the same ones that are relevant for specific domains or corpora . 
This is achieved , in a manner similar to Pantel and Lin 's ( 2002 ) sense clustering approach , by removing c 's features from the set of features used for finding similar words . 
1 Si ample cutoff functions proved unsatisfactory because of the bias they give to more frequent words . 
Discovering Corpus-Specific Word Senses
In section 2 , we present the graph model from which we discover word senses . 
Section 3 describes the way we divide graphs surrounding ambiguous words into different areas corresponding to different senses , using Markov clustering ( van Dongen , 2000 ) . 
Ambiguous words link otherwise unrelated areas of meaning E.g . rat and printer are very different in meaning , but they are both closely related to different meanings of mouse . 
Following Lin 's work ( 1998 ) , we are currently investigating a graph with verb-object , verb-subject and modifier-noun-collocations from which it is possible to infer more about the senses of systematically polygamous Word . 