<html>
<head><title>J00-3003_Gsummary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Given all available evidence E about a conversation , the goal is to find the DA sequence U that has the highest posterior probability P ( UIE ) given that evidence . </a>
<a name="1">[1]</a> <a href="#1" id=1>Further research within this framework can be characterized by which of these simplifications are addressed . </a>
<a name="2">[2]</a> <a href="#2" id=2>The latter can then be leveraged for more accurate speech recognition . </a>
<a name="3">[3]</a> <a href="#3" id=3>We also touch briefly on alternative machine learning models for prosodic features . </a>
<a name="4">[4]</a> <a href="#4" id=4>The more frequent DA types are briefly characterized below . </a>
<a name="5">[5]</a> <a href="#5" id=5>Questions were of several types . </a>
<a name="6">[6]</a> <a href="#6" id=6>1 % What did you wear to work today ? </a>
<a name="7">[7]</a> <a href="#7" id=7>The language model weight , ~ compensates for acoustic score variances that are effectively too large due to severe independence assumptions in the recognizer acoustic model . </a>
<a name="8">[8]</a> <a href="#8" id=8>Table 9 Combined utterance classification accuracies ( chance = 35 % ) . </a>
<a name="9">[9]</a> <a href="#9" id=9>The benefit of DA Modeling might therefore be more pronounced on corpus with more even DA distributions , as is typically the cases for task-oriented dialogged . </a></body>
</html>
