<html>
<head><title>P05-1004.system.</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>This application of semantic similarity demonstrates that an unsupervised methods can outperform supervised methods for some NLP tasks if enough data is available. </a>
<a name="1">[1]</a> <a href="#1" id=1>Our application of semantic similarity to supersense tagging follows earlier work by Hearst and SchuÂ¨ tze. </a>
<a name="2">[2]</a> <a href="#2" id=2>We also demonstrate the use of an extremely large shallow-parsed corpus for calculating vector-space semantic similarity. </a>
<a name="3">[3]</a> <a href="#3" id=3>One solution would be to take the intersection between vectors across words for each supersense. </a>
<a name="4">[4]</a> <a href="#4" id=4>Each synonym votes for each of its supersenses from WORDNET 1.6 using the similarity score from our synonym extractor. </a>
<a name="5">[5]</a> <a href="#5" id=5>An alternative approach worth exploring is to create context vectors for the supersense categories themselves and compare these against the words. </a>
<a name="6">[6]</a> <a href="#6" id=6>We would like to move onto the more difficult task of insertion into the hierarchy itself and compare against the initial work by Widdows  using latent semantic analysis. </a>
<a name="7">[7]</a> <a href="#7" id=7>This has the advantage of producing a much smaller number of vectors to compare against. </a>
<a name="8">[8]</a> <a href="#8" id=8>Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson. </a>
<a name="9">[9]</a> <a href="#9" id=9>Ciaramita and Johnson  present a tagger which uses synonym set glosses as annotated training examples. </a>
<a name="10">[10]</a> <a href="#10" id=10>The question now becomes how to construct vectors of supersenses. </a>
<a name="11">[11]</a> <a href="#11" id=11>In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD. </a>
<a name="12">[12]</a> <a href="#12" id=12>Further, our similarity system does not currently incorporate multi-word terms. </a>
<a name="13">[13]</a> <a href="#13" id=13>['The', 'limited', 'coverage', 'of', 'lexical-semantic', 'resources', 'is', 'a', 'significant', 'problem', 'for', 'NLP', 'systems', 'which']</a></body>
</html>
