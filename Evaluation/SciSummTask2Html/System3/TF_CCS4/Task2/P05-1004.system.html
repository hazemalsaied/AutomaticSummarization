<html>
<head><title>P05-1004.system.</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We would like to move onto the more difficult task of insertion into the hierarchy itself and compare against the initial work by Widdows  using latent semantic analysis. </a>
<a name="1">[1]</a> <a href="#1" id=1>This has the advantage of producing a much smaller number of vectors to compare against. </a>
<a name="2">[2]</a> <a href="#2" id=2>The question now becomes how to construct vectors of supersenses. </a>
<a name="3">[3]</a> <a href="#3" id=3>Canonical attributes summarise the key contexts for each headword and are used to improve the efficiency of the similarity comparisons. </a>
<a name="4">[4]</a> <a href="#4" id=4>One solution would be to take the intersection between vectors across words for each supersense. </a>
<a name="5">[5]</a> <a href="#5" id=5>In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD. </a>
<a name="6">[6]</a> <a href="#6" id=6>Further, our similarity system does not currently incorporate multi-word terms. </a>
<a name="7">[7]</a> <a href="#7" id=7>This application of semantic similarity demonstrates that an unsupervised methods can outperform supervised methods for some NLP tasks if enough data is available. </a>
<a name="8">[8]</a> <a href="#8" id=8>We also demonstrate the use of an extremely large shallow-parsed corpus for calculating vector-space semantic similarity. </a>
<a name="9">[9]</a> <a href="#9" id=9>Our preliminary experiments suggest that only combining the vectors for unambiguous words produces the best results. </a>
<a name="10">[10]</a> <a href="#10" id=10>Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson. </a>
<a name="11">[11]</a> <a href="#11" id=11>The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words. </a>
<a name="12">[12]</a> <a href="#12" id=12>['While', 'contextual', 'information', 'is', 'the', 'primary', 'source', 'of', 'information', 'used', 'in', 'WSD', 'research', 'and', 'has', 'been', 'used', 'for', 'acquiring', 'semantic', 'lexicons', 'and', 'classifying', 'unknown', 'words', 'in', 'other', 'languages']</a></body>
</html>
