<html>
<head><title>C00-2123.system.</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The experimental tests are carried out on the Verbmobil task (GermanEnglish, 8000-word vocabulary), which is a limited-domain spoken-language task. However there is no global pruning. In this case, we have no finite-state restrictions for the search space. The resulting algorithm has a complexity of O(n!). For the error counts, a range from 0:0 to 1:0 is used. Here, the pruning threshold t0 = 10:0 is used. The translation direction is from German to English. What is important and is not expressed by the notation is the so-called coverage constraint: each source position j should be 'hit' exactly once by the path of the inverted alignment bI 1 = b1:::bi:::bI . Using the inverted alignments in the maximum approximation, we obtain as search criterion: max I (p(JjI) max eI 1 ( I Yi=1 p(eijeiÃṀÂÂÂ1 iÃṀÂÂÂ2) max bI 1 I Yi=1 [p(bijbiÃṀÂÂÂ1; I; J) p(fbi jei)])) = = max I (p(JjI) max eI 1;bI 1 ( I Yi=1 p(eijeiÃṀÂÂÂ1 iÃṀÂÂÂ2) p(bijbiÃṀÂÂÂ1; I; J) p(fbi jei)])); where the two products over i have been merged into a single product over i. p(eijeiÃṀÂÂÂ1 iÃṀÂÂÂ2) is the trigram language model probability. On the other hand, only very restricted reorderings are necessary, e.g. for the translation direction from Table 2: Coverage set hypothesis extensions for the IBM reordering. The word joining is done on the basis of a likelihood criterion. The approach assumes that the word reordering is restricted to a few positions in the source sentence. Pr(eI 1) is the language model of the target</a></body>
</html>
