<html>
<head><title>C00-2123.system.</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this paper, we describe search procedure for statistical machine translation (MT) based on dynamic programming (DP).</a>
<a name="1">[1]</a> <a href="#1" id=1>The experimental tests are carried out on the Verbmobil task (GermanEnglish, 8000-word vocabulary), which is limited-domain spoken-language task.</a>
<a name="2">[2]</a> <a href="#2" id=2>The goal of machine translation is the translation of text given in some source language into target language.</a>
<a name="3">[3]</a> <a href="#3" id=3>Pr(eI 1) is the language model of the target language, whereas Pr(fJ jeI1) is the transla tion model.</a>
<a name="4">[4]</a> <a href="#4" id=4>These alignment models are similar to the concept of hidden Markov models (HMM) in speech recognition.</a>
<a name="5">[5]</a> <a href="#5" id=5>Word Re-ordering and DP-based Search in Statistical Machine Translation</a>
<a name="6">[6]</a> <a href="#6" id=6>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="7">[7]</a> <a href="#7" id=7>In Section 4, we present the performance measures used and give translation results on the Verbmobil task.</a>
<a name="8">[8]</a> <a href="#8" id=8>In Section 3, we introduce our novel concept to word reordering and DP-based search, which is especially suitable for the translation direction from German to English.</a>
<a name="9">[9]</a> <a href="#9" id=9>Our approach uses word-to-word dependencies between source and target words.</a>
<a name="10">[10]</a> <a href="#10" id=10>For the translation model Pr(fJ jeI 1), we go on the assumption that each source word is aligned to exactly one target word.</a>
<a name="11">[11]</a> <a href="#11" id=11>Starting from DP-based solution to the traveling salesman problem, we present novel technique to restrict the possible word reordering between source and target language in order to achieve an eÆcient search algorithm.</a>
<a name="12">[12]</a> <a href="#12" id=12>For the inverted alignment probability p(bijbi􀀀1; I; J), we drop the dependence on the target sentence length I. 2.2 Word</a></body>
</html>
