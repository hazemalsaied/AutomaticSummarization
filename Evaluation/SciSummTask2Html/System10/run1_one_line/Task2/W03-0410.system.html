<html>
<head><title>W03-0410.system.</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>We cluster verbs into lexical semantic classes, using a general set of noisy features that capture syntactic and semantic properties of the verbs.</a>
<a name="1">[1]</a> <a href="#1" id=1>In moving to a scenario of verb class discovery, using clustering, we face the problem of having a large number of irrelevant features for a particular clustering task.</a>
<a name="2">[2]</a> <a href="#2" id=2>In an unsupervised (clustering) scenario of verb class discovery, can we maintain the benefit of only needing noisy features, without the generality of the feature space leading to “the curse of dimensionality”?</a>
<a name="3">[3]</a> <a href="#3" id=3>We chose hierarchical clustering because it may be possible to find coherent subclusters of verbs even when there are not exactly good clusters, where is the number of classes.</a>
<a name="4">[4]</a> <a href="#4" id=4>Then for all verbs , consider to be classified correctly if Class( )=ClusterLabel( ), where Class( ) is the actual class of and ClusterLabel( ) is the label assigned to the cluster in which is placed.</a>
<a name="5">[5]</a> <a href="#5" id=5>As we have defined it, necessarily generally increases as the number of clusters increases, with the extreme being at the #verbs correctly classified #verbs total thus provides a measure of the usefulness in practice of a clustering—that is, if one were to use the clustering as a classification, this measure tells how accurate overall the class assignments would be.</a>
<a name="6">[6]</a> <a href="#6" id=6>” In some ways our current clustering task is too easy, because all of the verbs are from one of the target classes.</a></body>
</html>
