<html>
<head><title>J96-3004.system.</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>As shown in Sproat et al.</a>
<a name="1">[1]</a> <a href="#1" id=1>(1996), which is based on weighted finite-state transducers (FSTs).</a>
<a name="2">[2]</a> <a href="#2" id=2>Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting optical character recognition (OCR) erÂ\xad rors (Wu and Tseng, 1993; Nagao and Mori, 1994; Nagata, 1996a; Nagata, 1996b; Sproat et al., 1996; Fung, 1998).</a>
<a name="3">[3]</a> <a href="#3" id=3>We used a simple greedy algorithm described in [Sproat et al., 1996].</a>
<a name="4">[4]</a> <a href="#4" id=4>(1996) also uses multiple human judges.</a>
<a name="5">[5]</a> <a href="#5" id=5>First of all, it is really difficult to build a reliable and objective gold-standard given the fact that there is only 70% agreement between native speakers on this task (Sproat et al., 1996).</a>
<a name="6">[6]</a> <a href="#6" id=6>(1996) can be taken as an evidence that the hypothesis of one tokenization per source has already in practical use.</a>
<a name="7">[7]</a> <a href="#7" id=7>An initial step of any text­ analysis task is the tokenization of the input into words.</a>
<a name="8">[8]</a> <a href="#8" id=8>from the subset of the United Informatics corpus not used in the training of the models.</a>
<a name="9">[9]</a> <a href="#9" id=9>This WFST represents the segmentation of the text into the words AB and CD, word boundaries being marked by arcs mapping between f and part-of-speech labels.</a>
<a name="10">[10]</a> <a href="#10" id=10>Two sets of examples from Gan are given in (1) and (2) (:::::: Gan's Appendix B, exx.</a>
<a name="11">[11]</a> <a href="#11" id=11>Figure 5 shows how this model is implemented as part of the dictionary WFST.</a></body>
</html>
