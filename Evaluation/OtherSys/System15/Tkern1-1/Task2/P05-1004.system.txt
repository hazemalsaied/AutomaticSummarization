Instead, we use vector-space similarity to retrieve a number of synonyms for each unknown common noun. However, our early experiments suggest that this produces extremely large vectors which do not match well against the much smaller vectors of each unseen word. We describe an unsupervised approach, based on vector-space similarity, which does not require annotated examples but significantly outperforms their tagger. We also demonstrate the use of an extremely large shallow-parsed corpus for calculating vector-space semantic similarity. C O R P U S D O C S . S E N T S . WO R D S B N C 4 1 2 4 6 . 2 M 1 1 4 M R C V1 8 0 6 7 9 1 8 . 1 M 2 0 7 M C S R -I I I 4 9 1 3 4 9 9 . 3 M 2 2 6 M NA N T C 9 3 0 3 6 7 2 3. A considerable amount of research addresses structurally and statistically manipulating the hierarchy of WORD- NET and the construction of new wordnets using the concept structure from English. Such a corpus is needed to acquire reliable contextual information for the often very rare nouns we are attempting to supersense tag. However, there are 174 multi-word terms (23%) in the WORDNET 1.7.1 test set which we could probably tag more accurately with synonyms for the whole multi-word term. The supersenses of these synonyms are then combined to determine the supersense.
