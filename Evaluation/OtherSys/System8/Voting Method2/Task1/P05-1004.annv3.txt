Citance Number: 1 | Reference Article:   P05-1004.xml | Citing Article:  C10-2101.xml | Citation Marker Offset:  ['74'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['74'] | Citation Text:  <S sid ="74" ssid = "44">Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).</S> | Reference Offset:  ['20', '68', '108', '3'] | Reference Text:  <S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="3" ssid = "3">Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:   P05-1004.xml | Citing Article:  E09-1045.xml | Citation Marker Offset:  ['23'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['23'] | Citation Text:  <S sid ="23" ssid = "23">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['3', '73', '108', '65'] | Reference Text:  <S sid ="3" ssid = "3">Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</S><S sid ="73" ssid = "6">The WORD- NET 1.6 test set consists of several cross-validation sets of 755 nouns randomly selected from the BLLIP training set used by Ciaramita and Johnson (2003).</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 3 | Reference Article:   P05-1004.xml | Citing Article:  J07-4005.xml | Citation Marker Offset:  ['229'] | Citation Marker:  2005 | Citation Offset:  ['229'] | Citation Text:  <S sid ="229" ssid = "72">Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.</S> | Reference Offset:  ['36', '68', '147', '20'] | Reference Text:  <S sid ="36" ssid = "10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="147" ssid = "1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 4 | Reference Article:   P05-1004.xml | Citing Article:  J09-3004.xml | Citation Marker Offset:  ['446'] | Citation Marker:  Curran 2005 | Citation Offset:  ['446'] | Citation Text:  <S sid ="446" ssid = "30">An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.</S> | Reference Offset:  ['18', '92', '11', '1'] | Reference Text:  <S sid ="18" ssid = "18">These problems demonstrate the need for automatic or semiautomatic methods for the creation and maintenance of lexical-semantic resources.</S><S sid ="92" ssid = "6">Curran and Moens (2002b) compared several context extraction methods and found that the shallow pipeline and grammatical relation extraction used in SEXTANT was both extremely fast and produced high-quality results.</S><S sid ="11" ssid = "11">Bur- gun and Bodenreider (2001) compared an alignment of WORDNET with the UMLS medical resource and found only a very small degree of overlap.</S><S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:   P05-1004.xml | Citing Article:  N06-1017.xml | Citation Marker Offset:  ['26'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['26'] | Citation Text:  <S sid ="26" ssid = "26">There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.</S> | Reference Offset:  ['147', '1', '108', '65'] | Reference Text:  <S sid ="147" ssid = "1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S><S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 6 | Reference Article:   P05-1004.xml | Citing Article:  N06-1017.xml | Citation Marker Offset:  ['189'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['189'] | Citation Text:  <S sid ="189" ssid = "11">Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.</S> | Reference Offset:  ['106', '62', '148', '108'] | Reference Text:  <S sid ="106" ssid = "20">JACCARD and TTEST produced better quality synonyms than existing measures in the literature, so we use Curran and Moen’s configuration for our super- sense tagging experiments.</S><S sid ="62" ssid = "15">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S sid ="148" ssid = "2">This technique is similar to Hearst and Schu¨ tze (1993) and Widdows (2003).</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 7 | Reference Article:   P05-1004.xml | Citing Article:  N07-1024.xml | Citation Marker Offset:  ['83'] | Citation Marker:  Curran 2005 | Citation Offset:  ['83'] | Citation Text:  <S sid ="83" ssid = "3">While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)</S> | Reference Offset:  ['94', '47', '108', '1'] | Reference Text:  <S sid ="94" ssid = "8">The efficiency of the SEXTANT approach makes the extraction of contextual information from over 2 billion words of raw text feasible.</S><S sid ="47" ssid = "21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 8 | Reference Article:   P05-1004.xml | Citing Article:  P12-2050.xml | Citation Marker Offset:  ['15'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.</S> | Reference Offset:  ['14', '35', '68', '20'] | Reference Text:  <S sid ="14" ssid = "14">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S><S sid ="35" ssid = "9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 9 | Reference Article:   P05-1004.xml | Citing Article:  S07-1032.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['65', '171', '96', '108'] | Reference Text:  <S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S><S sid ="171" ssid = "1">We have used the WORDNET 1.6 test set to experiment with different parameter settings and have kept the WORDNET 1.7.1 test set as a final comparison of best results with Ciaramita and Johnson (2003).</S><S sid ="96" ssid = "10">Curran and Moens (2002a) compared several different similarity measures and found that Grefenstette’s weighted JACCARD measure performed the best: R E L AT I O N D E S C R I P T I O N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations from SEXTANT against the CELEX lexical database (Minnen et al., 2001) – and is very efficient, analysing over 80 000 words per second.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 10 | Reference Article:   P05-1004.xml | Citing Article:  S10-1090.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['3', '73', '108', '65'] | Reference Text:  <S sid ="3" ssid = "3">Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</S><S sid ="73" ssid = "6">The WORD- NET 1.6 test set consists of several cross-validation sets of 755 nouns randomly selected from the BLLIP training set used by Ciaramita and Johnson (2003).</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 11 | Reference Article:   P05-1004.xml | Citing Article:  S12-1011.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).</S> | Reference Offset:  ['108', '26', '96', '92'] | Reference Text:  <S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="26" ssid = "26">Qc 2005 Association for Computational Linguistics L E X -FI L E D E S C R I P T I O N act acts or actions animal animals artifact man-made objects attribute attributes of people and objects body body parts cognition cognitive processes and contents communication communicative processes and contents event natural events feeling feelings and emotions food foods and drinks group groupings of people or objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession and transfer of possession process natural processes quantity quantities and units of measure relation relations between people/things/ideas shape two and three dimensional shapes state stable states of affairs substance substances time time and temporal relations Table 1: 25 noun lexicographer files in WORDNET</S><S sid ="96" ssid = "10">Curran and Moens (2002a) compared several different similarity measures and found that Grefenstette’s weighted JACCARD measure performed the best: R E L AT I O N D E S C R I P T I O N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations from SEXTANT against the CELEX lexical database (Minnen et al., 2001) – and is very efficient, analysing over 80 000 words per second.</S><S sid ="92" ssid = "6">Curran and Moens (2002b) compared several context extraction methods and found that the shallow pipeline and grammatical relation extraction used in SEXTANT was both extremely fast and produced high-quality results.</S> | Discourse Facet:  ['Method_Citation', 'Hypothesis_Citation'] | Annotator:  CIST |


Citance Number: 12 | Reference Article:   P05-1004.xml | Citing Article:  S12-1011.xml | Citation Marker Offset:  ['50'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['50'] | Citation Text:  <S sid ="50" ssid = "2">Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.</S> | Reference Offset:  ['20', '68', '108', '169'] | Reference Text:  <S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="169" ssid = "23">A disadvantage of this similarity approach is that it requires full synonym extraction, which compares the unknown word against a large number of words when, in S Y S T E M W N 1.6 W N 1.7 .1 Cia ra mit a an d Joh nso n bas eli ne 2 1 % 2 8 % Cia ra mit a an d Joh nso n per cep tro n 5 3 % 5 3 % Si mil arit y bas ed res ult s 6 8 % 6 3 % Table 6: Summary of supersense tagging accuracies fact, we want to calculate the similarity to a small number of supersenses.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 13 | Reference Article:   P05-1004.xml | Citing Article:  S12-1023.xml | Citation Marker Offset:  ['234'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['234'] | Citation Text:  <S sid ="234" ssid = "15">A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.</S> | Reference Offset:  ['108', '198', '106', '61'] | Reference Text:  <S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="198" ssid = "28">This is not surprising since these concrete words tend to have very fewer other senses, well constrained contexts and a relatively high frequency.</S><S sid ="106" ssid = "20">JACCARD and TTEST produced better quality synonyms than existing measures in the literature, so we use Curran and Moen’s configuration for our super- sense tagging experiments.</S><S sid ="61" ssid = "14">Further, they also use the same vector-space techniques to label previously unseen words using the most common class assigned to the top 20 synonyms for that word.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 14 | Reference Article:   P05-1004.xml | Citing Article:  W06-1670.xml | Citation Marker Offset:  ['94'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['94'] | Citation Text:  <S sid ="94" ssid = "12">Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.</S> | Reference Offset:  ['20', '68', '222', '108'] | Reference Text:  <S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="222" ssid = "20">We intend to extend our experiments beyond the Ciaramita and Johnson (2003) set to include previous and more recent versions of WORDNET to compare their difficulty, and also perform experiments over a range of corpus sizes to determine the impact of corpus size on the quality of results.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |