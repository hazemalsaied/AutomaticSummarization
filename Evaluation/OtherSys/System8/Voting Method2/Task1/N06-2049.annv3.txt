Citance Number: 1 | Reference Article:  N06-2049.xml | Citing Article:  C10-2139.xml | Citation Marker Offset:  ['290'] | Citation Marker:  Zh ang et al., 200 6 | Citation Offset:  ['290','305'] | Citation Text:  <S sid ="290" ssid = "189">AS C U MS R PK U (Zh ang et al., 200 6) 95.</S><S sid ="305" ssid = "204">2 Table 5: Segmentation performance presented in previous work and of our combination model.</S> | Reference Offset:  ['5', '43', '80', '111'] | Reference Text:  <S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S><S sid ="43" ssid = "21">In the third step, we used the CRFs approach to train the IOB tagger (Lafferty et al., 2001) on the training data.</S><S sid ="80" ssid = "9">Table 1 shows the performance of the dictionary-based segmentation.</S><S sid ="111" ssid = "40">We found the results in Table 3 were better than those in Table 2 and Table 1, which prove that using confidence measure approach achieved the best performance over the dictionary-based segmentation and the IOB tagging approach.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:  N06-2049.xml | Citing Article:  D13-1031.xml | Citation Marker Offset:  ['274'] | Citation Marker:  2006 | Citation Offset:  ['273','274'] | Citation Text:  <S sid ="273" ssid = "109">CRF + Rule system represents a combination of CRF model and rule based model presented in Zhang et al.</S><S sid ="274" ssid = "110">(2006).</S> | Reference Offset:  ['25', '32', '33', '152'] | Reference Text:  <S sid ="25" ssid = "3">It is composed of three parts: a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.</S><S sid ="32" ssid = "10">First, we extracted a word list from the training data sorted in decreasing order by their counts in the training 193 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 193–196, New York, June 2006.</S><S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="152" ssid = "2">Using the CRFs approaches, we prove that it outperformed the character- based method using the CRF approaches.</S> | Discourse Facet:  ['Aim_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 3 | Reference Article:  N06-2049.xml | Citing Article:  I08-4009.xml | Citation Marker Offset:  ['19'] | Citation Marker:  Zhang et al., 2006a | Citation Offset:  ['19'] | Citation Text:  <S sid ="19" ssid = "19">Consequently, many strategies are proposed to balance the IV and OOV performance (Goh et al., 2005), (Zhang et al., 2006a).</S> | Reference Offset:  ['5', '89', '14', '134'] | Reference Text:  <S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S><S sid ="89" ssid = "18">The segmentation results of the dictionary-based were re-segmented Table 1: Our segmentation results by the dictionary- based approach for the closed test of Bakeoff 2005, very low R-oov rates due to no OOV recognition applied.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S><S sid ="134" ssid = "3">Later, this approach was implemented by the CRF-based method (Peng and McCallum, 2004), which was proved to achieve better results than the maximum entropy approach because it can solve the label bias problem (Lafferty et al., 2001).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 4 | Reference Article:  N06-2049.xml | Citing Article:  I08-4009.xml | Citation Marker Offset:  ['20'] | Citation Marker:  Zhang et al., 2006a | Citation Offset:  ['20'] | Citation Text:  <S sid ="20" ssid = "20">Among these strategies, the confidence measure used to combine the results of CT and DS is a straightforward one, which is introduced in (Zhang et al., 2006a).</S> | Reference Offset:  ['57', '58', '150', '108'] | Reference Text:  <S sid ="57" ssid = "35">In this section we introduce a confidence measure approach to combine the two results.</S><S sid ="58" ssid = "36">We define a confidence measure, C M(tiob |w), to measure the confidence of the results produced by the IOB tagging by using the results from the dictionary-based segmentation.</S><S sid ="150" ssid = "19">By way of the confidence measure we combined results from the dictionary-based and the IOB-tagging-based and as a result, we could achieve the optimal performance.</S><S sid ="108" ssid = "37">In section 2.2, we proposed a confidence measure approach to reevaluate the results of IOB tagging by combinations of the results of the dictionary-based segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:  N06-2049.xml | Citing Article:  I08-4015.xml | Citation Marker Offset:  ['36'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['36'] | Citation Text:  <S sid ="36" ssid = "22">After we get word-based segmentation result, we use it to revise the CRF tagging result similar to (Zhang et al., 2006).</S> | Reference Offset:  ['25', '101', '60', '14'] | Reference Text:  <S sid ="25" ssid = "3">It is composed of three parts: a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.</S><S sid ="101" ssid = "30">The segmentation results using CRF tagging are shown in Table 2, where the upper numbers of each slot were produced by the character-based approach while the lower numbers were of the subword-based.</S><S sid ="60" ssid = "38">Its calculation is defined as: C M(tiob |w) = αC Miob (tiob |w) + (1 − α)δ(tw , tiob )ng (2) where tiob is the word w’s IOB tag assigned by the IOB tagging; tw , a prior IOB tag determined by the results of the dictionary-based segmentation.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 6 | Reference Article:  N06-2049.xml | Citing Article:  I08-4030.xml | Citation Marker Offset:  ['13'] | Citation Marker:  R. Zhang et al., 2006 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">If the confidence of a character is lower than the threshold, the tag of that character will be adjusted to the tag assigned by the Maximum Probability Segmentation (R. Zhang et al., 2006).</S> | Reference Offset:  ['33', '62', '34', '8'] | Reference Text:  <S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="62" ssid = "40">Each subword is given a prior IOB tag, tw . C Miob (t|w), a  M  confidence probability derived in the process of IOB tag exp )&apos; )&apos; λk fk (ti−1 , ti , W ) + )&apos; µk gk (ti , W ) /Z,  i=1  k k   (1) ging, is defined as Z = )&apos; T =t0 t1 ···tM p(T |W ) C Miob (t|w ) = L,T =t0 t1 ···tM ,ti =t P(T |W, wi ) T =t 0 t1 ··· tM P ( T|W ) where we call fk (ti−1 , ti , W ) bigram feature functions because the features trigger the previous observation ti−1 where the numerator is a sum of all the observation sequences with word wi labeled as t. δ(tw , tiob )ng denotes the contribution of the dictionary- based segmentation.</S><S sid ="34" ssid = "12">We chose all the single characters and the top multi- character words as a lexicon subset for the IOB tagging.</S><S sid ="8" ssid = "8">In this work we propose a subword-based IOB tagging, which assigns tags to a predefined lexicon subset consisting of the most frequent multiple-character words in addition to single Chinese characters.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 7 | Reference Article:  N06-2049.xml | Citing Article:  I08-4030.xml | Citation Marker Offset:  ['51'] | Citation Marker:  R. Zhang et al., 2006 | Citation Offset:  ['51'] | Citation Text:  <S sid ="51" ssid = "7">According to the results reported in (R. Zhang et al., 2006), CRF performs relatively better on Out-of-Vocabulary (OOV) words while Maximum Probability performs well on IV words, so a model combining the advantages of these two methods is appealing.</S> | Reference Offset:  ['25', '134', '44', '14'] | Reference Text:  <S sid ="25" ssid = "3">It is composed of three parts: a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.</S><S sid ="134" ssid = "3">Later, this approach was implemented by the CRF-based method (Peng and McCallum, 2004), which was proved to achieve better results than the maximum entropy approach because it can solve the label bias problem (Lafferty et al., 2001).</S><S sid ="44" ssid = "22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 8 | Reference Article:  N06-2049.xml | Citing Article:  J11-1005.xml | Citation Marker Offset:  ['277'] | Citation Marker:  2006 | Citation Offset:  ['277'] | Citation Text:  <S sid ="277" ssid = "168">We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang, Kikui, and Sumita (2006) for comparison.</S> | Reference Offset:  ['4', '14', '129', '111'] | Reference Text:  <S sid ="4" ssid = "4">By these techniques we achieved higher F-scores in CITYU, PKU and MSR corpora than the best results from Sighan Bakeoff 2005.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S><S sid ="129" ssid = "58">95 1 Table 4: Comparison our results with the best ones from Sighan Bakeoff 2005 in terms of F-score ivs than Table 2.</S><S sid ="111" ssid = "40">We found the results in Table 3 were better than those in Table 2 and Table 1, which prove that using confidence measure approach achieved the best performance over the dictionary-based segmentation and the IOB tagging approach.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 9 | Reference Article:  N06-2049.xml | Citing Article:  N09-1007.xml | Citation Marker Offset:  ['134'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['134'] | Citation Text:  <S sid ="134" ssid = "17">Z06-a and Z06-b represents the pure sub- word CRF model and the conﬁdence-based combination of CRF and rule-based models, respectively (Zhang et al., 2006);</S> |  Reference Offset:  ['44', '25', '5', '14'] | Reference Text:  <S sid ="44" ssid = "22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S><S sid ="25" ssid = "3">It is composed of three parts: a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.</S><S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 10 | Reference Article:  N06-2049.xml | Citing Article:  P06-2123.xml | Citation Marker Offset:  ['197'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['197'] | Citation Text:  <S sid ="197" ssid = "75">Detailed descriptions about subword tagging by CRF can be found in our paper (Zhang et al., 2006).</S> | Reference Offset:  ['5', '14', '33', '101'] | Reference Text:  <S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S><S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="101" ssid = "30">The segmentation results using CRF tagging are shown in Table 2, where the upper numbers of each slot were produced by the character-based approach while the lower numbers were of the subword-based.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 11 | Reference Article:  N06-2049.xml | Citing Article:  P07-1106.xml | Citation Marker Offset:  ['94'] | Citation Marker:  2006 | Citation Offset:  ['93','94'] | Citation Text:  <S sid ="93" ssid = "9">One existing method that is based on sub-word information, Zhang et al.</S><S sid ="94" ssid = "10">(2006), combines a C R F and a rule-based model.</S> | Reference Offset:  ['99', '45', '38', '57'] | Reference Text:  <S sid ="99" ssid = "28">The upper numbers are of the character- based and the lower ones, the subword-based.</S><S sid ="45" ssid = "23">The model parameters were trained by maximizing the log-likelihood of the training data using L-BFGS gradient descent optimization method.</S><S sid ="38" ssid = "16">For a character-based IOB tagger, there is only one possibility of re-segmentation.</S><S sid ="57" ssid = "35">In this section we introduce a confidence measure approach to combine the two results.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 12 | Reference Article:  N06-2049.xml | Citing Article:  P07-1106.xml | Citation Marker Offset:  ['172'] | Citation Marker:  2006 | Citation Offset:  ['172','173'] | Citation Text:  <S sid ="172" ssid = "72">We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al.</S><S sid ="173" ssid = "73">(2006) for comparison.</S> | Reference Offset:  ['129', '4', '33', '14'] | Reference Text:  <S sid ="129" ssid = "58">95 1 Table 4: Comparison our results with the best ones from Sighan Bakeoff 2005 in terms of F-score ivs than Table 2.</S><S sid ="4" ssid = "4">By these techniques we achieved higher F-scores in CITYU, PKU and MSR corpora than the best results from Sighan Bakeoff 2005.</S><S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 13 | Reference Article:  N06-2049.xml | Citing Article:  P12-1027.xml | Citation Marker Offset:  ['189'] | Citation Marker:  2006 | Citation Offset:  ['188'] | Citation Text:  <S sid ="188" ssid = "41">Best05 represents the best system of the Second International Chinese Word Segmentation Bakeoff on the corresponding data; CRF + rule-system represents confidence- based combination of CRF and rule-based models, presented in Zhang et al.</S><S sid ="189" ssid = "42">(2006).</S> | Reference Offset:  ['33', '25', '32', '14'] | Reference Text:  <S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="25" ssid = "3">It is composed of three parts: a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.</S><S sid ="32" ssid = "10">First, we extracted a word list from the training data sorted in decreasing order by their counts in the training 193 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 193–196, New York, June 2006.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 14 | Reference Article:  N06-2049.xml | Citing Article:  W06-0118.xml | Citation Marker Offset:  ['14'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['14'] | Citation Text:  <S sid ="14" ssid = "2">Also, the CRF model using maximum subword-based tagging (Zhang et al., 2006)</S> | Reference Offset:  ['101', '30', '44', '14'] | Reference Text:  <S sid ="101" ssid = "30">The segmentation results using CRF tagging are shown in Table 2, where the upper numbers of each slot were produced by the character-based approach while the lower numbers were of the subword-based.</S><S sid ="30" ssid = "8">2.1 Subword-based IOB tagging using CRFs.</S><S sid ="44" ssid = "22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  ['Method_Citation', 'Implication_Citation'] | Annotator:  CIST |


Citance Number: 15 | Reference Article:  N06-2049.xml | Citing Article:  W06-0118.xml | Citation Marker Offset:  ['24'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['24'] | Citation Text:  <S sid ="24" ssid = "12">Recently (Zhang et al., 2006) proposed a maximum subword-based IOB tagger for Chinese word segmentation, and our system applies their approach which obtains a very high accuracy on the shared task data from previous SIGHAN competitions.</S> | Reference Offset:  ['1', '5', '33', '151'] | Reference Text:  <S sid ="1" ssid = "1">We proposed two approaches to improve Chinese word segmentation: a subword-based tagging and a confidence measure approach.</S><S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S><S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="151" ssid = "1">In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 16 | Reference Article:  N06-2049.xml | Citing Article:  W08-0335.xml | Citation Marker Offset:  ['55'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['55','56'] | Citation Text: <S sid ="55" ssid = "21">Part of the work using this tool was described by (Zhang et al., 2006).</S><S sid ="56" ssid = "22">The approach was reported to achieve the highest word segmentation accuracy using the data from the second Sighan Bakeoff.</S> | Reference Offset:  ['14', '72', '33', '4'] | Reference Text:  <S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S><S sid ="72" ssid = "1">We used the data provided by Sighan Bakeoff 2005 to test our approaches described in the previous sections.</S><S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S><S sid ="4" ssid = "4">By these techniques we achieved higher F-scores in CITYU, PKU and MSR corpora than the best results from Sighan Bakeoff 2005.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 17 | Reference Article:  N06-2049.xml | Citing Article:  W08-0335.xml | Citation Marker Offset:  ['160'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['160'] | Citation Text:  <S sid ="160" ssid = "19">Note a lexicon and a LM are the only needed resources for building a dictionary-based CWS, like the â€œdict-hybrid.â€ (Zhang et al., 2006) We used the â€œdict-hybridâ€ to segment the SMT training corpus and test data.</S> | Reference Offset:  ['43', '14', '72', '44'] | Reference Text:  <S sid ="43" ssid = "21">In the third step, we used the CRFs approach to train the IOB tagger (Lafferty et al., 2001) on the training data.</S><S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S><S sid ="72" ssid = "1">We used the data provided by Sighan Bakeoff 2005 to test our approaches described in the previous sections.</S><S sid ="44" ssid = "22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 18 | Reference Article:  N06-2049.xml | Citing Article:  W10-4128.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['11'] | Citation Text:  <S sid ="11" ssid = "11">Some previous work (Peng et al., 2004; Tseng et al., 2005; Low et al., 2005) illustrated the effectiveness of using characters as tagging units, while literatures (Zhang et al., 2006; Zhao and Kit, 2007a; Zhang and Clark, 2007) focus on employing lexical words or subwords as tagging units.</S> | Reference Offset:  ['14', '5', '8', '36'] | Reference Text:  <S sid ="14" ssid = "14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S><S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S><S sid ="8" ssid = "8">In this work we propose a subword-based IOB tagging, which assigns tags to a predefined lexicon subset consisting of the most frequent multiple-character words in addition to single Chinese characters.</S><S sid ="36" ssid = "14">We regard the words in the subset as the subwords for the IOB tagging.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 19 | Reference Article:  N06-2049.xml | Citing Article:  W10-4135.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['11'] | Citation Text:  <S sid ="11" ssid = "11">For this purpose, our system is based on a combination of subword-based tagging method (Zhang et al., 2006) and accessor variety-based new word recognition method (Feng et al., 2004).</S> | Reference Offset:  ['19', '151', '0', '5'] | Reference Text:  <S sid ="19" ssid = "19">In the followings, we illustrate our word segmentation process in Section 2, where the subword-based tagging is implemented by the CRFs method.</S><S sid ="151" ssid = "1">In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.</S><S sid ="0">Subword-based Tagging by Conditional Random Fields for Chinese Word Segmentation</S><S sid ="5" ssid = "5">The character-based “IOB” tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 20 | Reference Article:  N06-2049.xml | Citing Article:  W10-4135.xml | Citation Marker Offset:  ['25'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['25'] | Citation Text:  <S sid ="25" ssid = "11">Feature Template Description f) in(str, subword-list) is str in subword list g) in(str, confident-word-list) is str in confident-word list Table 2: Subword Features for CRF-based Segmenter dure for constructing a subword list is similar to the one used in (Zhang et al., 2006).</S> | Reference Offset:  ['137', '62', '44', '50'] | Reference Text:  <S sid ="137" ssid = "6">Our results are listed together with the best results from Bakeoff 2005 in Table 4 in terms of F-scores.</S><S sid ="62" ssid = "40">Each subword is given a prior IOB tag, tw . C Miob (t|w), a  M  confidence probability derived in the process of IOB tag exp )&apos; )&apos; λk fk (ti−1 , ti , W ) + )&apos; µk gk (ti , W ) /Z,  i=1  k k   (1) ging, is defined as Z = )&apos; T =t0 t1 ···tM p(T |W ) C Miob (t|w ) = L,T =t0 t1 ···tM ,ti =t P(T |W, wi ) T =t 0 t1 ··· tM P ( T|W ) where we call fk (ti−1 , ti , W ) bigram feature functions because the features trigger the previous observation ti−1 where the numerator is a sum of all the observation sequences with word wi labeled as t. δ(tw , tiob )ng denotes the contribution of the dictionary- based segmentation.</S><S sid ="44" ssid = "22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S><S sid ="50" ssid = "28">For the bigram features, we only used the previous and the current observations, t−1 t0 . As to feature selection, we simply used absolute counts for each feature in the training data.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 21 | Reference Article:  N06-2049.xml | Citing Article:  W10-4135.xml | Citation Marker Offset:  ['30'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['30'] | Citation Text:  <S sid ="30" ssid = "16">See the details of subword-based Chinese word segmentation in (Zhang et al., 2006)</S> | Reference Offset:  ['0', '1', '151', '33'] | Reference Text:  <S sid ="0">Subword-based Tagging by Conditional Random Fields for Chinese Word Segmentation</S><S sid ="1" ssid = "1">We proposed two approaches to improve Chinese word segmentation: a subword-based tagging and a confidence measure approach.</S><S sid ="151" ssid = "1">In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.</S><S sid ="33" ssid = "11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ &lt;LQJ &amp;KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% &lt;LQJ/, &amp;KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ&lt;LQJ&amp;KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 22 | Reference Article:  N06-2049.xml | Citing Article:  W10-4138.xml | Citation Marker Offset:  ['22'] | Citation Marker:  2006 | Citation Offset:  ['21','22'] | Citation Text:  <S sid ="21" ssid = "14">Thus, the bigram â€œRAIL ENQUIRIESâ€ gives a misleading probability that â€œRAILâ€ is followed by â€œENQUIRIESâ€ irrespective of what precedes it.</S><S sid ="22" ssid = "15">This problem happens not only with word-token corpora but also with corpora in which all the compounds are tagged as units since overlapping N- grams still appear, therefore corresponding solutions such as those of Zhang et al.</S><S sid ="23" ssid = "16">(2006) were proposed.</S> | Reference Offset:  ['151', '62', '8', '16'] | Reference Text:  <S sid ="151" ssid = "1">In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.</S><S sid ="62" ssid = "40">Each subword is given a prior IOB tag, tw . C Miob (t|w), a  M  confidence probability derived in the process of IOB tag exp )&apos; )&apos; λk fk (ti−1 , ti , W ) + )&apos; µk gk (ti , W ) /Z,  i=1  k k   (1) ging, is defined as Z = )&apos; T =t0 t1 ···tM p(T |W ) C Miob (t|w ) = L,T =t0 t1 ···tM ,ti =t P(T |W, wi ) T =t 0 t1 ··· tM P ( T|W ) where we call fk (ti−1 , ti , W ) bigram feature functions because the features trigger the previous observation ti−1 where the numerator is a sum of all the observation sequences with word wi labeled as t. δ(tw , tiob )ng denotes the contribution of the dictionary- based segmentation.</S><S sid ="8" ssid = "8">In this work we propose a subword-based IOB tagging, which assigns tags to a predefined lexicon subset consisting of the most frequent multiple-character words in addition to single Chinese characters.</S><S sid ="16" ssid = "16">In this work we propose a confidence measure approach to lessen the weakness.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |