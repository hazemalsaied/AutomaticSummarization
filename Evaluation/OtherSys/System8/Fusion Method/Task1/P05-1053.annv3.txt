Citance Number: 1 | Reference Article:  P05-1053.xml | Citing Article:  C08-1088.xml | Citation Marker Offset:  ['37'] | Citation Marker: 2005 | Citation Offset:  ['36','37'] | Citation Text:  <S sid ="36" ssid = "2">For those interested in feature-based methods, please refer to Zhou et al.</S><S sid ="37" ssid = "3">(2005) for more details.</S> | Reference Offset:  ['57', '162', '163', '25'] | Reference Text:  <S sid ="57" ssid = "13">For details about SVMLight, please see http://svmlight.joachims.org/</S><S sid ="162" ssid = "44">It also shows that feature-based methods dramatically outperform kernel methods.</S><S sid ="163" ssid = "45">This suggests that feature-based methods can effectively combine different features from a variety of sources (e.g. WordNet and gazetteers) that can be brought to bear on relation extraction.</S><S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:  P05-1053.xml | Citing Article:  C08-1088.xml | Citation Marker Offset:  ['15'] | Citation Marker:  2005 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">However, detailed research (Zhou et al., 2005) shows that itâ€™s difficult to extract new effective features to further improve the extraction accuracy.</S> | Reference Offset:  ['213', '5', '38', '6'] | Reference Text:  <S sid ="213" ssid = "95">Although tree kernel-based approaches facilitate the exploration of the implicit feature space with the parse tree structure, yet the current technologies are expected to be further advanced to be effective for relatively complicated relation extraction tasks such as the one defined in ACE where 5 types and 24 subtypes need to be extracted.</S><S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="38" ssid = "9">Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.</S><S sid ="6" ssid = "6">Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 3 | Reference Article:  P05-1053.xml | Citing Article:  C08-1088.xml | Citation Marker Offset:  ['180'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['180'] | Citation Text:  <S sid ="180" ssid = "28">Furthermore, when the UPST (FPT) kernel is com bined with a linear state-of-the-state feature- based kernel (Zhou et al., 2005) into a composite one via polynomial interpolation in a setting similar to Zhou et al.</S> | Reference Offset:  ['51', '90', '163', '87'] | Reference Text:  <S sid ="51" ssid = "7">Moreover, we only apply the simple linear kernel, although other kernels can peform better.</S><S sid ="90" ssid = "33">Similar to word features, three categories of phrase heads are considered: 1) the phrase heads in between are also classified into three bins: the first phrase head in between, the last phrase head in between and other phrase heads in between; 2) the phrase heads before M1 are classified into two bins: the first phrase head before and the second phrase head before; 3) the phrase heads after M2 are classified into two bins: the first phrase head after and the second phrase head after.</S><S sid ="163" ssid = "45">This suggests that feature-based methods can effectively combine different features from a variety of sources (e.g. WordNet and gazetteers) that can be brought to bear on relation extraction.</S><S sid ="87" ssid = "30">In this way, we can separately evaluate the contributions of base phrase chunking and full parsing.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 4 | Reference Article:  P05-1053.xml | Citing Article:  C10-1018.xml | Citation Marker Offset:  ['12'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">In building these systems, researchers used a wide variety of features (Kambhatla, 2004; Zhou et al., 2005; Jiang and Zhai, 2007).</S> | Reference Offset:  ['212', '43', '34', '20'] | Reference Text:  <S sid ="212" ssid = "94">The effective incorporation of diverse features enables our system outperform previously best- reported systems on the ACE corpus.</S><S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:  P05-1053.xml | Citing Article:  C10-1018.xml | Citation Marker Offset:  ['42'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['42'] | Citation Text:  <S sid ="42" ssid = "5">Most of the features used in our system are based on the work in (Zhou et al., 2005).</S> | Reference Offset:  ['86', '212', '20', '108'] | Reference Text:  <S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="212" ssid = "94">The effective incorporation of diverse features enables our system outperform previously best- reported systems on the ACE corpus.</S><S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S><S sid ="108" ssid = "1">This paper uses the ACE corpus provided by LDC to train and evaluate our feature-based relation extraction system.</S> | Discourse Facet:  ['Method_Citation', 'Implication_Citation'] | Annotator:  CIST |


Citance Number: 6 | Reference Article:  P05-1053.xml | Citing Article:  C10-1018.xml | Citation Marker Offset:  ['45'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['45'] | Citation Text:  <S sid ="45" ssid = "8">Due to space limitations, we only describe the collocation features and refer the reader to (Zhou et al., 2005) for the rest of the features.</S> | Reference Offset:  ['133', '132', '37', '28'] | Reference Text:  <S sid ="133" ssid = "15">• Entity type features are very useful and improve the F-measure by 8.1 largely due to the recall increase.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="28" ssid = "28">Section 3 and Section 4 describe our approach and various features employed respectively.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 7 | Reference Article:  P05-1053.xml | Citing Article:  C10-1064.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction.</S> | Reference Offset:  ['36', '37', '214', '17'] | Reference Text:  <S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 8 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['14'] | Citation Marker:   | Citation Offset:  ['14'] | Citation Text:  <S sid ="14" ssid = "14">Among them, feature-based methods (Kambhatla 2004; Zhou et al., 2005) achieve certain success by employing a large amount of diverse linguistic features, varying from lexical knowledge, entity- related information to syntactic parse trees, dependency trees and semantic information</S> | Reference Offset:  ['34', '93', '192', '17'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="93" ssid = "36">This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.</S><S sid ="192" ssid = "74">In this paper, we have presented a feature-based approach for relation extraction where diverse lexical, syntactic and semantic knowledge are employed.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 9 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['14'] | Citation Marker:   | Citation Offset:  ['14'] | Citation Text:  <S sid ="14" ssid = "14">How ever, it is difficult for them to effectively capture struc tured parse tree information (Zhou et al 2005), which is critical for further performance improvement in relation extraction.</S> | Reference Offset:  ['4', '3', '5', '211'] | Reference Text:  <S sid ="4" ssid = "4">This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.</S><S sid ="3" ssid = "3">Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.</S><S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="211" ssid = "93">Besides, we also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 10 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['161'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['161'] | Citation Text:  <S sid ="161" ssid = "24">Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al (2006), is applied to integrate the proposed c ontextsensitive convolution tree kernel with a state -of the-art linear kernel (Zhou et al 2005)</S> | Reference Offset:  ['32', '33', '25', '51'] | Reference Text:  <S sid ="32" ssid = "3">Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="51" ssid = "7">Moreover, we only apply the simple linear kernel, although other kernels can peform better.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 11 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['167'] | Citation Marker:  20 05 | Citation Offset:  ['166','167'] | Citation Text:  <S sid ="166" ssid = "29">7 Here, we use the same set of flat features (i.e. word,.</S><S sid ="167" ssid = "30">entity type, mention level, overlap, base phrase chunk- ing, dependency tree, parse tree and semantic information) as Zhou et al (20 05).</S> | Reference Offset:  ['34', '93', '74', '132'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="93" ssid = "36">This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.</S><S sid ="74" ssid = "17">set as the last word of the mention.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 12 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['177'] | Citation Marker:  2005 | Citation Offset:  ['176','177'] | Citation Text:  <S sid ="176" ssid = "39"> dependency kernel Zhou et al.</S><S sid ="177" ssid = "40">(2005)</S> | Reference Offset:  ['25', '33', '210', '204'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="210" ssid = "92">Dependency tree th parse trees.</S><S sid ="204" ssid = "86">Covolution kernels for natural language.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 13 | Reference Article:  P05-1053.xml | Citing Article:  D09-1149.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">This paper focuses on the ACE RDC subtask, where many machine learning methods have been proposed, including supervised methods (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005; Zhang et al., 2006; Qian et al., 2008), semi-supervised methods (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006; Zhou et al., 2008), and unsupervised methods (Hasegawa et al., 2004; Zhang et al., 2005) . Current work on semantic relation extraction task mainly uses supervised learning methods, since it achieves relatively better performance.</S> | Reference Offset:  ['214', '17', '34', '30'] | Reference Text:  <S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="30" ssid = "1">The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</S> | Discourse Facet:  ['Method_Citation', 'Hypthesis_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 14 | Reference Article:  P05-1053.xml | Citing Article:  D09-1149.xml | Citation Marker Offset:  ['53'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['53'] | Citation Text:  <S sid ="53" ssid = "5">For each pair of entity mentions, we extract and compute various lexical and syntactic features, as employed in a state-of-the-art relation extraction system (Zhou et al., 2005).</S> | Reference Offset:  ['60', '192', '2', '34'] | Reference Text:  <S sid ="60" ssid = "3">For each pair of mentions3, we compute various lexical, syntactic and semantic features.</S><S sid ="192" ssid = "74">In this paper, we have presented a feature-based approach for relation extraction where diverse lexical, syntactic and semantic knowledge are employed.</S><S sid ="2" ssid = "2">This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 15 | Reference Article:  P05-1053.xml | Citing Article:  D09-1149.xml | Citation Marker Offset:  ['53'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  [] | Citation Text:  <S sid ="81" ssid = "19">It is well known that the number of the instances for each relation type in the ACE RDC corpora is greatly unbalanced (Zhou et al., 2005) as shown in Table 1 for the ACE RDC 2004 corpus.</S> | Reference Offset:  ['43', '214', '44', '117'] | Reference Text:  <S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S><S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S><S sid ="117" ssid = "10">Table 1 lists the types and subtypes of relations for the ACE Relation Detection and Characterization (RDC) task, along with their frequency of occurrence in the ACE training set.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 16 | Reference Article:  P05-1053.xml | Citing Article:  D12-1074.xml | Citation Marker Offset:  ['100'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['100'] | Citation Text:  <S sid ="100" ssid = "36">This is a lightweight model and generally does not attempt to exhaustively leverage all possible proven sources of useful features (Zhou et al., 2005) towards a higher absolute score, but rather to serve as a point of comparison to the models which rely on syntactic information.</S> | Reference Offset:  ['3', '31', '93', '41'] | Reference Text:  <S sid ="3" ssid = "3">Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.</S><S sid ="31" ssid = "2">Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</S><S sid ="93" ssid = "36">This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.</S><S sid ="41" ssid = "12">Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 17 | Reference Article:  P05-1053.xml | Citing Article:  E06-2012.xml | Citation Marker Offset:  ['59'] | Citation Marker:  Zelenko et al, 2003, Zhou et al, 2005 | Citation Offset:  ['59'] | Citation Text:  <S sid ="59" ssid = "29">Recent work has begun to address relation and event extraction through trainable means, chiefly SVM classification (Zelenko et al, 2003, Zhou et al, 2005).</S> | Reference Offset:  ['38', '33', '216', '25'] | Reference Text:  <S sid ="38" ssid = "9">Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="216" ssid = "98">In the future work, we will focus on exploring more semantic knowledge in relation extraction, which has not been covered by current research.</S><S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 18 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['54'] | Citation Marker:  2005 | Citation Offset:  ['54'] | Citation Text:  <S sid ="54" ssid = "34">For the choice of features, we use the full set of features from Zhou et al.</S><S sid ="55" ssid = "35">(2005) since it is reported to have a state-of-the-art performance (Sun et al., 2011).</S> | Reference Offset:  ['131', '132', '86', '130'] | Reference Text:  <S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 19 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['109'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['109'] | Citation Text:  <S sid ="109" ssid = "34">We use a state-of-the-art feature space (Zhou et al., 2005) to represent examples (including all correct examples, erroneous ones and untagged examples) and use MaxEnt as the weight learning model since it shows competitive performance in relation extraction (Jiang and Zhai, 2007) and outputs probabilities associated with each prediction.</S> | Reference Offset:  ['5', '211', '213', '39'] | Reference Text:  <S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="211" ssid = "93">Besides, we also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="213" ssid = "95">Although tree kernel-based approaches facilitate the exploration of the implicit feature space with the parse tree structure, yet the current technologies are expected to be further advanced to be effective for relatively complicated relation extraction tasks such as the one defined in ACE where 5 types and 24 subtypes need to be extracted.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 20 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['55'] | Citation Marker:  2005 | Citation Offset:  ['55'] | Citation Text:  <S sid ="54" ssid = "34">For the choice of features, we use the full set of features from Zhou et al.</S><S sid ="55" ssid = "35">(2005) since it is reported to have a state-of-the-art performance (Sun et al., 2011).</S> | Reference Offset:  ['131', '132', '86', '130'] | Reference Text:  <S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 21 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['225'] | Citation Marker:  2005 | Citation Offset:  ['224','225'] | Citation Text:  <S sid ="224" ssid = "3">We use SVM as our learning algorithm with the full feature set from Zhou et al.</S><S sid ="225" ssid = "4">(2005).</S> | Reference Offset:  ['25', '86', '131', '52'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="52" ssid = "8">The reason why we choose SVMs for this purpose is that SVMs represent the state-of–the-art in the machine learning research community, and there are good implementations of the algorithm available.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 22 | Reference Article:  P05-1053.xml | Citing Article:  I08-1004.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).</S> | Reference Offset:  ['2', '192', '5', '211'] | Reference Text:  <S sid ="2" ssid = "2">This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.</S><S sid ="192" ssid = "74">In this paper, we have presented a feature-based approach for relation extraction where diverse lexical, syntactic and semantic knowledge are employed.</S><S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="211" ssid = "93">Besides, we also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 23 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">However it is reported (Zhou et al., 2005; Kambhatla, 2004) that hierarchical structured syntactic features contributes less to performance improvement.</S> | Reference Offset:  ['41', '20', '3', '130'] | Reference Text:  <S sid ="41" ssid = "12">Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect.</S><S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S><S sid ="3" ssid = "3">Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.</S><S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 24 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['32'] | Citation Marker:  2005 | Citation Offset:  ['31','32'] | Citation Text:  <S sid ="31" ssid = "7">Zhou et al.</S><S sid ="32" ssid = "8">(2005) explore various features in relation extraction using SVM.</S> | Reference Offset:  ['36', '2', '34', '216'] | Reference Text:  <S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S><S sid ="2" ssid = "2">This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="216" ssid = "98">In the future work, we will focus on exploring more semantic knowledge in relation extraction, which has not been covered by current research.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 25 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['36'] | Citation Marker:  2005 | Citation Offset:  ['35','36'] | Citation Text:  <S sid ="35" ssid = "11">The features used in Kambhatla (2004) and Zhou et al.</S><S sid ="36" ssid = "12">(2005) have to be selected and carefully calibrated manually.</S> | Reference Offset:  ['34', '41', '43', '36'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="41" ssid = "12">Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect.</S><S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S><S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 26 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['39'] | Citation Marker:  2005 | Citation Offset:  ['38'] | Citation Text:  <S sid ="38" ssid = "14">Besides, Zhou et al.</S><S sid ="39" ssid = "15">(2005) introduce additional chunking features to enhance the parse tree features.</S> | Reference Offset:  ['86', '97', '195', '140'] | Reference Text:  <S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="97" ssid = "40">This category of features concerns about the information inherent only in the full parse tree.</S><S sid ="195" ssid = "77">While short-distance relations dominate and can be resolved by simple features such as word and chunking features, the further dependency tree and parse tree features can only take effect in the remaining much less and more difficult long-distance relations.</S><S sid ="140" ssid = "22">• To our surprise, incorporating the dependency tree and parse tree features only improve the F- measure by 0.6 and 0.4 respectively.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 27 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['136'] | Citation Marker:  2005 | Citation Offset:  ['135','136'] | Citation Text:  <S sid ="135" ssid = "6">we call the features used in Zhou et al.</S><S sid ="136" ssid = "7">(2005) and Kambhatla (2004) flat feature set.</S> | Reference Offset:  ['131', '132', '34', '133'] | Reference Text:  <S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="133" ssid = "15">• Entity type features are very useful and improve the F-measure by 8.1 largely due to the recall increase.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 28 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['137'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['137'] | Citation Text:  <S sid ="137" ssid = "8">(Zhou et al., 2005), our experiments are carried out on explicit relations due to the poor inter-annotator agreement in annotation of implicit relations and their limited numbers.</S> | Reference Offset:  ['110', '23', '22', '14'] | Reference Text:  <S sid ="110" ssid = "3">In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.</S><S sid ="23" ssid = "23">Implicit relations need not have explicit supporting evidence in text, though they should be evident from a reading of the document.</S><S sid ="22" ssid = "22">explicit relations occur in text with explicit evidence suggesting the relationships.</S><S sid ="14" ssid = "14">The RDC task detects and classifies implicit and explicit relations1 between entities identified by the EDT task.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 29 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['12'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">The first utilizes a set of carefully selected features obtained from different levels of text analysis, from part-of-speech (POS) tagging to full parsing and dependency parsing (Kambhatla, 2004; Zhao and Grishman, 2005; Zhou et al., 2005)1.</S> | Reference Offset:  ['34', '86', '132', '196'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="196" ssid = "78">Second, it is well known that full parsing is always prone to long-distance parsing errors although the Collins’ parser used in our system achieves the state-of-the-art performance.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 30 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['34'] | Citation Marker:  2005 | Citation Offset:  ['33','34'] | Citation Text:  <S sid ="33" ssid = "1">Zhao and Grishman (2005) and Zhou et al.</S><S sid ="34" ssid = "2">(2005) explored a large set of features that are potentially useful for relation extraction.</S> | Reference Offset:  ['4', '34', '37', '216'] | Reference Text:  <S sid ="4" ssid = "4">This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="216" ssid = "98">In the future work, we will focus on exploring more semantic knowledge in relation extraction, which has not been covered by current research.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 31 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['117'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['117'] | Citation Text:  <S sid ="117" ssid = "64">Entity Attributes: Previous studies have shown that entity types and entity mention types of arg 1 and arg 2 are very useful (Zhao and Grishman, 2005; Zhou et al., 2005; Zhang et al., 2006b).</S> | Reference Offset:  ['133', '78', '11', '107'] | Reference Text:  <S sid ="133" ssid = "15">• Entity type features are very useful and improve the F-measure by 8.1 largely due to the recall increase.</S><S sid ="78" ssid = "21">This feature concerns about the entity type of both the mentions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GeoPolitical Entity or GPE: • ET12: combination of mention entity types 4.3 Mention Level.</S><S sid ="11" ssid = "11">In ACE vocabulary, entities are objects, mentions are references to them, and relations are semantic relationships between entities.</S><S sid ="107" ssid = "50">• SC1ET2: combination of the entity type of M2 and the semantic class of M1 when the first mention triggers a personal social subtype.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 32 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['124'] | Citation Marker:  2005 | Citation Offset:  ['122','123','124'] | Citation Text:  <S sid ="122" ssid = "69">Bag-of-Words: These features have also been explore by Zhao and Grishman (2005) and Zhou et.</S><S sid ="123" ssid = "70">al.</S><S sid ="124" ssid = "71">(2005).</S> | Reference Offset:  ['25', '90', '131', '37'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="90" ssid = "33">Similar to word features, three categories of phrase heads are considered: 1) the phrase heads in between are also classified into three bins: the first phrase head in between, the last phrase head in between and other phrase heads in between; 2) the phrase heads before M1 are classified into two bins: the first phrase head before and the second phrase head before; 3) the phrase heads after M2 are classified into two bins: the first phrase head after and the second phrase head after.</S><S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 33 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['132'] | Citation Marker:  2005 | Citation Offset:  ['130','131','132'] | Citation Text:  <S sid ="130" ssid = "77">Dependency Relations and Dependency Paths: These features have been explored by Bunescu and Mooney (2005a), Zhao and Grishman (2005), and Zhou et.</S><S sid ="131" ssid = "78">al.</S><S sid ="132" ssid = "79">(2005).</S> | Reference Offset:  ['25', '33', '24', '37'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="24" ssid = "24">427 Proceedings of the 43rd Annual Meeting of the ACL, pages 427–434, Ann Arbor, June 2005.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 34 | Reference Article:  P05-1053.xml | Citing Article:  N09-3012.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Although in order to achieve the best performance, it is necessary to use a proper combination of these features (Zhou et al., 2005), in this paper, we will concentrate on how to better capture the syntactic features for relation extraction.</S> | Reference Offset:  ['108', '5', '130', '211'] | Reference Text:  <S sid ="108" ssid = "1">This paper uses the ACE corpus provided by LDC to train and evaluate our feature-based relation extraction system.</S><S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S><S sid ="211" ssid = "93">Besides, we also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 35 | Reference Article:  P05-1053.xml | Citing Article:  N13-1093.xml | Citation Marker Offset:  ['73'] | Citation Marker:  2005 | Citation Offset:  ['72','73'] | Citation Text:  <S sid ="72" ssid = "61">The former is Zhou et al.</S><S sid ="73" ssid = "62">(2005), which uses 51 different features.</S> | Reference Offset:  ['131', '132', '100', '163'] | Reference Text:  <S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="100" ssid = "43">Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships.</S><S sid ="163" ssid = "45">This suggests that feature-based methods can effectively combine different features from a variety of sources (e.g. WordNet and gazetteers) that can be brought to bear on relation extraction.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 36 | Reference Article:  P05-1053.xml | Citing Article:  N13-1093.xml | Citation Marker Offset:  ['108'] | Citation Marker:  2005 | Citation Offset:  ['107','108'] | Citation Text:  <S sid ="107" ssid = "11">These experiments are done using Zhou et al.</S><S sid ="108" ssid = "12">(2005), TPWF kernel, SL kernel, different versions of proposed KH F kernel and KH ybrid kernel.</S> | Reference Offset:  ['132', '32', '17', '215'] | Reference Text:  <S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="32" ssid = "3">Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="215" ssid = "97">The experiment result also shows that our feature-based approach outperforms the tree kernel-based approaches by more than 20 F-measure on the extraction of 5 ACE relation types.</S> | Discourse Facet:  Results_Citation | Annotator:  CIST |


Citance Number: 37 | Reference Article:  P05-1053.xml | Citing Article:  N13-1093.xml | Citation Marker Offset:  ['73'] | Citation Marker:   | Citation Offset:  ['72','73'] | Citation Text:  <S sid ="72" ssid = "61">The former is Zhou et al.</S><S sid ="73" ssid = "62">(2005), which uses 51 different features.</S> | Reference Offset:  ['131', '132', '100', '163'] | Reference Text:  <S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="100" ssid = "43">Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships.</S><S sid ="163" ssid = "45">This suggests that feature-based methods can effectively combine different features from a variety of sources (e.g. WordNet and gazetteers) that can be brought to bear on relation extraction.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 38 | Reference Article:  P05-1053.xml | Citing Article:  N13-1093.xml | Citation Marker Offset:  ['113'] | Citation Marker:  2005 | Citation Offset:  ['112','113'] | Citation Text:  <S sid ="112" ssid = "16">We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al.</S><S sid ="113" ssid = "17">(2005), TPWF kernel, SL kernel, PET kernel, KH F kernel and KH ybrid kernel separately (only the results of KH ybrid are reported in Table 1 due to space limitation).</S> | Reference Offset:  ['215', '214', '130', '132'] | Reference Text:  <S sid ="215" ssid = "97">The experiment result also shows that our feature-based approach outperforms the tree kernel-based approaches by more than 20 F-measure on the extraction of 5 ACE relation types.</S><S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S> | Discourse Facet:  Results_Citation | Annotator:  CIST |


Citance Number: 39 | Reference Article:  P05-1053.xml | Citing Article:  N13-1095.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Relation Extraction is a well-studied problem (Miller et al., 2000; Zhou et al., 2005; Kambhatla, 2004; Min et al., 2012a).</S> | Reference Offset:  ['34', '39', '43', '126'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S><S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S><S sid ="126" ssid = "8">In this way, we model relation extraction as a multi-class classification problem with 43 classes, two for each relation subtype (except the above 6 symmetric subtypes) and a “NONE” class for the case where the two mentions are not related.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 40 | Reference Article:  P05-1053.xml | Citing Article:  N13-1095.xml | Citation Marker Offset:  ['13'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">One major challenge in relation extraction is due to the data sparseness problem (Zhou et al 2005).</S> | Reference Offset:  ['214', '126', '38', '184'] | Reference Text:  <S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="126" ssid = "8">In this way, we model relation extraction as a multi-class classification problem with 43 classes, two for each relation subtype (except the above 6 symmetric subtypes) and a “NONE” class for the case where the two mentions are not related.</S><S sid ="38" ssid = "9">Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.</S><S sid ="184" ssid = "66">3 5 5 . 2 4 1 . 6 Parent 2 5 1 7 0 10 0 6 8 . 0 8 1 . 0 System Table 4: Performa nce of different relation types and major subtypes in the test data R e l a t i o n D e t e c t i o n R D C o n T y p e s R D C o n S u b t y p e s P R F P R F P R F Ou rs: fea ture bas ed 8 4.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 41 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['18'] | Citation Marker:   | Citation Offset:  ['18'] | Citation Text:  <S sid ="18" ssid = "18">While various machine learning approaches, such as generative modeling (Miller et al 2000), maximum entropy (Kambhatla 2004) and support vector machines (Zhao and Grisman 2005; Zhou et al 2005), have been applied in the relation extraction task, no explicit learning strategy is proposed to deal with the inherent data sparseness problem caused by the much uneven distribution among different relations.</S> | Reference Offset:  ['214', '30', '36', '39'] | Reference Text:  <S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="30" ssid = "1">The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</S><S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S> | Discourse Facet:  ['Method_Citation', 'Hypthesis_Citation', 'Implication_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 42 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['30'] | Citation Marker:  2005 | Citation Offset:  ['29','30'] | Citation Text:  <S sid ="29" ssid = "2">With the increasing popularity of ACE, this task is starting to attract more and more researchers within the natural language processing and machine learning communities.</S><S sid ="30" ssid = "3">Typical works include Miller et al (2000), Zelenko et al (2003), Culotta and Sorensen (2004), Bunescu and Mooney (2005a), Bunescu and Mooney (2005b), Zhang et al (2005), Roth and Yih (2002), Kambhatla (2004), Zhao and Grisman (2005) and Zhou et al (2005).</S> | Reference Offset:  ['30', '37', '164', '45'] | Reference Text:  <S sid ="30" ssid = "1">The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="164" ssid = "46">The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.</S><S sid ="45" ssid = "1">Support Vector Machines (SVMs) are a supervised machine learning technique motivated by the statistical learning theory (Vapnik 1998).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 43 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['45'] | Citation Marker:  | Citation Offset:  ['45'] | Citation Text:  <S sid ="45" ssid = "18">Zhou et al (2005) further systematically explored diverse lexical, syntactic and semantic features through support vector machines and achieved F- measure of 68.1 and 55.5 on the 5 relation types and the 24 relation subtypes in the ACE RDC 2003 corpus respectively.</S> | Reference Offset:  ['36', '17', '35', '6'] | Reference Text:  <S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="35" ssid = "6">It achieves 52.8 F- measure on the 24 ACE relation subtypes.</S><S sid ="6" ssid = "6">Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 44 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['128'] | Citation Marker:  2005 | Citation Offset:  ['128'] | Citation Text:  <S sid ="128" ssid = "60">Same as Zhou et al (2005), we only model explicit relations and explicitly model the argument order of the two mentions involved.</S> | Reference Offset:  ['59', '123', '110', '142'] | Reference Text:  <S sid ="59" ssid = "2">In addition, we distinguish the argument order of the two mentions (M1 for the first mention and M2 for the second mention), e.g. M1-Parent- Of-M2 vs. M2-Parent-Of-M1.</S><S sid ="123" ssid = "5">Type Subtype Freq Residence 308 Other 6 ROLE(4756) General-Staff 1331 Management 1242 Member 1091 Owner 232 Other 158 SOCIAL(827) Associate 91 Grandparent 12 Other-Personal 85 Spouse 77 Table 1: Relation types and subtypes in the ACE training data In this paper, we explicitly model the argument order of the two mentions involved.</S><S sid ="110" ssid = "3">In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.</S><S sid ="142" ssid = "24">Table 3 shows that about 70% of relations exist where two mentions are embedded in each other or separated by at most one word.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 45 | Reference Article:  P05-1053.xml | Citing Article:  P06-1017.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Many machine learning methods have been proposed to address this problem, e.g., supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithms (Hasegawa et al., 2004).</S> | Reference Offset:  ['45', '31', '33', '44'] | Reference Text:  <S sid ="45" ssid = "1">Support Vector Machines (SVMs) are a supervised machine learning technique motivated by the statistical learning theory (Vapnik 1998).</S><S sid ="31" ssid = "2">Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 46 | Reference Article:  P05-1053.xml | Citing Article:  P06-1017.xml | Citation Marker Offset:  ['199'] | Citation Marker:  2005 | Citation Offset:  ['198','199'] | Citation Text:  <S sid ="198" ssid = "9">Bootstrapping Currently most of works on the RDC task of ACE focused on supervised learning methods Culotta and Soresen (2004; Kambhatla (2004; Zhou et al.</S><S sid ="199" ssid = "10">(2005).</S> | Reference Offset:  ['25', '164', '44', '43'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="164" ssid = "46">The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.</S><S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S><S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 47 | Reference Article:  P05-1053.xml | Citing Article:  P06-1017.xml | Citation Marker Offset:  ['199'] | Citation Marker:  2005 | Citation Offset:  ['198','199'] | Citation Text:  <S sid ="198" ssid = "9">Bootstrapping Currently most of works on the RDC task of ACE focused on supervised learning methods Culotta and Soresen (2004; Kambhatla (2004; Zhou et al.</S><S sid ="199" ssid = "10">(2005).</S> | Reference Offset:  ['25', '164', '44', '43'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="164" ssid = "46">The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.</S><S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S><S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 48 | Reference Article:  P05-1053.xml | Citing Article:  P06-1017.xml | Citation Marker Offset:  ['207'] | Citation Marker:  2005 | Citation Offset:  ['206','207'] | Citation Text:  <S sid ="206" ssid = "17">In the future, we would like to use more effective feature sets Zhou et al.</S><S sid ="207" ssid = "18">(2005) or kernel based similarity measure with LP for relation extraction.</S> | Reference Offset:  ['212', '3', '132', '131'] | Reference Text:  <S sid ="212" ssid = "94">The effective incorporation of diverse features enables our system outperform previously best- reported systems on the ACE corpus.</S><S sid ="3" ssid = "3">Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 49 | Reference Article:  P05-1053.xml | Citing Article:  P06-1104.xml | Citation Marker Offset:  ['35'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['35'] | Citation Text:  <S sid ="35" ssid = "1">Many techniques on relation extraction, such as rule-based (MUC, 19871998; Miller et al., 2000), feature-based (Kambhatla 2004; Zhou et al., 2005) and kernel-based (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005), have been proposed in the literature.</S> | Reference Offset:  ['32', '37', '44', '33'] | Reference Text:  <S sid ="32" ssid = "3">Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 50 | Reference Article:  P05-1053.xml | Citing Article:  P06-1104.xml | Citation Marker Offset:  ['39'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "5">Feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Zhao and Grishman, 20052 ) for this task employ a large amount of diverse linguistic features, such as lexical, syntactic and semantic features.</S> | Reference Offset:  ['40', '17', '192', '2'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="192" ssid = "74">In this paper, we have presented a feature-based approach for relation extraction where diverse lexical, syntactic and semantic knowledge are employed.</S><S sid ="2" ssid = "2">This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.</S> | Discourse Facet:  ['Method_Citation', 'Implication_Citation'] | Annotator:  CIST |


Citance Number: 51 | Reference Article:  P05-1053.xml | Citing Article:  P06-2012.xml | Citation Marker Offset:  ['5'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['5'] | Citation Text:  <S sid ="5" ssid = "5">Many methods have been proposed to deal with this task, including supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithm (Hasegawa et al., 2004).</S> | Reference Offset:  ['45', '37', '31', '33'] | Reference Text:  <S sid ="45" ssid = "1">Support Vector Machines (SVMs) are a supervised machine learning technique motivated by the statistical learning theory (Vapnik 1998).</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="31" ssid = "2">Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 52 | Reference Article:  P05-1053.xml | Citing Article:  P08-2023.xml | Citation Marker Offset:  ['29'] | Citation Marker:  2005 | Citation Offset:  ['29','30'] | Citation Text:  <S sid ="29" ssid = "9">Based on his work, Zhou et al (2005)</S><S sid ="30" ssid = "10">further incorporated the base phrase chunking information and semi-automatically collected country name list and personal relative trigger word list.</S> | Reference Offset:  ['86', '193', '155', '102'] | Reference Text:  <S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="193" ssid = "75">Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance.</S><S sid ="155" ssid = "37">This is largely due to incorporation of two semantic resources, i.e. the country name list and the personal relative trigger word list.</S><S sid ="102" ssid = "45">Two features are defined to include this information: • ET1Country: the entity type of M1 when M2 is a country name • CountryET2: the entity type of M2 when M1 is a country name 5 http://ilk.kub.nl/~sabine/chunklink/ Personal Relative Trigger Word List This is used to differentiate the six personal social relation subtypes in ACE: Parent, Grandparent, Spouse, Sibling, Other-Relative and Other- Personal.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 53 | Reference Article:  P05-1053.xml | Citing Article:  P09-1113.xml | Citation Marker Offset:  ['39'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "39">While syntactic features are known to improve the performance of supervised IE, at least using clean hand-labeled ACE data (Zhou et al., 2007; Zhou et al., 2005), we do not know whether syntactic features can improve the performance of unsupervised or distantly supervised IE.</S> | Reference Offset:  ['130', '132', '193', '17'] | Reference Text:  <S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="193" ssid = "75">Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 54 | Reference Article:  P05-1053.xml | Citing Article:  P09-1113.xml | Citation Marker Offset:  ['52'] | Citation Marker:  2005 | Citation Offset:  ['50','51','52'] | Citation Text:  <S sid ="50" ssid = "10">More recent approaches have used deeper syntactic information derived from parses of the input sentences, including work exploiting syntactic dependencies by Lin and Pantel (2001) and Snow et al.</S><S sid ="51" ssid = "11">(2005), and work in the ACE paradigm such as Zhou et al.</S><S sid ="52" ssid = "12">(2005) and Zhou et al.</S><S sid ="53" ssid = "13">(2007).</S> | Reference Offset:  ['25', '33', '39', '24'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S><S sid ="24" ssid = "24">427 Proceedings of the 43rd Annual Meeting of the ACL, pages 427–434, Ann Arbor, June 2005.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 55 | Reference Article:  P05-1053.xml | Citing Article:  P09-1114.xml | Citation Marker Offset:  ['25'] | Citation Marker:  2005 | Citation Offset:  ['23','24','25'] | Citation Text:  <S sid ="23" ssid = "1">Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods.</S><S sid ="24" ssid = "2">Zhou et al.</S><S sid ="25" ssid = "3">(2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction.</S> | Reference Offset:  ['5', '3', '215', '216'] | Reference Text:  <S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="3" ssid = "3">Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement.</S><S sid ="215" ssid = "97">The experiment result also shows that our feature-based approach outperforms the tree kernel-based approaches by more than 20 F-measure on the extraction of 5 ACE relation types.</S><S sid ="216" ssid = "98">In the future work, we will focus on exploring more semantic knowledge in relation extraction, which has not been covered by current research.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 56 | Reference Article:  P05-1053.xml | Citing Article:  P09-1114.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Recent work on relation extraction has shown that supervised machine learning coupled with intelligent feature engineering or kernel design provides state-of-the-art solutions to the problem (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008).</S> | Reference Offset:  ['44', '37', '34', '36'] | Reference Text:  <S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 57 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Then the feature based method explicitly extracts a variety of lexical, syntactic and semantic features for statistical learning, either generative or discriminative (Miller et al., 2000; Kambhatla, 2004; Boschee et al., 2005; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007).</S> | Reference Offset:  ['41', '31', '130', '36'] | Reference Text:  <S sid ="41" ssid = "12">Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect.</S><S sid ="31" ssid = "2">Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</S><S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S><S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 58 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['81'] | Citation Marker:  2005 | Citation Offset:  ['80','81'] | Citation Text:  <S sid ="80" ssid = "44">We first adopted the full feature set from Zhou et al.</S><S sid ="81" ssid = "45">(2005), a state-of-the-art feature based relation extraction system.</S> | Reference Offset:  ['86', '34', '6', '132'] | Reference Text:  <S sid ="86" ssid = "29">In this paper, we separate the features of base phrase chunking from those of full parsing.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="6" ssid = "6">Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 59 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['86'] | Citation Marker:  2005 | Citation Offset:  ['85','86'] | Citation Text:  <S sid ="85" ssid = "49">In addition, we cherry-picked the following features which were not included in Zhou et al.</S><S sid ="86" ssid = "50">(2005) but were shown to be quite effective for relation extraction.</S> | Reference Offset:  ['215', '132', '80', '4'] | Reference Text:  <S sid ="215" ssid = "97">The experiment result also shows that our feature-based approach outperforms the tree kernel-based approaches by more than 20 F-measure on the extraction of 5 ACE relation types.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="80" ssid = "23">This category of features includes: • #MB: number of other mentions in between • #WB: number of words in between • M1&gt;M2 or M1&lt;M2: flag indicating whether M2/M1is included in M1/M2.</S><S sid ="4" ssid = "4">This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 60 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['193'] | Citation Marker:  2005 | Citation Offset:  ['193'] | Citation Text:  <S sid ="193" ssid = "157">Zhou et al.</S><S sid ="194" ssid = "158">(2005) tested their system on the ACE 2003 data;.</S> | Reference Offset:  ['129', '44', '184', '212'] | Reference Text:  <S sid ="129" ssid = "11">Table 2 measures the performance of our relation extrac tion system over the 43 ACE relation subtypes on the testing set.</S><S sid ="44" ssid = "15">It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.</S><S sid ="184" ssid = "66">3 5 5 . 2 4 1 . 6 Parent 2 5 1 7 0 10 0 6 8 . 0 8 1 . 0 System Table 4: Performa nce of different relation types and major subtypes in the test data R e l a t i o n D e t e c t i o n R D C o n T y p e s R D C o n S u b t y p e s P R F P R F P R F Ou rs: fea ture bas ed 8 4.</S><S sid ="212" ssid = "94">The effective incorporation of diverse features enables our system outperform previously best- reported systems on the ACE corpus.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 61 | Reference Article:  P05-1053.xml | Citing Article:  P11-1056.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['11'] | Citation Text:  <S sid ="11" ssid = "11">However, most approaches to RE have assumed that the relationsâ€™ arguments are given as input (Chan and Roth, 2010; Jiang and Zhai, 2007; Jiang, 2009; Zhou et al., 2005), and therefore offer only a partial solution to the problem.</S> | Reference Offset:  ['214', '25', '38', '39'] | Reference Text:  <S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="38" ssid = "9">Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 62 | Reference Article:  P05-1053.xml | Citing Article:  P11-1056.xml | Citation Marker Offset:  ['58'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['58'] | Citation Text:  <S sid ="58" ssid = "19">Most prior RE evaluation on ACE data assumed that mentions are already pre-annotated and given as input (Chan and Roth, 2010; Jiang and Zhai, 2007; Zhou et al., 2005).</S> | Reference Offset:  ['214', '128', '43', '213'] | Reference Text:  <S sid ="214" ssid = "96">Evaluation on the ACE RDC task shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relation types with a relatively small amount of annotated data.</S><S sid ="128" ssid = "10">In this paper, we only measure the performance of relation extraction on “true” mentions with “true” chaining of coreference (i.e. as annotated by the corpus annotators) in the ACE corpus.</S><S sid ="43" ssid = "14">Evaluation on the ACE corpus shows that our system outperforms Kambhatla (2004) by about 3 F-measure on extracting 24 ACE relation subtypes.</S><S sid ="213" ssid = "95">Although tree kernel-based approaches facilitate the exploration of the implicit feature space with the parse tree structure, yet the current technologies are expected to be further advanced to be effective for relatively complicated relation extraction tasks such as the one defined in ACE where 5 types and 24 subtypes need to be extracted.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 63 | Reference Article:  P05-1053.xml | Citing Article:  P11-3012.xml | Citation Marker Offset:  ['34'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['34'] | Citation Text:  <S sid ="34" ssid = "7">We used Zhou et al.â€™s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010).</S> | Reference Offset:  ['130', '212', '132', '36'] | Reference Text:  <S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S><S sid ="212" ssid = "94">The effective incorporation of diverse features enables our system outperform previously best- reported systems on the ACE corpus.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="36" ssid = "7">Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 64 | Reference Article:  P05-1053.xml | Citing Article:  P11-3012.xml | Citation Marker Offset:  ['47'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['47'] | Citation Text:  <S sid ="47" ssid = "4">Although a bit lower than Zhou et al.â€™s result of 55.5 (Zhou et al., 2005), we attribute the difference to our use of a different tokenizer, different parser, and having not used the semantic information features.</S> | Reference Offset:  ['100', '5', '211', '106'] | Reference Text:  <S sid ="100" ssid = "43">Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships.</S><S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="211" ssid = "93">Besides, we also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="106" ssid = "49">Two features are defined to include this information: • ET1SC2: combination of the entity type of M1 and the semantic class of M2 when M2 triggers a personal social subtype.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 65 | Reference Article:  P05-1053.xml | Citing Article:  P11-3012.xml | Citation Marker Offset:  ['47'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['47'] | Citation Text:  <S sid ="47" ssid = "4">Although a bit lower than Zhou et al.â€™s result of 55.5 (Zhou et al., 2005), we attribute the difference to our use of a different tokenizer, different parser, and having not used the semantic information features.</S> | Reference Offset:  ['100', '5', '211', '106'] | Reference Text:  <S sid ="100" ssid = "43">Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships.</S><S sid ="5" ssid = "5">We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="211" ssid = "93">Besides, we also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance.</S><S sid ="106" ssid = "49">Two features are defined to include this information: • ET1SC2: combination of the entity type of M1 and the semantic class of M2 when M2 triggers a personal social subtype.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 66 | Reference Article:  P05-1053.xml | Citing Article:  P13-1147.xml | Citation Marker Offset:  ['167'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['167'] | Citation Text:  <S sid ="167" ssid = "10">This is slightly behind that of Zhang (2006); the reason might be threefold: i) different data partitioning; ii) different pre-processing; iii) they incorporate features from additional sources, i.e. a phrase chunker, dependency parser and semantic resources (Zhou et al., 2005) (we have on average 9 features/instance, they use 40).</S> | Reference Offset:  ['93', '132', '100', '131'] | Reference Text:  <S sid ="93" ssid = "36">This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="100" ssid = "43">Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships.</S><S sid ="131" ssid = "13">Table 2 also measures the contributions of different features by gradually increasing the feature set.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 67 | Reference Article:  P05-1053.xml | Citing Article:  W06-1634.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">Techniques based on machine learning (Zhou et al., 2005; Hao et al., 2005; Bunescu and Mooney, 2006) are expected to alleviate this problem in manually crafted IE.</S> | Reference Offset:  ['45', '52', '30', '46'] | Reference Text:  <S sid ="45" ssid = "1">Support Vector Machines (SVMs) are a supervised machine learning technique motivated by the statistical learning theory (Vapnik 1998).</S><S sid ="52" ssid = "8">The reason why we choose SVMs for this purpose is that SVMs represent the state-of–the-art in the machine learning research community, and there are good implementations of the algorithm available.</S><S sid ="30" ssid = "1">The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</S><S sid ="46" ssid = "2">Based on the structural risk minimization of the statistical learning theory, SVMs seek an optimal separating hyper-plane to divide the training examples into two classes and make decisions based on support vectors which are selected as the only effective instances in the training set.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 68 | Reference Article:  P05-1053.xml | Citing Article:  W06-1634.xml | Citation Marker Offset:  ['17'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['17'] | Citation Text:  <S sid ="17" ssid = "2">A technique that many previous approaches have used is shallow parsing (Koike et al., 2003; Yao et al., 2004; Zhou et al., 2005).</S> | Reference Offset:  ['4', '32', '37', '25'] | Reference Text:  <S sid ="4" ssid = "4">This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.</S><S sid ="32" ssid = "3">Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S> | Discourse Facet:  ['Method_Citation', 'Implication_Citation'] | Annotator:  CIST |


Citance Number: 69 | Reference Article:  P05-1053.xml | Citing Article:  W06-1667.xml | Citation Marker Offset:  ['8'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['8'] | Citation Text:  <S sid ="8" ssid = "8">Prior work on automatic relation extraction come in three kinds: supervised learning algorithms (Miller et al., 2000; Zelenko et al., 2002; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), semi-supervised learning algorithms (Brin, 1998; Agichtein and Gravano, 2000; Zhang, 2004), and unsupervised learning algorithm (Hasegawa et al., 2004).</S> | Reference Offset:  ['30', '33', '34', '37'] | Reference Text:  <S sid ="30" ssid = "1">The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</S><S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 70 | Reference Article:  P05-1053.xml | Citing Article:  W06-1667.xml | Citation Marker Offset:  ['174'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['174'] | Citation Text:  <S sid ="174" ssid = "110">Especially, although we did not concern the dependency tree and full parse tree information as other supervised methods (Miller et al., 2000; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), the incorporation of simple features, such as words and chunking information, still can provide complement information for capturing the characteristics of entity pairs.</S> | Reference Offset:  ['93', '97', '31', '4'] | Reference Text:  <S sid ="93" ssid = "36">This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.</S><S sid ="97" ssid = "40">This category of features concerns about the information inherent only in the full parse tree.</S><S sid ="31" ssid = "2">Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</S><S sid ="4" ssid = "4">This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 71 | Reference Article:  P05-1053.xml | Citing Article:  W08-0602.xml | Citation Marker Offset:  ['39'] | Citation Marker:  2005 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "39">This follows on from the success of these methods in general NLP (see for example Zhou et al (2005)).</S> | Reference Offset:  ['25', '179', '15', '81'] | Reference Text:  <S sid ="25" ssid = "25">Qc 2005 Association for Computational Linguistics ture-based approach outperforms tree kernel-based approaches by 11 F-measure in relation detection and more than 20 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="179" ssid = "61">8 6 9 . 4 7 2 . 6 General Staff 2 0 1 1 0 8 4 6 71.</S><S sid ="15" ssid = "15">For example, we want to determine whether a person is at a location, based on the evidence in the context.</S><S sid ="81" ssid = "24">Normally, the above overlap features are too general to be effective alone.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 72 | Reference Article:  P05-1053.xml | Citing Article:  W08-0602.xml | Citation Marker Offset:  ['136'] | Citation Marker:  2005 | Citation Offset:  ['136'] | Citation Text:  <S sid ="136" ssid = "51">We use features developed in part from those described in Zhou et al (2005) and Wang et al (2006).</S> | Reference Offset:  ['28', '132', '133', '212'] | Reference Text:  <S sid ="28" ssid = "28">Section 3 and Section 4 describe our approach and various features employed respectively.</S><S sid ="132" ssid = "14">It shows that: Features P R F Words 69.2 23.7 35.3 +Entity Type 67.1 32.1 43.4 +Mention Level 67.1 33.0 44.2 +Overlap 57.4 40.9 47.8 +Chunking 61.5 46.5 53.0 +Dependency Tree 62.1 47.2 53.6 +Parse Tree 62.3 47.6 54.0 +Semantic Resources 63.1 49.5 55.5 Table 2: Contribution of different features over 43 relation subtypes in the test data • Using word features only achieves the performance of 69.2%/23.7%/35.3 in precision/recall/F- measure.</S><S sid ="133" ssid = "15">• Entity type features are very useful and improve the F-measure by 8.1 largely due to the recall increase.</S><S sid ="212" ssid = "94">The effective incorporation of diverse features enables our system outperform previously best- reported systems on the ACE corpus.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 73 | Reference Article:  P05-1053.xml | Citing Article:  W11-1101.xml | Citation Marker Offset:  ['203'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['203'] | Citation Text:  <S sid ="203" ssid = "11">A variety of features have been explored for ERD in previous research (Zhou et al., 2005; Zhou et al., 2008; Jiang and Zhai, 2007; Miller et al., 2000).</S> | Reference Offset:  ['37', '39', '163', '216'] | Reference Text:  <S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S><S sid ="163" ssid = "45">This suggests that feature-based methods can effectively combine different features from a variety of sources (e.g. WordNet and gazetteers) that can be brought to bear on relation extraction.</S><S sid ="216" ssid = "98">In the future work, we will focus on exploring more semantic knowledge in relation extraction, which has not been covered by current research.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 74 | Reference Article:  P05-1053.xml | Citing Article:  W11-1101.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Researchers have used supervised and semi-supervised approaches (Hasegawa et al., 2004; Mintz et al., 2009; Jiang, 2009), and explored rich features (Kambhatla, 2004), kernel design (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008) and inference algorithms (Chan and Roth, 2011), to detect predefined relations between NEs.</S> | Reference Offset:  ['33', '37', '34', '24'] | Reference Text:  <S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S><S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="24" ssid = "24">427 Proceedings of the 43rd Annual Meeting of the ACL, pages 427–434, Ann Arbor, June 2005.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 75 | Reference Article:  P05-1053.xml | Citing Article:  W11-1815.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">BB task example Ureaplasma parvum is a mycoplasma and a pathogenic biology challenges (Kim et al., 2010) and geographical locations (Zhou et al., 2005).</S> | Reference Offset:  ['15', '39', '14', '12'] | Reference Text:  <S sid ="15" ssid = "15">For example, we want to determine whether a person is at a location, based on the evidence in the context.</S><S sid ="39" ssid = "10">Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model.</S><S sid ="14" ssid = "14">The RDC task detects and classifies implicit and explicit relations1 between entities identified by the EDT task.</S><S sid ="12" ssid = "12">Entities can be of five types: persons, organizations, locations, facilities and geopolitical entities (GPE: geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |