Citance Number: 1 | Reference Article:   P05-1004.xml | Citing Article:  C10-2101.xml | Citation Marker Offset:  ['74'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['74'] | Citation Text:  <S sid ="74" ssid = "44">Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).</S> | Reference Offset:  ['68', '20', '35', '71'] | Reference Text:  <S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="35" ssid = "9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S><S sid ="71" ssid = "4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:   P05-1004.xml | Citing Article:  E09-1045.xml | Citation Marker Offset:  ['23'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['23'] | Citation Text:  <S sid ="23" ssid = "23">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['71', '3', '229', '65'] | Reference Text:  <S sid ="71" ssid = "4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S><S sid ="3" ssid = "3">Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</S><S sid ="229" ssid = "5">Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson (2003).</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 3 | Reference Article:   P05-1004.xml | Citing Article:  J07-4005.xml | Citation Marker Offset:  ['229'] | Citation Marker:  2005 | Citation Offset:  ['229'] | Citation Text:  <S sid ="229" ssid = "72">Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.</S> | Reference Offset:  ['2', '36', '68', '147'] | Reference Text:  <S sid ="2" ssid = "2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S><S sid ="36" ssid = "10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="147" ssid = "1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 4 | Reference Article:   P05-1004.xml | Citing Article:  J09-3004.xml | Citation Marker Offset:  ['446'] | Citation Marker:  Curran 2005 | Citation Offset:  ['446'] | Citation Text:  <S sid ="446" ssid = "30">An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.</S> | Reference Offset:  ['11', '18', '1', '14'] | Reference Text:  <S sid ="11" ssid = "11">Bur- gun and Bodenreider (2001) compared an alignment of WORDNET with the UMLS medical resource and found only a very small degree of overlap.</S><S sid ="18" ssid = "18">These problems demonstrate the need for automatic or semiautomatic methods for the creation and maintenance of lexical-semantic resources.</S><S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S><S sid ="14" ssid = "14">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:   P05-1004.xml | Citing Article:  N06-1017.xml | Citation Marker Offset:  ['26'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['26'] | Citation Text:  <S sid ="26" ssid = "26">There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.</S> | Reference Offset:  ['1', '147', '108', '148'] | Reference Text:  <S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S><S sid ="147" ssid = "1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="148" ssid = "2">This technique is similar to Hearst and Schu¨ tze (1993) and Widdows (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 6 | Reference Article:   P05-1004.xml | Citing Article:  N06-1017.xml | Citation Marker Offset:  ['189'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['189'] | Citation Text:  <S sid ="189" ssid = "11">Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.</S> | Reference Offset:  ['42', '148', '62', '106'] | Reference Text:  <S sid ="42" ssid = "16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S><S sid ="148" ssid = "2">This technique is similar to Hearst and Schu¨ tze (1993) and Widdows (2003).</S><S sid ="62" ssid = "15">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S sid ="106" ssid = "20">JACCARD and TTEST produced better quality synonyms than existing measures in the literature, so we use Curran and Moen’s configuration for our super- sense tagging experiments.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 7 | Reference Article:   P05-1004.xml | Citing Article:  N07-1024.xml | Citation Marker Offset:  ['83'] | Citation Marker:  Curran 2005 | Citation Offset:  ['83'] | Citation Text:  <S sid ="83" ssid = "3">While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)</S> | Reference Offset:  ['2', '47', '108', '1'] | Reference Text:  <S sid ="2" ssid = "2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S><S sid ="47" ssid = "21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="1" ssid = "1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 8 | Reference Article:   P05-1004.xml | Citing Article:  P12-2050.xml | Citation Marker Offset:  ['15'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃŸ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.</S> | Reference Offset:  ['20', '68', '14', '2'] | Reference Text:  <S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="14" ssid = "14">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S><S sid ="2" ssid = "2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 9 | Reference Article:   P05-1004.xml | Citing Article:  S07-1032.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">Thus, some research has been focused on deriving different sense groupings to overcome the fineâ€“ grained distinctions of WN (Hearst and SchuÂ¨ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['65', '171', '42', '3'] | Reference Text:  <S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S><S sid ="171" ssid = "1">We have used the WORDNET 1.6 test set to experiment with different parameter settings and have kept the WORDNET 1.7.1 test set as a final comparison of best results with Ciaramita and Johnson (2003).</S><S sid ="42" ssid = "16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S><S sid ="3" ssid = "3">Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 10 | Reference Article:   P05-1004.xml | Citing Article:  S10-1090.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['3', '71', '229', '65'] | Reference Text:  <S sid ="3" ssid = "3">Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</S><S sid ="71" ssid = "4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S><S sid ="229" ssid = "5">Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson (2003).</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 11 | Reference Article:   P05-1004.xml | Citing Article:  S12-1011.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).</S> | Reference Offset:  ['26', '108', '10', '96'] | Reference Text:  <S sid ="26" ssid = "26">Qc 2005 Association for Computational Linguistics L E X -FI L E D E S C R I P T I O N act acts or actions animal animals artifact man-made objects attribute attributes of people and objects body body parts cognition cognitive processes and contents communication communicative processes and contents event natural events feeling feelings and emotions food foods and drinks group groupings of people or objects location spatial position motive goals object natural objects (not man-made) person people phenomenon natural phenomena plant plants possession possession and transfer of possession process natural processes quantity quantities and units of measure relation relations between people/things/ideas shape two and three dimensional shapes state stable states of affairs substance substances time time and temporal relations Table 1: 25 noun lexicographer files in WORDNET</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="10" ssid = "10">Technical domains, such as medicine, require separate treatment since common words often take on special meanings, and a significant proportion of their vocabulary does not overlap with everyday vocabulary.</S><S sid ="96" ssid = "10">Curran and Moens (2002a) compared several different similarity measures and found that Grefenstette’s weighted JACCARD measure performed the best: R E L AT I O N D E S C R I P T I O N adj noun–adjectival modifier relation dobj verb–direct object relation iobj verb–indirect object relation nn noun–noun modifier relation nnprep noun–prepositional head relation subj verb–subject relation Table 4: Grammatical relations from SEXTANT against the CELEX lexical database (Minnen et al., 2001) – and is very efficient, analysing over 80 000 words per second.</S> | Discourse Facet:  ['Method_Citation', 'Hypothesis_Citation'] | Annotator:  CIST |


Citance Number: 12 | Reference Article:   P05-1004.xml | Citing Article:  S12-1011.xml | Citation Marker Offset:  ['50'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['50'] | Citation Text:  <S sid ="50" ssid = "2">Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelâ€™s ability to cluster words by their semantics.</S> | Reference Offset:  ['68', '20', '44', '35'] | Reference Text:  <S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="44" ssid = "18">Supersense tagging can provide automated or semi- automated assistance to lexicographers adding words to the WORDNET hierarchy.</S><S sid ="35" ssid = "9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 13 | Reference Article:   P05-1004.xml | Citing Article:  S12-1023.xml | Citation Marker Offset:  ['234'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['234'] | Citation Text:  <S sid ="234" ssid = "15">A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.</S> | Reference Offset:  ['198', '108', '106', '65'] | Reference Text:  <S sid ="198" ssid = "28">This is not surprising since these concrete words tend to have very fewer other senses, well constrained contexts and a relatively high frequency.</S><S sid ="108" ssid = "22">Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</S><S sid ="106" ssid = "20">JACCARD and TTEST produced better quality synonyms than existing measures in the literature, so we use Curran and Moen’s configuration for our super- sense tagging experiments.</S><S sid ="65" ssid = "18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet:  ['Method_Citation', 'Aim_Citation'] | Annotator:  CIST |


Citance Number: 14 | Reference Article:   P05-1004.xml | Citing Article:  W06-1670.xml | Citation Marker Offset:  ['94'] | Citation Marker:  Curran, 2005 | Citation Offset:  ['94'] | Citation Text:  <S sid ="94" ssid = "12">Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.</S> | Reference Offset:  ['68', '20', '35', '225'] | Reference Text:  <S sid ="68" ssid = "1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S sid ="20" ssid = "20">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S><S sid ="35" ssid = "9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S><S sid ="225" ssid = "1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and Schu¨ tze (1993) and Widdows (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |