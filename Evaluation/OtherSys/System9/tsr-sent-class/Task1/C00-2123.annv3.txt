Citance Number: 1 | Reference Article: C00-2123.xml | Citing Article: C02-1050.xml | Citation Marker Offset: ['41'] | Citation Marker: 2000 | Citation Offset: ['41'] | Citation Text: <S sid ="39" ssid = "19">Under this constraint, many researchers had contributed algorithms and associated pruning strategies, such as Berger et al.</S><S sid ="40" ssid = "20">(1996), Och et al.</S><S sid ="41" ssid = "21">(2001), Wang and Waibel (1997), Tillmann and Ney (2000) GarciaVarea and Casacuberta (2001) and Germann et al.</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 5 | Reference Article: C00-2123.xml | Citing Article: C04-1091.xml | Citation Marker Offset: ['22'] | Citation Marker: Tillman and Ney, 2000 | Citation Offset: ['22'] | Citation Text: <S sid ="22" ssid = "22">Tillman and Ney showed how to improve the complexity of the Held-Karp algorithm for restricted word reordering and gave a O (l3m4) ≈ O (m7) algo rithm for French-English translation (Tillman and Ney, 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 6 | Reference Article: C00-2123.xml | Citing Article: E06-1004.xml | Citation Marker Offset: ['22'] | Citation Marker: Tillman, 2000 | Citation Offset: ['22'] | Citation Text: <S sid ="21" ssid = "21">â€¢ Conditional Probability Given the model parameters and a sentence pair (f , e), compute P (f | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 7 | Reference Article: C00-2123.xml | Citing Article: H01-1062.xml | Citation Marker Offset: ['113'] | Citation Marker: 20 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "16">To summarize these experimental tests, we briefly report experimental offline results for the following translation approaches: â€¢ single-word based approach [20];</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 8 | Reference Article: C00-2123.xml | Citing Article: J03-1005.xml | Citation Marker Offset: ['117'] | Citation Marker: 2000 | Citation Offset: ['115','117'] | Citation Text: <S sid ="115" ssid = "73">This article will present a DP-based beam search decoder for the IBM4 translation model.</S><S sid ="117" ssid = "75">A preliminary version of the work presented here was published in Tillmann and Ney (2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 9 | Reference Article: C00-2123.xml | Citing Article: J04-2003.xml | Citation Marker Offset: ['35'] | Citation Marker: Tillmann and Ney 2000 | Citation Offset: ['35'] | Citation Text: <S sid ="35" ssid = "35">Many existing systems for statistical machine translation 1 1 (Garc´ıa-Varea and Casacuberta 2001; Germann et al. 2001; Nießen et al. 1998; Och, Tillmann, and Ney 1999) implement models presented by Brown, Della Pietra, Della Pietra, and Mercer (1993): The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position.</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 11 | Reference Article: C00-2123.xml | Citing Article: J04-4002.xml | Citation Marker Offset: ['282'] | Citation Marker: Tillmann and Ney 2000 | Citation Offset: ['282'] | Citation Text: <S sid ="282" ssid = "48">We call this selection of highly probable words observation pruning (Tillmann and Ney 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 12 | Reference Article: C00-2123.xml | Citing Article: N03-1010.xml | Citation Marker Offset: ['16'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "16">Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 13 | Reference Article: C00-2123.xml | Citing Article: P01-1027.xml | Citation Marker Offset: ['127'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['127'] | Citation Text: <S sid ="127" ssid = "34">We use the top-10 list of hypothesis provided by the translation system described in (Tillmann and Ney, 2000) for rescoring the hypothesis using the ME models and sort them according to the new maximum entropy score.</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 14 | Reference Article: C00-2123.xml | Citing Article: P03-1039.xml | Citation Marker Offset: ['113'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "22">The decoding algorithm employed for this chunk + weight Ã— j f req(EA j , J j ) based statistical translation is based on the beam search algorithm for word alignment statistical in which Ptm(J|E) and Plm (E) are translationmodel and language model probability, respec translation presented in (Tillmann and Ney, 2000), tively1 , f req(EA j , J j ) is the frequency for the which generates outputs in left-to-right order by consuming input in an arbitrary order.</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 16 | Reference Article: C00-2123.xml | Citing Article: W01-0505.xml | Citation Marker Offset: ['13'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['13'] | Citation Text: <S sid ="13" ssid = "13">They were usually incorporated in the EM algorithm (Brown et al., 1993; Kupiec, 1993; Tillmann and Ney, 2000; Och et al., 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 17 | Reference Article: C00-2123.xml | Citing Article: W01-1404.xml | Citation Marker Offset: ['5'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['5'] | Citation Text: <S sid ="5" ssid = "5">Some of these studies have concentrated on finite-state or extended finite-state machinery, such as (Vilar and others, 1999), others have chosen models closer to context-free grammars and context-free transduction, such as (Alshawi et al., 2000; Watanabe et al., 2000; Yamamoto and Matsumoto, 2000), and yet other studies cannot be comfortably assigned to either of these two frameworks, such as (Brown and others, 1990) and (Tillmann and Ney, 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 18 | Reference Article: C00-2123.xml | Citing Article: W01-1407.xml | Citation Marker Offset: ['110'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['110'] | Citation Text: <S sid ="110" ssid = "26">We used a translation system called â€œsingle- word based approachâ€ described in (Tillmann and Ney, 2000) and compared to other approaches in (Ney et al., 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 19 | Reference Article: C00-2123.xml | Citing Article: W01-1408.xml | Citation Marker Offset: ['47'] | Citation Marker: Tillmann, 2001; Tillmann and Ney, 2000 | Citation Offset: ['47'] | Citation Text: <S sid ="47" ssid = "23">Search algorithms We evaluate the following two search algorithms: â€¢ beam search algorithm (BS): (Tillmann, 2001; Tillmann and Ney, 2000) In this algorithm the search space is explored in a breadth-first manner.</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

Citance Number: 20 | Reference Article: C00-2123.xml | Citing Article: W02-1020.xml | Citation Marker Offset: ['62'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['61','62'] | Citation Text: <S sid ="61" ssid = "19">It is faster because the search problem for noisy- channel models is NP-complete (Knight, 1999), and even the fastest dynamic-programming heuristics used in statistical MT (Niessen et al., 1998; Till- mann and Ney, 2000), are polynomial in J —for in p(v1, w2</S><S sid ="62" ssid = "20">, wm−1, um|h, s) = stance O(mJ 4V 3) in (Tillmann and Ney, 2000).</S> | Reference Offset: ['6'] | Reference Text: <S sid="6" ssid="6">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S> | Discourse Facet: Method | Annotator: TSR_Sent_Class | 

