As successful as our seed set of features is, it still does not achieve the accuracy of a supervised learner. 
We instead proposed a semi-supervised method in which a seed set of verbs is chosen for training a supervised classifier, from which the useful features are extracted for use in clustering. 
We have explored manual, unsupervised, and semi- supervised methods for feature selection in a clustering approach for verb class discovery. 
Furthermore, we might question the clustering approach itself, in the context of verb class discovery. 
In moving to a scenario of verb class discovery, using clustering, we face the problem of having a large number of irrelevant features for a particular clustering task. 
Our feature set is essentially a generalization of theirs, but in scaling up the feature space to be useful across English verb classes in general, we necessarily face a dimensionality problem that did not arise in their research. 
However, Schulte im Waldeâ€™s features rely on accurate subcategorization statistics, and her experiments include a much larger set of classes. 
We cluster verbs into lexical semantic classes, using a general set of noisy features that capture syntactic and semantic properties of the verbs. 
We find that manual selection of a subset of features based on the known classification performs better than using a full set of noisy features, demonstrating the potential benefit of feature selection in our task. 
Following Stevenson and Joanis, we selected 20 verbs from each class which occur at least 100 times in our corpus. 
