 Citance Number: 1 | Reference Article: P05-1004.xml | Citing Article: C10-2101.xml | Citation Marker Offset: ['74'] | Citation Marker: Curran, 2005 | Citation Offset: ['74'] | Citation Text: <S sid="74" ssid="44">Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).</S> | Reference Offset: ['35' , '38' , '36' , '42' , '43' , '40' , '47' , '44' , '71' , '225' ] | Reference Text: <S sid="35" ssid="9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S> <S sid="38" ssid="12">Ciaramita et al.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> <S sid="42" ssid="16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S> <S sid="43" ssid="17">They suggest that supersense tagging is similar to named entity recognition, which also has a very small set of categories with similar granularity (e.g. location and person) for labelling predominantly unseen terms.</S> <S sid="40" ssid="14">Other alternative sets of supersenses can be created by an arbitrary cut through the WORDNET hierarchy near the top, or by using topics from a thesaurus such as Roget?s (Yarowsky, 1992).</S> <S sid="47" ssid="21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S> <S sid="44" ssid="18">Supersense tagging can provide automated or semi- automated assistance to lexicographers adding words to the WORDNET hierarchy.</S> <S sid="71" ssid="4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S> <S sid="225" ssid="1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and Schu? tze (1993) and Widdows (2003).</S>  | Discourse Facet: Method_Citation | Annotator: Mark Able, Re |
 Citance Number: 10 | Reference Article: P05-1004.xml | Citing Article: S10-1090.xml | Citation Marker Offset: ['16'] | Citation Marker: Curran, 2005 | Citation Offset: ['16'] | Citation Text: <S sid="16" ssid="16">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset: ['38' , '71' ] | Reference Text: <S sid="38" ssid="12">Ciaramita et al.</S> <S sid="71" ssid="4">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 11 | Reference Article: P05-1004.xml | Citing Article: S12-1011.xml | Citation Marker Offset: ['6'] | Citation Marker: Curran, 2005 | Citation Offset: ['6'] | Citation Text: <S sid="6" ssid="6">Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).</S> | Reference Offset: ['10' , '13' , '16' ] | Reference Text: <S sid="10" ssid="10">Technical domains, such as medicine, require separate treatment since common words often take on special meanings, and a significant proportion of their vocabulary does not overlap with everyday vocabulary.</S> <S sid="13" ssid="13">Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses.</S> <S sid="16" ssid="16">consistency when classifying similar words into categories.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 12 | Reference Article: P05-1004.xml | Citing Article: S12-1011.xml | Citation Marker Offset: ['50'] | Citation Marker: Curran, 2005 | Citation Offset: ['50'] | Citation Text: <S sid="50" ssid="2">Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a model?s ability to cluster words by their semantics.</S> | Reference Offset: ['2' , '35' , '38' , '36' , '42' , '43' , '40' , '47' , '44' , '225' ] | Reference Text: <S sid="2" ssid="2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S> <S sid="35" ssid="9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S> <S sid="38" ssid="12">Ciaramita et al.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> <S sid="42" ssid="16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S> <S sid="43" ssid="17">They suggest that supersense tagging is similar to named entity recognition, which also has a very small set of categories with similar granularity (e.g. location and person) for labelling predominantly unseen terms.</S> <S sid="40" ssid="14">Other alternative sets of supersenses can be created by an arbitrary cut through the WORDNET hierarchy near the top, or by using topics from a thesaurus such as Roget?s (Yarowsky, 1992).</S> <S sid="47" ssid="21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S> <S sid="44" ssid="18">Supersense tagging can provide automated or semi- automated assistance to lexicographers adding words to the WORDNET hierarchy.</S> <S sid="225" ssid="1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and Schu? tze (1993) and Widdows (2003).</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 13 | Reference Article: P05-1004.xml | Citing Article: S12-1023.xml | Citation Marker Offset: ['234'] | Citation Marker: Curran, 2005 | Citation Offset: ['234'] | Citation Text: <S sid="234" ssid="15">A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.</S> | Reference Offset: ['13' ] | Reference Text: <S sid="13" ssid="13">Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 14 | Reference Article: P05-1004.xml | Citing Article: W06-1670.xml | Citation Marker Offset: ['94'] | Citation Marker: Curran, 2005 | Citation Offset: ['94'] | Citation Text: <S sid="94" ssid="12">Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.</S> | Reference Offset: ['22' , '35' , '38' , '36' , '42' , '43' , '40' , '47' , '44' , '120' , '122' , '225' ] | Reference Text: <S sid="22" ssid="22">Instead, we use vector-space similarity to retrieve a number of synonyms for each unknown common noun.</S> <S sid="35" ssid="9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S> <S sid="38" ssid="12">Ciaramita et al.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> <S sid="42" ssid="16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S> <S sid="43" ssid="17">They suggest that supersense tagging is similar to named entity recognition, which also has a very small set of categories with similar granularity (e.g. location and person) for labelling predominantly unseen terms.</S> <S sid="40" ssid="14">Other alternative sets of supersenses can be created by an arbitrary cut through the WORDNET hierarchy near the top, or by using topics from a thesaurus such as Roget?s (Yarowsky, 1992).</S> <S sid="47" ssid="21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S> <S sid="44" ssid="18">Supersense tagging can provide automated or semi- automated assistance to lexicographers adding words to the WORDNET hierarchy.</S> <S sid="120" ssid="34">This corresponds to assuming right-branching noun compounds.</S> <S sid="122" ssid="36">Pass 2: Noun Post-modifiers This pass scans NPs, right to left, creating post-modifier GRs between the unattached heads of NPs and PPs.</S> <S sid="225" ssid="1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and Schu? tze (1993) and Widdows (2003).</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 2 | Reference Article: P05-1004.xml | Citing Article: E09-1045.xml | Citation Marker Offset: ['23'] | Citation Marker: Curran, 2005 | Citation Offset: ['23'] | Citation Text: <S sid="23" ssid="23">Qc 2009 Association for Computational Linguistics In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset: ['38' ] | Reference Text: <S sid="38" ssid="12">Ciaramita et al.</S>  | Discourse Facet: Method_Citation | Annotator: Mark Able, Re |
 Citance Number: 3 | Reference Article: P05-1004.xml | Citing Article: J07-4005.xml | Citation Marker Offset: ['229'] | Citation Marker: 2005 | Citation Offset: ['229'] | Citation Text: <S sid="229" ssid="72">Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.</S> | Reference Offset: ['7' , '11' , '14' , '17' , '19' , '22' , '36' , '37' , '120' , '122' ] | Reference Text: <S sid="7" ssid="7">In particular, WORDNET (Fellbaum, 1998) has significantly influenced research in NLP.</S> <S sid="11" ssid="11">Bur- gun and Bodenreider (2001) compared an alignment of WORDNET with the UMLS medical resource and found only a very small degree of overlap.</S> <S sid="14" ssid="14">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S> <S sid="17" ssid="17">For instance, the WORDNET lexicographer file for ionosphere (location) is different to exo- sphere and stratosphere (object), two other layers of the earth?s atmosphere.</S> <S sid="19" ssid="19">Broad semantic classification is currently used by lexicographers to or- ganise the manual insertion of words into WORDNET, and is an experimental precursor to automatically inserting words directly into the WORDNET hierarchy.</S> <S sid="22" ssid="22">Instead, we use vector-space similarity to retrieve a number of synonyms for each unknown common noun.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> <S sid="37" ssid="11">Ciaramita (2002) has produced a mini- WORDNET by manually reducing the WORDNET hierarchy to 106 broad categories.</S> <S sid="120" ssid="34">This corresponds to assuming right-branching noun compounds.</S> <S sid="122" ssid="36">Pass 2: Noun Post-modifiers This pass scans NPs, right to left, creating post-modifier GRs between the unattached heads of NPs and PPs.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 4 | Reference Article: P05-1004.xml | Citing Article: J09-3004.xml | Citation Marker Offset: ['446'] | Citation Marker: Curran 2005 | Citation Offset: ['446'] | Citation Text: <S sid="446" ssid="30">An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.</S> | Reference Offset: ['7' , '10' , '17' , '19' , '36' ] | Reference Text: <S sid="7" ssid="7">In particular, WORDNET (Fellbaum, 1998) has significantly influenced research in NLP.</S> <S sid="10" ssid="10">Technical domains, such as medicine, require separate treatment since common words often take on special meanings, and a significant proportion of their vocabulary does not overlap with everyday vocabulary.</S> <S sid="17" ssid="17">For instance, the WORDNET lexicographer file for ionosphere (location) is different to exo- sphere and stratosphere (object), two other layers of the earth?s atmosphere.</S> <S sid="19" ssid="19">Broad semantic classification is currently used by lexicographers to or- ganise the manual insertion of words into WORDNET, and is an experimental precursor to automatically inserting words directly into the WORDNET hierarchy.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 5 | Reference Article: P05-1004.xml | Citing Article: N06-1017.xml | Citation Marker Offset: ['26'] | Citation Marker: Curran, 2005 | Citation Offset: ['26'] | Citation Text: <S sid="26" ssid="26">There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.</S> | Reference Offset: ['16' , '22' ] | Reference Text: <S sid="16" ssid="16">consistency when classifying similar words into categories.</S> <S sid="22" ssid="22">Instead, we use vector-space similarity to retrieve a number of synonyms for each unknown common noun.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 6 | Reference Article: P05-1004.xml | Citing Article: N06-1017.xml | Citation Marker Offset: ['189'] | Citation Marker: Curran, 2005 | Citation Offset: ['189'] | Citation Text: <S sid="189" ssid="11">Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.</S> | Reference Offset: ['13' ] | Reference Text: <S sid="13" ssid="13">Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 7 | Reference Article: P05-1004.xml | Citing Article: N07-1024.xml | Citation Marker Offset: ['83'] | Citation Marker: Curran 2005 | Citation Offset: ['83'] | Citation Text: <S sid="83" ssid="3">While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005), it has been used in only one previous study on semantic classification of Chinese unknown words (Chen and Lin,2000).</S> | Reference Offset: ['2' , '10' , '13' , '16' , '19' , '22' ] | Reference Text: <S sid="2" ssid="2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S> <S sid="10" ssid="10">Technical domains, such as medicine, require separate treatment since common words often take on special meanings, and a significant proportion of their vocabulary does not overlap with everyday vocabulary.</S> <S sid="13" ssid="13">Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses.</S> <S sid="16" ssid="16">consistency when classifying similar words into categories.</S> <S sid="19" ssid="19">Broad semantic classification is currently used by lexicographers to or- ganise the manual insertion of words into WORDNET, and is an experimental precursor to automatically inserting words directly into the WORDNET hierarchy.</S> <S sid="22" ssid="22">Instead, we use vector-space similarity to retrieve a number of synonyms for each unknown common noun.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 8 | Reference Article: P05-1004.xml | Citing Article: P12-2050.xml | Citation Marker Offset: ['15'] | Citation Marker: Curran, 2005 | Citation Offset: ['15'] | Citation Text: <S sid="15" ssid="15">More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paa? and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.</S> | Reference Offset: ['2' , '7' , '17' , '19' , '21' , '35' , '38' , '36' , '42' , '43' , '40' , '47' , '44' , '225' ] | Reference Text: <S sid="2" ssid="2">Supersense tagging assigns unknown nouns one of 26 broad semantic categories used by lexicographers to organise their manual insertion into WORDNET.</S> <S sid="7" ssid="7">In particular, WORDNET (Fellbaum, 1998) has significantly influenced research in NLP.</S> <S sid="17" ssid="17">For instance, the WORDNET lexicographer file for ionosphere (location) is different to exo- sphere and stratosphere (object), two other layers of the earth?s atmosphere.</S> <S sid="19" ssid="19">Broad semantic classification is currently used by lexicographers to or- ganise the manual insertion of words into WORDNET, and is an experimental precursor to automatically inserting words directly into the WORDNET hierarchy.</S> <S sid="21" ssid="21">This paper describes an unsupervised approach to supersense tagging that does not require annotated sentences.</S> <S sid="35" ssid="9">Ciaramita and Johnson (2003) call the noun lex-file classes supersenses.</S> <S sid="38" ssid="12">Ciaramita et al.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> <S sid="42" ssid="16">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S> <S sid="43" ssid="17">They suggest that supersense tagging is similar to named entity recognition, which also has a very small set of categories with similar granularity (e.g. location and person) for labelling predominantly unseen terms.</S> <S sid="40" ssid="14">Other alternative sets of supersenses can be created by an arbitrary cut through the WORDNET hierarchy near the top, or by using topics from a thesaurus such as Roget?s (Yarowsky, 1992).</S> <S sid="47" ssid="21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S> <S sid="44" ssid="18">Supersense tagging can provide automated or semi- automated assistance to lexicographers adding words to the WORDNET hierarchy.</S> <S sid="225" ssid="1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and Schu? tze (1993) and Widdows (2003).</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
 Citance Number: 9 | Reference Article: P05-1004.xml | Citing Article: S07-1032.xml | Citation Marker Offset: ['16'] | Citation Marker: Curran, 2005 | Citation Offset: ['16'] | Citation Text: <S sid="16" ssid="16">Thus, some research has been focused on deriving different sense groupings to overcome the fine? grained distinctions of WN (Hearst and Schu? tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset: ['13' , '38' ] | Reference Text: <S sid="13" ssid="13">Some specialist topics are better covered in WORD- NET than others, e.g. dog has finer-grained distinctions than cat and worm although this does not reflect finer distinctions in reality; limited coverage of infrequent words and senses.</S> <S sid="38" ssid="12">Ciaramita et al.</S>  | Discourse Facet: Method_Citation | Annotator: Sweta Kumari |
