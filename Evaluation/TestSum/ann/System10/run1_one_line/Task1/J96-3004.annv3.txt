 Citance Number: 1 | Reference Article: J96-3004.xml | Citing Article: A00-2032.xml | Citation Marker Offset: ['142'] | Citation Marker: 1996 | Citation Offset: ['141'] | Citation Text: <S sid="141" ssid="10">Chinese According to Sproat et al.</S> | Reference Offset: ['51' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '181' , '199' , '197' , '228' , '221' , '244' , '264' , '51' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '181' , '199' , '197' , '228' , '221' , '244' , '264' ] | Reference Text: <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="181" ssid="45">4.2 A Sample Segmentation Using Only Dictionary Words Figure 4 shows two possible paths from the lattice of possible analyses of the input sentence B X:? .:.S:P:l 'How do you say octopus in Japanese?' previously shown in Figure 1.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="181" ssid="45">4.2 A Sample Segmentation Using Only Dictionary Words Figure 4 shows two possible paths from the lattice of possible analyses of the input sentence B X:? .:.S:P:l 'How do you say octopus in Japanese?' previously shown in Figure 1.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 10 | Reference Article: J96-3004.xml | Citing Article: J00-3004.xml | Citation Marker Offset: ['42'] | Citation Marker: 1996 | Citation Offset: ['42'] | Citation Text: <S sid="42" ssid="42">According to Sproat et al. {1996) and Wu and Fung {1994), experiments show that only about 75% agreement between native speakers is to be expected on the "correct" segmentation, and the figure reduces as more people become involved.</S> | Reference Offset: ['1' , '36' , '38' , '51' , '53' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '143' , '185' , '183' , '199' , '197' , '219' , '244' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="38" ssid="38">Many hanzi have more than one pronunciation, where the correct.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S> <S sid="185" ssid="49">Both of these analyses are shown in Figure 4; fortunately, the correct analysis is also the one with the lowest cost, so it is this analysis that is chosen.</S> <S sid="183" ssid="47">As indicated in Figure 1(c), apart from this correct analysis, there is also the analysis taking B ri4 as a word (e.g., a common abbreviation for Japan), along with X:? wen2zhangl 'essay/ and f!!.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="219" ssid="83">An analysis of nouns that occur in both the singular and the plural in our database reveals that there is indeed a slight but significant positive correlation-R2 = 0.20, p < 0.005; see Figure 6.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 11 | Reference Article: J96-3004.xml | Citing Article: J00-3004.xml | Citation Marker Offset: ['96'] | Citation Marker: 1996 | Citation Offset: ['96'] | Citation Text: <S sid="96" ssid="41">Sproat et al.</S> | Reference Offset: ['199' , '244' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 12 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['53'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['53'] | Citation Text: <S sid="53" ssid="53">In Chinese text segmentation there are three basic approaches (Sproat et al. 1996): pure heuristic, pure statistical, and a hybrid of the two.</S> | Reference Offset: ['1' , '20' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '199' , '197' , '228' , '221' , '244' , '264' , '350' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 13 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['113'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['113'] | Citation Text: <S sid="113" ssid="9">There are several commonly used segmentation methods such as forward maximum matching and backward maximum matching(Teahan et al. 2000; Dai, Loh, and Khoo 1999; Sproat et al. 1996).</S> | Reference Offset: ['36' , '53' , '52' , '93' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '165' , '173' , '199' , '197' , '244' , '310' ] | Reference Text: <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="93" ssid="31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="165" ssid="29">The segmentation chosen is the best path through the WFST, shown in (d).</S> <S sid="173" ssid="37">In any event, to date, we have not compared different methods for deriving the set of initial frequency estimates.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="310" ssid="19">The method being described-henceforth ST..</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 14 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['211'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['211'] | Citation Text: <S sid="211" ssid="32">In addition, there is no commonly accepted standard for evaluating the performance of word extraction methods, and it is very hard to decide whether a word is meaningful or not (Sproat et al. 1996).</S> | Reference Offset: ['23' , '31' , '91' , '166' , '157' , '174' , '199' , '201' , '200' , '191' , '216' , '205' , '244' , '460' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="157" ssid="21">Each word is terminated by an arc that represents the transduction between f and the part of speech of that word, weighted with an estimated cost for that word.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 15 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['321'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['321'] | Citation Text: <S sid="321" ssid="7">As even human judges differ when facing the task of segmenting a text into words and test corpora differ from system to system (Sproat et al. 1996), it is very difficult to compare two methods.</S> | Reference Offset: ['1' , '23' , '31' , '91' , '136' , '130' , '166' , '172' , '174' , '199' , '201' , '200' , '191' , '216' , '205' , '222' , '244' , '252' , '350' , '460' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="136" ssid="74">Furthermore, even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus: as Fung and Wu (1994) have shown, one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="172" ssid="36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic? ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="222" ssid="86">attaching to terms denoting human beings.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 16 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['88'] | Citation Marker: 1996 | Citation Offset: ['88'] | Citation Text: <S sid="88" ssid="24">A previous work along this line is Sproat et al.</S> | Reference Offset: ['199' , '244' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 17 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['126'] | Citation Marker: 1996 | Citation Offset: ['125'] | Citation Text: <S sid="125" ssid="61">As shown in Sproat et al.</S> | Reference Offset: ['199' , '244' , '350' , '199' , '244' , '350' , '458' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 18 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['132'] | Citation Marker: 1996 | Citation Offset: ['131'] | Citation Text: <S sid="131" ssid="67">Similarly, Sproat et al.</S> | Reference Offset: ['199' , '244' , '350' , '138' , '199' , '244' , '350' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S> <S sid="138" ssid="2">More formally, we start by representing the dictionary D as a Weighted Finite State Trans? ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 19 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['490'] | Citation Marker: 1996 | Citation Offset: ['489'] | Citation Text: <S sid="489" ssid="153">The Chinese person-name model is a modified version of that described in Sproat et al.</S> | Reference Offset: ['20' , '91' , '133' , '128' , '199' , '228' , '221' , '218' , '249' , '244' , '264' , '401' , '460' , '20' , '91' , '133' , '128' , '199' , '228' , '221' , '218' , '249' , '244' , '264' , '401' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="401" ssid="4">handled given appropriate models.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S> <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="401" ssid="4">handled given appropriate models.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 2 | Reference Article: J96-3004.xml | Citing Article: A00-2032.xml | Citation Marker Offset: ['5'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['5'] | Citation Text: <S sid="5" ssid="5">Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting optical character recognition (OCR) er? rors (Wu and Tseng, 1993; Nagao and Mori, 1994; Nagata, 1996a; Nagata, 1996b; Sproat et al., 1996; Fung, 1998).</S> | Reference Offset: ['1' , '53' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '143' , '199' , '197' , '244' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 20 | Reference Article: J96-3004.xml | Citing Article: J11-1005.xml | Citation Marker Offset: ['123'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['123'] | Citation Text: <S sid="123" ssid="14">Experiments have shown that there is only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al. 1996).</S> | Reference Offset: ['23' , '31' , '36' , '38' , '51' , '53' , '52' , '91' , '113' , '112' , '117' , '132' , '134' , '133' , '135' , '128' , '130' , '129' , '143' , '166' , '201' , '200' , '197' , '191' , '216' , '208' , '205' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="38" ssid="38">Many hanzi have more than one pronunciation, where the correct.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="132" ssid="70">For example Chen and Liu (1992) report precision and recall rates of over 99%, but this counts only the words that occur in the test corpus that also occur in their dictionary.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="208" ssid="72">Finally, as? suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i?1J1l.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 21 | Reference Article: J96-3004.xml | Citing Article: J11-3001.xml | Citation Marker Offset: ['326'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['326'] | Citation Text: <S sid="326" ssid="279">Gold standards, however, 435 cannot be uni?ed into a single standard (Fung and Wu 1994; Sproat et al. 1996).</S> | Reference Offset: ['199' , '244' , '253' , '458' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="253" ssid="117">Other good classes include JADE and GOLD; other bad classes are DEATH and RAT.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 23 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['9'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['9'] | Citation Text: <S sid="9" ssid="9">Since in written Chinese there is no explicit word delimiter (equivalent to the blank space in written English), the problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made (e.g., Bai 1995; Zhang et al. 1994; Chen and Liu 1992; Chiang et al. 1992; Fan and Tsai 1988; Gan 1995; Gan, Palmer, and Lua 1996; Guo 1993; He, Xu, and Sun 1991; Huang 1989; Huang and Xia 1996; Jie 1989; Jie, Liu, and Liang 1991a, 1991b; Jin and Chen 1995; Lai et al. 1992; Li et al. 1995; Liang 1986, 1987, 1990; Liu 1986a, 1986b; Liu, Tan, and Shen 1994; Lua 1990, 1994, and 1995; Ma 1996; Nie, Jin, and Hannan 1994; Sproat and Shih 1990; Sproat et al. 1996; Sun and T'sou 1995; Sun and Huang 1996; Tung and Lee 1994; Wang, Su, and Mo 1990; Wang 1989; Wang, Wang, and Bai 1991; Wong et al. 1995; Wong et al. 1994; Wu et al. 1994; Wu and Su 1993; Yao, Zhang, and Wu 1990; Yeh and Lee 1991; Zhang, Chen, and Chen 1991).</S> | Reference Offset: ['31' , '91' ] | Reference Text: <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 24 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['515'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['515'] | Citation Text: <S sid="515" ssid="92">The three tokenization definitions in this section are essentially descriptive restatements of the corresponding constructive tokenization procedures, which in turn are realiza? tions of the widely followed principle of maximum tokenization (e.g., Liu 1986; Liang 1986a, 1986b; Wang 1989; Jie 1989; Wang, Su, and Mo 1990; Jie, Liu, and Liang 1991a, b; Yeh and Lee 1991; Webster and Kit 1992; Chen and Liu 1992; Guo 1993; Wu and Su 1993; Nie, Jin, and Hannan 1994; Sproat et al. 1996; Wu et al. 1994; Li et al. 1995; Sun and T'sou 1995; Wong et al. 1995; Bai 1995; Sun and Huang 1996).</S> | Reference Offset: ['91' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 25 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['613'] | Citation Marker: 1996 | Citation Offset: ['612'] | Citation Text: <S sid="612" ssid="54">The weighted finite-state transducer model developed by Sproat et al.</S> | Reference Offset: ['199' , '190' , '218' , '249' , '244' , '458' , '199' , '190' , '218' , '249' , '244' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="190" ssid="54">The morphological anal?ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="190" ssid="54">The morphological anal?ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 26 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['621'] | Citation Marker: 1996 | Citation Offset: ['621'] | Citation Text: <S sid="621" ssid="63">While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching, they are ap? parently employed neither in Sproat et al.</S> | Reference Offset: ['37' , '199' , '244' ] | Reference Text: <S sid="37" ssid="37">However, there are several reasons why this approach will not in general work: 1.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 27 | Reference Article: J96-3004.xml | Citing Article: N10-1068.xml | Citation Marker Offset: ['6'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['6'] | Citation Text: <S sid="6" ssid="6">Many natural language models can be captured by weighted finite-state transducers (Pereira et al., 1994; Sproat et al., 1996; Knight and AlOnaizan, 1998; Clark, 2002; Kolak et al., 2003; Mathias and Byrne, 2006), which offer several benefits:? WFSTs provide a uniform knowledge represen tation.</S> | Reference Offset: ['91' , '190' , '218' , '249' , '244' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="190" ssid="54">The morphological anal?ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 28 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['41'] | Citation Marker: 1996 | Citation Offset: ['41'] | Citation Text: <S sid="41" ssid="18">One example of such approaches is Sproat et al.</S> | Reference Offset: ['37' , '199' , '244' , '458' ] | Reference Text: <S sid="37" ssid="37">However, there are several reasons why this approach will not in general work: 1.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 29 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['122'] | Citation Marker: 1996 | Citation Offset: ['122'] | Citation Text: <S sid="122" ssid="27">Because any character strings can be in principle named entities of one or more types, to limit the number of candidates for a more effective search, we generate named entity candidates, given an input string, in two steps: First, for each type, we use a set of constraints (which are compiled by 3 Sproat et al.</S> | Reference Offset: ['1' , '91' , '199' , '191' , '229' , '228' , '247' , '244' , '243' , '281' , '252' , '250' , '257' , '260' , '258' , '259' , '264' , '262' , '284' , '285' , '291' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="247" ssid="111">Yet, some hanzi are far more probable in women's names than they are in men's names, and there is a similar list of male-oriented hanzi: mixing hanzi from these two lists is generally less likely than would be predicted by the independence model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="250" ssid="114">For previously unseen hanzi in given names, Chang et al. assign a uniform small cost; but we know that some unseen hanzi are merely acci? dentally missing, whereas others are missing for a reason-for example, because they have a bad connotation.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="258" ssid="122">hanzi in the various name positions, derived from a million names.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 3 | Reference Article: J96-3004.xml | Citing Article: C00-2095.xml | Citation Marker Offset: ['80'] | Citation Marker: Sproat ct a.l., 1996 | Citation Offset: ['80'] | Citation Text: <S sid="80" ssid="25">As (Sproat ct a.l., 1996) testify, several native Chinese speakers do not always agree on one unique tokeniza.tion for a. given sentence.</S> | Reference Offset: ['199' , '210' , '223' , '244' , '458' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="210" ssid="74">The cost estimate, cost(i?JJ1l.fn is computed in the obvious way by summing the negative log probabilities of i?JJ1l.</S> <S sid="223" ssid="87">However, it is possible to personify any noun, so in children's stories or fables, i?JJ1l.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 30 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['155'] | Citation Marker: 1996 | Citation Offset: ['155'] | Citation Text: <S sid="155" ssid="60">(1996): FNs are usually transliterated using Chinese character strings whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Reference Offset: ['20' , '133' , '128' , '191' , '228' , '221' , '281' , '264' , '285' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 31 | Reference Article: J96-3004.xml | Citing Article: P06-1010.xml | Citation Marker Offset: ['43'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['43'] | Citation Text: <S sid="43" ssid="11">As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese.</S> | Reference Offset: ['20' , '91' , '133' , '128' , '229' , '228' , '221' , '247' , '243' , '281' , '252' , '250' , '257' , '260' , '258' , '259' , '264' , '262' , '283' , '284' , '285' , '291' , '328' , '410' , '20' , '91' , '133' , '128' , '229' , '228' , '221' , '247' , '243' , '281' , '252' , '250' , '257' , '260' , '258' , '259' , '264' , '262' , '283' , '284' , '285' , '291' , '328' , '410' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="247" ssid="111">Yet, some hanzi are far more probable in women's names than they are in men's names, and there is a similar list of male-oriented hanzi: mixing hanzi from these two lists is generally less likely than would be predicted by the independence model.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="250" ssid="114">For previously unseen hanzi in given names, Chang et al. assign a uniform small cost; but we know that some unseen hanzi are merely acci? dentally missing, whereas others are missing for a reason-for example, because they have a bad connotation.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="258" ssid="122">hanzi in the various name positions, derived from a million names.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="283" ssid="147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 'Shamir,' which is a legal Chi? nese personal name, retains a foreign flavor because of liM.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="410" ssid="13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S> <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="247" ssid="111">Yet, some hanzi are far more probable in women's names than they are in men's names, and there is a similar list of male-oriented hanzi: mixing hanzi from these two lists is generally less likely than would be predicted by the independence model.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="250" ssid="114">For previously unseen hanzi in given names, Chang et al. assign a uniform small cost; but we know that some unseen hanzi are merely acci? dentally missing, whereas others are missing for a reason-for example, because they have a bad connotation.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="258" ssid="122">hanzi in the various name positions, derived from a million names.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="283" ssid="147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 'Shamir,' which is a legal Chi? nese personal name, retains a foreign flavor because of liM.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="410" ssid="13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 32 | Reference Article: J96-3004.xml | Citing Article: P06-1126.xml | Citation Marker Offset: ['7'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['7'] | Citation Text: <S sid="7" ssid="7">Chinese word segmentation is the initial stage of many Chinese language processing tasks, and has received a lot of attention in the literature (Sproat et al., 1996; Sun and Tsou, 2001; Zhang et al., 2003; Peng et al., 2004).</S> | Reference Offset: ['1' , '31' , '36' , '51' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '125' , '128' , '130' , '129' , '166' , '183' , '172' , '197' , '191' , '205' , '228' , '221' , '264' , '440' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="125" ssid="63">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac? tually tag the words as belonging to one or another class of expression.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="183" ssid="47">As indicated in Figure 1(c), apart from this correct analysis, there is also the analysis taking B ri4 as a word (e.g., a common abbreviation for Japan), along with X:? wen2zhangl 'essay/ and f!!.</S> <S sid="172" ssid="36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic? ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="440" ssid="43">Turning now to (1), we have the similar problem that splitting.into.ma3 'horse' andlu4 'way' is more costly than retaining this as one word .ma3lu4 'road.'</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 33 | Reference Article: J96-3004.xml | Citing Article: P07-1015.xml | Citation Marker Offset: ['113'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['113'] | Citation Text: <S sid="113" ssid="21">Using the 495 characters that are frequently used for transliterating foreign names (Sproat et al., 1996), a sequence of three of more characters from the list was taken as a possible candidate for Chinese.</S> | Reference Offset: ['20' , '91' , '133' , '128' , '229' , '228' , '221' , '247' , '243' , '281' , '252' , '250' , '257' , '260' , '258' , '259' , '264' , '262' , '283' , '284' , '285' , '291' , '435' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="247" ssid="111">Yet, some hanzi are far more probable in women's names than they are in men's names, and there is a similar list of male-oriented hanzi: mixing hanzi from these two lists is generally less likely than would be predicted by the independence model.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="250" ssid="114">For previously unseen hanzi in given names, Chang et al. assign a uniform small cost; but we know that some unseen hanzi are merely acci? dentally missing, whereas others are missing for a reason-for example, because they have a bad connotation.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="258" ssid="122">hanzi in the various name positions, derived from a million names.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="283" ssid="147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 'Shamir,' which is a legal Chi? nese personal name, retains a foreign flavor because of liM.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S> <S sid="435" ssid="38">For the examples given in (1) and (2) this certainly seems possible.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 34 | Reference Article: J96-3004.xml | Citing Article: P07-1016.xml | Citation Marker Offset: ['70'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['70'] | Citation Text: <S sid="70" ssid="42">As discussed elsewhere (Sproat et al., 1996), out of several thousand common Chinese characters, a subset of a few hundred characters tends to be used overwhelmingly for transliterating English names to Chinese, e.g. only 731 Chinese characters are adopted in the E-C corpus.</S> | Reference Offset: ['20' , '73' , '91' , '133' , '128' , '229' , '228' , '221' , '247' , '243' , '273' , '281' , '252' , '250' , '257' , '260' , '258' , '259' , '264' , '262' , '284' , '285' , '287' , '291' , '410' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="73" ssid="11">A Brief Introduction to the Chinese Writing System Most readers will undoubtedly be at least somewhat familiar with the nature of the Chinese writing system, but there are enough common misunderstandings that it is as well to spend a few paragraphs on properties of the Chinese script that will be relevant to topics discussed in this paper.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="247" ssid="111">Yet, some hanzi are far more probable in women's names than they are in men's names, and there is a similar list of male-oriented hanzi: mixing hanzi from these two lists is generally less likely than would be predicted by the independence model.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="273" ssid="137">In the numerator, however, the counts of ni1s are quite irregular, in? cluding several zeros (e.g., RAT, none of whose members were seen).</S> <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="250" ssid="114">For previously unseen hanzi in given names, Chang et al. assign a uniform small cost; but we know that some unseen hanzi are merely acci? dentally missing, whereas others are missing for a reason-for example, because they have a bad connotation.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="258" ssid="122">hanzi in the various name positions, derived from a million names.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="287" ssid="151">For instance, the common "suffixes," -nia (e.g.,.</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S> <S sid="410" ssid="13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 35 | Reference Article: J96-3004.xml | Citing Article: P12-1110.xml | Citation Marker Offset: ['105'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['105'] | Citation Text: <S sid="105" ssid="53">3.3.1 Dictionary features Because segmentation using a dictionary alone can serve as a strong baseline in Chinese word segmentation (Sproat et al., 1996), the use of dictionaries is expected to make our joint model more robust and enables us to investigate the contribution of the syntactic dependency in a more realistic setting.</S> | Reference Offset: ['23' , '31' , '52' , '88' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '125' , '128' , '130' , '129' , '166' , '201' , '197' , '191' , '212' , '208' , '228' , '221' , '218' , '249' , '244' , '264' , '284' , '286' , '458' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="88" ssid="26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="125" ssid="63">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac? tually tag the words as belonging to one or another class of expression.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="208" ssid="72">Finally, as? suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i?1J1l.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 36 | Reference Article: J96-3004.xml | Citing Article: P12-1111.xml | Citation Marker Offset: ['91'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['91'] | Citation Text: <S sid="91" ssid="31">In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996).</S> | Reference Offset: ['3' , '23' , '31' , '91' , '166' , '199' , '201' , '200' , '191' , '216' , '212' , '205' , '218' , '249' , '244' , '245' , '243' , '264' , '286' , '401' , '415' ] | Reference Text: <S sid="3" ssid="3">For a language like English, this problem is generally regarded as trivial since words are delimited in English text by whitespace or marks of punctuation.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.'s model, which we improve upon.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S> <S sid="401" ssid="4">handled given appropriate models.</S> <S sid="415" ssid="18">The major problem for our seg? menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 37 | Reference Article: J96-3004.xml | Citing Article: P97-1041.xml | Citation Marker Offset: ['12'] | Citation Marker: 1996 | Citation Offset: ['12'] | Citation Text: <S sid="12" ssid="12">For a discussion of recent Chinese segmentation work, see Sproat et al. {1996).</S> | Reference Offset: ['23' , '36' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '197' , '228' , '221' , '264' , '458' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 38 | Reference Article: J96-3004.xml | Citing Article: P97-1041.xml | Citation Marker Offset: ['39'] | Citation Marker: 1996 | Citation Offset: ['39'] | Citation Text: <S sid="39" ssid="5">It is rule-based, but relies on 2 See, for example, Sproat et al.</S> | Reference Offset: ['91' , '199' , '244' , '460' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 39 | Reference Article: J96-3004.xml | Citing Article: P98-1076.xml | Citation Marker Offset: ['145'] | Citation Marker: 1996 | Citation Offset: ['144'] | Citation Text: <S sid="144" ssid="11">The actual implementation of the weighted finite? state transducer by Sproat et al.</S> | Reference Offset: ['199' , '244' , '458' , '199' , '244' ] | Reference Text: <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 4 | Reference Article: J96-3004.xml | Citing Article: C02-1049.xml | Citation Marker Offset: ['58'] | Citation Marker: Sproat et al, 1996 | Citation Offset: ['58'] | Citation Text: <S sid="58" ssid="39">Conventionally a word segmentation process identifies the words in input text by matching lexical entries and resolving the ambiguous matching (Chen & Liu, 1992, Sproat et al, 1996).</S> | Reference Offset: ['1' , '23' , '31' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '244' , '240' , '350' , '415' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="240" ssid="104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: ? the probability that a word chosen randomly from a text will be a name-p(rule 1), and ? the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and ? the probability that the family name is the particular hanzi F1-p(rule 6), and ? the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S> <S sid="415" ssid="18">The major problem for our seg? menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 40 | Reference Article: J96-3004.xml | Citing Article: P98-1076.xml | Citation Marker Offset: ['150'] | Citation Marker: 1996 | Citation Offset: ['149'] | Citation Text: <S sid="149" ssid="2">utilizing local and sentential constraints, what Sproat et al.</S> | Reference Offset: ['91' , '199' , '244' , '91' , '199' , '244' , '460' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 41 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['6'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['5'] | Citation Text: <S sid="5" ssid="5">In Japanese, around 95% word segmentation ac? curacy is reported by using a word-based lan? guage model and the Viterbi-like dynamic program? ming procedures (Nagata, 1994; Yamamoto, 1996; Takeuchi and Matsumoto, 1997; Haruno and Mat? sumoto, 1997).</S> | Reference Offset: ['31' , '36' , '113' , '112' , '109' , '119' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '228' , '221' , '218' , '249' , '244' , '264' , '8' , '31' , '113' , '112' , '109' , '119' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '228' , '221' , '218' , '249' , '244' , '264' ] | Reference Text: <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="8" ssid="8">And if one is interested in TIS, one would probably consider the single orthographic word ACL to consist of three phonological words-lei s'i d/-corresponding to the pronunciation of each of the letters in the acronym.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 42 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['8'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['8'] | Citation Text: <S sid="8" ssid="8">There are two approaches to solve this problem: to increase the coverage of the dictionary (Fung and Wu, 1994; Chang et al., 1995; Mori and Nagao, 1996) and to design a better model for unknown words (Nagata, 1996; Sproat et al., 1996).</S> | Reference Offset: ['23' , '31' , '91' , '109' , '166' , '174' , '199' , '201' , '200' , '191' , '216' , '212' , '205' , '218' , '249' , '244' , '245' , '242' , '240' , '256' , '284' , '286' , '328' , '348' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.'s model, which we improve upon.</S> <S sid="242" ssid="106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> <S sid="240" ssid="104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: ? the probability that a word chosen randomly from a text will be a name-p(rule 1), and ? the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and ? the probability that the family name is the particular hanzi F1-p(rule 6), and ? the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> <S sid="256" ssid="120">The use of the Good-Turing equation presumes suitable estimates of the unknown expectations it requires.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="348" ssid="57">However, this result is consistent with the results of ex? periments discussed in Wu and Fung (1994).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 43 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['10'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['10'] | Citation Text: <S sid="10" ssid="10">To improve word segmenta? tion accuracy, (Nagata, 1996) used a single general purpose unknown word model, while (Sproat et al., 1996) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.</S> | Reference Offset: ['23' , '31' , '91' , '109' , '119' , '166' , '174' , '199' , '201' , '200' , '191' , '216' , '205' , '218' , '249' , '244' , '256' , '264' , '283' , '285' , '286' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="256" ssid="120">The use of the Good-Turing equation presumes suitable estimates of the unknown expectations it requires.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="283" ssid="147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 'Shamir,' which is a legal Chi? nese personal name, retains a foreign flavor because of liM.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 44 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['178'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['178'] | Citation Text: <S sid="178" ssid="108">Word segmentation accuracy is expressed in terms of recall and precision as is done in the previous research (Sproat et al., 1996).</S> | Reference Offset: ['23' , '31' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '143' , '144' , '166' , '157' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '244' , '240' , '314' , '361' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S> <S sid="144" ssid="8">then define the best segmentation to be the cheapest or best path in Id(I) o D* (i.e., Id(I) composed with the transitive closure of 0).6 Consider the abstract example illustrated in Figure 2.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="157" ssid="21">Each word is terminated by an arc that represents the transduction between f and the part of speech of that word, weighted with an estimated cost for that word.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="240" ssid="104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: ? the probability that a word chosen randomly from a text will be a name-p(rule 1), and ? the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and ? the probability that the family name is the particular hanzi F1-p(rule 6), and ? the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> <S sid="314" ssid="23">computing the precision of the other's judgments relative to this standard.</S> <S sid="361" ssid="70">On a set of 11 sentence fragments-the A set-where they reported 100% recall and precision for name identification, we had 73% recall and 80% precision.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 45 | Reference Article: J96-3004.xml | Citing Article: W00-0803.xml | Citation Marker Offset: ['29'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['29'] | Citation Text: <S sid="29" ssid="29">Segmentation rutd morphological analysis related issues of both Chinese and Japanese are intensively addressed elsewhere (Sproat et al., 1996; MatsUIIt(ltO et al., 1997 and many others).</S> | Reference Offset: ['1' , '20' , '73' , '91' , '133' , '128' , '200' , '197' , '217' , '228' , '221' , '244' , '264' , '410' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="73" ssid="11">A Brief Introduction to the Chinese Writing System Most readers will undoubtedly be at least somewhat familiar with the nature of the Chinese writing system, but there are enough common misunderstandings that it is as well to spend a few paragraphs on properties of the Chinese script that will be relevant to topics discussed in this paper.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="217" ssid="81">This representation gives ir, an appropriate morphological decomposition, pre? serving information that would be lost by simply listing ir, as an unanalyzed form.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="410" ssid="13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 46 | Reference Article: J96-3004.xml | Citing Article: W00-1207.xml | Citation Marker Offset: ['10'] | Citation Marker: Sproat et al 1996 | Citation Offset: ['10'] | Citation Text: <S sid="10" ssid="10">Purely statistical methods of word segmentation (e.g. de Marcken 1996, Sproat et al 1996, Tung and Lee 1994, Lin et al (1993), Chiang et al (1992), Lua, Huang et al, etc.) often fail to identify those words because of the sparse data problem, as the likelihood for those words to appear in the training texts is extremely low.</S> | Reference Offset: ['1' , '8' , '23' , '31' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '157' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '249' , '244' , '328' , '350' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="8" ssid="8">And if one is interested in TIS, one would probably consider the single orthographic word ACL to consist of three phonological words-lei s'i d/-corresponding to the pronunciation of each of the letters in the acronym.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="157" ssid="21">Each word is terminated by an arc that represents the transduction between f and the part of speech of that word, weighted with an estimated cost for that word.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 47 | Reference Article: J96-3004.xml | Citing Article: W01-0513.xml | Citation Marker Offset: ['41'] | Citation Marker: Sproat, et al, 1996 | Citation Offset: ['40'] | Citation Text: <S sid="40" ssid="11">The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et.</S> | Reference Offset: ['23' , '31' , '37' , '91' , '113' , '112' , '109' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '244' , '415' , '23' , '31' , '37' , '91' , '113' , '112' , '109' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '244' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="37" ssid="37">However, there are several reasons why this approach will not in general work: 1.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="415" ssid="18">The major problem for our seg? menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="37" ssid="37">However, there are several reasons why this approach will not in general work: 1.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 48 | Reference Article: J96-3004.xml | Citing Article: W02-1117.xml | Citation Marker Offset: ['13'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['13'] | Citation Text: <S sid="13" ssid="13">For examples: these words should be obtained: The ambiguous string is .There are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [Guo 1997; Sproat et al. 1996; Gu and Mao 1994; Li et al. 1991; Wang et al. 1991b; Wang et al. 1990].</S> | Reference Offset: ['23' , '31' , '109' , '166' , '174' , '201' , '200' , '191' , '216' , '205' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 49 | Reference Article: J96-3004.xml | Citing Article: W02-1808.xml | Citation Marker Offset: ['5'] | Citation Marker: 1996 | Citation Offset: ['5'] | Citation Text: <S sid="5" ssid="5">Since all prob(w ) < 1.0, this probability becomes smaller for a greater n. Clearly, it looks more straightforward in an equi-probability setting.Statistical approaches involve language mod els mostly finite-state ones trained on some large-scale corpora as showed in Fan and Tsai (1988) Chang et al (1991) Chiang et al (1992) Sproat et al (1996) Pont and Croft (1996) and Ng and Lua (forthcoming) These approaches do not provide any explicit strategy for disambiguation but they get more ambiguous chunks correctly segmented than MMs by virtue of probability Other linguistic resources or computational processes can also be integrated for further improvement e g Lai et al (1991) attempts to integrate POS tagging with word segmentation for the enhancement of accuracy and Gan et al (1997) integrates word boundary disambiguation into sentence processing within a probabilistic emergent model There are also other approaches that incorporate various techniques of statistical NLP and machine learning e g transformation-based error-driven learning (Palmer 1997 Hockenmaier and Brew 1998) and compression-based algorithm (Teahan et al 2 ) Recent research shifts its focus onto the following aspects resorting to a variety of resources and techniques in particular machine learning techniques 1 Lexical resource acquisition including.</S> | Reference Offset: ['172' , '210' , '204' , '236' , '277' , '254' , '285' , '339' ] | Reference Text: <S sid="172" ssid="36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic? ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> <S sid="210" ssid="74">The cost estimate, cost(i?JJ1l.fn is computed in the obvious way by summing the negative log probabilities of i?JJ1l.</S> <S sid="204" ssid="68">10 Here we use the Good-Turing estimate (Baayen 1989; Church and Gale 1991), whereby the aggregate probability of previously unseen instances of a construction is estimated as ni/N, where N is the total number of observed tokens and n1 is the number of types observed only once.</S> <S sid="236" ssid="100">For a sequence of hanzi that is a possible name, we wish to assign a probability to that sequence qua name.</S> <S sid="277" ssid="141">The final estimating equation is then: (3) Since the total of all these class estimates was about 10% off from the Turing estimate n1/N for the probability of all unseen hanzi, we renormalized the estimates so that they would sum to n 1jN.</S> <S sid="254" ssid="118">We can better predict the probability of an unseen hanzi occurring in a name by computing a within-class Good-Turing estimate for each radical class.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="339" ssid="48">The question is how to normalize the probabilities in such a way that smaller groupings have a better shot at winning.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 5 | Reference Article: J96-3004.xml | Citing Article: C02-1049.xml | Citation Marker Offset: ['127'] | Citation Marker: Sproat et al, 1996 | Citation Offset: ['125'] | Citation Text: <S sid="125" ssid="106">msi +1 () msi + 2 (?)</S> | Reference Offset: ['91' , '100' , '199' , '244' , '91' , '100' , '199' , '244' , '460' , '91' , '100' , '199' , '244' , '460' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="100" ssid="38">Similarly, there is no compelling evidence that either of the syllables of f.ifflll binllang2 'betelnut' represents a morpheme, since neither can occur in any context without the other: more likely fjfflll binllang2 is a disyllabic morpheme.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="100" ssid="38">Similarly, there is no compelling evidence that either of the syllables of f.ifflll binllang2 'betelnut' represents a morpheme, since neither can occur in any context without the other: more likely fjfflll binllang2 is a disyllabic morpheme.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="100" ssid="38">Similarly, there is no compelling evidence that either of the syllables of f.ifflll binllang2 'betelnut' represents a morpheme, since neither can occur in any context without the other: more likely fjfflll binllang2 is a disyllabic morpheme.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 50 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['17'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['17'] | Citation Text: <S sid="17" ssid="17">There are multiple studies (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper to lower . The agreement between multiple human subjects is even lower (Wu and Fung, 1994).</S> | Reference Offset: ['91' , '199' , '244' , '460' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 51 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['180'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['180'] | Citation Text: <S sid="180" ssid="4">Chinese word segmentation is a well-known problem that has been studied extensively (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) and it is known that human agreement is relatively low.</S> | Reference Offset: ['20' , '31' , '51' , '53' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '199' , '201' , '200' , '197' , '191' , '188' , '216' , '208' , '205' , '228' , '221' , '244' , '264' , '410' , '415' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="188" ssid="52">One class comprises words derived by productive morphologi? cal processes, such as plural noun formation using the suffix ir, menD.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="208" ssid="72">Finally, as? suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i?1J1l.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="410" ssid="13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S> <S sid="415" ssid="18">The major problem for our seg? menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 52 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['187'] | Citation Marker: 1996 | Citation Offset: ['187'] | Citation Text: <S sid="187" ssid="11">(1996) employs stochastic finite state machines to find word boundaries.</S> | Reference Offset: ['1' , '2' , '23' , '31' , '109' , '119' , '166' , '174' , '199' , '201' , '200' , '191' , '216' , '205' , '244' , '1' , '8' , '23' , '31' , '109' , '119' , '166' , '174' , '199' , '201' , '200' , '191' , '216' , '205' , '244' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="2" ssid="2">An initial step of any text? analysis task is the tokenization of the input into words.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="8" ssid="8">And if one is interested in TIS, one would probably consider the single orthographic word ACL to consist of three phonological words-lei s'i d/-corresponding to the pronunciation of each of the letters in the acronym.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 53 | Reference Article: J96-3004.xml | Citing Article: W03-1728.xml | Citation Marker Offset: ['3'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['3'] | Citation Text: <S sid="3" ssid="3">This may sound simple enough but in reality identifying words in Chinese is a nontrivial problem that has drawn a large body of research in the Chinese language processing community (Fan and Tsai, 1988; Gan et al., 1996; Sproat et al., 1996; Wu, 2003; Xue, 2003).</S> | Reference Offset: ['1' , '20' , '31' , '36' , '91' , '133' , '128' , '166' , '199' , '201' , '200' , '191' , '188' , '216' , '208' , '205' , '228' , '221' , '244' , '264' , '348' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="188" ssid="52">One class comprises words derived by productive morphologi? cal processes, such as plural noun formation using the suffix ir, menD.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="208" ssid="72">Finally, as? suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i?1J1l.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="348" ssid="57">However, this result is consistent with the results of ex? periments discussed in Wu and Fung (1994).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 54 | Reference Article: J96-3004.xml | Citing Article: W04-3236.xml | Citation Marker Offset: ['157'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['157'] | Citation Text: <S sid="157" ssid="35">Much previous research on Chinese language processing focused on word segmentation (Sproat et al., 1996; Teahan et al., 2000; Sproat and Emerson, 2003).</S> | Reference Offset: ['20' , '31' , '51' , '53' , '91' , '113' , '112' , '117' , '132' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '161' , '199' , '201' , '200' , '197' , '191' , '216' , '208' , '205' , '228' , '221' , '264' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="132" ssid="70">For example Chen and Liu (1992) report precision and recall rates of over 99%, but this counts only the words that occur in the test corpus that also occur in their dictionary.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="161" ssid="25">7 Big 5 is the most popular Chinese character coding standard in use in Taiwan and Hong Kong.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="208" ssid="72">Finally, as? suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i?1J1l.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 55 | Reference Article: J96-3004.xml | Citing Article: W05-0709.xml | Citation Marker Offset: ['83'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['83'] | Citation Text: <S sid="83" ssid="9">In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al., 1996).</S> | Reference Offset: ['31' , '36' , '91' , '113' , '112' , '117' , '134' , '135' , '130' , '129' , '166' , '201' , '197' , '191' , '212' , '249' , '244' , '284' , '286' ] | Reference Text: <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 56 | Reference Article: J96-3004.xml | Citing Article: W06-1630.xml | Citation Marker Offset: ['118'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['118'] | Citation Text: <S sid="118" ssid="13">The words were stemmed all possible ways using simple hand-developed affix lists: for example, given a Hindi word c1 c2 c3 , if both c3 and c2 c3 are in our suffix and ending list, then this single word generates three possible candidates: c1 , c1 c2 , and c1c2 c3 . In contrast, Chinese candidates were extracted using a list of 495 characters that are frequently used for foreign names (Sproat et al., 1996).</S> | Reference Offset: ['98' , '166' , '183' , '226' , '342' ] | Reference Text: <S sid="98" ssid="36">This is orthographically represented as 7C.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="183" ssid="47">As indicated in Figure 1(c), apart from this correct analysis, there is also the analysis taking B ri4 as a word (e.g., a common abbreviation for Japan), along with X:? wen2zhangl 'essay/ and f!!.</S> <S sid="226" ssid="90">0 Figure 5 An example of affixation: the plural affix.</S> <S sid="342" ssid="51">"c' 0 + 0 "0 ' ? + a n t i g r e e d y x g r e e d y < > c u r r e n t m e t h o d o d i e t . o n l y ? Taiwan 0 ?;; 0 c CD E i5 0"' 9 9 ? Mainland ? ? ? ? -0.30.20.1 0.0 0.1 0.2 Dimension 1 (62%) Figure 7 Classical metric multidimensional scaling of distance matrix, showing the two most significant dimensions.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 57 | Reference Article: J96-3004.xml | Citing Article: W10-3212.xml | Citation Marker Offset: ['16'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['16'] | Citation Text: <S sid="16" ssid="2">In such languages, words are segmented using more advanced techniques, which can be categorized into three methods: (i) Dictionary/lexicon based approaches (ii) Linguistic knowledge based approaches (iii) Machine learning based approaches/statistical approaches (Haruechaiyasak et al., 2008) Longest matching (Poowarawan, 1986; Richard Sproat, 1996) and maximum matching (Sproat et al., 1996; Haizhou & Baosheng, 1998) are examples of lexicon based approaches.</S> | Reference Offset: ['1' , '8' , '23' , '31' , '91' , '107' , '134' , '135' , '166' , '172' , '174' , '199' , '201' , '200' , '191' , '216' , '212' , '205' , '244' , '240' , '284' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="8" ssid="8">And if one is interested in TIS, one would probably consider the single orthographic word ACL to consist of three phonological words-lei s'i d/-corresponding to the pronunciation of each of the letters in the acronym.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="107" ssid="45">The second concerns the methods used (if any) to ex? tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="172" ssid="36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic? ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="240" ssid="104">G1 and G2 are hanzi, we can estimate the probability of the sequence being a name as the product of: ? the probability that a word chosen randomly from a text will be a name-p(rule 1), and ? the probability that the name is of the form 1hanzi-family 2hanzi-given-p(rule 2), and ? the probability that the family name is the particular hanzi F1-p(rule 6), and ? the probability that the given name consists of the particular hanzi G1 and G2-p(rule 9) This model is essentially the one proposed in Chang et al.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 58 | Reference Article: J96-3004.xml | Citing Article: W10-3708.xml | Citation Marker Offset: ['16'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['16'] | Citation Text: <S sid="16" ssid="16">Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996).</S> | Reference Offset: ['36' , '51' , '53' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '143' , '197' , '191' ] | Reference Text: <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 59 | Reference Article: J96-3004.xml | Citing Article: W11-0823.xml | Citation Marker Offset: ['174'] | Citation Marker: 1996 | Citation Offset: ['174'] | Citation Text: <S sid="174" ssid="7">There are a number of popular dictionary-based solutions such as Cha Sen10 and Juman.11 Sproat et al (1996) proposed an alternative solution based on distributional statistics such as mutual information.</S> | Reference Offset: ['91' , '143' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 6 | Reference Article: J96-3004.xml | Citing Article: C02-1080.xml | Citation Marker Offset: ['20'] | Citation Marker: Sproat et al. 96 | Citation Offset: ['20'] | Citation Text: <S sid="20" ssid="20">Chinese NE recognition is much more difficult than that in English due to two major problems.</S> | Reference Offset: ['1' , '23' , '172' , '228' , '221' , '264' , '458' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="172" ssid="36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic? ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 60 | Reference Article: J96-3004.xml | Citing Article: W12-1011.xml | Citation Marker Offset: ['41'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['41'] | Citation Text: <S sid="41" ssid="5">Indeed, even native speakers can agree on word boundaries in modern Chinese only about 76% of the time (Sproat et al., 1996).</S> | Reference Offset: ['20' , '31' , '91' , '133' , '128' , '166' , '199' , '200' , '191' , '188' , '216' , '208' , '205' , '228' , '221' , '264' , '328' , '468' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="188" ssid="52">One class comprises words derived by productive morphologi? cal processes, such as plural noun formation using the suffix ir, menD.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="208" ssid="72">Finally, as? suming a simple bigram backoff model, we can derive the probability estimate for the particular unseen word i?1J1l.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="468" ssid="14">We thank United Informatics for providing us with our corpus of Chinese text, and BDC for the 'Behavior ChineseEnglish Electronic Dictionary.'</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 61 | Reference Article: J96-3004.xml | Citing Article: W12-1011.xml | Citation Marker Offset: ['204'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['204'] | Citation Text: <S sid="204" ssid="9">No comparable figure has been reported for classical Chinese word segmentation, but this rate compares favorably with past attempts for modern Chinese, e.g., an average of 76% inter- human agreement rate in (Sproat et al., 1996).</S> | Reference Offset: ['20' , '31' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '197' , '191' , '188' , '205' , '228' , '221' , '264' , '410' , '440' ] | Reference Text: <S sid="20" ssid="20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ? ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="188" ssid="52">One class comprises words derived by productive morphologi? cal processes, such as plural noun formation using the suffix ir, menD.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="410" ssid="13">However, until such standards are universally adopted in evaluating Chinese segmenters, claims about performance in terms of simple measures like percent correct should be taken with a grain of salt; see, again, Wu and Fung (1994) for further arguments supporting this conclusion.</S> <S sid="440" ssid="43">Turning now to (1), we have the similar problem that splitting.into.ma3 'horse' andlu4 'way' is more costly than retaining this as one word .ma3lu4 'road.'</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 62 | Reference Article: J96-3004.xml | Citing Article: W12-2303.xml | Citation Marker Offset: ['12'] | Citation Marker: 1996 | Citation Offset: ['12'] | Citation Text: <S sid="12" ssid="12">(1996), which utilize information such as word frequency statistics in a corpus to build the model and are less efficient but more accurate.</S> | Reference Offset: ['23' , '31' , '91' , '166' , '157' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '212' , '205' , '218' , '249' , '245' , '242' , '243' , '264' , '286' , '415' , '441' , '23' , '31' , '91' , '166' , '157' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '212' , '205' , '218' , '249' , '245' , '242' , '243' , '264' , '286' , '441' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="157" ssid="21">Each word is terminated by an arc that represents the transduction between f and the part of speech of that word, weighted with an estimated cost for that word.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.'s model, which we improve upon.</S> <S sid="242" ssid="106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S> <S sid="415" ssid="18">The major problem for our seg? menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S> <S sid="441" ssid="44">However, there is again local grammatical information that should favor the split in the case of (1a): both .ma3 'horse' and .ma3 lu4 are nouns, but only .ma3 is consistent with the classifier pil, the classifier for horses.21 By a similar argument, the preference for not splitting , lm could be strengthened in (lb) by the observation that the classifier 1'1* tiao2 is consistent with long or winding objects like , lm ma3lu4 'road' but not with,ma3 'horse.'</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="157" ssid="21">Each word is terminated by an arc that represents the transduction between f and the part of speech of that word, weighted with an estimated cost for that word.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="249" ssid="113">The second weakness is purely conceptual, and probably does not affect the per? formance of the model.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.'s model, which we improve upon.</S> <S sid="242" ssid="106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S> <S sid="441" ssid="44">However, there is again local grammatical information that should favor the split in the case of (1a): both .ma3 'horse' and .ma3 lu4 are nouns, but only .ma3 is consistent with the classifier pil, the classifier for horses.21 By a similar argument, the preference for not splitting , lm could be strengthened in (lb) by the observation that the classifier 1'1* tiao2 is consistent with long or winding objects like , lm ma3lu4 'road' but not with,ma3 'horse.'</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 63 | Reference Article: J96-3004.xml | Citing Article: W12-2303.xml | Citation Marker Offset: ['157'] | Citation Marker: 1996 | Citation Offset: ['157'] | Citation Text: <S sid="157" ssid="32">(1996) system can successfully recognize OOVs of strong patterns, such as Chinese personal names, transliterations, using finite-state techniques.</S> | Reference Offset: ['133' , '128' , '138' , '199' , '229' , '228' , '221' , '244' , '242' , '252' , '257' , '260' , '259' , '264' , '262' , '283' , '285' , '291' , '328' , '133' , '128' , '199' , '229' , '228' , '221' , '244' , '242' , '252' , '257' , '260' , '259' , '264' , '262' , '283' , '285' , '291' , '328' ] | Reference Text: <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="138" ssid="2">More formally, we start by representing the dictionary D as a Weighted Finite State Trans? ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="242" ssid="106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="283" ssid="147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 'Shamir,' which is a legal Chi? nese personal name, retains a foreign flavor because of liM.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="229" ssid="93">The family name set is restricted: there are a few hundred single-hanzi family names, and about ten double-hanzi ones.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="242" ssid="106">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S> <S sid="252" ssid="116">Not surprisingly some semantic classes are better for names than others: in our corpora, many names are picked from the GRASS class but very few from the SICKNESS class.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="260" ssid="124">where the husband's family name is optionally prepended to the woman's full name; thus ;f:*lf#i xu3lin2-yan2hai3 would represent the name that Ms. Lin Yanhai would take if she married someone named Xu.</S> <S sid="259" ssid="123">12 One class of full personal names that this characterization does not cover are married women's names.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="262" ssid="126">It is formally straightforward to extend the grammar to include these names, though it does increase the likelihood of overgeneration and we are unaware of any working systems that incorporate this type of name.</S> <S sid="283" ssid="147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 'Shamir,' which is a legal Chi? nese personal name, retains a foreign flavor because of liM.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="291" ssid="155">logical rules, and personal names; the transitive closure of the resulting machine is then computed.</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 64 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['26'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['26'] | Citation Text: <S sid="26" ssid="26">One of the major problems in unsupervised word segmentation is the treatment of unseen word [Sproat et al., 1996] wrote lexical rules for each productive morphological process, such as plur noun formation, Chinese personal names, and transliterations offoreign words.</S> | Reference Offset: ['23' , '26' , '31' , '36' , '52' , '91' , '113' , '112' , '109' , '119' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '206' , '207' , '204' , '205' , '228' , '221' , '244' , '264' ] | Reference Text: <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="26" ssid="26">immediately by a Romanization into the pinyin transliteration scheme; numerals following each pinyin syllable represent tones.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="206" ssid="70">For irt the Good-Turing estimate just discussed gives us an estimate of p(unseen(f,) I f,)-the probability of observing a previously unseen instance of a construction in ft given that we know that we have a construction in f,.</S> <S sid="207" ssid="71">This Good? Turing estimate of p(unseen(f,) If,) can then be used in the normal way to define the probability of finding a novel instance of a construction in ir, in a text: p(unseen(f,)) = p(unseen(f,) I f,) p(fn Here p(ir,) is just the probability of any construction in ft as estimated from the frequency of such constructions in the corpus.</S> <S sid="204" ssid="68">10 Here we use the Good-Turing estimate (Baayen 1989; Church and Gale 1991), whereby the aggregate probability of previously unseen instances of a construction is estimated as ni/N, where N is the total number of observed tokens and n1 is the number of types observed only once.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 65 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['69'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['69'] | Citation Text: <S sid="69" ssid="5">We used a simple greedy algorithm described in [Sproat et al., 1996].</S> | Reference Offset: ['138' , '199' , '244' ] | Reference Text: <S sid="138" ssid="2">More formally, we start by representing the dictionary D as a Weighted Finite State Trans? ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 66 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['73'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['73'] | Citation Text: <S sid="73" ssid="9">[Sproat et al., 1996] also proposed another method to estimate a set of initial word frequencies without segmenting the corpus.</S> | Reference Offset: ['1' , '23' , '31' , '91' , '166' , '172' , '174' , '199' , '201' , '200' , '191' , '190' , '216' , '210' , '202' , '204' , '205' , '218' , '244' , '243' , '256' , '257' , '285' , '328' , '350' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="172" ssid="36">Clearly this is not the only way to estimate word-frequencies, however, and one could consider applying other methods: in partic? ular since the problem is similar to the problem of assigning part-of-speech tags to an untagged corpus given a lexicon and some initial estimate of the a priori probabilities for the tags, one might consider a more sophisticated approach such as that described in Kupiec (1992); one could also use methods that depend on a small hand-tagged seed corpus, as suggested by one reviewer.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="190" ssid="54">The morphological anal?ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="210" ssid="74">The cost estimate, cost(i?JJ1l.fn is computed in the obvious way by summing the negative log probabilities of i?JJ1l.</S> <S sid="202" ssid="66">So, 1: f, xue2shengl+men0 (student+PL) 'students' occurs and we estimate its cost at 11.43; similarly we estimate the cost of f, jiang4+men0 (general+PL) 'generals' (as in 'J' f, xiao3jiang4+men0 'little generals'), at 15.02.</S> <S sid="204" ssid="68">10 Here we use the Good-Turing estimate (Baayen 1989; Church and Gale 1991), whereby the aggregate probability of previously unseen instances of a construction is estimated as ni/N, where N is the total number of observed tokens and n1 is the number of types observed only once.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrict? ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> <S sid="256" ssid="120">The use of the Good-Turing equation presumes suitable estimates of the unknown expectations it requires.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> <S sid="328" ssid="37">In addition to the automatic methods, AG, GR, and ST, just discussed, we also added to the plot the values for the current algorithm using only dictionary entries (i.e., no productively derived words or names).</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 67 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['86'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['86'] | Citation Text: <S sid="86" ssid="22">The problem of the longest match string frequency method is that if a word W1 is a substring of other word w2 and if wl always appears as a substring of w2 in the training text, just like m 1Although (Sproat et al., 1996] calls it "maximum matching", we call this method "longest match" according to a review on Chinese word segmentation [Wu and Tseng, 1993) and the literal translation of the Japanese name of the method Hi!:.</S> | Reference Offset: ['1' , '23' , '31' , '51' , '52' , '91' , '113' , '112' , '109' , '117' , '134' , '133' , '135' , '137' , '124' , '128' , '130' , '129' , '166' , '173' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '207' , '205' , '228' , '221' , '218' , '244' , '257' , '264' , '308' , '458' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="137" ssid="1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S> <S sid="124" ssid="62">Several systems propose statistical methods for handling unknown words (Chang et al. 1992; Lin, Chiang, and Su 1993; Peng and Chang 1993).</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="173" ssid="37">In any event, to date, we have not compared different methods for deriving the set of initial frequency estimates.</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="207" ssid="71">This Good? Turing estimate of p(unseen(f,) If,) can then be used in the normal way to define the probability of finding a novel instance of a construction in ir, in a text: p(unseen(f,)) = p(unseen(f,) I f,) p(fn Here p(ir,) is just the probability of any construction in ft as estimated from the frequency of such constructions in the corpus.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="218" ssid="82">Note that the backoff model assumes that there is a positive correlation between the frequency of a singular noun and its plural.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="257" ssid="121">In the denomi 11 We have two such lists, one containing about 17,000 full names, and another containing frequencies of.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="308" ssid="17">shortest match at each point.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 68 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['121'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['121'] | Citation Text: <S sid="121" ssid="15">Word Segmentation accuracy is expressed in terms of recall and precision as is done for bracketing of partial parses [Nagata, 1994, Sproat et al., 1996).</S> | Reference Offset: ['8' , '23' , '31' , '36' , '51' , '53' , '52' , '91' , '113' , '112' , '109' , '119' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '143' , '166' , '174' , '199' , '201' , '200' , '197' , '191' , '216' , '205' , '244' , '361' ] | Reference Text: <S sid="8" ssid="8">And if one is interested in TIS, one would probably consider the single orthographic word ACL to consist of three phonological words-lei s'i d/-corresponding to the pronunciation of each of the letters in the acronym.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="51" ssid="12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="109" ssid="47">This method, one instance of which we term the "greedy algorithm" in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin? ning) of the sentence is reached.</S> <S sid="119" ssid="57">The simplest approach involves scoring the various analyses by costs based on word frequency, and picking the lowest cost path; variants of this approach have been described in Chang, Chen, and Chen (1991) and Chang and Chen (1993).</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="143" ssid="7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="174" ssid="38">Note also that the costs currently used in the system are actually string costs, rather than word costs.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="200" ssid="64">However, for our purposes it is not sufficient to repre? sent the morphological decomposition of, say, plural nouns: we also need an estimate of the cost of the resulting word.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="216" ssid="80">For the seen word ir, 'gen? erals,' there is an c:NC transduction from to the node preceding ir,; this arc has cost cost( f,) - cost(unseen(f,)), so that the cost of the whole path is the desired cost( f,).</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="361" ssid="70">On a set of 11 sentence fragments-the A set-where they reported 100% recall and precision for name identification, we had 73% recall and 80% precision.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 69 | Reference Article: J96-3004.xml | Citing Article: W97-0316.xml | Citation Marker Offset: ['11'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['10'] | Citation Text: <S sid="10" ssid="10">This makes it difficult to do machine studies on these languages since isolated words are needed for many purposes, such as linguistic analysis, machine translation, etc. Automatic methods for correctly isolating words in a sentence -- a process called word segmentation -- is therefore an important and necessary first step to be taken before other analysis can begin.</S> | Reference Offset: ['1' , '27' , '31' , '36' , '53' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '125' , '128' , '130' , '129' , '144' , '168' , '166' , '183' , '199' , '197' , '191' , '205' , '244' , '460' , '440' , '1' , '31' , '52' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '125' , '128' , '130' , '129' , '144' , '168' , '166' , '183' , '199' , '197' , '191' , '205' , '244' , '440' ] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="27" ssid="27">Examples will usually be accompanied by a translation, plus a morpheme-by-morpheme gloss given in parentheses whenever the translation does not adequately serve this purpose.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="125" ssid="63">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac? tually tag the words as belonging to one or another class of expression.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="144" ssid="8">then define the best segmentation to be the cheapest or best path in Id(I) o D* (i.e., Id(I) composed with the transitive closure of 0).6 Consider the abstract example illustrated in Figure 2.</S> <S sid="168" ssid="32">Word frequencies are estimated by a re-estimation procedure that involves apply? ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="183" ssid="47">As indicated in Figure 1(c), apart from this correct analysis, there is also the analysis taking B ri4 as a word (e.g., a common abbreviation for Japan), along with X:? wen2zhangl 'essay/ and f!!.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="460" ssid="6">Since the transducers are built from human-readable descriptions using a lexical toolkit (Sproat 1995), the system is easily maintained and extended.</S> <S sid="440" ssid="43">Turning now to (1), we have the similar problem that splitting.into.ma3 'horse' andlu4 'way' is more costly than retaining this as one word .ma3lu4 'road.'</S> <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng's (1993) discussion of the role of segmentation in information retrieval.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="125" ssid="63">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac? tually tag the words as belonging to one or another class of expression.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="144" ssid="8">then define the best segmentation to be the cheapest or best path in Id(I) o D* (i.e., Id(I) composed with the transitive closure of 0).6 Consider the abstract example illustrated in Figure 2.</S> <S sid="168" ssid="32">Word frequencies are estimated by a re-estimation procedure that involves apply? ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="183" ssid="47">As indicated in Figure 1(c), apart from this correct analysis, there is also the analysis taking B ri4 as a word (e.g., a common abbreviation for Japan), along with X:? wen2zhangl 'essay/ and f!!.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="205" ssid="69">Let us notate the set of previously unseen, or novel, members of a category X as unseen(X); thus, novel members of the set of words derived in f, menO will be de? noted unseen(f,).</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="440" ssid="43">Turning now to (1), we have the similar problem that splitting.into.ma3 'horse' andlu4 'way' is more costly than retaining this as one word .ma3lu4 'road.'</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 7 | Reference Article: J96-3004.xml | Citing Article: C02-1143.xml | Citation Marker Offset: ['107'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['107'] | Citation Text: <S sid="107" ssid="48">We used a maximum- matching algorithm and a dictionary compiled from the CTB (Sproat et al., 1996; Xue, 2001) to do segmentation, and trained a maximum entropy part-of- speech tagger (Ratnaparkhi, 1998) and TAG-based parser (Bikel and Chiang, 2000) on the CTB to do tagging and parsing.4 Then the same feature extraction and model-training was done for the PDN corpus as for the CTB.</S> | Reference Offset: ['91' , '134' , '135' , '201' , '197' , '212' , '244' , '284' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="201" ssid="65">For derived words that occur in our corpus we can estimate these costs as we would the costs for an underived dictionary entry.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil? ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 8 | Reference Article: J96-3004.xml | Citing Article: E09-1063.xml | Citation Marker Offset: ['107'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['107'] | Citation Text: <S sid="107" ssid="4">First of all, it is really difficult to build a reliable and objective gold-standard given the fact that there is only 70% agreement between native speakers on this task (Sproat et al., 1996).</S> | Reference Offset: ['91' , '199' , '244' ] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
 Citance Number: 9 | Reference Article: J96-3004.xml | Citing Article: I05-3031.xml | Citation Marker Offset: ['7'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['6'] | Citation Text: <S sid="6" ssid="6">The Chinese word segmentation is a nontrivial task because no explicit delimiters (like spaces in English) are used for word separation.</S> | Reference Offset: ['31' , '88' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '199' , '197' , '191' , '228' , '221' , '244' , '264' , '31' , '88' , '91' , '113' , '112' , '117' , '134' , '133' , '135' , '128' , '130' , '129' , '166' , '199' , '197' , '191' , '228' , '221' , '244' , '264' ] | Reference Text: <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="88" ssid="26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S> <S sid="31" ssid="31">Arguably this consists of about three phonological words.</S> <S sid="88" ssid="26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="113" ssid="51">Methods that allow multiple segmentations must provide criteria for choosing the best segmentation.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="117" ssid="55">Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence, and picks the best segmentation from the set of possible segmentations using a probabilistic or cost? based scoring mechanism.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="135" ssid="73">The dictionary sizes reported in the literature range from 17,000 to 125,000 entries, and it seems reasonable to assume that the coverage of the base dictionary constitutes a major factor in the performance of the various approaches, possibly more important than the particular set of methods used in the segmentation.</S> <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a "correct" segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="166" ssid="30">(In this figure eps is c) be implemented, though, such as a maximal-grouping strategy (as suggested by one reviewer of this paper); or a pairwise-grouping strategy, whereby long sequences of unattached hanzi are grouped into two-hanzi words (which may have some prosodic motivation).</S> <S sid="199" ssid="63">ogy (Koskenniemi 1983; Antworth 1990; Tzoukermann and Liberman 1990; Karttunen, Kaplan, and Zaenen 1992; Sproat 1992); we represent the fact that ir, attaches to nouns by allowing t:-transitions from the final states of all noun entries, to the initial state of the sub-WFST representing f,.</S> <S sid="197" ssid="61">Figure 4 Input lattice (top) and two segmentations (bottom) of the sentence 'How do you say octopus in Japanese?'.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.'s Model.</S> <S sid="264" ssid="128">This is in general very difficult, given the extremely free manner in which Chinese given names are formed, and given that in these cases we lack even a family name to give the model confidence that it is identifying a name.</S>  | Discourse Facet: Method_Citation | Annotator: Ankita Patel |
