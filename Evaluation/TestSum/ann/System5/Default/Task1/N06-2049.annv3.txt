Citance Number:  1 | Reference Article:  N06-2049.xml | Citing Article:  C10-2139.xml | Citation Marker Offset:  ['290'] | Citation Marker:  Zh ang et al., 200 6 | Citation Offset:  ['290','305'] | Citation Text:  <S sid="290" ssid="189">AS C U MS R PK U (Zh ang et al., 200 6) 95.</S><S sid="305" ssid="204">2 Table 5Segmentation performance presented in previous work and of our combination model.</S> | Reference Offset:  ['52'] | Reference Text:  <S sid="52" ssid="30">A forward-backward algorithm was used in the training and viterbi algorithm was used in the decoding.</S> | Discourse Facet:  Results_Citation | Annotator:  Rali | 


Citance Number:  2 | Reference Article:  N06-2049.xml | Citing Article:  D13-1031.xml | Citation Marker Offset:  ['274'] | Citation Marker:  2006 | Citation Offset:  ['273','274'] | Citation Text:  <S sid="273" ssid="109">CRF + Rule system represents a combination of CRF model and rule based model presented in Zhang et al.</S><S sid="274" ssid="110">(2006).</S> | Reference Offset:  ['44'] | Reference Text:  <S sid="44" ssid="22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T |W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  3 | Reference Article:  N06-2049.xml | Citing Article:  I08-4009.xml | Citation Marker Offset:  ['19'] | Citation Marker:  Zhang et al., 2006a | Citation Offset:  ['19'] | Citation Text:  <S sid="19" ssid="19">Consequently, many strategies are proposed to balance the IV and OOV performance (Goh et al., 2005), (Zhang et al., 2006a).</S> | Reference Offset:  ['82'] | Reference Text:  <S sid="82" ssid="11">In fact, there were no OOV recognition.</S> | Discourse Facet:  Results_Citation | Annotator:  Rali | 


Citance Number:  4 | Reference Article:  N06-2049.xml | Citing Article:  I08-4009.xml | Citation Marker Offset:  ['20'] | Citation Marker:  Zhang et al., 2006a | Citation Offset:  ['20'] | Citation Text:  <S sid="20" ssid="20">Among these strategies, the confidence measure used to combine the results of CT and DS is a straightforward one, which is introduced in (Zhang et al., 2006a).</S> | Reference Offset:  ['57'] | Reference Text:  <S sid="57" ssid="35">In this section we introduce a confidence measure approach to combine the two results.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  5 | Reference Article:  N06-2049.xml | Citing Article:  I08-4015.xml | Citation Marker Offset:  ['36'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['36'] | Citation Text:  <S sid="36" ssid="22">After we get word-based segmentation result, we use it to revise the CRF tagging result similar to (Zhang et al., 2006).</S> | Reference Offset:  ['23'] | Reference Text:  <S sid="23" ssid="1">Our word segmentation process is illustrated in Fig.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  6 | Reference Article:  N06-2049.xml | Citing Article:  I08-4030.xml | Citation Marker Offset:  ['13'] | Citation Marker:  R. Zhang et al., 2006 | Citation Offset:  ['13'] | Citation Text:  <S sid="13" ssid="13">If the confidence of a character is lower than the threshold, the tag of that character will be adjusted to the tag assigned by the Maximum Probability Segmentation (R. Zhang et al., 2006).</S> | Reference Offset:  ['71'] | Reference Text:  <S sid="71" ssid="49">In Section 3.2 we will present the experimental segmentation results of the confidence measure approach.</S> | Discourse Facet:  Aim_Citation | Annotator:  Rali | 


Citance Number:  7 | Reference Article:  N06-2049.xml | Citing Article:  I08-4030.xml | Citation Marker Offset:  ['51'] | Citation Marker:  R. Zhang et al., 2006 | Citation Offset:  ['51'] | Citation Text:  <S sid="51" ssid="7">According to the results reported in (R. Zhang et al., 2006), CRF performs relatively better on Out-of-Vocabulary (OOV) words while Maximum Probability performs well on IV words, so a model combining the advantages of these two methods is appealing.</S> | Reference Offset:  ['51'] | Reference Text:  <S sid="51" ssid="29">We defined a cutoff value for each feature type and selected the features with occurrence counts over the cutoff.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  8 | Reference Article:  N06-2049.xml | Citing Article:  J11-1005.xml | Citation Marker Offset:  ['277'] | Citation Marker:  2006 | Citation Offset:  ['277'] | Citation Text:  <S sid="277" ssid="168">We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang, Kikui, and Sumita (2006) for comparison.</S> | Reference Offset:  ['14'] | Reference Text:  <S sid="14" ssid="14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  9 | Reference Article:  N06-2049.xml | Citing Article:  N09-1007.xml | Citation Marker Offset:  ['134'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['134'] | Citation Text:  <S sid="134" ssid="17">Z06-a and Z06-b represents the pure sub- word CRF model and the conﬁdence-based combination of CRF and rule-based models, respectively (Zhang et al., 2006);</S> | Reference Offset:  [] | Reference Text:   | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  10 | Reference Article:  N06-2049.xml | Citing Article:  P06-2123.xml | Citation Marker Offset:  ['197'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['197'] | Citation Text:  <S sid="197" ssid="75">Detailed descriptions about subword tagging by CRF can be found in our paper (Zhang et al., 2006).</S> | Reference Offset:  ['78'] | Reference Text:  <S sid="78" ssid="7">For the dictionary-based approach, we extracted a word list from the training data as the vocabulary.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  11 | Reference Article:  N06-2049.xml | Citing Article:  P07-1106.xml | Citation Marker Offset:  ['94'] | Citation Marker:  2006 | Citation Offset:  ['93','94'] | Citation Text:  <S sid="93" ssid="9">One existing method that is based on sub-word information, Zhang et al.</S><S sid="94" ssid="10">(2006), combines a C R F and a rule-based model.</S> | Reference Offset:  ['44'] | Reference Text:  <S sid="44" ssid="22">We downloaded and used the package “CRF++” from the site “http://www.chasen.org/˜taku/software.” According to the CRFs, the probability of an IOB tag sequence, T = t0 t1 · · · tM , given the word sequence, W = w0 w1 · · · wM , is defined by p(T|W ) = and current observation ti simultaneously; gk (ti , W ), the unigram feature functions because they trigger only current observation ti . λk and µk are the model parameters corresponding to feature functions fk and gk respectively.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  12 | Reference Article:  N06-2049.xml | Citing Article:  P07-1106.xml | Citation Marker Offset:  ['172'] | Citation Marker:  2006 | Citation Offset:  ['172','173'] | Citation Text:  <S sid="172" ssid="72">We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al.</S><S sid="173" ssid="73">(2006) for comparison.</S> | Reference Offset:  ['14'] | Reference Text:  <S sid="14" ssid="14">In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  13 | Reference Article:  N06-2049.xml | Citing Article:  P12-1027.xml | Citation Marker Offset:  ['189'] | Citation Marker:  2006 | Citation Offset:  ['188','189'] | Citation Text:  <S sid="188" ssid="41">Best05 represents the best system of the Second International Chinese Word Segmentation Bakeoff on the corresponding data; CRF + rule-system represents confidence- based combination of CRF and rule-based models, presented in Zhang et al.</S><S sid="189" ssid="42">(2006).</S> | Reference Offset:  ['33'] | Reference Text:  <S sid="33" ssid="11">Qc 2006 Association for Computational Linguistics input 咘㣅᯹ԣ೼࣫ҀᏖ +XDQJ<LQJ&KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation 咘 㣅 ᯹ ԣ ೼ ࣫ҀᏖ +XDQJ <LQJ &KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% <LQJ/, &KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation 咘/% 㣅/, ᯹/, ԣ/2 ೼/2 ࣫Ҁ/% Ꮦ/, +XDQJ/% <LQJ/, &KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output 咘㣅᯹ ԣ ೼ ࣫ҀᏖ +XDQJ<LQJ&KXQ OLYHV LQ %HLMLQJFLW\ Figure 1: Outline of word segmentation process data.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  14 | Reference Article:  N06-2049.xml | Citing Article:  W06-0118.xml | Citation Marker Offset:  ['14'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['14'] | Citation Text:  <S sid="14" ssid="2">Also, the CRF model using maximum subword-based tagging (Zhang et al., 2006)</S> | Reference Offset:  ['51'] | Reference Text:  <S sid="51" ssid="29">We defined a cutoff value for each feature type and selected the features with occurrence counts over the cutoff.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  15 | Reference Article:  N06-2049.xml | Citing Article:  W06-0118.xml | Citation Marker Offset:  ['24'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['24'] | Citation Text:  <S sid="24" ssid="12">Recently (Zhang et al., 2006) proposed a maximum subword-based IOB tagger for Chinese word segmentation, and our system applies their approach which obtains a very high accuracy on the shared task data from previous SIGHAN competitions.</S> | Reference Offset:  ['151'] | Reference Text:  <S sid="151" ssid="1">In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  16 | Reference Article:  N06-2049.xml | Citing Article:  W08-0335.xml | Citation Marker Offset:  ['55'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['55','56'] | Citation Text:  <S sid="55" ssid="21">Part of the work using this tool was described by (Zhang et al., 2006).</S><S sid="56" ssid="22">The approach was reported to achieve the highest word segmentation accuracy using the data from the second Sighan Bakeoff.</S> | Reference Offset:  ['41','23'] | Reference Text:  <S sid="41" ssid="19">Of course, backward maximal match (BMM) or other approaches are also applicable.</S><S sid="23" ssid="1">Our word segmentation process is illustrated in Fig.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  17 | Reference Article:  N06-2049.xml | Citing Article:  W08-0335.xml | Citation Marker Offset:  ['160'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['160'] | Citation Text:  <S sid="160" ssid="19">Note a lexicon and a LM are the only needed resources for building a dictionary-based CWS, like the â€œdict-hybrid.â€\x9d (Zhang et al., 2006) We used the â€œdict-hybridâ€\x9d to segment the SMT training corpus and test data.</S> | Reference Offset:  ['143'] | Reference Text:  <S sid="143" ssid="12">For AS corpus, “Adam Smith” are two words in the training but become a one- word in the test, “AdamSmith”.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  18 | Reference Article:  N06-2049.xml | Citing Article:  W10-4128.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['11'] | Citation Text:  <S sid="11" ssid="11">Some previous work (Peng et al., 2004; Tseng et al., 2005; Low et al., 2005) illustrated the effectiveness of using characters as tagging units, while literatures (Zhang et al., 2006; Zhao and Kit, 2007a; Zhang and Clark, 2007) focus on employing lexical words or subwords as tagging units.</S> | Reference Offset:  ['72'] | Reference Text:  <S sid="72" ssid="1">We used the data provided by Sighan Bakeoff 2005 to test our approaches described in the previous sections.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  19 | Reference Article:  N06-2049.xml | Citing Article:  W10-4135.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['11'] | Citation Text:  <S sid="11" ssid="11">For this purpose, our system is based on a combination of subword-based tagging method (Zhang et al., 2006) and accessor variety-based new word recognition method (Feng et al., 2004).</S> | Reference Offset:  ['68'] | Reference Text:  <S sid="68" ssid="46">A new OOV was thus created.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  20 | Reference Article:  N06-2049.xml | Citing Article:  W10-4135.xml | Citation Marker Offset:  ['25'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['25'] | Citation Text:  <S sid="25" ssid="11">Feature Template Description f) in(str, subword-list) is str in subword list g) in(str, confident-word-list) is str in confident-word list Table 2Subword Features for CRF-based Segmenter dure for constructing a subword list is similar to the one used in (Zhang et al., 2006).</S> | Reference Offset:  ['78'] | Reference Text:  <S sid="78" ssid="7">For the dictionary-based approach, we extracted a word list from the training data as the vocabulary.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  21 | Reference Article:  N06-2049.xml | Citing Article:  W10-4135.xml | Citation Marker Offset:  ['30'] | Citation Marker:  Zhang et al., 2006 | Citation Offset:  ['30'] | Citation Text:  <S sid="30" ssid="16">See the details of subword-based Chinese word segmentation in (Zhang et al., 2006)</S> | Reference Offset:  [] | Reference Text:   | Discourse Facet:  Method_Citation | Annotator:  Rali | 


Citance Number:  22 | Reference Article:  N06-2049.xml | Citing Article:  W10-4138.xml | Citation Marker Offset:  ['22'] | Citation Marker:  2006 | Citation Offset:  ['21','22','23'] | Citation Text:  <S sid="21" ssid="14">Thus, the bigram â€œRAIL ENQUIRIESâ€\x9d gives a misleading probability that â€œRAILâ€\x9d is followed by â€œENQUIRIESâ€\x9d irrespective of what precedes it.</S><S sid="22" ssid="15">This problem happens not only with word-token corpora but also with corpora in which all the compounds are tagged as units since overlapping N- grams still appear, therefore corresponding solutions such as those of Zhang et al.</S><S sid="23" ssid="16">(2006) were proposed.</S> | Reference Offset:  ['68','62','151'] | Reference Text:  <S sid="68" ssid="46">A new OOV was thus created.</S><S sid="62" ssid="40">Each subword is given a prior IOB tag, tw . C Miob (t|w), a  M  confidence probability derived in the process of IOB tag exp )' )' λk fk (ti−1 , ti , W ) + )' µk gk (ti , W ) /Z,  i=1  k k   (1) ging, is defined as Z = )' T =t0 t1 ···tM p(T |W ) C Miob (t|w ) = L,T =t0 t1 ···tM ,ti =t P(T |W, wi ) T =t 0 t1 ··· tM P ( T|W ) where we call fk (ti−1 , ti , W ) bigram feature functions because the features trigger the previous observation ti−1 where the numerator is a sum of all the observation sequences with word wi labeled as t. δ(tw , tiob )ng denotes the contribution of the dictionary- based segmentation.</S><S sid="151" ssid="1">In this work, we proposed a subword-based IOB tagging method for Chinese word segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  Rali | 


