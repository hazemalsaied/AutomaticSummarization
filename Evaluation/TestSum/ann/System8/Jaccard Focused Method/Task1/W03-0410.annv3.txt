Citance Number: 1 | Reference Article:   W03-0410.xml | Citing Article:  D07-1018.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">Stevenson and Joanis, 2003 for English semantic verb classes</S> | Reference Offset:  ['120', '51', '192', '17'] | Reference Text:  <S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 2 | Reference Article:   W03-0410.xml | Citing Article:  D09-1138.xml | Citation Marker Offset:  ['25'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['25'] | Citation Text:  <S sid ="25" ssid = "25">Supervised methods for automatic verb classification have been extensively investigated (Stevenson et al., 1999; Stevenson and Merlo, 1999; Merlo and Stevenson, 2001; Stevenson and Joanis, 2003; Joanis and Stevenson, 2003; Joanis et al., 2008).</S> | Reference Offset:  ['11', '51', '17', '252'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="252" ssid = "1">Using the same measure as ours, Stevenson and Merlo (1999) achieved performance in clustering very close to that of their supervised classification.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 3 | Reference Article:   W03-0410.xml | Citing Article:  D09-1138.xml | Citation Marker Offset:  ['70'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['70'] | Citation Text: <S sid ="70" ssid = "43">The present work inherits the spirit of the supervised approaches to verb classification (Stevenson et al., 1999; Stevenson and Merlo, 1999; Merlo and Stevenson, 2001; Stevenson and Joanis, 2003; Joanis and Stevenson, 2003; Joanis et al., 2008).</S> | Reference Offset:  ['11', '9', '17', '252'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="9" ssid = "9">A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (Gildea and Jurafsky, 2002), selectional preferences (Resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (Dorr and Jones, 1996; Lapata and Brew, 1999; Merlo and Stevenson, 2001; Joanis and Stevenson, 2003).</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="252" ssid = "1">Using the same measure as ours, Stevenson and Merlo (1999) achieved performance in clustering very close to that of their supervised classification.</S> | Discourse Facet:  ['Method_Citation', 'Implication_Citation'] | Annotator:  CIST |


Citance Number: 4 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['17'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['17'] | Citation Text:  <S sid ="17" ssid = "17">We adopt as our baseline method a well-known hierarchical method – agglomerative clustering (AGG) – which has been previously used to acquire flat Levin-style classifications (Stevenson and Joanis, 2003)</S> | Reference Offset:  ['131', '51', '17', '120'] | Reference Text:  <S sid ="131" ssid = "2">We used the hierarchical clustering command in Matlab, which implements bottom-up agglomerative clustering, for all our unsupervised experiments.</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 5 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['38'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['38'] | Citation Text:  <S sid ="38" ssid = "5">We used three gold standards (and corresponding test sets) extracted from these resources in our experiments: T1: The first gold standard is a flat gold standard which includes 13 classes appearing in Levin’s original taxonomy (Stevenson and Joanis, 2003).</S> | Reference Offset:  ['120', '51', '228', '123'] | Reference Text:  <S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="228" ssid = "66">Each clustering experiment used the full set of 20 verbs per class; i.e., seed verbs were included, following our proposed model of guided verb class discovery.5 The results using these feature sets are shown in the third subcolumn (Seed) under our three evaluation measures in Table 2.</S><S sid ="123" ssid = "73">All experiments reported here were run on this same final set of 20 verbs per class (including a replication of our earlier supervised experiments).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 6 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['40'] | Citation Marker:  Stevenson and Joanis (2003) | Citation Offset:  ['40'] | Citation Text:  <S sid ="40" ssid = "7">Following Stevenson and Joanis (2003), we selected 20 verbs from each class which occur at least 100 times in our corpus.</S> | Reference Offset:  ['117', '120', '51', '192'] | Reference Text:  <S sid ="117" ssid = "67">We started with a list of all the verbs in the given classes from Levin, removing any verb that did not occur at least 100 times in our corpus (the BNC, described below).</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 7 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['54'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['54'] | Citation Text:  <S sid ="54" ssid = "2">Previous works on Levin style verb classification have investigated optimal features for this task (Stevenson and Joanis, 2003; Li and Brew, 2008; Sun and Korhonen, 2009)).</S> | Reference Offset:  ['11', '17', '39', '120'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="39" ssid = "6">Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 8 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['82'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['82','83'] | Citation Text:  <S sid ="82" ssid = "30">Although they can be removed using a cut-based method, this requires a predefined cutoff value which is difficult to set (Stevenson and Joanis, 2003).</S><S sid ="83" ssid = "31">In addition, a significant amount of information is lost in pairwise clustering.</S> | Reference Offset:  ['213', '51', '17', '214'] | Reference Text:  <S sid ="213" ssid = "51">We performed a number of experiments in which we tested the performance of each feature set from cardinality 1 to the total number of features, where each set of size differs from the set of size in the addition of the feature with next highest rank (according to the proposed entropy measure).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="214" ssid = "52">Many feature sets performed very well, and some far outperformed our best results using other feature selection methods.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 9 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['167'] | Citation Marker:  Stevenson and Joanis (2003) | Citation Offset:  ['167'] | Citation Text:  <S sid ="167" ssid = "16">Table 1: Comparison against Stevenson and Joanis (2003)’s result on T1 (using similar features).</S> | Reference Offset:  ['39', '192', '188', '51'] | Reference Text:  <S sid ="39" ssid = "6">Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.</S><S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S><S sid ="188" ssid = "26">The first subcolumn (Full) under each of the three clustering evaluation measures in Table 2 shows the results using the full set of features (i.e., no feature selection).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 10 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['168'] | Citation Marker:  Stevenson and Joanis (2003) | Citation Offset:  ['168'] | Citation Text:  <S sid ="168" ssid = "17">Table 1 shows our results and the results of Stevenson and Joanis (2003) on T1 when employing AGG using Ward as the linkage criterion.</S> | Reference Offset:  ['188', '192', '10', '149'] | Reference Text:  <S sid ="188" ssid = "26">The first subcolumn (Full) under each of the three clustering evaluation measures in Table 2 shows the results using the full set of features (i.e., no feature selection).</S><S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S><S sid ="10" ssid = "10">Unsupervised or semi-supervised approaches have been successful as well, but have tended to be more restrictive, in relying on human filtering of the results (Riloff and Schmelzenbach, 1998), on the hand- selection of features (Stevenson and Merlo, 1999), or on the use of an extensive grammar (Schulte im Walde and Brew, 2002).</S><S sid ="149" ssid = "20">These figures are reported with our results in Table 2 below.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 11 | Reference Article:   W03-0410.xml | Citing Article:  D11-1095.xml | Citation Marker Offset:  ['169'] | Citation Marker:  Stevenson and Joanis (2003) | Citation Offset:  ['169'] | Citation Text:  <S sid ="169" ssid = "18">In this experiment, we used the same feature set as Stevenson and Joanis (2003) (set B, see section 3.1) and were therefore able to reproduce their AGG result with a difference smaller than 2%.</S> | Reference Offset:  ['192', '120', '51', '236'] | Reference Text:  <S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="236" ssid = "74">In our clustering experiments, we find that smaller subsets of features generally perform better than the full set of features.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 12 | Reference Article:   W03-0410.xml | Citing Article:  J06-2001.xml | Citation Marker Offset:  ['397'] | Citation Marker:  Stevenson and Joanis 2003 | Citation Offset:  ['397'] | Citation Text:  <S sid ="397" ssid = "325">For example, the accuracy/purity measure (Stevenson and Joanis 2003; Korhonen, Krymolowski, and Marx 2003) evaluates whether a verb is assigned to a correct cluster with respect to the gold standard class of the majority of cluster members.</S> | Reference Offset:  ['151', '143', '142', '157'] | Reference Text:  <S sid ="151" ssid = "22">Our second measure, the adjusted Rand measure used by Schulte im Walde (2003), instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification.</S><S sid ="143" ssid = "14">Then for all verbs , consider to be classified correctly if Class( )=ClusterLabel( ), where Class( ) is the actual class of and ClusterLabel( ) is the label assigned to the cluster in which is placed.</S><S sid ="142" ssid = "13">4.2.1 Accuracy We can assign each cluster the class label of the majority of its members.</S><S sid ="157" ssid = "28">4.2.3 Mean Silhouette gives an average of the individual goodness of the clusters, and a measure of the overall goodness, both with respect to the gold standard classes.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 13 | Reference Article:   W03-0410.xml | Citing Article:  J06-2001.xml | Citation Marker Offset:  ['586'] | Citation Marker:  Stevenson and Joanis (2003) | Citation Offset:  ['586','587','588','589'] | Citation Text:  <S sid ="586" ssid = "35">In recent work, Stevenson and Joanis (2003) compared their supervised method for verb classification with semisupervised and unsupervised techniques.</S><S sid ="587" ssid = "36">In these experiments, they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes, with a total of 841 verbs.</S><S sid ="588" ssid = "37">Low- frequency and ambiguous verbs were excluded from the classes.</S><S sid ="589" ssid = "38">They found that a semisupervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 approach of Dash, Liu, and Yao (1997), which used an entropy measure to organize data into a multidimensional space.</S> | Reference Offset:  ['120', '27', '28', '119'] | Reference Text:  <S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="27" ssid = "27">In this paper, we report results on several feature selection approaches to the problem: manual selection (based on linguistic knowledge), unsupervised selection (based on an entropy measure among the features, Dash et al., 1997), and a semi- supervised approach (in which seed verbs are used to train a supervised learner, from which we extract the useful features).</S><S sid ="28" ssid = "28">Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).</S><S sid ="119" ssid = "69">Table 1 above shows the number of verbs in each class at the end of this process.</S> | Discourse Facet:  ['Results_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 14 | Reference Article:   W03-0410.xml | Citing Article:  N13-1118.xml | Citation Marker Offset:  ['52'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['52'] | Citation Text:  <S sid ="52" ssid = "8">Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005).</S> | Reference Offset:  ['11', '19', '256', '51'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="19" ssid = "19">Dorr and Jones, 1996; Schulte im Walde and Brew, 2002).</S><S sid ="256" ssid = "5">The scores of Schulte im Walde (2003) range from .09 to .18, while ours range from .02 to .34, with a mean of .17 across all tasks.</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S> | Discourse Facet:  ['Implication_Citation', 'Method_Citation'] | Annotator:  CIST |


Citance Number: 15 | Reference Article:   W03-0410.xml | Citing Article:  P03-1009.xml | Citation Marker Offset:  ['124'] | Citation Marker:  (Stevenson and Joanis, 2003) | Citation Offset:  ['124'] | Citation Text:  <S sid ="124" ssid = "67">Our second measure is derived from purity, a global measure which evaluates the mean precision of the clusters, weighted according to the cluster size (Stevenson and Joanis, 2003).</S> | Reference Offset:  ['144', '168', '171', '151'] | Reference Text:  <S sid ="144" ssid = "15">Then accuracy has the standard definition:2 2 is equivalent to the weighted mean precision of the clusters, weighted according to cluster size.</S><S sid ="168" ssid = "6">We use , the mean of the silhouette measure from Matlab, which measures how distant a data point is from other clusters.</S><S sid ="171" ssid = "9">We calculate the mean silhouette of all points in a clustering to obtain an overall measure of how well the clusters are separated.</S><S sid ="151" ssid = "22">Our second measure, the adjusted Rand measure used by Schulte im Walde (2003), instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 16 | Reference Article:   W03-0410.xml | Citing Article:  P03-1009.xml | Citation Marker Offset:  ['143'] | Citation Marker:  Stevenson and Joanis (2003) | Citation Offset:  ['143'] | Citation Text:  <S sid ="143" ssid = "86">For example, Stevenson and Joanis (2003) report an accuracy of 29% (which implies mP U R ≤ 29%), but their task involves classifying 841 verbs to 14 classes based on differences in the predicate-argument structure.</S> | Reference Offset:  ['120', '51', '192', '17'] | Reference Text:  <S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |


Citance Number: 17 | Reference Article:   W03-0410.xml | Citing Article:  P04-2007.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['11'] | Citation Text:  <S sid ="11" ssid = "11">For this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted ((Merlo and Stevenson, 2001), (Stevenson and Joanis, 2003), (Schulte im Walde, 2003)).</S> | Reference Offset:  ['11', '9', '51', '120'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="9" ssid = "9">A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (Gildea and Jurafsky, 2002), selectional preferences (Resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (Dorr and Jones, 1996; Lapata and Brew, 1999; Merlo and Stevenson, 2001; Joanis and Stevenson, 2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 18 | Reference Article:   W03-0410.xml | Citing Article:  P04-2007.xml | Citation Marker Offset:  ['75'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['75'] | Citation Text:  <S sid ="75" ssid = "7">Our choice of the parameter settings is motivated by the work of (Stevenson and Joanis, 2003).</S> | Reference Offset:  ['39', '120', '51', '17'] | Reference Text:  <S sid ="39" ssid = "6">Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 19 | Reference Article:   W03-0410.xml | Citing Article:  P04-2007.xml | Citation Marker Offset:  ['125'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['125'] | Citation Text:  <S sid ="125" ssid = "57">Nevertheless, our results are comparable to a subset of experiments reported in (Stevenson and Joanis, 2003), where they perform similar clustering experiments on English verbs based on a general description of verbs, obtaining average Adjusted Rand measures of 0.04 and 0.07.</S> | Reference Offset:  ['192', '120', '151', '51'] | Reference Text:  <S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="151" ssid = "22">Our second measure, the adjusted Rand measure used by Schulte im Walde (2003), instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification.</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 20 | Reference Article:   W03-0410.xml | Citing Article:  P07-3016.xml | Citation Marker Offset:  ['39'] | Citation Marker:  (Stevenson and Joanis, 2003) | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "16">(Stevenson and Joanis, 2003) investigate the applicability of this general feature space to unsupervised verb clustering tasks.</S> | Reference Offset:  ['23', '22', '39', '51'] | Reference Text:  <S sid ="23" ssid = "23">In an unsupervised (clustering) scenario of verb class discovery, can we maintain the benefit of only needing noisy features, without the generality of the feature space leading to “the curse of dimensionality”?</S><S sid ="22" ssid = "22">However, a general feature space means that most features will be irrelevant to any given verb discrimination task.</S><S sid ="39" ssid = "6">Here we briefly describe the features that comprise our feature space, and refer the interested reader to Joanis and Stevenson (2003) for details.</S><S sid ="51" ssid = "1">We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 21 | Reference Article:   W03-0410.xml | Citing Article:  W06-2910.xml | Citation Marker Offset:  ['8'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['7','8'] | Citation Text:  <S sid ="7" ssid = "7">As an alternative to the resource-intensive manual classifications, automatic methods such as classification and clustering are applied to induce verb classes from corpus data, e.g.</S><S sid ="8" ssid = "8">(Merlo and Stevenson, 2001; Joanis and Stevenson, 2003; Korhonen et al., 2003; Stevenson and Joanis, 2003; Schulte im Walde, 2003; Fer- rer, 2004).</S> | Reference Offset:  ['11', '256', '120', '261'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="256" ssid = "5">The scores of Schulte im Walde (2003) range from .09 to .18, while ours range from .02 to .34, with a mean of .17 across all tasks.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="261" ssid = "1">We have explored manual, unsupervised, and semi- supervised methods for feature selection in a clustering approach for verb class discovery.</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 22 | Reference Article:   W03-0410.xml | Citing Article:  W06-2910.xml | Citation Marker Offset:  ['13'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">In larger-scale classifications such as (Korhonen et al., 2003; Stevenson and Joanis, 2003; Schulte im Walde, 2003), which model verb classes with similarity at the syntax-semantics interface, it is not clear which features are the most salient.</S> | Reference Offset:  ['255', '11', '17', '120'] | Reference Text:  <S sid ="255" ssid = "4">Schulte im Walde and Brew (2002) and Schulte im Walde (2003), on the other hand, use a larger set of features intended to be useful for a broad number of classes, as in our work.</S><S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 23 | Reference Article:   W03-0410.xml | Citing Article:  W06-2910.xml | Citation Marker Offset:  ['118'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['118','119'] | Citation Text:  <S sid ="118" ssid = "21">For the evaluation of the clustering results, we calculated the accuracy of the clusters, a cluster similarity measure that has been applied before, cf.</S><S sid ="119" ssid = "22">(Stevenson and Joanis, 2003; Korhonen et al., 2003)</S> | Reference Offset:  ['141', '150', '171', '188'] | Reference Text:  <S sid ="141" ssid = "12">We use three separate evaluation measures, that tap into very different properties of the clusterings.</S><S sid ="150" ssid = "21">4.2.2 Adjusted Rand Measure Accuracy can be relatively high for a clustering when a few clusters are very good, and others are not good.</S><S sid ="171" ssid = "9">We calculate the mean silhouette of all points in a clustering to obtain an overall measure of how well the clusters are separated.</S><S sid ="188" ssid = "26">The first subcolumn (Full) under each of the three clustering evaluation measures in Table 2 shows the results using the full set of features (i.e., no feature selection).</S> | Discourse Facet:  Method_Citation | Annotator:  CIST |


Citance Number: 24 | Reference Article:   W03-0410.xml | Citing Article: E09-1072.xml | Citation Marker Offset:  ['80'] | Citation Marker:  Stevenson and Joanis, 2003 | Citation Offset:  ['80'] | Citation Text:  <S sid ="80" ssid = "6">Following a strategy in line with work on verb classification (Merlo and Stevenson, 2001; Stevenson and Joanis, 2003), we set out to classify common noun lemmas based on their morphosyntactic distribution in a considerably larger corpus.</S> | Reference Offset:  ['11', '120', '17', '192'] | Reference Text:  <S sid ="11" ssid = "11">We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.</S><S sid ="120" ssid = "70">Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).</S><S sid ="17" ssid = "17">We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).</S><S sid ="192" ssid = "30">Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.</S> | Discourse Facet:  ['Method_Citation', 'Results_Citation'] | Annotator:  CIST |