We used the hierarchical clustering command in Matlab, which implements bottom-up agglomerative clustering, for all our unsupervised experiments. We have explored manual, unsupervised, and semi- supervised methods for feature selection in a clustering approach for verb class discovery. We then replaced 10 of the 260 verbs (4%) to enable us to have representative seed verbs for certain classes in our semi-supervised experiments (e.g., so that we could include wipe as a seed verb for the Wipe verbs, and fill for the Fill verbs). 4.2.1 Accuracy We can assign each cluster the class label of the majority of its members. In performing hierarchical clustering, both a vector distance measure and a cluster distance (ÃḃÂÂlinkageÃḃÂÂ) measure are specified. Ward linkage essentially minimizes the distances of all cluster points to the centroid, and thus is less sensitive to outliers than some other methods. Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2. 1 For practical reasons, as well as for enabling us to draw more general conclusions from the results, the classes also could neither be too small nor contain mostly infrequent verbs. Each clustering experiment used the full set of 20 verbs per class; i.e., seed verbs were included, following our proposed model of guided verb class discovery.5 The results using these feature sets are shown in the third subcolumn (Seed)
