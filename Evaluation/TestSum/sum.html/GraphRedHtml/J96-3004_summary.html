<html>
<head><title>J96-3004_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="1">[1]</a> <a href="#1" id=1>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="2">[2]</a> <a href="#2" id=2>Church and Hanks [ 1989 ] ) , and we have used lists of character pairs ranked by mutual information to expand our own dictionary . </a>
<a name="3">[3]</a> <a href="#3" id=3>In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . </a>
<a name="4">[4]</a> <a href="#4" id=4>For novel texts , no lexicon that consists simply of a list of word entries will ever be entirely satisfactory , since the list will inevitably omit many constructions that should be considered words . </a>
<a name="5">[5]</a> <a href="#5" id=5>A related point is that mutual information is helpful in augmenting existing electronic dictionaries , ( cf . </a>
<a name="6">[6]</a> <a href="#6" id=6>A related point is that mutual information is helpful in augmenting existing electronic dictionaries , ( cf . </a>
<a name="7">[7]</a> <a href="#7" id=7>All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria </a>
<a name="8">[8]</a> <a href="#8" id=8>All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria </a>
<a name="9">[9]</a> <a href="#9" id=9>Furthermore , even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus : as Fung and Wu ( 1994 ) have shown , one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented . </a>
<a name="10">[10]</a> <a href="#10" id=10>It has been shown for English ( Wang and Hirschberg 1992 ; Hirschberg 1993 ; Sproat 1994 , inter aria that grammatical part of speech provides useful information for these tasks . </a>
<a name="11">[11]</a> <a href="#11" id=11>In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . </a>
<a name="12">[12]</a> <a href="#12" id=12>Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . </a>
<a name="13">[13]</a> <a href="#13" id=13>4.2 A Sample Segmentation Using Only Dictionary Words Figure 4 shows two possible paths from the lattice of possible analyses of the input sentence B X : Â¥ . : .S : P : l 'How do you say octopus in Japanese ? ' previously shown in Figure 1 . </a>
<a name="14">[14]</a> <a href="#14" id=14>2 Chinese ? l* han 4zi 4 character ' ; this is the same word as Japanese Kania </a>
<a name="15">[15]</a> <a href="#15" id=15>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="16">[16]</a> <a href="#16" id=16>( See Sproat and Shih 1995 . ) </a>
<a name="17">[17]</a> <a href="#17" id=17>The method just described segments dictionary words , but as noted in Section 1 , there are several classes of words that should be handled that are not found in a standard dictionary . </a>
<a name="18">[18]</a> <a href="#18" id=18>The cost is computed as follows , where N is the corpus size and f is the frequency : ( 1 ) Besides actual words from the base dictionary , the lexicon contains all Hanni in the Big 5 Chinese code with their pronunciation ( s ) , plus entries for other characters that can be found in Chinese text , such as Roman letters , numerals , and special symbols . </a>
<a name="19">[19]</a> <a href="#19" id=19>Purely statistical approaches have not been very popular , and so far as we are aware earlier work by Sproat and Shih ( 1990 ) is the only published instance of such an approach . </a>
<a name="20">[20]</a> <a href="#20" id=20>While size of the resulting transducers may seem daunting-the segmented described here , as it is used in the Bell Labs Mandarin TTS system has about 32,000 states and 209,000 arcs-recent work on minimization of weighted machines and transducers ( cf . </a>
<a name="21">[21]</a> <a href="#21" id=21>( See Sproat and Shih 1995 . ) </a>
<a name="22">[22]</a> <a href="#22" id=22>The average agreement among the human judges is .76 , and the average agreement between ST and the humans is .75 , or about 99 % of the inter human One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix , computing a classical metric multidimensional scaling ( Torgerson 1958 ; Becker , Chambers , Wilks 1988 ) on that disÂ­ stance matrix , and plotting the first two most significant dimensions . </a>
<a name="23">[23]</a> <a href="#23" id=23>In ( 1 ) the sequencema 3lu 4 can not be resolved locally , but depends instead upon broader context ; similarly in ( 2 ) , the sequence : : : tcai2neng2 can not be resolved locally : 1 . </a>
<a name="24">[24]</a> <a href="#24" id=24>In ( 1 ) the sequencema 3lu 4 can not be resolved locally , but depends instead upon broader context ; similarly in ( 2 ) , the sequence : : : tcai2neng2 can not be resolved locally : 1 . </a>
<a name="25">[25]</a> <a href="#25" id=25>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="26">[26]</a> <a href="#26" id=26>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="27">[27]</a> <a href="#27" id=27>( See Sproat and Shih 1995 . ) </a>
<a name="28">[28]</a> <a href="#28" id=28>Unfortunately , there is no standard corpus of Chinese texts , tagged with either single or multiple human judgments , with which one can compare performance of various methods . </a>
<a name="29">[29]</a> <a href="#29" id=29>com Â§Cambridge , UK Email : nc201 eng.cam.ac.uk 1996 Association for Computational Linguistics ( a ) B ) ( , : & ; ? ' H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? ' ( b ) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : & I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l ' J a p a n e s e ' ' o c t o p u s ' ' h o w ' ' s a y ' ( c ) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [ Â§ ] lxI 1 : & I ri4 wen 2 yu2zen3 shuttle ' essay fish how say A Chinese sentence in ( a ) illustrating the lack of word boundaries . </a>
<a name="30">[30]</a> <a href="#30" id=30>In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . </a>
<a name="31">[31]</a> <a href="#31" id=31>Word type N % Dic son entries 2 , 5 4 3 9 7 . 4 7 Mor pho log call y derived wor ds 3 0 . 1 1 Fore ign ran rat ons 9 0 . 3 4 Per son al na mes 5 4 2 . 0 7 cases . </a>
<a name="32">[32]</a> <a href="#32" id=32>Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . </a>
<a name="33">[33]</a> <a href="#33" id=33>Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . </a>
<a name="34">[34]</a> <a href="#34" id=34>The model we use provides a simple framework in which to incorporate a wide variety of lexical information in a uniform way . </a>
<a name="35">[35]</a> <a href="#35" id=35>The model we use provides a simple framework in which to incorporate a wide variety of lexical information in a uniform way . </a>
<a name="36">[36]</a> <a href="#36" id=36>Furthermore , by inverting the transducer so that it maps from phonemic transcriptions to Hanni sequences , one can apply the segmented to other problems , such as speech recognition ( Pereira , Riley , and Sproat 1994 ) . </a>
<a name="37">[37]</a> <a href="#37" id=37>( See Sproat and Shih 1995 . ) </a>
<a name="38">[38]</a> <a href="#38" id=38>( See Sproat and Shih 1995 . ) </a>
<a name="39">[39]</a> <a href="#39" id=39>( See Sproat and Shih 1995 . ) </a>
<a name="40">[40]</a> <a href="#40" id=40>( See Sproat and Shih 1995 . ) </a>
<a name="41">[41]</a> <a href="#41" id=41>( See Sproat and Shih 1995 . ) </a>
<a name="42">[42]</a> <a href="#42" id=42>As a first step towards modeling transliterated names , we have collected all Hanni occurring more than once in the roughly 750 foreign names in our dictionary , and we estimate the probabilÂ­ ity of occurrence of each Hanni in a transliteration ( pTN ( Hanni ; ) ) using the maximum likelihood estimate . </a>
<a name="43">[43]</a> <a href="#43" id=43>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="44">[44]</a> <a href="#44" id=44>All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria </a>
<a name="45">[45]</a> <a href="#45" id=45>For a sequence of Hanni that is a possible name , we wish to assign a probability to that sequence qua name . </a>
<a name="46">[46]</a> <a href="#46" id=46>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="47">[47]</a> <a href="#47" id=47>In this paper we present a stochastic finite-state model for segmenting Chinese text into words , both words found in a ( static ) lexicon as well as words derived via the above-mentioned productive processes . </a>
<a name="48">[48]</a> <a href="#48" id=48>Nonetheless , the results of the comparison with human judges demonstrates that there is mileage being gained by incorporating models of these types of words . </a>
<a name="49">[49]</a> <a href="#49" id=49>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="50">[50]</a> <a href="#50" id=50>( See Sproat and Shih 1995 . ) </a>
<a name="51">[51]</a> <a href="#51" id=51>Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . </a>
<a name="52">[52]</a> <a href="#52" id=52>Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . </a>
<a name="53">[53]</a> <a href="#53" id=53>( See Sproat and Shih 1995 . ) </a>
<a name="54">[54]</a> <a href="#54" id=54>Other strategies could readily 6 As a reviewer has pointed out , it should be made clear that the function for computing the best path is . an instance of the Viterbi algorithm . </a>
<a name="55">[55]</a> <a href="#55" id=55>All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria </a>
<a name="56">[56]</a> <a href="#56" id=56>In this way , the method reported on here will necessarily be similar to a greedy method , though of course not identical . </a>
<a name="57">[57]</a> <a href="#57" id=57>G1 and G2 are Hanni we can estimate the probability of the sequence being a name as the product of : â¢ the probability that a word chosen randomly from a text will be a name-p ( rule 1 ) , and â¢ the probability that the name is of the form 1hanzi-family 2hanzi-given-p ( rule 2 ) , and â¢ the probability that the family name is the particular Hanni ( rule 6 ) , and â¢ the probability that the given name consists of the particular Hanni and G2-p ( rule 9 ) This model is essentially the one proposed in Chang et al . </a>
<a name="58">[58]</a> <a href="#58" id=58>Other kinds of productive word classes , such as company names , abbreviations ( termed fijsuolxie3 in Mandarin ) , and place names can easily be 20 Note that 7 in E 7 is normally pronounced as leO , but as part of a resultant it is liao 3.. </a>
<a name="59">[59]</a> <a href="#59" id=59>Affix Pron Base category N found N missed ( recall ) N correct ( precision ) t , -,7 The second issue is that rare family names can be responsible for over generation especially if these names are otherwise common as single-hanzi words . </a>
<a name="60">[60]</a> <a href="#60" id=60>As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . </a>
<a name="61">[61]</a> <a href="#61" id=61>including Third Tone Sandhi ( Shih 1986 ) , which changes a 3 ( low ) tone into a 2 ( rising ) tone before another 3 tone : 'j '' ; gil , xiao 3 lao 3 ] little rat , ' becomes xiao 3 lao2shu3 , rather than xiao 2 lao2shu3 , because the rule first applies within the word lao3shu3 , ' blocking its phrasal application . </a>
<a name="62">[62]</a> <a href="#62" id=62>In various dialects of Mandarin certain phonetic rules apply at the word . </a>
<a name="63">[63]</a> <a href="#63" id=63>In various dialects of Mandarin certain phonetic rules apply at the word . </a>
<a name="64">[64]</a> <a href="#64" id=64>For that application , at a minimum , one would want to know the phonological word boundaries . </a>
<a name="65">[65]</a> <a href="#65" id=65>( See Sproat and Shih 1995 . ) </a>
<a name="66">[66]</a> <a href="#66" id=66>( See Sproat and Shih 1995 . ) </a>
<a name="67">[67]</a> <a href="#67" id=67>including Third Tone Sandhi ( Shih 1986 ) , which changes a 3 ( low ) tone into a 2 ( rising ) tone before another 3 tone : 'j '' ; gil , xiao 3 lao 3 ] little rat , ' becomes xiao 3 lao2shu3 , rather than xiao 2 lao2shu3 , because the rule first applies within the word lao3shu3 , ' blocking its phrasal application . </a>
<a name="68">[68]</a> <a href="#68" id=68>More formally , we start by representing the dictionary D as a Weighted Finite State TransÂ­ duce WFST ) ( Pereira , Riley , and Sproat 1994 ) . </a>
<a name="69">[69]</a> <a href="#69" id=69>However , there will remain a large number of words that are not readily adduced to any producÂ­ tie pattern and that would simply have to be added to the dictionary . </a>
<a name="70">[70]</a> <a href="#70" id=70>In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . </a>
<a name="71">[71]</a> <a href="#71" id=71>As we have seen , the lexicon of basic words and stems is represented as a WFST ; most arcs in this WFST represent mappings between Hanni and pronunciations , and are costless . </a>
<a name="72">[72]</a> <a href="#72" id=72>In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . </a>
<a name="73">[73]</a> <a href="#73" id=73>Gan 's solution depends upon a fairly sophisticated language model that attempts to find valid syntactic , semantic , and lexical relations between objects of various linguistic types ( Hanni words , phrases ) . </a>
<a name="74">[74]</a> <a href="#74" id=74>There are thus some very good reasons why segmentation into words is an important task . </a>
<a name="75">[75]</a> <a href="#75" id=75>( See Sproat and Shih 1995 . ) </a>
<a name="76">[76]</a> <a href="#76" id=76>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="77">[77]</a> <a href="#77" id=77>There are thus some very good reasons why segmentation into words is an important task . </a>
<a name="78">[78]</a> <a href="#78" id=78>As noted , this sentence consists of four words , namely B X ri4wen2 , ' : Â¥ , zhanglyu 2 : & P : l zen 3me 0 , ' and IDt shuttle . ' </a>
<a name="79">[79]</a> <a href="#79" id=79>As noted , this sentence consists of four words , namely B X ri4wen2 , ' : Â¥ , zhanglyu 2 : & P : l zen 3me 0 , ' and IDt shuttle . ' </a>
<a name="80">[80]</a> <a href="#80" id=80>logical rules , and personal names ; the transitive closure of the resulting machine is then computed . </a>
<a name="81">[81]</a> <a href="#81" id=81>( See Sproat and Shih 1995 . ) </a>
<a name="82">[82]</a> <a href="#82" id=82>( See Sproat and Shih 1995 . ) </a>
<a name="83">[83]</a> <a href="#83" id=83>One class comprises words derived by productive morphologiÂ­ cal processes , such as plural noun formation using the suffix ir , menD . </a>
<a name="84">[84]</a> <a href="#84" id=84>( See Sproat and Shih 1995 . ) </a>
<a name="85">[85]</a> <a href="#85" id=85>This larger corpus was kindly provided to us by United Informatics Inc. , R.O.C . a set of initial estimates of the word frequencies. 9 In this re-estimation procedure only the entries in the base dictionary were used : in other words , derived words not in the base dictionary and personal and foreign names were not used . </a>
<a name="86">[86]</a> <a href="#86" id=86>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="87">[87]</a> <a href="#87" id=87>There are thus some very good reasons why segmentation into words is an important task . </a>
<a name="88">[88]</a> <a href="#88" id=88>There are thus some very good reasons why segmentation into words is an important task . </a>
<a name="89">[89]</a> <a href="#89" id=89>There are thus some very good reasons why segmentation into words is an important task . </a></body>
</html>
