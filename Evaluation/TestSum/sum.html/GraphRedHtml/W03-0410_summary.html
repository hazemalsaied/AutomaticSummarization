<html>
<head><title>W03-0410_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Like others , we have assumed lexical semantic classes of verbs as defined in Levin ( 1993 ) ( hereafter Levin ) , which have served as a gold standard in computational linguistics research ( Dorr and Jones , 1996 ; Kipper et al. , 2000 ; Merlo and Stevenson , 2001 ; Schulte im Walde and Brew , 2002 ) . </a>
<a name="1">[1]</a> <a href="#1" id=1>A number of supervised learning approaches have extracted such information about verbs from corpora , including their argument roles ( Gildea and Jurafsky , 2002 ) , selectional preferences ( Resnik , 1996 ) , and lexical semantic classification ( i.e. , grouping verbs according to their argument structure properties ) ( Dorr and Jones , 1996 ; Lapata and Brew , 1999 ; Merlo and Stevenson , 2001 ; Joanis and Stevenson , 2003 ) . </a>
<a name="2">[2]</a> <a href="#2" id=2>A number of supervised learning approaches have extracted such information about verbs from corpora , including their argument roles ( Gildea and Jurafsky , 2002 ) , selectional preferences ( Resnik , 1996 ) , and lexical semantic classification ( i.e. , grouping verbs according to their argument structure properties ) ( Dorr and Jones , 1996 ; Lapata and Brew , 1999 ; Merlo and Stevenson , 2001 ; Joanis and Stevenson , 2003 ) . </a>
<a name="3">[3]</a> <a href="#3" id=3>Our second measure , the adjusted Rand measure used by Schulte im Walde ( 2003 ) , instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification . </a>
<a name="4">[4]</a> <a href="#4" id=4>However , Schulte im Waldeâs features rely on accurate categorization statistics , and her experiments include a much larger set of classes ( around 40 ) , each with a much smaller number of verbs ( average around 4 ) . </a>
<a name="5">[5]</a> <a href="#5" id=5>Of these verbs , 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson ( 2003 ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>However , a general feature space means that most features will be irrelevant to any given verb discrimination task . </a>
<a name="7">[7]</a> <a href="#7" id=7>In other ways , however , it is too difficult : the learner has to distinguish multiple classes , rather than focus on the important properties of a single class . </a>
<a name="8">[8]</a> <a href="#8" id=8>However , in many aspects of computational linguistics , it has been found that a small amount of labeled data contains sufficient information to allow us to go beyond the limits of completely unsupervised approaches . </a>
<a name="9">[9]</a> <a href="#9" id=9>Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . </a>
<a name="10">[10]</a> <a href="#10" id=10>These figures are reported with our results in Table 2 below . </a>
<a name="11">[11]</a> <a href="#11" id=11>However , Schulte im Waldeâs features rely on accurate categorization statistics , and her experiments include a much larger set of classes ( around 40 ) , each with a much smaller number of verbs ( average around 4 ) . </a>
<a name="12">[12]</a> <a href="#12" id=12>Rather than trying to separate a set of new verbs into coherent clusters , we suggest that it may be useful to perform a nearest-neighbour type of classification using a seed set , asking for each new verb âis it like these or not ? â In some ways our current clustering task is too easy , because all of the verbs are from one of the target classes . </a>
<a name="13">[13]</a> <a href="#13" id=13>In this paper , we report results on several feature selection approaches to the problem : manual selection ( based on linguistic knowledge ) , unsupervised selection ( based on an entropy measure among the features , Dash et al. , 1997 ) , and a semi- supervised approach ( in which seed verbs are used to train a supervised learner , from which we extract the useful features ) . </a>
<a name="14">[14]</a> <a href="#14" id=14>Although our motivation is verb class discovery , we perform our experiments on English , for which we have an accepted classification to serve as a gold standard ( Levin , 1993 ) . </a>
<a name="15">[15]</a> <a href="#15" id=15>Although our motivation is verb class discovery , we perform our experiments on English , for which we have an accepted classification to serve as a gold standard ( Levin , 1993 ) . </a>
<a name="16">[16]</a> <a href="#16" id=16>Although our motivation is verb class discovery , we perform our experiments on English , for which we have an accepted classification to serve as a gold standard ( Levin , 1993 ) . </a>
<a name="17">[17]</a> <a href="#17" id=17>Our second measure , the adjusted Rand measure used by Schulte im Walde ( 2003 ) , instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification . </a>
<a name="18">[18]</a> <a href="#18" id=18>The formula is as follows ( Hubert and Arabie , 1985 ) : where is the entry in the contingency table between the classification and the clustering , counting the size of the intersection of class and cluster . Intuitively , measures the similarity of two partitions of data by considering agreements and disagreements between them there is agreement , for example , if and from the same class are in the same cluster , and disagreement if they are not . </a>
<a name="19">[19]</a> <a href="#19" id=19>Of these verbs , 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson ( 2003 ) . </a>
<a name="20">[20]</a> <a href="#20" id=20>Development of minimally supervised methods is of particular importance if we are to automatically classify verbs for languages other than English , where substantial amounts of labeled data are not available for training classifiers . </a>
<a name="21">[21]</a> <a href="#21" id=21>Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . </a>
<a name="22">[22]</a> <a href="#22" id=22>Although our motivation is verb class discovery , we perform our experiments on English , for which we have an accepted classification to serve as a gold standard ( Levin , 1993 ) . </a>
<a name="23">[23]</a> <a href="#23" id=23>In an unsupervised ( clustering ) scenario of verb class discovery , can we maintain the benefit of only needing noisy features , without the generality of the feature space leading to âthe curse of dimensionality </a>
<a name="24">[24]</a> <a href="#24" id=24>Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . </a>
<a name="25">[25]</a> <a href="#25" id=25>Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . </a>
<a name="26">[26]</a> <a href="#26" id=26>Of these verbs , 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson ( 2003 ) . </a>
<a name="27">[27]</a> <a href="#27" id=27>The formula is as follows ( Hubert and Arabie , 1985 ) : where is the entry in the contingency table between the classification and the clustering , counting the size of the intersection of class and cluster . Intuitively , measures the similarity of two partitions of data by considering agreements and disagreements between them there is agreement , for example , if and from the same class are in the same cluster , and disagreement if they are not . </a>
<a name="28">[28]</a> <a href="#28" id=28>Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . </a>
<a name="29">[29]</a> <a href="#29" id=29>However , Schulte im Waldeâs features rely on accurate categorization statistics , and her experiments include a much larger sets of Class ( around 40 ) , each with a much smaller numbers of Verb ( average around 4 ) . </a></body>
</html>
