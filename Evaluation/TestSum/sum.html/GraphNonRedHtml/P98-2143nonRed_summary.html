<html>
<head><title>P98-2143nonRed_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In fact , our evaluation shows that the reÂ­ cults are comparable to syntax-based methods ( Lappin & Leass I994 ) . </a>
<a name="1">[1]</a> <a href="#1" id=1>Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain Andros linguistic knowledge ( Baldwin 1997 ; Dagan & ital 1990 ; Kennedy & Boguraev 1996 ; Mitkov 1998 ; Nasukawa 1994 ; Williams et al . 1996 ) . </a>
<a name="2">[2]</a> <a href="#2" id=2>We have described a robust , knowledge-poor apÂ­ roach to pronoun resolution which operates on texts pre-processed by a part-of-speech tagger . </a>
<a name="3">[3]</a> <a href="#3" id=3>Robust pronoun resolution with limited knowledge</a>
<a name="4">[4]</a> <a href="#4" id=4>This measure ( Mitkov 1998b applies only to anaphora ambiguous '' from the point of view of number and gender ( i.e . to those `` tough '' anaphora , after activating the gender and number filters , still have more than one candidate for antecedent ) and is indicative of the performance of the antecedent indicators . </a>
<a name="5">[5]</a> <a href="#5" id=5>The approach works as follows : it takes as an input the output of a text processed by a part-of-speech tagger , identifies the noun phrases which precede the anaphora within a distance of 2 sentences , checks them for gender and number agreement with the anaphora and then applies the genre-specific antecedent indicators to the reÂ­ raining candidates ( see next section ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>Finally , our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English , but also for other languages ( in our case Polish and Arabic ) . </a>
<a name="7">[7]</a> <a href="#7" id=7>This rule is ignored if there are no definite articles , possessive or demonstrative proÂ­ nouns in the paragraph ( this exception is taken into account because some English user 's guides tend to omit articles ) . </a>
<a name="8">[8]</a> <a href="#8" id=8>However , to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense . </a>
<a name="9">[9]</a> <a href="#9" id=9>It is also an example of how anaphora in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing . </a>
<a name="10">[10]</a> <a href="#10" id=10>For the most part , anaphora resolution has focused on traditional linguistic methods ( Carbonell & Brown 1988 ; Carter 1987 ; Hobbs 1978 ; Ingria & Stallard 1989 ; Lappin & McCord 1990 ; Lappin & Leass 1994 ; Mitkov 1994 ; Rich & LuperFoy 1988 ; Sidner 1979 ; Webber 1979 ) . </a>
<a name="11">[11]</a> <a href="#11" id=11>Givenness Noun phrases in previous sentences representing the `` given information '' ( theme ) 1 are deemed good candidates for antecedents and score I ( candidates not representing the theme score 0 ) . </a>
<a name="12">[12]</a> <a href="#12" id=12>ital candidate and assign scores ; the candidate with the highest aggregate score is proposed as 3A sentence splitter would already have segmented the text into sentences , a POS tagger would already have determined the parts of speech and a simple phrasal grammar would already have detected the noun phrases 4In this project we do not treat anaphora non-anaphoric `` it '' occurring in constructions such as `` It is important '' , `` It is necessary '' is eliminated by a `` referential filter '' 5Note that this restriction may not always apply in lanÂ­ gages other than English ( e.g . German ) ; on the other hand , there are certain collective nouns in English which do not agree in number with their antecedents ( e.g . `` government '' , `` team '' , `` parliament '' etc . can be referred to by `` they '' ; equally some plural nouns ( e.g . `` data '' ) can be referred to by `` it '' ) and are exempted from the agreeÂ­ met test . </a>
<a name="13">[13]</a> <a href="#13" id=13>3.2 Evaluation B . We carried out a second evaluation of the approach on a different set of sample texts from the genre of technical manuals ( 47-page Portable Style-Writer User 's Guide ( Stylewriter 1994 ) . </a>
<a name="14">[14]</a> <a href="#14" id=14>Note that `` Baseline subject '' can be assessed both in terms of recall and precision because this `` version '' is not robust : in the event of no subject being available , it is not able to propose an antecedent ( the manual guide used as evaluation text contained many imÂ­ imperative sentences ) . </a>
<a name="15">[15]</a> <a href="#15" id=15>3.3 Comparison to similar approaches : comparaÂ­ . </a>
<a name="16">[16]</a> <a href="#16" id=16>We have recently adapted the approach for AraÂ­ bic as well ( Mitkov & Belguith 1998 ) . </a>
<a name="17">[17]</a> <a href="#17" id=17>In order to evaluate the effectiveness of the apÂ­ roach and to explore if I how far it is superior over the baseline models for anaphora resolution , we also tested the sample text on ( i ) a Baseline Model which checks agreement in number and gender and , where more than one candidate remains , picks as anteceÂ­ dent the most recent subject matching the gender and number of the anaphora ii ) a Baseline Model which picks as antecedent the most recent noun phrase that matches the gender and number of the anaphora </a>
<a name="18">[18]</a> <a href="#18" id=18>It makes use of only a part-of-speech tagger , plus simple noun phrase rules ( sentence constituents are identified at the level of noun phrase at most ) and operates on the basis of antecedent-tracking preferences ( referred to hereafter as `` antecedent indicators '' ) . </a>
<a name="19">[19]</a> <a href="#19" id=19>Look for noun phrases 3 only to the left of the anaphor 4 2 . </a>
<a name="20">[20]</a> <a href="#20" id=20>As expected , some of the preferences had to be modified in order to fit with specific features of Polish ( Mitkov & Stys 1997 ) . </a>
<a name="21">[21]</a> <a href="#21" id=21>3.1 Evaluation A . Our first evaluation exercise ( Mitkov & Stys 1997 ) was based on a random sample text from a technical manual in English ( Minolta 1994 ) . </a>
<a name="22">[22]</a> <a href="#22" id=22>While various alternatives have been proposed , making use of e.g . neural networks , a situation seÂ­ antics framework , or the principles of reasoning with uncertainty ( e.g . Connoly et al . 1994 ; Mitkov 1995 ; Tin & Akman 1995 ) , there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems , and to enhance further the automatic proÂ­ cussing of growing language resources . </a>
<a name="23">[23]</a> <a href="#23" id=23>In particular , this strategy can often override incorrect decisions linked with strong centering preference ( Mitkov & Belguith I998 ) or syntactic and semantic parallelism preferÂ­ hences see below ) . </a>
<a name="24">[24]</a> <a href="#24" id=24>Our work is a continuation of these latest trends in the search for inexpensive , fast and reliable procedures for anaphÂ­ ora resolution . </a>
<a name="25">[25]</a> <a href="#25" id=25>2.2 Informal description of the algorithm . </a>
<a name="26">[26]</a> <a href="#26" id=26>While we acknowledge that most of the monolingual NLP approaches are not automatically transferable ( with the same degree of efficiency ) to other languages , it would be highly desirable if this could be done with minimal adaptaÂ­ son . </a>
<a name="27">[27]</a> <a href="#27" id=27>The evaluation carried out was manual to ensure that no added error was genÂ­ rated e.g . due to possible wrong sentence detection or POS tagging ) . </a>
<a name="28">[28]</a> <a href="#28" id=28>When all preferences ( antecedent indicators ) are taken into account , however , the right antecedent is still very likely to be tracked down - in the above example , the `` non-prepositional noun phrases '' heuristics ( penalty ) would be overturned by the `` collocation preference '' heuristics . </a>
<a name="29">[29]</a> <a href="#29" id=29>In the following we shall outline some the indicators used and shall illustrate them by exÂ­ ample . </a>
<a name="30">[30]</a> <a href="#30" id=30>For practical reasons , the approach presented does not incorporate syntactic and semantic information ( other than a list of domain terms ) and it is not realÂ­ is tic to expect its performance to be as good as an approach which makes use of syntactic and semantic knowledge in terms of constraints and preferences . </a>
<a name="31">[31]</a> <a href="#31" id=31>CogNIAC successfully resolved the pronouns in 75 % of the cases . </a>
<a name="32">[32]</a> <a href="#32" id=32>Syntactic parallelism , useful in discrimiÂ­ eating between identical pronouns on the basis of their syntactic function , also has to be forgone . </a>
<a name="33">[33]</a> <a href="#33" id=33>tie evaluation of Breck Baldwin 's CogNIAC We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin 's CogÂ­ NIAC ( Baldwin 1997 ) approach which features `` high precision preference with limited knowledge and linguistics resources '' . </a>
<a name="34">[34]</a> <a href="#34" id=34>In a coherent text ( Firbas 1992 ) , the given or known information , or theme , usually appears first , and thus forms a coÂ­ referential link with the preceding text . </a>
<a name="35">[35]</a> <a href="#35" id=35>Unwrap the paperiness form iti and align  then load iti into the drawer . </a>
<a name="36">[36]</a> <a href="#36" id=36>The reason is that both our approach and Breck Baldwin 's approach share common principles ( both are knowledge-poor and use a POS tagger to provide the input ) and therefore a comparison would be appropriate . </a>
<a name="37">[37]</a> <a href="#37" id=37>For the training data from the genre of technical manuals , it was rule 5 ( see Baldwin 1997 ) which was most frequently used ( 39 % of the cases , 100 % success ) , followed by rule 8 ( 33 % of the cases , 33 % success ) , rule 7 ( 11 % , 100 % ) , rule I ( 9 % , 100 % ) and rule 3 ( 7.4 % , 100 % ) . </a>
<a name="38">[38]</a> <a href="#38" id=38>Indicating verbs If a verb is a member of the Verb_set = { discuss , present , illustrate , identify , summarize examine , describe , define , show , check , develop , review , reÂ­ port , outline , consider , investigate , explore , assess , analysis synthesis study , survey , deal , cover } , we consider the first NP following it as the preferred anÂ­ antecedent scores 1 and 0 ) . </a>
<a name="39">[39]</a> <a href="#39" id=39>Evaluation shows a success rate of 89.7 % for the genre of techÂ­ finical manuals and at least in this genre , the approach appears to be more successful than other similar methods . </a>
<a name="40">[40]</a> <a href="#40" id=40>Similarly to the evaluation for English , we comÂ­ pared the approach for Polish with ( i ) a Baseline Model which discounts candidates on the basis of agreement in number and gender and , if there were still competing candidates , selects as the antecedent the most recent subject matching the anaphora in gender and number ( ii ) a Baseline Model which checks agreement in number and gender and , if there were still more than one candidate left , picks up as the antecedent the most recent noun phrase that agrees with the anaphora . </a>
<a name="41">[41]</a> <a href="#41" id=41>The algorithm for pronoun resolution can be deÂ­ scribed informally as follows : 1 . </a>
<a name="42">[42]</a> <a href="#42" id=42>Our evaluaÂ­ son based on 63 examples ( anaphora from a techÂ­ finical manual ( Sony 1992 ) , indicates a success rate of 95.2 % ( and critical success rate 89.3 % ) . </a>
<a name="43">[43]</a> <a href="#43" id=43>The antecedent indicators have been identiÂ­ fie empirically and are related to salience ( definiteness , givenness , indicating verbs , lexical reiteration , section heading preference , `` nonÂ­ prepositional '' noun phrases ) , to structural matches ( collocation , immediate reference ) , to referential distance or to preference of terms . </a>
<a name="44">[44]</a> <a href="#44" id=44>Given that our approach is robust and returns anÂ­ antecedent for each pronoun , in order to make the comparison as fair as possible , we used CogNIAC 's `` resolve all '' version by simulating it manually on the same training data used in evaluation B above . </a>
<a name="45">[45]</a> <a href="#45" id=45>Lexical reiteration Lexically reiterated items are likely candidates for antecedent ( a NP scores 2 if is repeated within the same paragraph twice or more , 1 if repeated once and 0 if not ) . </a>
<a name="46">[46]</a> <a href="#46" id=46>The noun phrase with the highest aggregate score is proposed as antecedent ; in the rare event of a tie , priority is given to the candidate with the higher score for imÂ­ mediate reference . </a>
<a name="47">[47]</a> <a href="#47" id=47>The robust approach adapted for Polish demonstrated a high success rate of 93.3 % in resolvÂ­ ing anaphora with critical success rate of 86.2 % ) . </a>
<a name="48">[48]</a> <a href="#48" id=48>For this purpose we have drawn up a compreÂ­ tensive list of all such cases ; to our knowledge , no other computational treatment of pronominal anaphora resoluÂ­ son has addressed the problem of `` agreement excepÂ­ sons . </a>
<a name="49">[49]</a> <a href="#49" id=49>A case where the system failed was when the anaphora and the antecedent were in the same senÂ­ sentence and where preference was given to a candidate in the preceding sentence . </a>
<a name="50">[50]</a> <a href="#50" id=50>The resolution of anaphora was carried out with a sucÂ­ less rate of 95.8 % . </a>
<a name="51">[51]</a> <a href="#51" id=51>We used the robust approach as a basis for develÂ­ oping a genre-specific reference resolution approach in Polish . </a>
<a name="52">[52]</a> <a href="#52" id=52>The lack of syntactic information , for instance , means giving up c-cornmand constraints and subject preference ( or on other occasions object preference , see Mitkov I995 ) which could be used in center tracking . </a>
<a name="53">[53]</a> <a href="#53" id=53>Term preference NPs representing terms in the field are more likely to be the antecedent than NPs which are not terms ( score 1 if the NP is a term and 0 if not ) . </a>
<a name="54">[54]</a> <a href="#54" id=54>The approach being robust ( an attempt is made to resolve each anaphora and a proÂ­ posed antecedent is returned ) , this figure represents both `` precision '' and `` recall '' if we use the MUC terminology . </a>
<a name="55">[55]</a> <a href="#55" id=55>With a view to avoiding complex syntactic , semanÂ­ tic and discourse analysis ( which is vital for realÂ­ world applications ) , we developed a robust , knowlÂ­ edge-poor approach to pronoun resolution which does not parse and analysis the input in order to identify antecedents of anaphora . </a>
<a name="56">[56]</a> <a href="#56" id=56>Similarly to the first evaluation , we found that the robust approach was not very successful on senÂ­ sentences with too complicated syntax - a price we have to pay for the `` convenience '' of developing a knowlÂ­ edge-poor system . </a>
<a name="57">[57]</a> <a href="#57" id=57>Another reason for doing it by hand is to ensure a fair comparison with Breck Baldwin 's method , which not being available to us , had to be hand-simulated ( see 3.3 ) . </a>
<a name="58">[58]</a> <a href="#58" id=58>If we regard as `` discriminative power '' of each antecedent indicator the ratio `` number of successful antecedent identifications when this indicator was applied '' / '' number of applications of this indicator '' ( for the non-prepositional noun phrase and definiteÂ­ less being penalizing indicators , this figure is calcuÂ­ lated as the ratio `` number of unsuccessful anteceÂ­ dent identifications '' / '' number of applications '' ) , the immediate reference emerges as the most discrimiÂ­ native indicator ( 100 % ) , followed by nonÂ­ prepositional noun phrase ( 92.2 % ) , collocation ( 90.9 % ) , section heading ( 61.9 % ) , lexical reiteration ( 58.5 % ) , givenness ( 49.3 % ) , term preference ( 35.7 % ) and referential distance ( 34.4 % ) . </a>
<a name="59">[59]</a> <a href="#59" id=59>In terms of frequency of use ( `` number of nonzero applications '' / '' number of anaphora ) , the most freÂ­ frequently used indicator proved to be referential disÂ­ stance used in 98.9 % of the cases , followed by term preference ( 97.8 % ) , givenness ( 83.3 % ) , lexical reitÂ­ ration 64.4 % ) , definiteness ( 40 % ) , section heading ( 37.8 % ) , immediate reference ( 31.1 % ) and collocaÂ­ son 11.1 % ) . </a>
<a name="60">[60]</a> <a href="#60" id=60>Our robust approach does not use these because it has no information about the syntactic structure of the sentence or about the synÂ­ tactic functionalism role of each individual word . </a>
<a name="61">[61]</a> <a href="#61" id=61>We regard a noun phrase as definite if the head noun is modified by a definite article , or by demonstrative or possesÂ­ give pronouns . </a>
<a name="62">[62]</a> <a href="#62" id=62>Typically , our preference-based model proved superior to both baseline models when the anteceÂ­ dent was neither the most recent subject nor the most recent noun phrase matching the anaphora in gender and number . </a>
<a name="63">[63]</a> <a href="#63" id=63>Also , a sequence of noun phrases with the same head counts as lexical reiteration ( e.g . `` toner bottle '' , `` bottle of toner '' , `` the bottle '' ) . </a>
<a name="64">[64]</a> <a href="#64" id=64>Top symptoms like `` lexical reiteration '' asÂ­ sign score `` 2 '' whereas `` non-prepositional '' noun phrases are given a negative score of `` -1 '' . </a>
<a name="65">[65]</a> <a href="#65" id=65>languages An attractive feature of any NLP approach would be its language `` universality '' . </a>
<a name="66">[66]</a> <a href="#66" id=66>Candidates are assigned a score ( -1 , 0 , 1 or 2 ) for each indicator ; the candidate with the highest aggregate score is proposed as the anteÂ­ cement . </a>
<a name="67">[67]</a> <a href="#67" id=67>From this example we can also see that our knowledge-poor approach successfully tackles cases in which the anaphora and theÂ· antecedent have not only different syntactic functions but also different semantic roles . </a>
<a name="68">[68]</a> <a href="#68" id=68>Given that our knowledgeÂ­ poor approach is basically an enhancement of a baseline model through a set of antecedent indicaÂ­ tors , we see a dramatic improvement in performance ( 95.8 % ) when these preferences are called upon . </a>
<a name="69">[69]</a> <a href="#69" id=69>The evaluation for Polish was based technical manuals available on the Internet ( Internet Manual , 1994 ; Java Manual 1998 ) . </a>
<a name="70">[70]</a> <a href="#70" id=70>It would be fair to say that even though the results show superiority of our approach on the training data used ( the genre of technical manuals ) , they can not be generalized automatically for other genres or unrestricted texts and for a more accurate picture , further extensive tests are necessary . </a>
<a name="71">[71]</a> <a href="#71" id=71>The aggregate score for `` the drawer '' is 7 ( definiteness 1 + givenness 0 + term preference 1 + indicating verbs I + lexical reiteration 0 + section heading 0 + collocation 0 + referential distance 2 + non-prepositional noun phrase 0 + immediate referÂ­ enc 2 = 7 ) , whereas aggregate score for the most recent matching noun phrase ( `` the lit paper port LED '' ) is 4 ( definiteness 1 + givenness 0 + term preference I + indicating verbs 0 + lexical reiteraÂ­ son 0 + section heading 0 + collocation 0 + referenÂ­ ital distance 2 + non-prepositional noun phrase 0 + immediate reference 0 = 4 ) . </a>
<a name="72">[72]</a> <a href="#72" id=72>As far as the typical failure cases are concerned , we anticipate the knowledge-poor approach to have difficulties with sentences which have a more comÂ­ lex syntactic structure . </a>
<a name="73">[73]</a> <a href="#73" id=73>For anaphora in simple sentences , noun phrases in the previous senÂ­ sentence are the best candidate for antecedent , followed by noun phrases situated 2 sentences further back and finally nouns 3 sentences further back { 1 , 0 , -1 ) . </a>
<a name="74">[74]</a> <a href="#74" id=74>For the time being , we are using the same score for Polish . </a></body>
</html>
