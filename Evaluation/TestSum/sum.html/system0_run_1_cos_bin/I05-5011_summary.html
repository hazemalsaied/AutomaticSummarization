<html>
<head><title>I05-5011_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Recently , this topic has been getting more attention , as is evident from the Paraphrase Workshops in 2003 and 2004 , driven by the needs of various NLP applications . </a>
<a name="1">[1]</a> <a href="#1" id=1>For example , we can easily imagine that the number of paraphrases for âA buys Bâ is enormous and it is not possible to create a comprehensive inventory by hand . </a>
<a name="2">[2]</a> <a href="#2" id=2>Automatic Paraphrase Discovery based on Context and Keywords between NE Pairs</a>
<a name="3">[3]</a> <a href="#3" id=3>Up to now , most IE researchers have been creating paraphrase knowledge ( or IE patterns ) by hand and for specific tasks . </a>
<a name="4">[4]</a> <a href="#4" id=4>In this paper , we will propose an unsupervised method to discover paraphrases from a large untagged corpus . </a>
<a name="5">[5]</a> <a href="#5" id=5>We realize the importance of paraphrase ; however , the major obstacle is the construction of paraphrase knowledge . </a>
<a name="6">[6]</a> <a href="#6" id=6>After tagging a large corpus with an automatic NE tagger , the method tries to find sets of paraphrases automatically without being given a seed phrase or any kinds of cue . </a>
<a name="7">[7]</a> <a href="#7" id=7>Also , we donate know how many such paraphrase sets are necessary to cover even some everyday things or events . </a>
<a name="8">[8]</a> <a href="#8" id=8>We agree with Sekine ( 2005 ) who claims that several different methods are required to discover a wider variety of paraphrases . </a>
<a name="9">[9]</a> <a href="#9" id=9>One of the difficulties in Natural Language Processing is the fact that there are many ways to express the same thing or event . </a>
<a name="10">[10]</a> <a href="#10" id=10>If the expression is a word or a short phrase ( like corporation and accompany , it is called a synonym . </a>
<a name="11">[11]</a> <a href="#11" id=11>As a later reï¬nement , Sekine ( 2005 ) makes a similar attempt at using distributional similarity over named entity pairs in order to produce a list of fully lexical phrasal paraphrases for specific concepts represented by keywords . </a>
<a name="12">[12]</a> <a href="#12" id=12>The basic strategy is , for a given pair of entity types , to start with some examples , like several famous book title and author pairs ; and find expressions which contains those names ; then using the found expressions , find more author and book title pairs . </a>
<a name="13">[13]</a> <a href="#13" id=13>There has been a lot of research on such lexical relations , along with the creation of resources such as WordNet . </a>
<a name="14">[14]</a> <a href="#14" id=14>We proposed an unsupervised method to discover paraphrases from a large untagged corpus . </a>
<a name="15">[15]</a> <a href="#15" id=15>We propose an unsupervised method to discover paraphrases from a large untagged corpus , without requiring any seed phrase or other cue . </a>
<a name="16">[16]</a> <a href="#16" id=16>If the expression is longer or complicated ( like âA buys Bâ and âAâs purchase of Bâ ) , it is called paraphrase i.e . a set of phrases which express the same thing or event . </a>
<a name="17">[17]</a> <a href="#17" id=17>However , those methods need initial seeds , so the relation between entities has to be known in advance . </a>
<a name="18">[18]</a> <a href="#18" id=18>For example , in Information Retrieval ( IR ) , we have to match a user query to the expressions in the desired documents , while in Question Answering ( QA ) , we have to find the answer to the user question even if the formulation of the answer in the document is different from the question . </a>
<a name="19">[19]</a> <a href="#19" id=19>Also , in Information Extraction ( IE ) , in which the system tries to extract elements of some events ( e.g . date and company names of a corporate merger event ) , several event instances from different news articles have to be aligned even if these are expressed differently . </a>
<a name="20">[20]</a> <a href="#20" id=20>Automatic paraphrase discovery is an important but challenging task . </a>
<a name="21">[21]</a> <a href="#21" id=21>The accuracy of the sets in representing paraphrase ranged from 73 % to 99 % , depending on the NE categories and set sizes ; the accuracy of the links for two evaluated domains was 73 % and 86 % . </a>
<a name="22">[22]</a> <a href="#22" id=22>So , there is a limitation that IE can only be performed for a predefined task , like discorporate or management . </a>
<a name="23">[23]</a> <a href="#23" id=23>In order to create an IE system for a new domain , one has to spend a long time to create the knowledge . </a>
<a name="24">[24]</a> <a href="#24" id=24>So , it is too costly to make IE technology âopen- domain or âon-demandâ like IR or QA . </a>
<a name="25">[25]</a> <a href="#25" id=25>We are focusing on phrases which have two Named Entities ( NEs ) , as those types of phrases are very important for IE applications . </a>
<a name="26">[26]</a> <a href="#26" id=26>2.1 Overview . </a>
<a name="27">[27]</a> <a href="#27" id=27>Before explaining our method in detail , we present a brief overview in this subsection . </a>
<a name="28">[28]</a> <a href="#28" id=28>First , from a large corpus , we extract all the NE instance pairs . </a>
<a name="29">[29]</a> <a href="#29" id=29>Here , an NE instance pair is any pair of NEs separated by at most 4 syntactic chunks ; for example , âIBM plans to acquire Lotusâ . </a>
<a name="30">[30]</a> <a href="#30" id=30>Here , the term frequency ( TF ) is the frequency of a word in the bag and the inverse term frequency ( ITF ) is the inverse of the log of the frequency in the entire corpus . </a>
<a name="31">[31]</a> <a href="#31" id=31>They contain about 200M words ( 25M , 110M , 40M and 19M words , respectively ) . </a>
<a name="32">[32]</a> <a href="#32" id=32>For each pair we also record the context , i.e . the phrase between the two NEs ( Step1 ) . </a>
<a name="33">[33]</a> <a href="#33" id=33>Next , for each pair of NE categories , we collect all the contexts and find the keywords which are topical for that NE category pair . </a>
<a name="34">[34]</a> <a href="#34" id=34>We use a simple TF/IDF method to measure the topicality of words . </a>
<a name="35">[35]</a> <a href="#35" id=35>Hereafter , each pair of NE categories will be called a domain ; e.g . the âCompany â Companyâ domain , which we will call CC- domain ( Step 2 ) . </a>
<a name="36">[36]</a> <a href="#36" id=36>For example , in Figure 3 , we can see that the phrases in the âbuyâ acquire and purchase sets are mostly paraphrases . </a>
<a name="37">[37]</a> <a href="#37" id=37>x EG , has agreed to be bought by H x EG , now owned by H x H to acquire EG x Hâs agreement to buys EG Three of those phrase are actually Paraphrase , but sometime there could be some noise ; such as the second phrase above . </a></body>
</html>
