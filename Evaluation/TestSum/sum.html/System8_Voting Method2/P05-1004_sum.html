<html>
<head><title>P05-1004_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</a>
<a name="1">[1]</a> <a href="#1" id=1>Ciaramita and Johnson (2003) present a tagger which uses synonym set glosses as annotated training examples.</a>
<a name="2">[2]</a> <a href="#2" id=2>Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</a>
<a name="3">[3]</a> <a href="#3" id=3>These problems demonstrate the need for automatic or semiautomatic methods for the creation and maintenance of lexical-semantic resources.</a>
<a name="4">[4]</a> <a href="#4" id=4>Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNETâs hierarchical structure to create many annotated training instances from the synset glosses.</a>
<a name="5">[5]</a> <a href="#5" id=5>Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNETâs hierarchical structure to create many annotated training instances from the synset glosses.</a>
<a name="6">[6]</a> <a href="#6" id=6>Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNETâs hierarchical structure to create many annotated training instances from the synset glosses.</a>
<a name="7">[7]</a> <a href="#7" id=7>There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</a>
<a name="8">[8]</a> <a href="#8" id=8>Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</a>
<a name="9">[9]</a> <a href="#9" id=9>The efficiency of the SEXTANT approach makes the extraction of contextual information from over 2 billion words of raw text feasible.</a>
<a name="10">[10]</a> <a href="#10" id=10>JACCARD and TTEST produced better quality synonyms than existing measures in the literature, so we use Curran and Moenâs configuration for our super- sense tagging experiments.</a>
<a name="11">[11]</a> <a href="#11" id=11>Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</a>
<a name="12">[12]</a> <a href="#12" id=12>Our implementation of SEXTANT uses a maximum entropy POS tagger designed to be very efficient, tagging at around 100 000 words per second (Curran and Clark, 2003), trained on the entire Penn Treebank (Marcus et al., 1994).</a>
<a name="13">[13]</a> <a href="#13" id=13>Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</a></body>
</html>
