<html>
<head><title>J96-3004_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="1">[1]</a> <a href="#1" id=1>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="2">[2]</a> <a href="#2" id=2>Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence , and picks the best segmentation from the set of possible segmentations using a probabilistic or costÂ­ based scoring mechanism . </a>
<a name="3">[3]</a> <a href="#3" id=3>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="4">[4]</a> <a href="#4" id=4>Indeed , as we shall show in Section 5 , even human judges differ when presented with the task of segmenting a text into words , so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures . </a>
<a name="5">[5]</a> <a href="#5" id=5>A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</a>
<a name="6">[6]</a> <a href="#6" id=6>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="7">[7]</a> <a href="#7" id=7>A Brief Introduction to the Chinese Writing System Most readers will undoubtedly be at least somewhat familiar with the nature of the Chinese writing system , but there are enough common misunderstandings that it is as well to spend a few paragraphs on properties of the Chinese script that will be relevant to topics discussed in this paper . </a>
<a name="8">[8]</a> <a href="#8" id=8>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="9">[9]</a> <a href="#9" id=9>Furthermore , even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus : as Fung and Wu ( 1994 ) have shown , one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented . </a>
<a name="10">[10]</a> <a href="#10" id=10>It has been shown for English ( Wang and Hirschberg 1992 ; Hirschberg 1993 ; Sproat 1994 , inter aria that grammatical part of speech provides useful information for these tasks . </a>
<a name="11">[11]</a> <a href="#11" id=11>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="12">[12]</a> <a href="#12" id=12>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="13">[13]</a> <a href="#13" id=13>We will evaluate various specific aspects of the segmentation , as well as the overall segmentation perÂ­ performance . </a>
<a name="14">[14]</a> <a href="#14" id=14>A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</a>
<a name="15">[15]</a> <a href="#15" id=15>The family name set is restricted : there are a few hundred single-hanzi family names , and about ten double-hanzi ones . </a>
<a name="16">[16]</a> <a href="#16" id=16>Lexical-knowledge-based approaches that include statistical information generally presume that one starts with all possible segmentations of a sentence , and picks the best segmentation from the set of possible segmentations using a probabilistic or costÂ­ based scoring mechanism . </a>
<a name="17">[17]</a> <a href="#17" id=17>Methods that allow multiple segmentations must provide criteria for choosing the best segmentation . </a>
<a name="18">[18]</a> <a href="#18" id=18>Raphael A ren 2 ' is a fairly uncontroversial case of a monograph word , and replica ( middle country ) 'China ' a fairly uncontroversial case of a diÂ­ grapheme word . </a>
<a name="19">[19]</a> <a href="#19" id=19>For eight judges , ranging k between 1 and 8 corresponded to a precision score range of 90 % to 30 % , meaning that there were relatively few words ( 30 % of those found by the automatic segmented on which all judges agreed , whereas most of the words found by the segmented such that one human judge agreed . </a>
<a name="20">[20]</a> <a href="#20" id=20>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="21">[21]</a> <a href="#21" id=21>In this paper we present a stochastic finite-state model wherein the basic workhorse is the weighted finite-state transducer . </a>
<a name="22">[22]</a> <a href="#22" id=22>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="23">[23]</a> <a href="#23" id=23>The average agreement among the human judges is .76 , and the average agreement between ST and the humans is .75 , or about 99 % of the inter human One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix , computing a classical metric multidimensional scaling ( Torgerson 1958 ; Becker , Chambers , Wilks 1988 ) on that disÂ­ stance matrix , and plotting the first two most significant dimensions . </a>
<a name="24">[24]</a> <a href="#24" id=24>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="25">[25]</a> <a href="#25" id=25>The average agreement among the human judges is .76 , and the average agreement between ST and the humans is .75 , or about 99 % of the inter human One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix , computing a classical metric multidimensional scaling ( Torgerson 1958 ; Becker , Chambers , Wilks 1988 ) on that disÂ­ stance matrix , and plotting the first two most significant dimensions . </a>
<a name="26">[26]</a> <a href="#26" id=26>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="27">[27]</a> <a href="#27" id=27>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="28">[28]</a> <a href="#28" id=28>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="29">[29]</a> <a href="#29" id=29>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="30">[30]</a> <a href="#30" id=30>The simplest approach involves scoring the various analyses by costs based on word frequency , and picking the lowest cost path ; variants of this approach have been described in Chang , Chen , and Chen ( 1991 ) and Chang and Chen ( 1993 ) . </a>
<a name="31">[31]</a> <a href="#31" id=31>In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . </a>
<a name="32">[32]</a> <a href="#32" id=32>The three solemnization definitions in this section are essentially descriptive restatements of the corresponding constructive solemnization procedures , which in turn are realizaÃÂ­ sons of the widely followed principle of maximum tokenization ( e.g. , Liu 1986 ; Liang 1986a , 1986b ; Wang 1989 ; Jie 1989 ; Wang , Su , and Mo 1990 ; Jie , Liu , and Liang 1991a , b ; Yeh and Lee 1991 ; Webster and Kit 1992 ; Chen and Liu 1992 ; Guo 1993 ; Wu and Su 1993 ; Nie , Jin , and Hannan 1994 ; Sproat et al . 1996 ; </a>
<a name="33">[33]</a> <a href="#33" id=33>The weighted finite-state transducer model developed by Sproat et al . </a>
<a name="34">[34]</a> <a href="#34" id=34>The weighted finite-state transducer model developed by Sproat et al . </a>
<a name="35">[35]</a> <a href="#35" id=35>While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching , they are apÃÂ­ apparently employed neither in Sproat et al . </a>
<a name="36">[36]</a> <a href="#36" id=36>While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching , they are apÃÂ­ apparently employed neither in Sproat et al . </a>
<a name="37">[37]</a> <a href="#37" id=37>The weighted finite-state transducer model developed by Sproat et al . </a>
<a name="38">[38]</a> <a href="#38" id=38>Purely statistical approaches have not been very popular , and so far as we are aware earlier work by Sproat and Shih ( 1990 ) is the only published instance of such an approach . </a>
<a name="39">[39]</a> <a href="#39" id=39>Purely statistical approaches have not been very popular , and so far as we are aware earlier work by Sproat and Shih ( 1990 ) is the only published instance of such an approach . </a>
<a name="40">[40]</a> <a href="#40" id=40>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="41">[41]</a> <a href="#41" id=41>The family name set is restricted : there are a few hundred single-hanzi family names , and about ten double-hanzi ones . </a>
<a name="42">[42]</a> <a href="#42" id=42>The family name set is restricted : there are a few hundred single-hanzi family names , and about ten double-hanzi ones . </a>
<a name="43">[43]</a> <a href="#43" id=43>4.4 Chinese Personal Names . </a>
<a name="44">[44]</a> <a href="#44" id=44>4.4 Chinese Personal Names . </a>
<a name="45">[45]</a> <a href="#45" id=45>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="46">[46]</a> <a href="#46" id=46>The family name set is restricted : there are a few hundred single-hanzi family names , and about ten double-hanzi ones . </a>
<a name="47">[47]</a> <a href="#47" id=47>This is in general very difficult , given the extremely free manner in which Chinese given names are formed , and given that in these cases we lack even a family name to give the model confidence that it is identifying a name . </a>
<a name="48">[48]</a> <a href="#48" id=48>The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words . </a>
<a name="49">[49]</a> <a href="#49" id=49>Raphael A ren 2 ' is a fairly uncontroversial case of a monograph word , and replica ( middle country ) 'China ' a fairly uncontroversial case of a diÂ­ grapheme word . </a>
<a name="50">[50]</a> <a href="#50" id=50>We will evaluate various specific aspects of the segmentation , as well as the overall segmentation perÂ­ performance . </a>
<a name="51">[51]</a> <a href="#51" id=51>A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</a>
<a name="52">[52]</a> <a href="#52" id=52>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="53">[53]</a> <a href="#53" id=53>The weighted finite-state transducer model developed by Sproat et al . </a>
<a name="54">[54]</a> <a href="#54" id=54>The weighted finite-state transducer model developed by Sproat et al . </a>
<a name="55">[55]</a> <a href="#55" id=55>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="56">[56]</a> <a href="#56" id=56>TIS systems in general need to do more than simply compute the . </a>
<a name="57">[57]</a> <a href="#57" id=57>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="58">[58]</a> <a href="#58" id=58>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="59">[59]</a> <a href="#59" id=59>The method just described segments dictionary words , but as noted in Section 1 , there are several classes of words that should be handled that are not found in a standard dictionary . </a>
<a name="60">[60]</a> <a href="#60" id=60>This is in general very difficult , given the extremely free manner in which Chinese given names are formed , and given that in these cases we lack even a family name to give the model confidence that it is identifying a name . </a>
<a name="61">[61]</a> <a href="#61" id=61>On a set of 11 sentence fragments-the A set-where they reported 100 % recall and precision for name identification , we had 73 % recall and 80 % precision . </a>
<a name="62">[62]</a> <a href="#62" id=62>We will evaluate various specific aspects of the segmentation , as well as the overall segmentation perÂ­ performance . </a>
<a name="63">[63]</a> <a href="#63" id=63>Indeed , as we shall show in Section 5 , even human judges differ when presented with the task of segmenting a text into words , so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures . </a>
<a name="64">[64]</a> <a href="#64" id=64>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="65">[65]</a> <a href="#65" id=65>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="66">[66]</a> <a href="#66" id=66>While the semantic aspect of radicals is by no means completely predictive , the semantic homogeneity of many classes is quite striking : for example 254 out of the 263 examples ( 97 % ) of the INSECT class listed by Wieger ( 1965 , 77376 ) denote crawling or invertebrate animals ; similarly 21 out of the 22 examples ( 95 % ) of the GHOST class ( page 808 ) denote ghosts or spirits . </a>
<a name="67">[67]</a> <a href="#67" id=67>Purely statistical approaches have not been very popular , and so far as we are aware earlier work by Sproat and Shih ( 1990 ) is the only published instance of such an approach . </a>
<a name="68">[68]</a> <a href="#68" id=68>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="69">[69]</a> <a href="#69" id=69>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="70">[70]</a> <a href="#70" id=70>A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</a>
<a name="71">[71]</a> <a href="#71" id=71>Raphael A ren 2 ' is a fairly uncontroversial case of a monograph word , and replica ( middle country ) 'China ' a fairly uncontroversial case of a diÂ­ grapheme word . </a>
<a name="72">[72]</a> <a href="#72" id=72>In this paper we present a stochastic finite-state model for segmenting Chinese text into words , both words found in a ( static ) lexicon as well as words derived via the above-mentioned productive processes . </a>
<a name="73">[73]</a> <a href="#73" id=73>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="74">[74]</a> <a href="#74" id=74>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="75">[75]</a> <a href="#75" id=75>In this paper we present a stochastic finite-state model for segmenting Chinese text into words , both words found in a ( static ) lexicon as well as words derived via the above-mentioned productive processes . </a>
<a name="76">[76]</a> <a href="#76" id=76>Purely statistical approaches have not been very popular , and so far as we are aware earlier work by Sproat and Shih ( 1990 ) is the only published instance of such an approach . </a>
<a name="77">[77]</a> <a href="#77" id=77>16 As one reviewer points out , one problem with the epigram model chosen here is that there is still a. tendency to pick a segmentation containing fewer words . </a>
<a name="78">[78]</a> <a href="#78" id=78>As we shall argue , the semantic class affiliation of a Hanni constitutes useful information in predicting its properties . </a>
<a name="79">[79]</a> <a href="#79" id=79>In this paper we present a stochastic finite-state model for segmenting Chinese text into words , both words found in a ( static ) lexicon as well as words derived via the above-mentioned productive processes . </a>
<a name="80">[80]</a> <a href="#80" id=80>There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . </a>
<a name="81">[81]</a> <a href="#81" id=81>Raphael A ren 2 ' is a fairly uncontroversial case of a monograph word , and replica ( middle country ) 'China ' a fairly uncontroversial case of a diÂ­ grapheme word . </a>
<a name="82">[82]</a> <a href="#82" id=82>Raphael A ren 2 ' is a fairly uncontroversial case of a monograph word , and replica ( middle country ) 'China ' a fairly uncontroversial case of a diÂ­ grapheme word . </a>
<a name="83">[83]</a> <a href="#83" id=83>In this way , the method reported on here will necessarily be similar to a greedy method , though of course not identical . </a>
<a name="84">[84]</a> <a href="#84" id=84>In this way , the method reported on here will necessarily be similar to a greedy method , though of course not identical . </a>
<a name="85">[85]</a> <a href="#85" id=85>In this way , the method reported on here will necessarily be similar to a greedy method , though of course not identical . </a>
<a name="86">[86]</a> <a href="#86" id=86>Let us notate the set of previously unseen , or novel , members of a category X as unseen ( X ) ; thus , novel members of the set of words derived in f , menO will be deÂ­ noted unseen ( f , ) . </a>
<a name="87">[87]</a> <a href="#87" id=87>The Chinese person-name model is a modified version of that described in Sproat et al . </a>
<a name="88">[88]</a> <a href="#88" id=88>This larger corpus was kindly provided to us by United Informatics Inc. , R.O.C . a set of initial estimates of the word frequencies. 9 In this re-estimation procedure only the entries in the base dictionary were used : in other words , derived words not in the base dictionary and personal and foreign names were not used . </a>
<a name="89">[89]</a> <a href="#89" id=89>In this paper we present a stochastic finite-state model for segmenting Chinese text into words , both words found in a ( static ) lexicon as well as words derived via the above-mentioned productive processes . </a>
<a name="90">[90]</a> <a href="#90" id=90>On a set of 11 sentence fragments-the A set-where they reported 100 % recall and precision for name identification , we had 73 % recall and 80 % precision . </a>
<a name="91">[91]</a> <a href="#91" id=91>orthographic words are thus only a starting point for further analysis and can only be regarded as a useful hint at the desired division of the sentence into words . </a>
<a name="92">[92]</a> <a href="#92" id=92>orthographic words are thus only a starting point for further analysis and can only be regarded as a useful hint at the desired division of the sentence into words . </a></body>
</html>
