<html>
<head><title>C00-2123_summary</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Word Re-ordering and DP-based Search in Statistical Machine Translation</a>
<a name="1">[1]</a> <a href="#1" id=1>Word Re-ordering and DP-based Search in Statistical Machine Translation</a>
<a name="2">[2]</a> <a href="#2" id=2>Word Re-ordering and DP-based Search in Statistical Machine Translation</a>
<a name="3">[3]</a> <a href="#3" id=3>We are given a source string fJ 1 = f1 : : : fj : : : fJ of length J , which is to be translated into a target string eI 1 = e1 : : : ei : : : eI of length I . Among all possible target strings , we will choose the string with the highest probability : ^eI 1 = arg max eI 1 fPr ( eI 1jfJ 1 ) g = arg max eI 1 fPr ( eI 1 ) Pr ( fJ 1 jeI 1 ) g : ( 1 ) The argyle operation denotes the search problem , i.e . the generation of the output sentence in the target language . </a>
<a name="4">[4]</a> <a href="#4" id=4>On average , 6 reference translations per automatic translation are available . </a>
<a name="5">[5]</a> <a href="#5" id=5>The computing time is given in terms of CPU time per sentence ( on a 450MHz PentiumIIIPC ) . </a>
<a name="6">[6]</a> <a href="#6" id=6>For each source word f , the list of its possible translations e is sorted according to p ( fje ) pun e ) , where pun e ) is the trigram probability of the English word e. It is suÃcient to consider only the best 50 words . </a>
<a name="7">[7]</a> <a href="#7" id=7>The sentence length probability p ( JjI ) is omitted without any loss in performance . </a>
<a name="8">[8]</a> <a href="#8" id=8>The sentence length probability p ( JjI ) is omitted without any loss in performance . </a>
<a name="9">[9]</a> <a href="#9" id=9>On average , 6 reference translations per automatic translation are available . </a>
<a name="10">[10]</a> <a href="#10" id=10>We show translation results for three approaches : the monotone search ( MonS ) , where no word reordering is allowed ( Tillmann , 1997 ) , the monotone search ( QmS ) as presented in this paper and the IBM style ( IbmS ) search as described in Section 3.2 . </a>
<a name="11">[11]</a> <a href="#11" id=11>We show translation results for three approaches : the monotone search ( MonS ) , where no word reordering is allowed ( Tillmann , 1997 ) , the monotone search ( QmS ) as presented in this paper and the IBM style ( IbmS ) search as described in Section 3.2 . </a>
<a name="12">[12]</a> <a href="#12" id=12>input : source string f1 : : : fj : : : fJ initialization for each cardinality c = 1 ; 2 ; ; J do for each pair ( C ; j ) , where j 2 C and jCj = c do for each target word e 2 E Qe0 ( e ; C ; j ) = p ( fj je ) max Ã ; e00 j02Cnfjg fp ( jjj 0 J ) p ( Ã ) pÃ ( eje 0 e00 ) Qe00 ( e0 ; C n fjg ; j0 ) g words fj in the input string of length J . For the final translation each source position is considered exactly once . </a>
<a name="13">[13]</a> <a href="#13" id=13>Word Re-ordering and DP-based Search in Statistical Machine Translation</a>
<a name="14">[14]</a> <a href="#14" id=14>The word joining is done on the basis of a likelihood criterion . </a>
<a name="15">[15]</a> <a href="#15" id=15>A procedural definition to restrict1In the approach described in ( Berger et al. , 1996 ) , a mor pathological analysis is carried out and word morphemes rather than full-form words are used during the search . </a>
<a name="16">[16]</a> <a href="#16" id=16>For a trigram language model , the partial hypotheses are of the form ( e0 ; e ; C ; j ) . </a>
<a name="17">[17]</a> <a href="#17" id=17>We show translation results for three approaches : the monotone search ( MonS ) , where no word reordering is allowed ( Tillmann , 1997 ) , the monotone search ( QmS ) as presented in this paper and the IBM style ( IbmS ) search as described in Section 3.2 . </a>
<a name="18">[18]</a> <a href="#18" id=18>An extended lexicon model is defined , and its likelihood is compared to a baseline lexicon model , which takes only single-word dependencies into account . </a>
<a name="19">[19]</a> <a href="#19" id=19>Word Re-ordering and DP-based Search in Statistical Machine Translation</a>
<a name="20">[20]</a> <a href="#20" id=20>An extended lexicon model is defined , and its likelihood is compared to a baseline lexicon model , which takes only single-word dependencies into account . </a>
<a name="21">[21]</a> <a href="#21" id=21>For each source word f , the list of its possible translations e is sorted according to p ( fje ) pun e ) , where pun e ) is the trigram probability of the English word e. It is suÃcient to consider only the best 50 words . </a>
<a name="22">[22]</a> <a href="#22" id=22>The complexity of the monotone search is O ( E3 J ( R2+LR ) ) . </a>
<a name="23">[23]</a> <a href="#23" id=23>We show translation results for three approaches : the monotone search ( MonS ) , where no word reordering is allowed ( Tillmann , 1997 ) , the monotone search ( QmS ) as presented in this paper and the IBM style ( IbmS ) search as described in Section 3.2 . </a>
<a name="24">[24]</a> <a href="#24" id=24>We show Translation results for three approaches : the monotone Search ( MonS ) , where no Word reordering is allowed ( Tillmann , 1997 ) , the monotone Search ( QmS ) as presented in this paper and the IBM Style ( IbmS ) Search as described in Section 3.2 . </a></body>
</html>
