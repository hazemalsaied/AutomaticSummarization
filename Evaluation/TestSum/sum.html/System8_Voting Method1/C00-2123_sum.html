<html>
<head><title>C00-2123_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</a>
<a name="1">[1]</a> <a href="#1" id=1>Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃcient search algorithm.</a>
<a name="2">[2]</a> <a href="#2" id=2>Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃcient search algorithm.</a>
<a name="3">[3]</a> <a href="#3" id=3>Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃcient search algorithm.</a>
<a name="4">[4]</a> <a href="#4" id=4>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="5">[5]</a> <a href="#5" id=5>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="6">[6]</a> <a href="#6" id=6>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="7">[7]</a> <a href="#7" id=7>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="8">[8]</a> <a href="#8" id=8>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="9">[9]</a> <a href="#9" id=9>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="10">[10]</a> <a href="#10" id=10>The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</a>
<a name="11">[11]</a> <a href="#11" id=11>This approach is compared to another reordering scheme presented in (Berger et al., 1996).</a>
<a name="12">[12]</a> <a href="#12" id=12>The alignment model uses two kinds of parameters alignment probabilities p(aj jajô1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajô1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</a>
<a name="13">[13]</a> <a href="#13" id=13>The alignment model uses two kinds of parameters alignment probabilities p(aj jajô1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajô1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</a>
<a name="14">[14]</a> <a href="#14" id=14>To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</a>
<a name="15">[15]</a> <a href="#15" id=15>To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</a>
<a name="16">[16]</a> <a href="#16" id=16>The baseline alignment model does not permit that a source word is aligned to two or more target words, e.g. for the translation direction from German toEnglish, the German compound noun 'Zahnarztter min' causes problems, because it must be translated by the two target words dentist's appointment.</a>
<a name="17">[17]</a> <a href="#17" id=17>The resulting algorithm has a complexity of O(n!).</a>
<a name="18">[18]</a> <a href="#18" id=18>The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</a>
<a name="19">[19]</a> <a href="#19" id=19>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a>
<a name="20">[20]</a> <a href="#20" id=20>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a>
<a name="21">[21]</a> <a href="#21" id=21>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a>
<a name="22">[22]</a> <a href="#22" id=22>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a>
<a name="23">[23]</a> <a href="#23" id=23>We show translation results for three approaches the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</a></body>
</html>
