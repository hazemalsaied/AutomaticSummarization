<html>
<head><title>P05-1053_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>Exploring Various Knowledge in Relation Extraction</a>
<a name="1">[1]</a> <a href="#1" id=1>Exploring Various Knowledge in Relation Extraction</a>
<a name="2">[2]</a> <a href="#2" id=2>Exploring Various Knowledge in Relation Extraction</a>
<a name="3">[3]</a> <a href="#3" id=3>Exploring Various Knowledge in Relation Extraction</a>
<a name="4">[4]</a> <a href="#4" id=4>Exploring Various Knowledge in Relation Extraction</a>
<a name="5">[5]</a> <a href="#5" id=5>This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</a>
<a name="6">[6]</a> <a href="#6" id=6>It also shows that our fea 1 In ACE (http//www.ldc.upenn.edu/Projects/ACE),.</a>
<a name="7">[7]</a> <a href="#7" id=7>The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</a>
<a name="8">[8]</a> <a href="#8" id=8>The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</a>
<a name="9">[9]</a> <a href="#9" id=9>The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</a>
<a name="10">[10]</a> <a href="#10" id=10>The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</a>
<a name="11">[11]</a> <a href="#11" id=11>Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</a>
<a name="12">[12]</a> <a href="#12" id=12>Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.</a>
<a name="13">[13]</a> <a href="#13" id=13>Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.</a>
<a name="14">[14]</a> <a href="#14" id=14>Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</a>
<a name="15">[15]</a> <a href="#15" id=15>Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</a>
<a name="16">[16]</a> <a href="#16" id=16>Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</a>
<a name="17">[17]</a> <a href="#17" id=17>Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</a>
<a name="18">[18]</a> <a href="#18" id=18>It achieves 52.8 F- measure on the 24 ACE relation subtypes.</a>
<a name="19">[19]</a> <a href="#19" id=19>It achieves 52.8 F- measure on the 24 ACE relation subtypes.</a>
<a name="20">[20]</a> <a href="#20" id=20>Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</a>
<a name="21">[21]</a> <a href="#21" id=21>Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</a>
<a name="22">[22]</a> <a href="#22" id=22>Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</a>
<a name="23">[23]</a> <a href="#23" id=23>Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</a>
<a name="24">[24]</a> <a href="#24" id=24>Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</a>
<a name="25">[25]</a> <a href="#25" id=25>Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.</a>
<a name="26">[26]</a> <a href="#26" id=26>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="27">[27]</a> <a href="#27" id=27>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="28">[28]</a> <a href="#28" id=28>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="29">[29]</a> <a href="#29" id=29>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="30">[30]</a> <a href="#30" id=30>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="31">[31]</a> <a href="#31" id=31>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="32">[32]</a> <a href="#32" id=32>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="33">[33]</a> <a href="#33" id=33>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="34">[34]</a> <a href="#34" id=34>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="35">[35]</a> <a href="#35" id=35>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="36">[36]</a> <a href="#36" id=36>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="37">[37]</a> <a href="#37" id=37>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="38">[38]</a> <a href="#38" id=38>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="39">[39]</a> <a href="#39" id=39>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="40">[40]</a> <a href="#40" id=40>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="41">[41]</a> <a href="#41" id=41>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="42">[42]</a> <a href="#42" id=42>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="43">[43]</a> <a href="#43" id=43>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="44">[44]</a> <a href="#44" id=44>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="45">[45]</a> <a href="#45" id=45>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="46">[46]</a> <a href="#46" id=46>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="47">[47]</a> <a href="#47" id=47>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="48">[48]</a> <a href="#48" id=48>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="49">[49]</a> <a href="#49" id=49>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="50">[50]</a> <a href="#50" id=50>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="51">[51]</a> <a href="#51" id=51>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="52">[52]</a> <a href="#52" id=52>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="53">[53]</a> <a href="#53" id=53>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="54">[54]</a> <a href="#54" id=54>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="55">[55]</a> <a href="#55" id=55>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="56">[56]</a> <a href="#56" id=56>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="57">[57]</a> <a href="#57" id=57>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="58">[58]</a> <a href="#58" id=58>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="59">[59]</a> <a href="#59" id=59>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="60">[60]</a> <a href="#60" id=60>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="61">[61]</a> <a href="#61" id=61>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="62">[62]</a> <a href="#62" id=62>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="63">[63]</a> <a href="#63" id=63>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="64">[64]</a> <a href="#64" id=64>Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</a>
<a name="65">[65]</a> <a href="#65" id=65>Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.</a>
<a name="66">[66]</a> <a href="#66" id=66>Yet further research work is still expected to make it effective with complicated relation extraction tasks such as the one defined in ACE.</a>
<a name="67">[67]</a> <a href="#67" id=67>Compared with Kambhatla (2004), we separately incorporate the base phrase chunking information, which contributes to most of the performance improvement from syntactic aspect.</a>
<a name="68">[68]</a> <a href="#68" id=68>We also show how semantic information like WordNet and Name List can be equipped to further improve the performance.</a>
<a name="69">[69]</a> <a href="#69" id=69>Therefore, we must extend SVMs to multi-class (e.g. K) such as the ACE RDC task.</a>
<a name="70">[70]</a> <a href="#70" id=70>For each pair of mentions3, we compute various lexical, syntactic and semantic features.</a>
<a name="71">[71]</a> <a href="#71" id=71>For each pair of mentions3, we compute various lexical, syntactic and semantic features.</a>
<a name="72">[72]</a> <a href="#72" id=72>This feature concerns about the entity type of both the mentions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GeoPolitical Entity or GPE â¢ ET12 combination of mention entity types 4.3 Mention Level.</a>
<a name="73">[73]</a> <a href="#73" id=73>In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.</a>
<a name="74">[74]</a> <a href="#74" id=74>In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.</a>
<a name="75">[75]</a> <a href="#75" id=75>â¢ Chunking features are very useful.</a>
<a name="76">[76]</a> <a href="#76" id=76>This is largely due to incorporation of two semantic resources, i.e. the country name list and the personal relative trigger word list.</a>
<a name="77">[77]</a> <a href="#77" id=77>It also shows that feature-based methods dramatically outperform kernel methods.</a>
<a name="78">[78]</a> <a href="#78" id=78>The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.</a></body>
</html>
