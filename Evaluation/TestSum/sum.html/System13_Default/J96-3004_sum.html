<html>
<head><title>J96-3004_sum</title> </head>
<body bgcolor="white">
<a name="0">[0]</a> <a href="#0" id=0>2 Chinese ?l* han4zi4 'Chinese character'; this is the same word as Japanese kanji..</a>
<a name="1">[1]</a> <a href="#1" id=1>Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</a>
<a name="2">[2]</a> <a href="#2" id=2>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="3">[3]</a> <a href="#3" id=3>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="4">[4]</a> <a href="#4" id=4>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="5">[5]</a> <a href="#5" id=5>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="6">[6]</a> <a href="#6" id=6>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="7">[7]</a> <a href="#7" id=7>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="8">[8]</a> <a href="#8" id=8>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="9">[9]</a> <a href="#9" id=9>There are thus some very good reasons why segmentation into words is an important task.</a>
<a name="10">[10]</a> <a href="#10" id=10>Morphologically derived words such as, xue2shengl+men0.</a>
<a name="11">[11]</a> <a href="#11" id=11>Personal names such as 00, 3R; zhoulenl-lai2 'Zhou Enlai.'</a>
<a name="12">[12]</a> <a href="#12" id=12>The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</a>
<a name="13">[13]</a> <a href="#13" id=13>Previous Work.</a>
<a name="14">[14]</a> <a href="#14" id=14>There is a sizable literature on Chinese word segmentation recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</a>
<a name="15">[15]</a> <a href="#15" id=15>Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</a>
<a name="16">[16]</a> <a href="#16" id=16>Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</a>
<a name="17">[17]</a> <a href="#17" id=17>(See Sproat and Shih 1995.)</a>
<a name="18">[18]</a> <a href="#18" id=18>The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</a>
<a name="19">[19]</a> <a href="#19" id=19>(1991}, Gu and Mao (1994), and Nie, Jin, and Hannan (1994).</a>
<a name="20">[20]</a> <a href="#20" id=20>The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</a>
<a name="21">[21]</a> <a href="#21" id=21>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="22">[22]</a> <a href="#22" id=22>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="23">[23]</a> <a href="#23" id=23>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="24">[24]</a> <a href="#24" id=24>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="25">[25]</a> <a href="#25" id=25>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="26">[26]</a> <a href="#26" id=26>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="27">[27]</a> <a href="#27" id=27>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="28">[28]</a> <a href="#28" id=28>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="29">[29]</a> <a href="#29" id=29>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="30">[30]</a> <a href="#30" id=30>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="31">[31]</a> <a href="#31" id=31>Chinese word segmentation can be viewed as a stochastic transduction problem.</a>
<a name="32">[32]</a> <a href="#32" id=32>More formally, we start by representing the dictionary D as a Weighted Finite State TransÃÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</a>
<a name="33">[33]</a> <a href="#33" id=33>Note also that the costs currently used in the system are actually string costs, rather than word costs.</a>
<a name="34">[34]</a> <a href="#34" id=34>We of course also fail to identify, by the methods just described, given names used without their associated family name.</a>
<a name="35">[35]</a> <a href="#35" id=35>Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</a>
<a name="36">[36]</a> <a href="#36" id=36>Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</a>
<a name="37">[37]</a> <a href="#37" id=37>Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</a>
<a name="38">[38]</a> <a href="#38" id=38>Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</a>
<a name="39">[39]</a> <a href="#39" id=39>Evaluation of the Segmentation as a Whole.</a>
<a name="40">[40]</a> <a href="#40" id=40>(See also Wu and Fung [1994].)</a>
<a name="41">[41]</a> <a href="#41" id=41>(See also Wu and Fung [1994].)</a>
<a name="42">[42]</a> <a href="#42" id=42>(See also Wu and Fung [1994].)</a>
<a name="43">[43]</a> <a href="#43" id=43>(See also Wu and Fung [1994].)</a>
<a name="44">[44]</a> <a href="#44" id=44>(See also Wu and Fung [1994].)</a>
<a name="45">[45]</a> <a href="#45" id=45>An anti-greedy algorithm, AG instead of the longest match, take the.</a>
<a name="46">[46]</a> <a href="#46" id=46>The result of this is shown in Figure 7.</a>
<a name="47">[47]</a> <a href="#47" id=47>This is to allow for fair comparison between the statistical method and GR, which is also purely dictionary-based.</a>
<a name="48">[48]</a> <a href="#48" id=48>Under this scheme, n human judges are asked independently to segment a text.</a>
<a name="49">[49]</a> <a href="#49" id=49>The performance was 80.99% recall and 61.83% precision.</a>
<a name="50">[50]</a> <a href="#50" id=50>The performance was 80.99% recall and 61.83% precision.</a>
<a name="51">[51]</a> <a href="#51" id=51>Examples are given in Table 4.</a>
<a name="52">[52]</a> <a href="#52" id=52>19 We note that it is not always clear in Wang, Li, and Chang's examples which segmented words.</a>
<a name="53">[53]</a> <a href="#53" id=53>constitute names, since we have only their segmentation, not the actual classification of the segmented words.</a>
<a name="54">[54]</a> <a href="#54" id=54>In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</a>
<a name="55">[55]</a> <a href="#55" id=55>In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</a>
<a name="56">[56]</a> <a href="#56" id=56>(For some recent corpus-based work on Chinese abbreviations, see Huang, Ahrens, and Chen [1993].)</a>
<a name="57">[57]</a> <a href="#57" id=57>We have argued that the proposed method performs well.</a>
<a name="58">[58]</a> <a href="#58" id=58>However, some caveats are in order in comparing this method (or any method) with other approaches to segÃÂ­ mentation reported in the literature.</a>
<a name="59">[59]</a> <a href="#59" id=59>For example, as Gan (1994) has noted, one can construct examples where the segmenÂ­ tation is locally ambiguous but can be determined on the basis of sentential or even discourse context.</a>
<a name="60">[60]</a> <a href="#60" id=60>In (1) the sequencema3lu4 cannot be resolved locally, but depends instead upon broader context; similarly in (2), the sequence tcai2neng2 cannot be resolved locally 1.</a>
<a name="61">[61]</a> <a href="#61" id=61>Consider first the examples in (2).</a>
<a name="62">[62]</a> <a href="#62" id=62>Consider first the examples in (2).</a>
<a name="63">[63]</a> <a href="#63" id=63>Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.</a>
<a name="64">[64]</a> <a href="#64" id=64>The model described here thus demonstrates great potential for use in widespread applications.</a>
<a name="65">[65]</a> <a href="#65" id=65>The model described here thus demonstrates great potential for use in widespread applications.</a>
<a name="66">[66]</a> <a href="#66" id=66>Chang of Tsinghua University, Taiwan, R.O.C., for kindly providing us with the name corpora.</a></body>
</html>
