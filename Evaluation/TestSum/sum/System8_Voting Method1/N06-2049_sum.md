Subword-based Tagging by Conditional Random Fields for Chinese Word Segmentation
We proposed two approaches to improve Chinese word segmentation a subword-based tagging and a confidence measure approach.
We proposed two approaches to improve Chinese word segmentation a subword-based tagging and a confidence measure approach.
We found the former achieved better performance than the existing character-based tagging, and the latter improved segmentation further by combining the former with a dictionary-based segmentation.
By these techniques we achieved higher F-scores in CITYU, PKU and MSR corpora than the best results from Sighan Bakeoff 2005.
The character-based âIOBâ tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).
The character-based âIOBâ tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).
The character-based âIOBâ tagging approach has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).
In this work we propose a subword-based IOB tagging, which assigns tags to a predefined lexicon subset consisting of the most frequent multiple-character words in addition to single Chinese characters.
In this work we propose a subword-based IOB tagging, which assigns tags to a predefined lexicon subset consisting of the most frequent multiple-character words in addition to single Chinese characters.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.
In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al., 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.
It is composed of three parts a dictionary-based N-gram word segmentation for segmenting IV words, a subword- based tagging by the CRF for recognizing OOVs, and a confidence-dependent word segmentation used for merging the results of both the dictionary-based and the IOB tagging.
First, we extracted a word list from the training data sorted in decreasing order by their counts in the training 193 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 193â196, New York, June 2006.
First, we extracted a word list from the training data sorted in decreasing order by their counts in the training 193 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 193â196, New York, June 2006.
Qc 2006 Association for Computational Linguistics input åã£á¯¹Ô£à³¼à£«Òá +XDQJ<LQJ&KXQ OLYHV LQ %HLMLQJFLW\ Dictionary-based word segmentation å ã£ á¯¹ Ô£ à³¼ à£«Òá +XDQJ <LQJ &KXQ OLYHV LQ %HLMLQJFLW\ Subword-based IOB tagging å/% ã£/, á¯¹/, Ô£/2 à³¼/2 à£«Ò/% á/, +XDQJ/% <LQJ/, &KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, Confidence-based segmentation å/% ã£/, á¯¹/, Ô£/2 à³¼/2 à£«Ò/% á/, +XDQJ/% <LQJ/, &KXQ/, OLYHV/2 LQ/2 %HLMLQJ/% FLW\/, output åã£á¯¹ Ô£ à³¼ à£«Òá +XDQJ<LQJ&KXQ OLYHV LQ %HLMLQJFLW\ Figure 1 Outline of word segmentation process data.
We used the data provided by Sighan Bakeoff 2005 to test our approaches described in the previous sections.
The segmentation results using CRF tagging are shown in Table 2, where the upper numbers of each slot were produced by the character-based approach while the lower numbers were of the subword-based.
95 1 Table 4 Comparison our results with the best ones from Sighan Bakeoff 2005 in terms of F-score ivs than Table 2.
Later, this approach was implemented by the CRF-based method (Peng and McCallum, 2004), which was proved to achieve better results than the maximum entropy approach because it can solve the label bias problem (Lafferty et al., 2001).