As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
Church and Hanks [ 1989 ] ) , and we have used lists of character pairs ranked by mutual information to expand our own dictionary . 
In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . 
For novel texts , no lexicon that consists simply of a list of word entries will ever be entirely satisfactory , since the list will inevitably omit many constructions that should be considered words . 
A related point is that mutual information is helpful in augmenting existing electronic dictionaries , ( cf . 
A related point is that mutual information is helpful in augmenting existing electronic dictionaries , ( cf . 
All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria 
All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria 
Furthermore , even the size of the dictionary per se is less important than the appropriateness of the lexicon to a particular test corpus : as Fung and Wu ( 1994 ) have shown , one can obtain substantially better segmentation by tailoring the lexicon to the corpus to be segmented . 
It has been shown for English ( Wang and Hirschberg 1992 ; Hirschberg 1993 ; Sproat 1994 , inter aria that grammatical part of speech provides useful information for these tasks . 
In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . 
Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . 
4.2 A Sample Segmentation Using Only Dictionary Words Figure 4 shows two possible paths from the lattice of possible analyses of the input sentence B X : Â¥ . : .S : P : l 'How do you say octopus in Japanese ? ' previously shown in Figure 1 . 
2 Chinese ? l* han 4zi 4 character ' ; this is the same word as Japanese Kania 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
( See Sproat and Shih 1995 . ) 
The method just described segments dictionary words , but as noted in Section 1 , there are several classes of words that should be handled that are not found in a standard dictionary . 
The cost is computed as follows , where N is the corpus size and f is the frequency : ( 1 ) Besides actual words from the base dictionary , the lexicon contains all Hanni in the Big 5 Chinese code with their pronunciation ( s ) , plus entries for other characters that can be found in Chinese text , such as Roman letters , numerals , and special symbols . 
Purely statistical approaches have not been very popular , and so far as we are aware earlier work by Sproat and Shih ( 1990 ) is the only published instance of such an approach . 
While size of the resulting transducers may seem daunting-the segmented described here , as it is used in the Bell Labs Mandarin TTS system has about 32,000 states and 209,000 arcs-recent work on minimization of weighted machines and transducers ( cf . 
( See Sproat and Shih 1995 . ) 
The average agreement among the human judges is .76 , and the average agreement between ST and the humans is .75 , or about 99 % of the inter human One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix , computing a classical metric multidimensional scaling ( Torgerson 1958 ; Becker , Chambers , Wilks 1988 ) on that disÂ­ stance matrix , and plotting the first two most significant dimensions . 
In ( 1 ) the sequencema 3lu 4 can not be resolved locally , but depends instead upon broader context ; similarly in ( 2 ) , the sequence : : : tcai2neng2 can not be resolved locally : 1 . 
In ( 1 ) the sequencema 3lu 4 can not be resolved locally , but depends instead upon broader context ; similarly in ( 2 ) , the sequence : : : tcai2neng2 can not be resolved locally : 1 . 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
( See Sproat and Shih 1995 . ) 
Unfortunately , there is no standard corpus of Chinese texts , tagged with either single or multiple human judgments , with which one can compare performance of various methods . 
com Â§Cambridge , UK Email : nc201 eng.cam.ac.uk 1996 Association for Computational Linguistics ( a ) B ) ( , : & ; ? ' H o w d o y o u s a y o c t o p u s i n J a p a n e s e ? ' ( b ) P l a u s i b l e S e g m e n t a t i o n I B X I I 1 : & I 0 0 r i 4 w e n 2 z h a n g l y u 2 z e n 3 m e 0 s h u o l ' J a p a n e s e ' ' o c t o p u s ' ' h o w ' ' s a y ' ( c ) Figure 1 I m p l a u s i b l e S e g m e n t a t i o n [ Â§ ] lxI 1 : & I ri4 wen 2 yu2zen3 shuttle ' essay fish how say A Chinese sentence in ( a ) illustrating the lack of word boundaries . 
In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . 
Word type N % Dic son entries 2 , 5 4 3 9 7 . 4 7 Mor pho log call y derived wor ds 3 0 . 1 1 Fore ign ran rat ons 9 0 . 3 4 Per son al na mes 5 4 2 . 0 7 cases . 
Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . 
Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . 
The model we use provides a simple framework in which to incorporate a wide variety of lexical information in a uniform way . 
The model we use provides a simple framework in which to incorporate a wide variety of lexical information in a uniform way . 
Furthermore , by inverting the transducer so that it maps from phonemic transcriptions to Hanni sequences , one can apply the segmented to other problems , such as speech recognition ( Pereira , Riley , and Sproat 1994 ) . 
( See Sproat and Shih 1995 . ) 
( See Sproat and Shih 1995 . ) 
( See Sproat and Shih 1995 . ) 
( See Sproat and Shih 1995 . ) 
( See Sproat and Shih 1995 . ) 
As a first step towards modeling transliterated names , we have collected all Hanni occurring more than once in the roughly 750 foreign names in our dictionary , and we estimate the probabilÂ­ ity of occurrence of each Hanni in a transliteration ( pTN ( Hanni ; ) ) using the maximum likelihood estimate . 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria 
For a sequence of Hanni that is a possible name , we wish to assign a probability to that sequence qua name . 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
In this paper we present a stochastic finite-state model for segmenting Chinese text into words , both words found in a ( static ) lexicon as well as words derived via the above-mentioned productive processes . 
Nonetheless , the results of the comparison with human judges demonstrates that there is mileage being gained by incorporating models of these types of words . 
There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . 
( See Sproat and Shih 1995 . ) 
Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . 
Since the transducers are built from human-readable descriptions using a lexical toolkit ( Sproat 1995 ) , the system is easily maintained and extended . 
( See Sproat and Shih 1995 . ) 
Other strategies could readily 6 As a reviewer has pointed out , it should be made clear that the function for computing the best path is . an instance of the Viterbi algorithm . 
All notions of word , with the exception of the orthographic word , are as relevant in Chinese as they are in English , and just as is the case in other languages , a word in Chinese may correspond to one or more symbols in the orthographic 1 For a related approach to the problem of word-segrnention in Japanese , see Nagata ( 1994 ) , inter aria 
In this way , the method reported on here will necessarily be similar to a greedy method , though of course not identical . 
G1 and G2 are Hanni we can estimate the probability of the sequence being a name as the product of : â¢ the probability that a word chosen randomly from a text will be a name-p ( rule 1 ) , and â¢ the probability that the name is of the form 1hanzi-family 2hanzi-given-p ( rule 2 ) , and â¢ the probability that the family name is the particular Hanni ( rule 6 ) , and â¢ the probability that the given name consists of the particular Hanni and G2-p ( rule 9 ) This model is essentially the one proposed in Chang et al . 
Other kinds of productive word classes , such as company names , abbreviations ( termed fijsuolxie3 in Mandarin ) , and place names can easily be 20 Note that 7 in E 7 is normally pronounced as leO , but as part of a resultant it is liao 3.. 
Affix Pron Base category N found N missed ( recall ) N correct ( precision ) t , -,7 The second issue is that rare family names can be responsible for over generation especially if these names are otherwise common as single-hanzi words . 
As described in Sproat ( 1995 ) , the Chinese segmented presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis . 
including Third Tone Sandhi ( Shih 1986 ) , which changes a 3 ( low ) tone into a 2 ( rising ) tone before another 3 tone : 'j '' ; gil , xiao 3 lao 3 ] little rat , ' becomes xiao 3 lao2shu3 , rather than xiao 2 lao2shu3 , because the rule first applies within the word lao3shu3 , ' blocking its phrasal application . 
In various dialects of Mandarin certain phonetic rules apply at the word . 
In various dialects of Mandarin certain phonetic rules apply at the word . 
For that application , at a minimum , one would want to know the phonological word boundaries . 
( See Sproat and Shih 1995 . ) 
( See Sproat and Shih 1995 . ) 
including Third Tone Sandhi ( Shih 1986 ) , which changes a 3 ( low ) tone into a 2 ( rising ) tone before another 3 tone : 'j '' ; gil , xiao 3 lao 3 ] little rat , ' becomes xiao 3 lao2shu3 , rather than xiao 2 lao2shu3 , because the rule first applies within the word lao3shu3 , ' blocking its phrasal application . 
More formally , we start by representing the dictionary D as a Weighted Finite State TransÂ­ duce WFST ) ( Pereira , Riley , and Sproat 1994 ) . 
However , there will remain a large number of words that are not readily adduced to any producÂ­ tie pattern and that would simply have to be added to the dictionary . 
In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . 
As we have seen , the lexicon of basic words and stems is represented as a WFST ; most arcs in this WFST represent mappings between Hanni and pronunciations , and are costless . 
In Chinese text , individual characters of the script , to which we shall refer by their traditional name of Hanni Z are written one after another with no intervening spaces ; a Chinese sentence is shown in Figure 1.3 Partly as a result of this , the notion `` word '' has never played a role in Chinese philological tradition , and the idea that Chinese lacks anyÂ­ thing analogous to words in European languages has been prevalent among Western monologists see DeFrancis ( 1984 ) . 
Gan 's solution depends upon a fairly sophisticated language model that attempts to find valid syntactic , semantic , and lexical relations between objects of various linguistic types ( Hanni words , phrases ) . 
There are thus some very good reasons why segmentation into words is an important task . 
( See Sproat and Shih 1995 . ) 
There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . 
There are thus some very good reasons why segmentation into words is an important task . 
As noted , this sentence consists of four words , namely B X ri4wen2 , ' : Â¥ , zhanglyu 2 : & P : l zen 3me 0 , ' and IDt shuttle . ' 
As noted , this sentence consists of four words , namely B X ri4wen2 , ' : Â¥ , zhanglyu 2 : & P : l zen 3me 0 , ' and IDt shuttle . ' 
logical rules , and personal names ; the transitive closure of the resulting machine is then computed . 
( See Sproat and Shih 1995 . ) 
( See Sproat and Shih 1995 . ) 
One class comprises words derived by productive morphologiÂ­ cal processes , such as plural noun formation using the suffix ir , menD . 
( See Sproat and Shih 1995 . ) 
This larger corpus was kindly provided to us by United Informatics Inc. , R.O.C . a set of initial estimates of the word frequencies. 9 In this re-estimation procedure only the entries in the base dictionary were used : in other words , derived words not in the base dictionary and personal and foreign names were not used . 
There is a sizable literature on Chinese word segmentation : recent reviews include Wang , Su , and Mo ( 1990 ) and Wu and Tseng ( 1993 ) . 
There are thus some very good reasons why segmentation into words is an important task . 
There are thus some very good reasons why segmentation into words is an important task . 
There are thus some very good reasons why segmentation into words is an important task . 