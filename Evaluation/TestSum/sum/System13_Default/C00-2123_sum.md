A search restriction especially useful for the translation direction from German to English is presented.
The goal of machine translation is the translation of a text given in some source language into a target language.
The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).
The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).
The sentence length probability p(JjI) is omitted without any loss in performance.
The advantage is that we can recombine search hypotheses by dynamic programming.
The resulting algorithm is depicted in Table 1.
The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.
Restrictions We compare our new approach with the word reordering used in the IBM translation approach (Berger et al., 1996).
Restrictions We compare our new approach with the word reordering used in the IBM translation approach (Berger et al., 1996).
Here, we process only full-form words within the translation procedure.
The perplexity for the trigram language model used is 265.
This measure has the advantage of being completely automatic.
We apply a beam search concept as in speech recognition.
However there is no global pruning.
However there is no global pruning.
Table 4 shows translation results for the three approaches.
In the last example, the less restrictive IbmS word reordering leads to a better translation, although the QmS translation is still acceptable.
In this paper, we have presented a new, eÃÂcient DP-based search procedure for statistical machine translation.
3) A tight coupling with the speech recognizer output.