A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (Gildea and Jurafsky, 2002), selectional preferences (Resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (Dorr and Jones, 1996; Lapata and Brew, 1999; Merlo and Stevenson, 2001; Joanis and Stevenson, 2003).
We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.
Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).
Like others, we have assumed lexical semantic classes of verbs as defined in Levin (1993) (hereafter Levin), which have served as a gold standard in computational linguistics research (Dorr and Jones, 1996; Kipper et al., 2000; Merlo and Stevenson, 2001; Schulte im Walde and Brew, 2002).
Currently, our only such feature is an extension of the animacy feature of Merlo and Stevenson (2001).
Currently, our only such feature is an extension of the animacy feature of Merlo and Stevenson (2001).
Currently, our only such feature is an extension of the animacy feature of Merlo and Stevenson (2001).
Currently, our only such feature is an extension of the animacy feature of Merlo and Stevenson (2001).
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
4.2.1 Accuracy We can assign each cluster the class label of the majority of its members.
Then accuracy has the standard definition2 2 is equivalent to the weighted mean precision of the clusters, weighted according to cluster size.
However, it gives important information about the quality of a clustering The other measures being equal, a clustering with a higher value indicates tighter and more separated clusters, suggesting stronger inherent patterns in the data.
The 13-way task includes all of our classes.
Although generally higher than the baseline, is well below that of the supervised learner, and and are generally low.
Although generally higher than the baseline, is well below that of the supervised learner, and and are generally low.
Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.
We might also ask, would any subset of verbs do as well?
We have explored manual, unsupervised, and semi- supervised methods for feature selection in a clustering approach for verb class discovery.
Furthermore, we might question the clustering approach itself, in the context of verb class discovery.