We cluster verbs into lexical semantic classes, using a general set of noisy features that capture syntactic and semantic properties of the verbs.
The feature set was previously shown to work well in a supervised learning setting, using known English verb classes.
The feature set was previously shown to work well in a supervised learning setting, using known English verb classes.
The feature set was previously shown to work well in a supervised learning setting, using known English verb classes.
The feature set was previously shown to work well in a supervised learning setting, using known English verb classes.
We investigate various approaches to feature selection, using both unsupervised and semi-supervised methods, comparing the results to subsets of features manually chosen according to linguistic properties.
We find that the unsupervised method we tried cannot be consistently applied to our data.
Computational linguists face a lexical acquisition bottleneck, as vast amounts of knowledge about individual words are required for language technologies.
We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.
Such classes group together verbs that share both a common semantics (such as transfer of possession or change of state), and a set of syntactic frames for expressing the arguments of the verb (Levin, 1993; FrameNet, 2003).
Development of minimally supervised methods is of particular importance if we are to automatically classify verbs for languages other than English, where substantial amounts of labelled data are not available for training classifiers.
We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
Although our motivation is verb class discovery, we perform our experiments on English, for which we have an accepted classification to serve as a gold standard (Levin, 1993).
We then describe our clustering methodology, the measures we use to evaluate a clustering, and our experimental results.
We then describe our clustering methodology, the measures we use to evaluate a clustering, and our experimental results.
LevinÃá¸ÃÂÃÂs classes form a hierarchy of verb groupings with shared meaning and syntax.
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
We started with a list of all the verbs in the given classes from Levin, removing any verb that did not occur at least 100 times in our corpus (the BNC, described below).
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
Of these verbs, 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson (2003).
We used the hierarchical clustering command in Matlab, which implements bottom-up agglomerative clustering, for all our unsupervised experiments.
However, we did experiment with (as in Strehl et al., 2000), and found that performance was generally better (even on our measure, described below, that discounts oversplitting).
4.2.1 Accuracy We can assign each cluster the class label of the majority of its members.
These figures are reported with our results in Table 2 below.
4.2.2 Adjusted Rand Measure Accuracy can be relatively high for a clustering when a few clusters are very good, and others are not good.
We have explored manual, unsupervised, and semi- supervised methods for feature selection in a clustering approach for verb class discovery.