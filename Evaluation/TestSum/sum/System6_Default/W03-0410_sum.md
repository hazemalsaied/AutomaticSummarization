Semi-supervised Verb Class Discovery Using Noisy Features
 Semi-supervised Verb Class Discovery Using Noisy Features
 Semi-supervised Verb Class Discovery Using Noisy Features
 A number of supervised learning approaches have extracted such information about verbs from corpora, including their argument roles (Gildea and Jurafsky, 2002), selectional preferences (Resnik, 1996), and lexical semantic classification (i.e., grouping verbs according to their argument structure properties) (Dorr and Jones, 1996; Lapata and Brew, 1999; Merlo and Stevenson, 2001; Joanis and Stevenson, 2003).
 We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.
 We focus here on extending the applicability of unsupervised methods, as in (Schulte im Walde and Brew, 2002; Stevenson and Merlo, 1999), to the lexical semantic classification of verbs.
 It is also necessary to consider the probable lack of sophisticated grammars or text processing tools for extracting accurate features.
 It is also necessary to consider the probable lack of sophisticated grammars or text processing tools for extracting accurate features.
 We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
 We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
 We have previously shown that a broad set of 220 noisy features performs well in supervised verb classification (Joanis and Stevenson, 2003).
 Like others, we have assumed lexical semantic classes of verbs as defined in Levin (1993) (hereafter Levin), which have served as a gold standard in computational linguistics research (Dorr and Jones, 1996; Kipper et al., 2000; Merlo and Stevenson, 2001; Schulte im Walde and Brew, 2002).
 Like others, we have assumed lexical semantic classes of verbs as defined in Levin (1993) (hereafter Levin), which have served as a gold standard in computational linguistics research (Dorr and Jones, 1996; Kipper et al., 2000; Merlo and Stevenson, 2001; Schulte im Walde and Brew, 2002).
 We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
 We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
 We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson (2003) to enable a comparison between the performance of the unsupervised and supervised methods.
 *Jane of her money/the money from Jane.
 *Jane of her money/the money from Jane.
 *Jane of her money/the money from Jane.
 *Jane of her money/the money from Jane.
 *Jane of her money/the money from Jane.
 We started with a list of all the verbs in the given classes from Levin, removing any verb that did not occur at least 100 times in our corpus (the BNC, described below).
 To calculate a random baseline, we evaluated 10,000 random clusterings with the same number of verbs and classes as in each of our experimental tasks.
 Following Joanis and Stevenson (2003), for each class, we systematically identified the subset of features 4 These results differ slightly from those reported in Joanis and Stevenson (2003), because of our slight changes in verb sets, discussed in Section 3.2.
 Schulte im Walde and Brew (2002) and Schulte im Walde (2003), on the other hand, use a larger set of features intended to be useful for a broad number of classes, as in our work.
 We instead proposed a semi-supervised method in which a seed set of verbs is chosen for training a supervised classifier, from which the useful features are extracted for use in clustering.