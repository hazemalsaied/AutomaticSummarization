Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 Exploring Various Knowledge in Relation Extraction
 This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM.
 This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.
 This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.
 This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.
 This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).
 This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).
 This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).
 This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).
 The rest of this paper is organized as follows.
 Section 3 and Section 4 describe our approach and various features employed respectively.
 The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.
 Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.
 Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.
 Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.
 Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees.
 Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.
 Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.
 Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.
 Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.
 Zelenko et al (2003) proposed extracting relations by computing kernel functions between parse trees.
 Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.
 Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.
 Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
 Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
 Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
 Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
 Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.
 Zhang (2004) approached relation classification by combining various lexical and syntactic features with bootstrapping on top of Support Vector Machines.
 Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.
 Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.
 Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.
 Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.
 Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.
 Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.
 It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.
 It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.
 It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.
 It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.
 It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.
 It also shows that our system outperforms tree kernel-based systems (Culotta et al 2004) by over 20 F-measure on extracting 5 ACE relation types.
 Support Vector Machines (SVMs) are a supervised machine learning technique motivated by the statistical learning theory (Vapnik 1998).
 Therefore, we must extend SVMs to multi-class (e.g. K) such as the ACE RDC task.
 Therefore, we must extend SVMs to multi-class (e.g. K) such as the ACE RDC task.
 Therefore, we must extend SVMs to multi-class (e.g. K) such as the ACE RDC task.
 Therefore, we must extend SVMs to multi-class (e.g. K) such as the ACE RDC task.
 Moreover, we only apply the simple linear kernel, although other kernels can peform better.
 For details about SVMLight, please see http//svmlight.joachims.org/
 This is done by replacing the pronominal mention with the most recent non-pronominal antecedent when determining the word features, which include  WM1 bag-of-words in M1  HM1 head word of M1 3 In ACE, each mention has a head annotation and an.
 For example, in the case where the noun phrase the former CEO of McDonald has the head annotation of CEO and the extent annotation of the former CEO of McDonald, we only consider the former CEO in this paper.
 This feature concerns about the entity type of both the mentions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GeoPolitical Entity or GPE  ET12 combination of mention entity types 4.3 Mention Level.
 This feature concerns about the entity type of both the mentions, which can be PERSON, ORGANIZATION, FACILITY, LOCATION and GeoPolitical Entity or GPE  ET12 combination of mention entity types 4.3 Mention Level.
 In this paper, we separate the features of base phrase chunking from those of full parsing.
 In this paper, we separate the features of base phrase chunking from those of full parsing.
 Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships.
 In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.
 During development, 155 of 674 documents in the training set are set aside for fine-tuning the system.
 Table 1 lists the types and subtypes of relations for the ACE Relation Detection and Characterization (RDC) task, along with their frequency of occurrence in the ACE training set.
 It also shows that the ACE RDC task defines some difficult sub- types such as the subtypes Based-In, Located and Residence under the type AT, which are difficult even for human experts to differentiate.
 It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.
  Entity type features are very useful and improve the F-measure by 8.1 largely due to the recall increase.
  The usefulness of mention level features is quite limited.
 This may be due to the fact that most of relations in the ACE corpus are quite local.
  Incorporating semantic resources such as the country name list and the personal relative trigger word list further increases the F-measure by 1.5 largely due to the differentiation of the relation subtype ROLE.Citizen-Of from ROLE.
 Table 4 separately measures the performance of different relation types and major subtypes.
 This is largely due to incorporation of two semantic resources, i.e. the country name list and the personal relative trigger word list.
 The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.
 The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.
 The tree kernels developed in Culotta et al (2004) are yet to be effective on the ACE RDC task.
 This may be due to three reasons First, most of relations defined in ACE have two mentions being close to each other.
 In the future work, we will focus on exploring more semantic knowledge in relation extraction, which has not been covered by current research.