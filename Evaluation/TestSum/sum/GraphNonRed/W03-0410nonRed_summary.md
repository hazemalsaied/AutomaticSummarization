Like others , we have assumed lexical semantic classes of verbs as defined in Levin ( 1993 ) ( hereafter Levin ) , which have served as a gold standard in computational linguistics research ( Dorr and Jones , 1996 ; Kipper et al. , 2000 ; Merlo and Stevenson , 2001 ; Schulte im Walde and Brew , 2002 ) . 
A number of supervised learning approaches have extracted such information about verbs from corpora , including their argument roles ( Gildea and Jurafsky , 2002 ) , selectional preferences ( Resnik , 1996 ) , and lexical semantic classification ( i.e. , grouping verbs according to their argument structure properties ) ( Dorr and Jones , 1996 ; Lapata and Brew , 1999 ; Merlo and Stevenson , 2001 ; Joanis and Stevenson , 2003 ) . 
In this paper , we report results on several feature selection approaches to the problem : manual selection ( based on linguistic knowledge ) , unsupervised selection ( based on an entropy measure among the features , Dash et al. , 1997 ) , and a semi- supervised approach ( in which seed verbs are used to train a supervised learner , from which we extract the useful features ) . 
Our second measure , the adjusted Rand measure used by Schulte im Walde ( 2003 ) , instead gives a measure of how consistent the given clustering is overall with respect to the gold standard classification . 
However , Schulte im Waldeâs features rely on accurate categorization statistics , and her experiments include a much larger set of classes ( around 40 ) , each with a much smaller number of verbs ( average around 4 ) . 
Of these verbs , 20 from each class were randomly selected to use as training data for our supervised experiments in Joanis and Stevenson ( 2003 ) . 
However , a general feature space means that most features will be irrelevant to any given verb discrimination task . 
In other ways , however , it is too difficult : the learner has to distinguish multiple classes , rather than focus on the important properties of a single class . 
However , in many aspects of computational linguistics , it has been found that a small amount of labeled data contains sufficient information to allow us to go beyond the limits of completely unsupervised approaches . 
Here we briefly describe the features that comprise our feature space , and refer the interested reader to Joanis and Stevenson ( 2003 ) for details . 
These figures are reported with our results in Table 2 below . 
Currently , our only such feature is an extension of the animate feature of Merlo and Stevenson ( 2001 ) . 
Rather than trying to separate a set of new verbs into coherent clusters , we suggest that it may be useful to perform a nearest-neighbour type of classification using a seed set , asking for each new verb âis it like these or not ? â In some ways our current clustering task is too easy , because all of the verbs are from one of the target classes . 
We use the same classes and example verbs as in the supervised experiments of Joanis and Stevenson ( 2003 ) to enable a comparison between the performance of the unsupervised and supervised methods . 
Although our motivation is verb class discovery , we perform our experiments on English , for which we have an accepted classification to serve as a gold standard ( Levin , 1993 ) . 
Spray/Load versus Fill versus Other Verbs of Putting ( several related Levin classes ) . 
3.1 The Verb Classes . 
Unsupervised or semi-supervised approaches have been successful as well , but have tended to be more restrictive , in relying on human filtering of the results ( Riloff and Schmelzenbach , 1998 ) , on the hand- selection of features ( Stevenson and Merlo , 1999 ) , or on the use of an extensive grammar ( Schulte im Walde and Brew , 2002 ) . 
The formula is as follows ( Hubert and Arabie , 1985 ) : where is the entry in the contingency table between the classification and the clustering , counting the size of the intersection of class and cluster . Intuitively , measures the similarity of two partitions of data by considering agreements and disagreements between them there is agreement , for example , if and from the same class are in the same cluster , and disagreement if they are not . 
Pairs or triples of verb classes from Levin were selected to form the test triples for each of a number of separate classification tasks . 
Development of minimally supervised methods is of particular importance if we are to automatically classify verbs for languages other than English , where substantial amounts of labeled data are not available for training classifiers . 
The boy played./The boy played soccer.These three classes are all optionally intransitive but as sign different semantic roles to their arguments ( Merlo and Stevenson , 2001 ) . 
For many tasks , knowing exactly what PP arguments each verb takes may be sufficient to perform the classification ( cf . 
In an unsupervised ( clustering ) scenario of verb class discovery , can we maintain the benefit of only needing noisy features , without the generality of the feature space leading to âthe curse of dimensionality 
In contrast to Merlo and Stevenson ( 2001 ) , we confirmed that a set of general features can be successfully used , without the need for manually determining the relevant features for distinguishing particular classes ( cf . 
We calculated the MI of each feature with respect to the classification of the seed verbs , and computed clusterings using the features above a certain MI threshold . 
In the remainder of the paper , we first briefly review our feature space and present our experimental classes and verbs . 
In performing hierarchical clustering , both a vector distance measure and a cluster distance ( linkage measure are specified . 
Tense , Voice , and Aspect Features ( 24 features ) Verb meaning , and therefore class membership , interacts in interesting ways with voice , tense , and aspect ( Levin , 1993 ; Merlo and Stevenson , 2001 ) . 
Schultz Walde and Brew ( 2002 ) and Schultz Walde ( 2003 ) , on the other hand , use a larger sets of features intended to be useful for a broad numbers of Class , as ins our work . 